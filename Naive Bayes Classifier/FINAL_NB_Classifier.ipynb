{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt9a0B1HEYtm"
   },
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mOQWAKskEYtw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWmsooicpPuu",
    "outputId": "a46f6844-9257-43d3-ee6b-b1042fa59c5e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V_Zz5V1KqtAc"
   },
   "outputs": [],
   "source": [
    "# pathdir = \"/content/drive/MyDrive/Colab Notebooks/ML Assignment\"\n",
    "pathdir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y15ymp-PEYt0"
   },
   "source": [
    "### txt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lLf4t7QVEYt1"
   },
   "outputs": [],
   "source": [
    "# file = open(pathdir + '/dataset_NB.txt','r')    # opening .txt file\n",
    "# dataset = file.readlines()    # reads text file and returns a list containing each line in the file as a list item\n",
    "# dataset[-1] = dataset[-1]+'\\n'\n",
    "# print(len(dataset))\n",
    "# print(dataset)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Pc04q6a1EYt3"
   },
   "outputs": [],
   "source": [
    "# text = []\n",
    "# spam = []\n",
    "# for data in dataset:\n",
    "#     text.append(data[:-2].rstrip())    # appending mail text to list\n",
    "#     spam.append(data[-2])              # appending spam label to list\n",
    "# print(text)\n",
    "# print(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZmMfvhDzEYt5"
   },
   "outputs": [],
   "source": [
    "# dictionary = {\n",
    "#     'mail':text,\n",
    "#     'spam':spam\n",
    "# }\n",
    "# df = pd.DataFrame(dictionary)    # convert dict to pandas dataframe\n",
    "# df.to_csv(pathdir + '/dataset_NB.csv',index=False)    # saving dataframe as .csv file\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSRkKfq3EYt6"
   },
   "outputs": [],
   "source": [
    "# print(len(dataset))\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWj_Wp54EYt8"
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "YYp1EpjjEYt9",
    "outputId": "4d27ee02-6d0e-40ef-ab51-6e305478c33b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mail  spam\n",
       "0    So there is no way for me to plug it in here i...     0\n",
       "1                          Good case, Excellent value.     1\n",
       "2                               Great for the jawbone.     1\n",
       "3    Tied to charger for conversations lasting more...     0\n",
       "4                                    The mic is great.     1\n",
       "..                                                 ...   ...\n",
       "995  The screen does get smudged easily because it ...     0\n",
       "996  What a piece of junk.. I lose more calls on th...     0\n",
       "997                       Item Does Not Match Picture.     0\n",
       "998  The only thing that disappoint me is the infra...     0\n",
       "999  You can not answer calls with the unit, never ...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(pathdir+'/dataset_NB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYCzgOHIEYuD",
    "outputId": "69ef7ec1-bd63-41d2-bc46-a1d3dfd7e5cb"
   },
   "outputs": [],
   "source": [
    "# checking text saved in csv\n",
    "# print(df.mail[0] + '||')\n",
    "# print(df['mail'][0])\n",
    "# print(df.iloc[0,0])\n",
    "# print(df.loc[0,'mail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZq3RfK-EYuG"
   },
   "source": [
    "### Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wRYrOYGEYuH",
    "outputId": "72a15998-dede-4177-efe5-09298bf8e8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels in given data\n",
      "1    500\n",
      "0    500\n",
      "Name: spam, dtype: int64\n",
      "Total number of words: 10246\n",
      "Total distinct words: 2514\n",
      "Top frequent words:-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 513,\n",
       " 'i': 313,\n",
       " 'and': 310,\n",
       " 'is': 238,\n",
       " 'it': 237,\n",
       " 'a': 217,\n",
       " 'this': 197,\n",
       " 'to': 195,\n",
       " 'my': 143,\n",
       " 'for': 119,\n",
       " 'of': 119,\n",
       " 'phone': 118,\n",
       " 'not': 115,\n",
       " 'with': 107,\n",
       " 'very': 102,\n",
       " 'was': 90,\n",
       " 'in': 87,\n",
       " 'on': 87,\n",
       " 'that': 75,\n",
       " 'have': 72,\n",
       " 'good': 66,\n",
       " 'great': 63,\n",
       " 'you': 62,\n",
       " 'as': 45,\n",
       " 'but': 45,\n",
       " 'works': 43,\n",
       " 'had': 43,\n",
       " 'so': 42,\n",
       " 'are': 41,\n",
       " 'battery': 39,\n",
       " 'sound': 35,\n",
       " 'one': 34,\n",
       " 'has': 34,\n",
       " 'all': 34,\n",
       " 'quality': 33,\n",
       " 'from': 33,\n",
       " 'phone.': 33,\n",
       " 'would': 32,\n",
       " 'your': 32,\n",
       " 'headset': 32,\n",
       " 'it.': 31,\n",
       " 'like': 30,\n",
       " 'if': 29,\n",
       " 'than': 28,\n",
       " \"i've\": 28,\n",
       " \"don't\": 28,\n",
       " 'use': 27,\n",
       " \"it's\": 27,\n",
       " 'product': 27,\n",
       " 'after': 27,\n",
       " 'no': 26,\n",
       " 'be': 26,\n",
       " 'really': 26,\n",
       " 'at': 24,\n",
       " 'recommend': 24,\n",
       " '-': 24,\n",
       " 'or': 23,\n",
       " 'does': 23,\n",
       " 'work': 23,\n",
       " 'get': 22,\n",
       " 'when': 22,\n",
       " 'only': 22,\n",
       " \"i'm\": 22,\n",
       " 'excellent': 21,\n",
       " 'up': 21,\n",
       " 'product.': 21,\n",
       " 'just': 21,\n",
       " 'any': 20,\n",
       " 'out': 20,\n",
       " 'well': 20,\n",
       " 'love': 20,\n",
       " 'am': 20,\n",
       " 'me': 19,\n",
       " 'ear': 19,\n",
       " 'do': 19,\n",
       " 'best': 19,\n",
       " 'nice': 19,\n",
       " '2': 19,\n",
       " 'also': 19,\n",
       " 'an': 19,\n",
       " 'can': 18,\n",
       " 'about': 18,\n",
       " 'even': 18,\n",
       " 'these': 18,\n",
       " 'because': 18,\n",
       " 'worked': 18,\n",
       " 'better': 18,\n",
       " 'great.': 17,\n",
       " 'then': 17,\n",
       " 'bought': 17,\n",
       " 'new': 17,\n",
       " 'they': 17,\n",
       " 'what': 16,\n",
       " 'could': 16,\n",
       " \"doesn't\": 16,\n",
       " 'its': 16,\n",
       " 'car': 15,\n",
       " 'time': 15,\n",
       " 'first': 15,\n",
       " 'well.': 15,\n",
       " 'case': 15,\n",
       " 'bluetooth': 15,\n",
       " 'buy': 15,\n",
       " 'been': 15,\n",
       " 'easy': 15,\n",
       " 'charger': 14,\n",
       " 'comfortable': 14,\n",
       " 'too': 14,\n",
       " 'still': 14,\n",
       " 'happy': 14,\n",
       " 'few': 14,\n",
       " 'which': 14,\n",
       " 'will': 14,\n",
       " 'more': 13,\n",
       " 'waste': 13,\n",
       " 'two': 13,\n",
       " 'now': 13,\n",
       " 'quality.': 13,\n",
       " 'reception': 13,\n",
       " 'got': 13,\n",
       " 'did': 13,\n",
       " 'while': 13,\n",
       " 'same': 13,\n",
       " 'worst': 13,\n",
       " 'ever': 13,\n",
       " 'there': 12,\n",
       " 'hear': 12,\n",
       " 'make': 12,\n",
       " 'enough': 12,\n",
       " 'price': 12,\n",
       " 'item': 12,\n",
       " 'much': 12,\n",
       " 'thing': 12,\n",
       " 'ear.': 12,\n",
       " 'piece': 12,\n",
       " 'cell': 12,\n",
       " 'used': 12,\n",
       " 'service.': 12,\n",
       " 'plug': 11,\n",
       " 'headset.': 11,\n",
       " 'makes': 11,\n",
       " 'other': 11,\n",
       " 'use.': 11,\n",
       " 'fits': 11,\n",
       " 'bad': 11,\n",
       " 'charge': 11,\n",
       " 'into': 10,\n",
       " 'long': 10,\n",
       " 'think': 10,\n",
       " 'people': 10,\n",
       " 'made': 10,\n",
       " 'motorola': 10,\n",
       " 'using': 10,\n",
       " \"couldn't\": 10,\n",
       " 'price.': 10,\n",
       " 'over': 10,\n",
       " 'them': 9,\n",
       " 'highly': 9,\n",
       " 'how': 9,\n",
       " 'poor': 9,\n",
       " 'camera': 9,\n",
       " 'calls': 9,\n",
       " 'pretty': 9,\n",
       " 'problems': 9,\n",
       " 'looks': 9,\n",
       " 'device': 9,\n",
       " 'work.': 9,\n",
       " 'lot': 9,\n",
       " 'customer': 9,\n",
       " 'working': 9,\n",
       " 'by': 8,\n",
       " 'right': 8,\n",
       " 'money.': 8,\n",
       " 'impressed': 8,\n",
       " 'design': 8,\n",
       " 'without': 8,\n",
       " 'me.': 8,\n",
       " 'little': 8,\n",
       " 'never': 8,\n",
       " 'life': 8,\n",
       " 'clear': 8,\n",
       " 'their': 8,\n",
       " 'verizon': 8,\n",
       " 'everything': 8,\n",
       " 'off': 8,\n",
       " 'found': 8,\n",
       " 'purchase.': 8,\n",
       " 'jabra': 8,\n",
       " 'service': 8,\n",
       " 'voice': 8,\n",
       " 'screen': 8,\n",
       " 'being': 8,\n",
       " 'low': 8,\n",
       " 'way': 7,\n",
       " 'several': 7,\n",
       " 'money': 7,\n",
       " 'went': 7,\n",
       " 'most': 7,\n",
       " 'problem': 7,\n",
       " \"didn't\": 7,\n",
       " 'years': 7,\n",
       " 'we': 7,\n",
       " 'phones': 7,\n",
       " 'buttons': 7,\n",
       " 'last': 7,\n",
       " 'headsets': 7,\n",
       " 'wear': 7,\n",
       " 'gets': 7,\n",
       " 'tried': 7,\n",
       " 'both': 7,\n",
       " 'call': 7,\n",
       " 'case.': 7,\n",
       " 'completely': 7,\n",
       " 'software': 7,\n",
       " 'some': 7,\n",
       " 'look': 7,\n",
       " 'nokia': 7,\n",
       " 'quite': 7,\n",
       " 'take': 7,\n",
       " 'unit': 7,\n",
       " 'again': 7,\n",
       " 'volume': 7,\n",
       " 'however,': 7,\n",
       " 'go': 6,\n",
       " 'going': 6,\n",
       " 'far': 6,\n",
       " 'talk': 6,\n",
       " 'need': 6,\n",
       " 'fine': 6,\n",
       " 'want': 6,\n",
       " 'dropped': 6,\n",
       " 'since': 6,\n",
       " 'this.': 6,\n",
       " 'within': 6,\n",
       " 'down': 6,\n",
       " 'great,': 6,\n",
       " 'broke': 6,\n",
       " 'received': 6,\n",
       " 'black': 6,\n",
       " 'more.': 6,\n",
       " 'light': 6,\n",
       " 'product,': 6,\n",
       " 'small': 6,\n",
       " 'cheap': 6,\n",
       " 'less': 6,\n",
       " 'put': 6,\n",
       " 'every': 6,\n",
       " 'stay': 6,\n",
       " 'company': 6,\n",
       " 'time.': 6,\n",
       " 'real': 6,\n",
       " 'good.': 6,\n",
       " 'fit': 6,\n",
       " 'came': 6,\n",
       " 'difficult': 6,\n",
       " 'original': 5,\n",
       " 'started': 5,\n",
       " 'three': 5,\n",
       " 'days': 5,\n",
       " 'months': 5,\n",
       " 'say': 5,\n",
       " 'hold': 5,\n",
       " 'sure': 5,\n",
       " '3': 5,\n",
       " 'turn': 5,\n",
       " 'disappointed': 5,\n",
       " 'great!': 5,\n",
       " 'headphones': 5,\n",
       " 'find': 5,\n",
       " 'purchase': 5,\n",
       " 'different': 5,\n",
       " 'week': 5,\n",
       " 'it,': 5,\n",
       " 'feels': 5,\n",
       " 'item.': 5,\n",
       " 'arrived': 5,\n",
       " 'poor.': 5,\n",
       " 'definitely': 5,\n",
       " 'pictures': 5,\n",
       " 'cool': 5,\n",
       " 'fit.': 5,\n",
       " 'end': 5,\n",
       " 'around': 5,\n",
       " '&': 5,\n",
       " 'know': 5,\n",
       " 'kind': 5,\n",
       " 'where': 5,\n",
       " 'phone,': 5,\n",
       " 'ever.': 5,\n",
       " 'year': 5,\n",
       " 'important': 5,\n",
       " 'return': 5,\n",
       " 'cable': 5,\n",
       " 'many': 5,\n",
       " 'problem.': 5,\n",
       " 'amazon': 5,\n",
       " 'couple': 5,\n",
       " 'terrible': 5,\n",
       " 'looking': 5,\n",
       " 'having': 5,\n",
       " 'especially': 5,\n",
       " 'keep': 5,\n",
       " 'fine.': 5,\n",
       " 'hard': 5,\n",
       " 'always': 5,\n",
       " 'none': 5,\n",
       " 'cannot': 5,\n",
       " \"can't\": 5,\n",
       " 'here': 4,\n",
       " 'case,': 4,\n",
       " 'value.': 4,\n",
       " 'sending': 4,\n",
       " 'one.': 4,\n",
       " 'must': 4,\n",
       " 'were': 4,\n",
       " 'blue': 4,\n",
       " 'again.': 4,\n",
       " 'absolutely': 4,\n",
       " 'it!': 4,\n",
       " 'she': 4,\n",
       " 'had.': 4,\n",
       " 'simple': 4,\n",
       " 'ears': 4,\n",
       " 'left': 4,\n",
       " 'hate': 4,\n",
       " 'kept': 4,\n",
       " 'priced': 4,\n",
       " 'seems': 4,\n",
       " 'loud': 4,\n",
       " 'actually': 4,\n",
       " 'sturdy': 4,\n",
       " 'disappointed.': 4,\n",
       " 'big': 4,\n",
       " 'too.': 4,\n",
       " 'purchased': 4,\n",
       " 'holds': 4,\n",
       " 'time,': 4,\n",
       " 'them.': 4,\n",
       " 'expect': 4,\n",
       " 'order': 4,\n",
       " 'free': 4,\n",
       " 'high': 4,\n",
       " 'pleased': 4,\n",
       " 'job': 4,\n",
       " '5': 4,\n",
       " 'hours': 4,\n",
       " 'audio': 4,\n",
       " 'obviously': 4,\n",
       " 'device.': 4,\n",
       " 'before': 4,\n",
       " 'phone!.': 4,\n",
       " 'signal': 4,\n",
       " 'useless': 4,\n",
       " 'lasts': 4,\n",
       " 'part': 4,\n",
       " 'back.': 4,\n",
       " 'lightweight': 4,\n",
       " \"i'd\": 4,\n",
       " 'horrible': 4,\n",
       " 'far.': 4,\n",
       " 'worth': 4,\n",
       " 'hands': 4,\n",
       " 'junk.': 4,\n",
       " 'up.': 4,\n",
       " 'buying': 4,\n",
       " 'quickly': 4,\n",
       " 'old': 4,\n",
       " 'ear,': 4,\n",
       " 'data': 4,\n",
       " 'comes': 4,\n",
       " 'rather': 4,\n",
       " 'back': 4,\n",
       " 'anything': 4,\n",
       " 'charging': 4,\n",
       " 'unfortunately': 4,\n",
       " 'those': 4,\n",
       " 'own': 4,\n",
       " 'off.': 4,\n",
       " 'ringtones': 4,\n",
       " 'samsung': 4,\n",
       " 'treo': 4,\n",
       " 'extra': 4,\n",
       " 'connection': 4,\n",
       " 'mic': 3,\n",
       " 'volume.': 3,\n",
       " 'razr': 3,\n",
       " 'battery.': 3,\n",
       " 'who': 3,\n",
       " 'great!.': 3,\n",
       " 'pair': 3,\n",
       " 'below': 3,\n",
       " 'pocket': 3,\n",
       " 'instructions': 3,\n",
       " 'helpful': 3,\n",
       " 'use,': 3,\n",
       " 'performance.': 3,\n",
       " 'picture': 3,\n",
       " 'right.': 3,\n",
       " 'features': 3,\n",
       " 'made.': 3,\n",
       " 'protection': 3,\n",
       " 'keyboard': 3,\n",
       " '510': 3,\n",
       " 'cool.': 3,\n",
       " 'perhaps': 3,\n",
       " \"phone's\": 3,\n",
       " 'front': 3,\n",
       " 'later': 3,\n",
       " 'trouble': 3,\n",
       " ',': 3,\n",
       " 'longer': 3,\n",
       " 'ease': 3,\n",
       " 'dont': 3,\n",
       " 'plan': 3,\n",
       " 'decision.': 3,\n",
       " 'shipping': 3,\n",
       " 'match': 3,\n",
       " 'between': 3,\n",
       " 'camera,': 3,\n",
       " 'fall': 3,\n",
       " 'such': 3,\n",
       " 'wife': 3,\n",
       " 'leather': 3,\n",
       " 'fast': 3,\n",
       " 'may': 3,\n",
       " 'strong': 3,\n",
       " 'set': 3,\n",
       " 'bt': 3,\n",
       " 'getting': 3,\n",
       " 'almost': 3,\n",
       " 'avoid': 3,\n",
       " 'earbud': 3,\n",
       " 'coverage': 3,\n",
       " 'drops': 3,\n",
       " 'glad': 3,\n",
       " 'did.': 3,\n",
       " 'used.': 3,\n",
       " 'fantastic': 3,\n",
       " 'internet,': 3,\n",
       " 'clear,': 3,\n",
       " 'minutes': 3,\n",
       " 'replacement': 3,\n",
       " 'extremely': 3,\n",
       " 'is.': 3,\n",
       " 'simply': 3,\n",
       " 'color': 3,\n",
       " 'thought': 3,\n",
       " 'reasonably': 3,\n",
       " 'should': 3,\n",
       " 'form': 3,\n",
       " 'range': 3,\n",
       " 'able': 3,\n",
       " 'all,': 3,\n",
       " 'experience': 3,\n",
       " \"there's\": 3,\n",
       " 'ordered': 3,\n",
       " 'sony': 3,\n",
       " 'mistake': 3,\n",
       " 'new.': 3,\n",
       " 'internet': 3,\n",
       " 'probably': 3,\n",
       " 'earpiece.': 3,\n",
       " 'unreliable': 3,\n",
       " 'family.': 3,\n",
       " 'poorly': 3,\n",
       " 'charged': 3,\n",
       " 'excellent.': 3,\n",
       " 'scratched': 3,\n",
       " 'terrible.': 3,\n",
       " 'microphone': 3,\n",
       " 'care': 3,\n",
       " 'plugged': 3,\n",
       " 'disappointing.': 3,\n",
       " 'times': 3,\n",
       " 'life.': 3,\n",
       " 'wireless': 3,\n",
       " 'face': 3,\n",
       " 'awesome': 3,\n",
       " 'weak': 3,\n",
       " 'others': 3,\n",
       " 'trying': 3,\n",
       " 'wanted.': 3,\n",
       " 'deal.': 3,\n",
       " 'satisfied': 3,\n",
       " 'give': 3,\n",
       " 'plantronics': 3,\n",
       " 'goes': 3,\n",
       " 'dead': 3,\n",
       " 'plastic': 3,\n",
       " 'overall,': 3,\n",
       " 'another': 3,\n",
       " 'away': 3,\n",
       " 'clarity': 3,\n",
       " '1': 3,\n",
       " 'anyone.': 3,\n",
       " 'might': 3,\n",
       " \"wasn't\": 3,\n",
       " 'turned': 3,\n",
       " 'lg': 3,\n",
       " 'under': 3,\n",
       " 'feature': 3,\n",
       " 'price!': 3,\n",
       " 'ago': 3,\n",
       " 'noise': 3,\n",
       " 'given': 3,\n",
       " 'palm': 3,\n",
       " 'seller': 3,\n",
       " 'design.': 3,\n",
       " 'said': 3,\n",
       " 'through': 3,\n",
       " 'speaker': 3,\n",
       " 'with.': 3,\n",
       " 'feel': 3,\n",
       " 'day': 3,\n",
       " 'cases': 3,\n",
       " 'anyone': 3,\n",
       " 'pay': 3,\n",
       " '--': 3,\n",
       " 'sound.': 3,\n",
       " 'replace': 3,\n",
       " 'pairing': 3,\n",
       " 'despite': 3,\n",
       " 'easier': 3,\n",
       " 't-mobile': 3,\n",
       " 'cingular': 3,\n",
       " 'easily.': 3,\n",
       " 'beep': 3,\n",
       " 'lasting': 2,\n",
       " 'line': 2,\n",
       " 'decent': 2,\n",
       " 'say,': 2,\n",
       " 'wasted': 2,\n",
       " 'he': 2,\n",
       " 'extended': 2,\n",
       " 'notice': 2,\n",
       " 'static': 2,\n",
       " 'though': 2,\n",
       " 'all.': 2,\n",
       " 'tooth': 2,\n",
       " 'advise': 2,\n",
       " 'everyone': 2,\n",
       " 'place': 2,\n",
       " 'website': 2,\n",
       " 'fire': 2,\n",
       " 'yet': 2,\n",
       " 'run': 2,\n",
       " 'bars': 2,\n",
       " \"that's\": 2,\n",
       " 'pc': 2,\n",
       " 'mobile': 2,\n",
       " 'pull': 2,\n",
       " 'charge.': 2,\n",
       " 'unusable': 2,\n",
       " 'included': 2,\n",
       " 'least': 2,\n",
       " 'thats': 2,\n",
       " 'audio.': 2,\n",
       " 'regarding': 2,\n",
       " 'returned': 2,\n",
       " 'days.': 2,\n",
       " 'turns': 2,\n",
       " 'pda': 2,\n",
       " 'instead': 2,\n",
       " 'large': 2,\n",
       " 'seconds': 2,\n",
       " 'bad.': 2,\n",
       " 'essentially': 2,\n",
       " 'forget': 2,\n",
       " 'tech': 2,\n",
       " 'support.': 2,\n",
       " 'particular': 2,\n",
       " 'cover': 2,\n",
       " 'let': 2,\n",
       " 'lock': 2,\n",
       " 'glasses': 2,\n",
       " 'series': 2,\n",
       " 'docking': 2,\n",
       " 'station': 2,\n",
       " 'home': 2,\n",
       " 'beautiful': 2,\n",
       " 'bargain.': 2,\n",
       " '6': 2,\n",
       " 'loves': 2,\n",
       " 'construction': 2,\n",
       " 'costs': 2,\n",
       " 'does.': 2,\n",
       " 'play': 2,\n",
       " 'music': 2,\n",
       " 'big.': 2,\n",
       " '....': 2,\n",
       " 'charger.': 2,\n",
       " 'huge': 2,\n",
       " 'although': 2,\n",
       " 'impressive': 2,\n",
       " 'ask': 2,\n",
       " 'slim': 2,\n",
       " 'display': 2,\n",
       " 'sex': 2,\n",
       " 'rocks': 2,\n",
       " 'full': 2,\n",
       " 'number': 2,\n",
       " 'unhappy': 2,\n",
       " 'earpieces': 2,\n",
       " 'signal.': 2,\n",
       " 'basically': 2,\n",
       " 'weeks,': 2,\n",
       " 'packaged': 2,\n",
       " 'logitech': 2,\n",
       " 'failed.': 2,\n",
       " 'stuff': 2,\n",
       " 'house': 2,\n",
       " 'recognition': 2,\n",
       " 'during': 2,\n",
       " 'calls,': 2,\n",
       " 'experienced': 2,\n",
       " 'area': 2,\n",
       " 'takes': 2,\n",
       " 'forever': 2,\n",
       " 'stated': 2,\n",
       " 'description': 2,\n",
       " 'months,': 2,\n",
       " 'hoping': 2,\n",
       " 'blackberry': 2,\n",
       " 'sounds': 2,\n",
       " 'technology': 2,\n",
       " \"wouldn't\": 2,\n",
       " 'wired': 2,\n",
       " 'these.': 2,\n",
       " 'previous': 2,\n",
       " 'there.': 2,\n",
       " 'perfectly!': 2,\n",
       " 'w810i': 2,\n",
       " 'tool': 2,\n",
       " 'maintain': 2,\n",
       " 'sharp': 2,\n",
       " 'long.': 2,\n",
       " 'thank': 2,\n",
       " 'igo': 2,\n",
       " 'network.': 2,\n",
       " 'connected': 2,\n",
       " \"wife's\": 2,\n",
       " 'charm': 2,\n",
       " 'slow': 2,\n",
       " 'once': 2,\n",
       " 'storage': 2,\n",
       " 'buzzing': 2,\n",
       " 'override': 2,\n",
       " 'conversations,': 2,\n",
       " 'you!': 2,\n",
       " 'functionality': 2,\n",
       " 'awesome.': 2,\n",
       " '10': 2,\n",
       " 'ring': 2,\n",
       " 'thin': 2,\n",
       " 'call.': 2,\n",
       " 'headset,': 2,\n",
       " 'nearly': 2,\n",
       " 'bother': 2,\n",
       " 'room': 2,\n",
       " 'felt': 2,\n",
       " 'embarrassing': 2,\n",
       " 'expected': 2,\n",
       " 'consumer': 2,\n",
       " 'background': 2,\n",
       " 'before.': 2,\n",
       " 'certainly': 2,\n",
       " 'usually': 2,\n",
       " 'mess': 2,\n",
       " 'now,': 2,\n",
       " 'tell': 2,\n",
       " '$$$': 2,\n",
       " 'comfort': 2,\n",
       " 'excited': 2,\n",
       " 'disappointment': 2,\n",
       " 'additional': 2,\n",
       " 'gels': 2,\n",
       " 'provided,': 2,\n",
       " 'whatsoever.': 2,\n",
       " 'well,': 2,\n",
       " 'secure,': 2,\n",
       " 'appears': 2,\n",
       " 'smell': 2,\n",
       " 'caused': 2,\n",
       " 'month': 2,\n",
       " 'flawlessly': 2,\n",
       " 'either.': 2,\n",
       " 'drain': 2,\n",
       " 'stars': 2,\n",
       " 'helpful.': 2,\n",
       " 'whole': 2,\n",
       " 'battery,': 2,\n",
       " 'uncomfortable': 2,\n",
       " 'gotten': 2,\n",
       " 'dialing': 2,\n",
       " 'cant': 2,\n",
       " 'best,': 2,\n",
       " 'neither': 2,\n",
       " 'sucks.': 2,\n",
       " 'comfortable.': 2,\n",
       " 'comfortably': 2,\n",
       " 'either': 2,\n",
       " 'ipod': 2,\n",
       " '(you': 2,\n",
       " 'recharge': 2,\n",
       " 'flip': 2,\n",
       " 'belt,': 2,\n",
       " 'lost': 2,\n",
       " 'also,': 2,\n",
       " 'save': 2,\n",
       " 'light,': 2,\n",
       " \"i'll\": 2,\n",
       " 'starts': 2,\n",
       " 'ringing': 2,\n",
       " 'reason.': 2,\n",
       " 'player.': 2,\n",
       " 'try': 2,\n",
       " 'push': 2,\n",
       " 'sides.': 2,\n",
       " 'skype': 2,\n",
       " 'handsfree': 2,\n",
       " 'finally': 2,\n",
       " 'market': 2,\n",
       " 'shipped': 2,\n",
       " 'exactly': 2,\n",
       " '!': 2,\n",
       " 'stupid': 2,\n",
       " 'chargers,': 2,\n",
       " 'buy.': 2,\n",
       " 'noticed': 2,\n",
       " 'jawbone': 2,\n",
       " 'too!': 2,\n",
       " 'talk.': 2,\n",
       " 'breaks': 2,\n",
       " 'clip.': 2,\n",
       " 'reception.': 2,\n",
       " 'easy.': 2,\n",
       " 'warning': 2,\n",
       " 'dying.': 2,\n",
       " 'moto': 2,\n",
       " 'nothing': 2,\n",
       " '20': 2,\n",
       " 'reading': 2,\n",
       " 'wearing': 2,\n",
       " 'perfectly.': 2,\n",
       " 'clarity.': 2,\n",
       " 'returning': 2,\n",
       " 'switch': 2,\n",
       " 'problems.': 2,\n",
       " 'understand': 2,\n",
       " 'batteries': 2,\n",
       " 'user': 2,\n",
       " 'ability': 2,\n",
       " 'receiving': 2,\n",
       " 'exchanged': 2,\n",
       " 'super': 2,\n",
       " 'wrong': 2,\n",
       " 'described.': 2,\n",
       " 'now.': 2,\n",
       " 'im': 2,\n",
       " 'star': 2,\n",
       " 'nothing.': 2,\n",
       " 'holster': 2,\n",
       " 'review': 2,\n",
       " 'not.': 2,\n",
       " 'amazed': 2,\n",
       " 'timeframe,': 2,\n",
       " 'complaint': 2,\n",
       " 'things': 2,\n",
       " 'ended': 2,\n",
       " 'store': 2,\n",
       " 'horrible,': 2,\n",
       " 'refund': 2,\n",
       " 'accidentally': 2,\n",
       " 'took': 2,\n",
       " 'above': 2,\n",
       " 'looking,': 2,\n",
       " 'setup': 2,\n",
       " 'eargels': 2,\n",
       " 'seem': 2,\n",
       " 'numerous': 2,\n",
       " 'happier': 2,\n",
       " 'would.': 2,\n",
       " 'side': 2,\n",
       " 'quality,': 2,\n",
       " 'sound,': 2,\n",
       " 'please': 2,\n",
       " 'barely': 2,\n",
       " 'forced': 2,\n",
       " 'charger,': 2,\n",
       " 'support': 2,\n",
       " 'calls.': 2,\n",
       " 'holding': 2,\n",
       " 'sprint': 2,\n",
       " 'cheap.': 2,\n",
       " 'belt': 2,\n",
       " 'operate': 2,\n",
       " 'paired': 2,\n",
       " 'usb': 2,\n",
       " 'come': 2,\n",
       " 'plus,': 2,\n",
       " 'red': 2,\n",
       " 'reviews': 2,\n",
       " 'disappointing': 2,\n",
       " 'awful': 2,\n",
       " 'tinny': 2,\n",
       " 'echo': 2,\n",
       " 'expensive': 2,\n",
       " 'told': 2,\n",
       " 'that,': 2,\n",
       " 'placed': 2,\n",
       " 'spring': 2,\n",
       " 'fine,': 2,\n",
       " 'tries': 2,\n",
       " 'download': 2,\n",
       " 'picture,': 2,\n",
       " 'access': 2,\n",
       " 'third': 2,\n",
       " 'work,': 2,\n",
       " 'flash': 2,\n",
       " 'awful.': 2,\n",
       " 'tones': 2,\n",
       " 'chinese': 2,\n",
       " 'cell.': 2,\n",
       " 'crisp': 2,\n",
       " 'is,': 2,\n",
       " 'video': 2,\n",
       " 'accept': 2,\n",
       " 'allows': 2,\n",
       " 'iphone': 2,\n",
       " 'power': 2,\n",
       " 'wall': 2,\n",
       " 'car,': 2,\n",
       " 'outlet.': 2,\n",
       " 'hand.': 2,\n",
       " 'cut': 2,\n",
       " 'sizes': 2,\n",
       " 'ears.': 2,\n",
       " 'next': 2,\n",
       " 'weeks': 2,\n",
       " 'worked.': 2,\n",
       " 'sounded': 2,\n",
       " 'feet': 2,\n",
       " 'easily': 2,\n",
       " 'send': 2,\n",
       " 'amazon.': 2,\n",
       " 'says': 2,\n",
       " 'far,': 2,\n",
       " 'laptop': 2,\n",
       " 'inside.': 2,\n",
       " 'normal': 2,\n",
       " 'making': 2,\n",
       " 'lose': 2,\n",
       " 'break': 2,\n",
       " 'cases.': 2,\n",
       " 'computer': 2,\n",
       " 'us': 1,\n",
       " 'unless': 1,\n",
       " 'converter.': 1,\n",
       " 'jawbone.': 1,\n",
       " 'tied': 1,\n",
       " 'conversations': 1,\n",
       " '45': 1,\n",
       " 'minutes.major': 1,\n",
       " 'problems!!': 1,\n",
       " 'jiggle': 1,\n",
       " 'dozen': 1,\n",
       " 'hundred': 1,\n",
       " 'contacts,': 1,\n",
       " 'imagine': 1,\n",
       " 'fun': 1,\n",
       " 'each': 1,\n",
       " 'owner...you': 1,\n",
       " 'this!': 1,\n",
       " 'needless': 1,\n",
       " 'time!.': 1,\n",
       " 'seperated': 1,\n",
       " 'mere': 1,\n",
       " '5+': 1,\n",
       " 'ft': 1,\n",
       " 'excessive': 1,\n",
       " 'garbled': 1,\n",
       " 'odd,': 1,\n",
       " '\"clip\"': 1,\n",
       " 'fooled!': 1,\n",
       " 'good!.': 1,\n",
       " 'clicks': 1,\n",
       " 'wonder': 1,\n",
       " 'mechanism': 1,\n",
       " 'last.': 1,\n",
       " \"motorola's\": 1,\n",
       " 'followed': 1,\n",
       " 'directions,': 1,\n",
       " 'kindle': 1,\n",
       " 'loved': 1,\n",
       " 'commercials': 1,\n",
       " 'misleading.': 1,\n",
       " 'charging.': 1,\n",
       " 'mother': 1,\n",
       " '/': 1,\n",
       " 'combination.': 1,\n",
       " 'owned': 1,\n",
       " '7': 1,\n",
       " 'provided': 1,\n",
       " 'couldnt': 1,\n",
       " 'earphone': 1,\n",
       " 'breakage': 1,\n",
       " 'unacceptible.': 1,\n",
       " 'ideal': 1,\n",
       " 'whose': 1,\n",
       " 'sensitive.': 1,\n",
       " 'moving': 1,\n",
       " 'freeway': 1,\n",
       " 'speed.': 1,\n",
       " 'contract': 1,\n",
       " 'ac': 1,\n",
       " 'juice.highy': 1,\n",
       " 'recommended': 1,\n",
       " 'mins': 1,\n",
       " 'book': 1,\n",
       " 'phone.battery': 1,\n",
       " 'short.': 1,\n",
       " '680.': 1,\n",
       " 'worthless': 1,\n",
       " '2mp,': 1,\n",
       " 'pics': 1,\n",
       " 'garbage': 1,\n",
       " 'mind': 1,\n",
       " 'gonna': 1,\n",
       " 'battery?.': 1,\n",
       " 'arguing': 1,\n",
       " 'should.': 1,\n",
       " 'bulky.': 1,\n",
       " 'usable': 1,\n",
       " 'real-world': 1,\n",
       " 'useful': 1,\n",
       " 'machine': 1,\n",
       " 'neat': 1,\n",
       " 'gadget.': 1,\n",
       " 'thing!': 1,\n",
       " 'reasonable': 1,\n",
       " 'i.e.': 1,\n",
       " 'stream': 1,\n",
       " 'submerged': 1,\n",
       " '15': 1,\n",
       " 'complaints': 1,\n",
       " 'end.': 1,\n",
       " \"microsoft's\": 1,\n",
       " 'faceplates': 1,\n",
       " 'nice,': 1,\n",
       " 'elegant': 1,\n",
       " 'seriously.': 1,\n",
       " 'angle': 1,\n",
       " 'party': 1,\n",
       " 'clearly.': 1,\n",
       " 'drawback': 1,\n",
       " 'mp3': 1,\n",
       " 'player': 1,\n",
       " 'pause': 1,\n",
       " 'skip': 1,\n",
       " 'songs': 1,\n",
       " 'seconds.': 1,\n",
       " 'activated': 1,\n",
       " 'suddenly': 1,\n",
       " 'died.': 1,\n",
       " 'sometimes.': 1,\n",
       " 'ipods': 1,\n",
       " 'situations:1.)': 1,\n",
       " 'bmw': 1,\n",
       " 'fairly': 1,\n",
       " 'quiet,': 1,\n",
       " 'hearing': 1,\n",
       " 'person': 1,\n",
       " 'saying.': 1,\n",
       " 'choice!': 1,\n",
       " 'd807...wrongly': 1,\n",
       " 'advertised': 1,\n",
       " 'd807.': 1,\n",
       " 'handy': 1,\n",
       " '.': 1,\n",
       " 'working!!!!!!!!!': 1,\n",
       " 'everyday': 1,\n",
       " 'packaged,': 1,\n",
       " 'intended.': 1,\n",
       " 'runs': 1,\n",
       " 'quickly.': 1,\n",
       " 'boy': 1,\n",
       " 'cheaper!': 1,\n",
       " 'loads': 1,\n",
       " 'super!': 1,\n",
       " 'does,': 1,\n",
       " 'greater': 1,\n",
       " 'sturdy.': 1,\n",
       " 'buds': 1,\n",
       " 'money...': 1,\n",
       " 'again!': 1,\n",
       " 'waaay': 1,\n",
       " 'bluetooths': 1,\n",
       " '(for': 1,\n",
       " 'listener)': 1,\n",
       " 'using.': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Distribution of labels in given data\")\n",
    "print(df['spam'].value_counts())    # count of unique labels in the 'spam' column\n",
    "# df.groupby('spam').spam.count()\n",
    "\n",
    "count = 0\n",
    "for mail in df['mail']:\n",
    "    count += len(mail.split())\n",
    "print(\"Total number of words:\", count)\n",
    "\n",
    "word_dict = {}\n",
    "for mail in df['mail']:\n",
    "    for word in mail.split():\n",
    "        word = word.lower()\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = 1\n",
    "        else:\n",
    "            word_dict[word] += 1\n",
    "print(\"Total distinct words:\", len(word_dict))\n",
    "print(\"Top frequent words:-\")\n",
    "dict(sorted(word_dict.items(), key=lambda item: item[1], reverse=True))    # prints a sorted dict with topmost freq words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Iv5TV8UhEYuI"
   },
   "outputs": [],
   "source": [
    "# Preprocessing steps:-\n",
    "# lowercase text\n",
    "# remove punctuations and other misc (digits, quotes, etc.)\n",
    "# remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bBzZYPyWEYuK"
   },
   "outputs": [],
   "source": [
    "# list of stopwords (words that don't carry any significant meaning / frequent words)\n",
    "stopwords = [\"i\", \"me\", \"my\", \"we\", \"our\", \"ours\", \"you\",\n",
    "             \"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"it\", \"its\",\n",
    "             \"they\", \"them\", \"their\", \"theirs\",\n",
    "             \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\",\n",
    "             \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "             \"do\", \"does\", \"did\", \"doing\",\n",
    "             \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\",\n",
    "             \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\",\n",
    "             \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\",\n",
    "             \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\",\n",
    "             \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\",\n",
    "             \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\",\n",
    "             \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \n",
    "             'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IwLRC1s2EYuR"
   },
   "outputs": [],
   "source": [
    "# function to lowercase text\n",
    "def lower_case(text):\n",
    "    clean_text = str(text).lower()\n",
    "    return clean_text\n",
    "\n",
    "# function to remove puctuations and other symbols\n",
    "def remove_punct(text):\n",
    "    punctuations = '''!#$%&'\"()*+,-./:;?@[\\]^_`{|}~0123456789'''\n",
    "    clean_text = \"\"\n",
    "    for char in text:\n",
    "        if char in punctuations:\n",
    "            clean_text += \" \"\n",
    "        else:\n",
    "            clean_text += char\n",
    "    return \" \".join(clean_text.strip().split())\n",
    "    \n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    tmp = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            tmp.append(word)\n",
    "    clean_text = \" \".join(tmp)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayzxU3DfEYuT",
    "outputId": "16ff58a7-a9d9-46b5-f2b1-96a4b6ca1824"
   },
   "outputs": [],
   "source": [
    "## checking preprocessing steps\n",
    "# line = \"Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\"\n",
    "# print(line)\n",
    "# line = lower_case(line)\n",
    "# print(line)\n",
    "# line = remove_punct(line)\n",
    "# print(line)\n",
    "# line = remove_stopwords(line)\n",
    "# print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rjh-FD_YEYua"
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "#     count = 0\n",
    "#     for text in df.iloc[:,0]:\n",
    "#         count += len(text.split())\n",
    "#     print('BEFORE pp word count:', count)\n",
    "    for i,data in enumerate(df.iloc[:,0]):\n",
    "        data = lower_case(data)\n",
    "        #print(1,data)\n",
    "        data = remove_punct(data)\n",
    "        #print(2,data)\n",
    "        data = remove_stopwords(data)\n",
    "        #print(3,data)\n",
    "        df.iloc[i] = data\n",
    "#     count = 0\n",
    "#     for text in df.iloc[:,0]:\n",
    "#         count += len(text.split())\n",
    "#     print('AFTER pp word count:', count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy and f1 score\n",
    "def score(Y_test, Y_pred):\n",
    "    # f1_score = TP/(TP+0.5*(FP+FN))\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_pred[i] == 1 and Y_test[i] == 1:\n",
    "            TP += 1\n",
    "        elif Y_pred[i] == 1 and Y_test[i] == 0:\n",
    "            FP += 1\n",
    "        elif Y_pred[i] == 0 and Y_test[i] == 1:\n",
    "            FN += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    acc = (TP+TN)/(len(Y_test))\n",
    "    f1_scr = TP/(TP+0.5*(FP+FN))\n",
    "    return acc, f1_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GppmdKJSEYur",
    "outputId": "6829ae12-6bf9-45b4-fd16-62e587b0cb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "ITERATION 1\n",
      "####################################################################################################\n",
      "Bag of Words shape: (857, 1560)\n",
      "Test Accuracy: 0.8321678321678322\n",
      "F1 Score:      0.8536585365853658\n",
      "####################################################################################################\n",
      "ITERATION 2\n",
      "####################################################################################################\n",
      "Bag of Words shape: (856, 1560)\n",
      "Test Accuracy: 0.8680555555555556\n",
      "F1 Score:      0.8741721854304636\n",
      "####################################################################################################\n",
      "ITERATION 3\n",
      "####################################################################################################\n",
      "Bag of Words shape: (856, 1572)\n",
      "Test Accuracy: 0.7916666666666666\n",
      "F1 Score:      0.8170731707317073\n",
      "####################################################################################################\n",
      "ITERATION 4\n",
      "####################################################################################################\n",
      "Bag of Words shape: (856, 1523)\n",
      "Test Accuracy: 0.7777777777777778\n",
      "F1 Score:      0.8\n",
      "####################################################################################################\n",
      "ITERATION 5\n",
      "####################################################################################################\n",
      "Bag of Words shape: (856, 1500)\n",
      "Test Accuracy: 0.7847222222222222\n",
      "F1 Score:      0.7769784172661871\n",
      "####################################################################################################\n",
      "ITERATION 6\n",
      "####################################################################################################\n",
      "Bag of Words shape: (856, 1528)\n",
      "Test Accuracy: 0.7777777777777778\n",
      "F1 Score:      0.7894736842105263\n",
      "####################################################################################################\n",
      "ITERATION 7\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# 7-fold Cross Validation\n",
    "\n",
    "train_kfacc = []    # to store training accuracy at every iteration of k-fold CV\n",
    "test_kfacc = []     # to store testing accuracy\n",
    "train_f1score = []\n",
    "test_f1score = []\n",
    "k = 7    # for 7-Fold Cross Validation\n",
    "for _ in range(0,k):\n",
    "    print('#'*100)\n",
    "    print(\"ITERATION\", _+1)\n",
    "    print('#'*100)\n",
    "    # K-FOLD SPLIT\n",
    "    start = int((_*len(df))/k)\n",
    "    end = int(((_+1)*len(df))/k)\n",
    "    # print(start, end)\n",
    "    ### TEST data\n",
    "    X_test = df.iloc[start:end+1, :-1]    # all cols except last col as features (X)\n",
    "    Y_test = df.iloc[start:end+1, -1]     # last col as labels/classes/categories (Y)\n",
    "    ### TRAINING data\n",
    "    X_train = df.iloc[:start, :-1]\n",
    "    X_train = X_train.append(df.iloc[end+1:, :-1])\n",
    "    Y_train = df.iloc[:start, -1]\n",
    "    Y_train = Y_train.append(df.iloc[end+1:, -1])\n",
    "    \n",
    "    # print(X_test)\n",
    "    # print('Y_test'+ '#'*100)\n",
    "    # print(Y_test)\n",
    "    # print('Y_train'+ '#'*100)\n",
    "    # print(Y_train)\n",
    "\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    Y_train = Y_train.reset_index(drop=True)\n",
    "    Y_test = Y_test.reset_index(drop=True)\n",
    "    \n",
    "    ###############################################\n",
    "    # TRAINING MODEL ('fit')\n",
    "    ###############################################    \n",
    "    \n",
    "    # DATA PREPROCESSING for training data\n",
    "    X_train = preprocessing(X_train)    \n",
    "    \n",
    "    ###############################################\n",
    "    \n",
    "    # UNIQUE WORDS DICTIONARY\n",
    "    uniq_dict = {}\n",
    "    for mail in X_train['mail']:\n",
    "        # print(mail)\n",
    "        for word in mail.split():\n",
    "            # print(word)\n",
    "            if word not in uniq_dict:\n",
    "                uniq_dict[word] = 1\n",
    "            else:\n",
    "                uniq_dict[word] += 1\n",
    "\n",
    "    # print('Unique word count:', len(uniq_dict))\n",
    "    \n",
    "    ###############################################\n",
    "    \n",
    "    # BAG OF WORDS\n",
    "    bow = []    # bag of words\n",
    "    for mail in X_train['mail']:\n",
    "        ohe_sent = [0] * len(uniq_dict)   # one hot encoding of words in a sentence\n",
    "        for word in mail.split():\n",
    "            ohe_sent[list(uniq_dict.keys()).index(word)] = 1\n",
    "        bow.append(ohe_sent)\n",
    "\n",
    "    boW = np.asarray(bow)\n",
    "    print(\"Bag of Words shape:\", boW.shape)\n",
    "    # print(boW)\n",
    " \n",
    "    ###############################################\n",
    " \n",
    "    # CALCULATING PROBABILITIES\n",
    "    ALPHA = 1    # Laplace Smoothing (to handle missing words in dictionary)\n",
    "    \n",
    "    #calculate prior probabilities => P(y=1) , P(y=0)\n",
    "    num_y1 = sum(Y_train)\n",
    "    num_y0 = len(Y_train) - num_y1\n",
    "    # print(\"1s and 0s:\", num_y1, num_y0)\n",
    "    prior_y1 = (num_y1+ALPHA)/(len(Y_train) + (len(Y_train.unique())*ALPHA))\n",
    "    prior_y0 = 1-prior_y1\n",
    "    # print(\"Prior probs y0 and y1:\")\n",
    "    # print(prior_y0, prior_y1)\n",
    " \n",
    "    #calculate likelihoods/conditional prob => P(x/y=0) , P(x/y=1)\n",
    "    # Case Y=0:\n",
    "    pw_y0 = [0] * len(uniq_dict)\n",
    "    for j in range(len(uniq_dict)):\n",
    "        sumw = 0\n",
    "        for i in range(len(boW)):\n",
    "            if boW[i][j] == 1 and Y_train[i] == 0:\n",
    "                sumw += 1\n",
    "            #pw_y1[j] = sum([val for val in boW[:][j] if boW[i][j]==1 and Y_train[i]==1])\n",
    "        pw_y0[j] = sumw\n",
    " \n",
    "    pw_y0 = np.asarray(pw_y0)\n",
    "    # print(pw_y0)\n",
    " \n",
    "    conditional_probs = np.zeros((len(uniq_dict)))    # array of conditional probabilities calculated for each word in dict  \n",
    "    conditional_probs = (pw_y0 + ALPHA)/(num_y0 + len(uniq_dict)*ALPHA)\n",
    "    conditional_probs = np.reshape(conditional_probs, (1,len(uniq_dict)))\n",
    "    # print(conditional_probs)\n",
    "    # print(conditional_probs.shape)\n",
    " \n",
    "    # Case Y=1:\n",
    "    pw_y1 = [0] * len(uniq_dict)\n",
    "    for j in range(len(uniq_dict)):\n",
    "        sumw = 0\n",
    "        for i in range(len(boW)):\n",
    "            if boW[i][j] == 1 and Y_train[i] == 1:\n",
    "                sumw += 1\n",
    "            #pw_y1[j] = sum([val for val in boW[:][j] if boW[i][j]==1 and Y_train[i]==1])\n",
    "        pw_y1[j] = sumw\n",
    " \n",
    "    pw_y1 = np.asarray(pw_y1)\n",
    "    # print(pw_y1)\n",
    " \n",
    "    arr = (pw_y1 + ALPHA)/(num_y1 + len(uniq_dict)*ALPHA)\n",
    "    arr = np.reshape(arr,(1, len(uniq_dict)))\n",
    "    conditional_probs = np.append(conditional_probs, arr, axis=0)\n",
    "    # print(conditional_probs)\n",
    "    # print(conditional_probs.shape)\n",
    " \n",
    "    ###############################################\n",
    "    # TESTING MODEL ('predict')\n",
    "    ###############################################\n",
    "    \n",
    "    # TRAINING ACCURACY\n",
    "    Y_pred = [0] * len(X_train)    # to store model predictions\n",
    "    for i,mail in enumerate(X_train['mail']):\n",
    "        py0_w = prior_y0\n",
    "        py1_w = prior_y1\n",
    "        for w in mail.split():\n",
    "            if w in uniq_dict:\n",
    "                py0_w *= conditional_probs[0][list(uniq_dict.keys()).index(w)]\n",
    "                py1_w *= conditional_probs[1][list(uniq_dict.keys()).index(w)]\n",
    "            else:\n",
    "                print(\"DEBUG\")\n",
    "                \n",
    "        # print(py1_w, py0_w)\n",
    "        if py1_w >= py0_w:\n",
    "            Y_pred[i] = 1\n",
    "        else:\n",
    "            Y_pred[i] = 0\n",
    "\n",
    "    # storing performance results\n",
    "    tr_acc, tr_f = score(Y_train, Y_pred)\n",
    "    train_kfacc.append(tr_acc)\n",
    "    train_f1score.append(tr_f)\n",
    "    ###############################################\n",
    "    \n",
    "    # TEST ACCURACY\n",
    "    X_test_pp = preprocessing(X_test)    \n",
    " \n",
    "    Y_pred = [0] * len(X_test_pp)\n",
    "    for i,mail in enumerate(X_test_pp['mail']):\n",
    "        py0_w = prior_y0\n",
    "        py1_w = prior_y1\n",
    "        for w in mail.split():\n",
    "            if w in uniq_dict:\n",
    "                py0_w *= conditional_probs[0][list(uniq_dict.keys()).index(w)]\n",
    "                py1_w *= conditional_probs[1][list(uniq_dict.keys()).index(w)]\n",
    "            else:\n",
    "                py0_w *= ALPHA/(num_y0 + len(uniq_dict)*ALPHA)\n",
    "                py1_w *= ALPHA/(num_y1 + len(uniq_dict)*ALPHA)\n",
    "                \n",
    "        # print(py1_w, py0_w)\n",
    "        if py1_w >= py0_w:\n",
    "            #y_pred.append(1)\n",
    "            Y_pred[i] = 1\n",
    "        else:\n",
    "            #y_pred.append(0)\n",
    "            Y_pred[i] = 0\n",
    "    \n",
    "    # storing performance results\n",
    "    acc, f_scr = score(Y_test, Y_pred)\n",
    "    test_kfacc.append(acc)\n",
    "    test_f1score.append(f_scr)\n",
    "    print(\"Test Accuracy:\", test_kfacc[_])\n",
    "    print(\"F1 Score:     \", test_f1score[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test_kfacc)):\n",
    "#     print(i+1, \"Training Accuracy:\", round(train_kfacc[i],4)*100, \"%\")\n",
    "#     print(\" \", \"F1 Score:     \", round(train_f1score[i],4))\n",
    "# print(\"Average Training Accuracy:\", round(sum(train_kfacc)/len(train_kfacc), 4)*100)\n",
    "# print(\"Average F1 Score:     \", sum(train_f1score)/len(train_f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_kfacc)):\n",
    "    print(str(i+1)+'.', \"Test Accuracy:\", round(test_kfacc[i],4)*100, \"%\")\n",
    "    print(\" \", \" F1 Score:     \", round(test_f1score[i],4))\n",
    "print(\"Average Test Accuracy:\", (sum(test_kfacc)/len(test_kfacc))*100)\n",
    "print(\"Average F1 Score:     \", sum(test_f1score)/len(test_f1score))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NB Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
