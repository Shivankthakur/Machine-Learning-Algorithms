{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Ariticial_neural_network.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_2cgn9ovgHd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from math import exp,log"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXMgtVI3vgHs"
      },
      "source": [
        "def initialize_network_double(inputs,hidden1,hidden2,outputs):\n",
        "    net = list()\n",
        "    hidden_layer1 = [{'weights':[random() for i in range(inputs + 1)]} for i in range(hidden1)]\n",
        "    net.append(hidden_layer1)\n",
        "    \n",
        "    hidden_layer2 = [{'weights':[random() for i in range(hidden1 + 1)]} for i in range(hidden2)]\n",
        "    net.append(hidden_layer2)\n",
        "    \n",
        "    output_layer = [{'weights':[random() for i in range(hidden2 + 1)]} for i in range(outputs)]\n",
        "    net.append(output_layer)\n",
        "    return net"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAq3wXSvgHt"
      },
      "source": [
        "def initialize_network_single(n_inputs, n_hidden, n_outputs):\n",
        "    network = list()\n",
        "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "    network.append(hidden_layer)\n",
        "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "    network.append(output_layer)\n",
        "    return network"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Si-0MUKvgHt"
      },
      "source": [
        "def activate(weights, inputs):\n",
        "    activation = weights[-1]\n",
        "    for i in range(len(weights)-1):\n",
        "        activation += weights[i] * inputs[i]\n",
        "    return activation"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GppX2u8MvgHu"
      },
      "source": [
        "# activation functions\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def transfer(x):\n",
        "    return sigmoid(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "admL4lDcvgHu"
      },
      "source": [
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "    return output * (1.0 - output)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afpOmh81vgHu"
      },
      "source": [
        "def forward_propagate(network, row):\n",
        "    inputs = row\n",
        "    for layer in network:            \n",
        "        new_inputs = []\n",
        "        for neuron in layer:\n",
        "            activation = activate(neuron['weights'], inputs)\n",
        "            neuron['output'] = transfer(activation)\n",
        "            new_inputs.append(neuron['output'])\n",
        "        inputs = new_inputs\n",
        "    return inputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG3nsgutvgHv"
      },
      "source": [
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "    for i in reversed(range(len(network))):\n",
        "        layer = network[i]\n",
        "        errors = list()\n",
        "        if i != len(network)-1:\n",
        "            for j in range(len(layer)):\n",
        "                error = 0.0\n",
        "                for neuron in network[i + 1]:\n",
        "                    error += (neuron['weights'][j] * neuron['delta'])\n",
        "                errors.append(error)\n",
        "        else:\n",
        "            for j in range(len(layer)):\n",
        "                neuron = layer[j]\n",
        "                errors.append(expected[j] - neuron['output'])\n",
        "        for j in range(len(layer)):\n",
        "            neuron = layer[j]\n",
        "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT1LIpULvgHv"
      },
      "source": [
        "def update_weights(network, row, l_rate):\n",
        "    for i in range(len(network)):\n",
        "        inputs = row[:-1]\n",
        "        if i != 0:\n",
        "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "        for neuron in network[i]:\n",
        "            for j in range(len(inputs)):\n",
        "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "            neuron['weights'][-1] += l_rate * neuron['delta']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SweJ3UmrvgHv"
      },
      "source": [
        "def train_network(network, train, lr, n_epochs, n_outputs, accuracy_score, loss_score):\n",
        "    for epoch in range(n_epochs):\n",
        "        sum_error = 0\n",
        "        for i,row in enumerate(train):\n",
        "            outputs = forward_propagate(network, row)\n",
        "            expected = [0 for i in range(n_outputs)]\n",
        "            expected[row[-1]] = 1\n",
        "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "            backward_propagate_error(network, expected)\n",
        "            # store accuracy and loss every 50 iterations\n",
        "            if i%50 == 0:\n",
        "                acc = calculate_accuracy(network,train)\n",
        "                accuracy_score.append(acc)\n",
        "                loss_score.append(sum_error)\n",
        "                print(f'Iteration {i} | Accuracy: {acc} | Loss:{sum_error}')\n",
        "            update_weights(network, row, lr)\n",
        "        print('#'*50)\n",
        "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, lr, sum_error))\n",
        "        print('#'*50)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEY-s6gOvgHw"
      },
      "source": [
        "# def accuracy_metric(actual, predicted):\n",
        "#     correct = 0\n",
        "#     for i in range(len(actual)):\n",
        "#         if actual[i] == predicted[i]:\n",
        "#             correct += 1\n",
        "#     return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9llDqGGHv9pb",
        "outputId": "ef271240-7106-4266-f479-9a51321f8a15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UkIC5ycvgHx"
      },
      "source": [
        "pathdir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/dataset_NN.csv'\n",
        "df = pd.read_csv(pathdir)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrpDihj1vgHy"
      },
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "    minmax = list()\n",
        "    stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "    return stats\n",
        "\n",
        "    # Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "    for row in dataset:\n",
        "        for i in range(len(row)-1):\n",
        "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq-7NxtJvgHy"
      },
      "source": [
        "df = df.values\n",
        "minmax = dataset_minmax(df)\n",
        "normalize_dataset(df, minmax)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31DJhwCJvgHw"
      },
      "source": [
        "def split_train_test(data, split, seed):\n",
        "\n",
        "    #creating the training and testing dataset\n",
        "    rows = int(data.shape[0] * split)\n",
        "    indices = np.arange(data.shape[0])\n",
        "    \n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    train = data[indices[:rows]]\n",
        "    test = data[indices[rows:]]\n",
        "\n",
        "    return train,test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR8n3OVpvgHy"
      },
      "source": [
        "train, test = split_train_test(df, 0.7, 23)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU6hBAwNvgHz",
        "outputId": "c2a9950d-a3a0-421e-d3b4-272df5623d8e"
      },
      "source": [
        "print(train)\n",
        "print(len(train))\n",
        "print(len(test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          0.33333333  0.         ...  0.56914545  0.4965783\n",
            "  10.        ]\n",
            " [ 0.          0.5         0.2        ...  0.3884311   0.36209795\n",
            "   5.        ]\n",
            " [ 0.          0.5         0.2        ...  0.50324073  0.67034833\n",
            "   6.        ]\n",
            " ...\n",
            " [ 0.          0.5         0.2        ...  0.56304156  0.68562956\n",
            "   6.        ]\n",
            " [ 0.5         0.16666667  0.2        ...  0.23035431  0.17132389\n",
            "   7.        ]\n",
            " [ 0.          0.33333333  0.         ...  0.68549271  0.62199407\n",
            "   3.        ]]\n",
            "1400\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG8rlFvwvgH0",
        "outputId": "3438a15b-4237-4a78-9fbf-d7764a07a128"
      },
      "source": [
        "train = train.tolist()\n",
        "test = test.tolist()\n",
        "print(train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0, 0.3333333333333333, 0.0, 0.5938012263979114, 0.5691454454889607, 0.496578300994987, 10.0], [0.0, 0.5, 0.2, 0.4042559650294457, 0.38843109906263373, 0.36209795456640775, 5.0], [0.0, 0.5, 0.2, 0.6699350373383524, 0.5032407338961983, 0.6703483329938266, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6698743245704571, 0.5821565268880988, 0.5494421769792431, 3.0], [0.0, 0.5, 0.2, 0.7108023192277336, 0.5483339510374444, 0.7211043711532072, 6.0], [0.0, 0.5, 0.2, 0.627132535972315, 0.5575287632214069, 0.5513933082730226, 4.0], [0.0, 0.5, 0.2, 0.27439135450185176, 0.11327479628284655, 0.11174721223438497, 2.0], [0.0, 0.5, 0.2, 0.49620545200655686, 0.47051640673518985, 0.39647110754309006, 5.0], [0.0, 0.3333333333333333, 0.0, 0.41178434824843657, 0.28128736426170253, 0.32252554946908435, 5.0], [0.5, 0.16666666666666666, 0.2, 0.26259789933823086, 0.172911220933704, 0.10652900117175026, 10.0], [0.0, 0.3333333333333333, 0.0, 0.3784530386740331, 0.32321587000189356, 0.22188520749037927, 8.0], [0.0, 0.3333333333333333, 0.0, 0.8485520004857022, 0.6748110769476281, 0.7603993796766177, 6.0], [1.0, 0.0, 0.4, 0.29980723696193307, 0.19931229185597105, 0.0669768457858002, 9.0], [0.0, 0.3333333333333333, 0.0, 0.48409325481148696, 0.5209251449914095, 0.39312198018199085, 5.0], [0.0, 0.3333333333333333, 0.0, 0.4488191366644404, 0.40304434969065017, 0.36723504566034965, 5.0], [0.0, 0.3333333333333333, 0.0, 1.0, 0.8786820343265106, 0.853946292797376, 1.0], [0.5, 0.0, 0.0, 0.2777760913120029, 0.09111499299296871, 0.023522780990144827, 1.0], [0.0, 0.6666666666666666, 0.4, 0.6642280371562139, 0.5235511403307167, 0.5739159458109419, 4.0], [0.0, 0.3333333333333333, 0.0, 0.644450853014389, 0.6284442843476822, 0.5100028574340936, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4380274421710885, 0.47583155347690026, 0.3859335109373696, 5.0], [0.0, 0.3333333333333333, 0.0, 0.3765102301013903, 0.34653281160204497, 0.2687103337125798, 5.0], [0.0, 0.6666666666666666, 0.2, 0.42107340173638524, 0.44505106412456674, 0.37801122901408807, 5.0], [0.0, 0.3333333333333333, 0.0, 0.43036245522433364, 0.4686588796227425, 0.2630282733684736, 8.0], [0.5, 0.16666666666666666, 0.2, 0.32529901038188336, 0.2796536841059174, 0.1633103223324278, 10.0], [0.5, 0.16666666666666666, 0.2, 0.37142553579017673, 0.33961904864563097, 0.1822937248345782, 7.0], [0.0, 0.3333333333333333, 0.0, 0.34864306963754477, 0.14857436648326872, 0.11846637012973746, 2.0], [0.5, 0.16666666666666666, 0.2, 0.29635419828790005, 0.23982071504600994, 0.15287917753982364, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5878969097201142, 0.4941632700710567, 0.49099336594913007, 3.0], [0.0, 0.3333333333333333, 0.0, 0.3695434399854288, 0.3794910231613507, 0.22890969073210152, 8.0], [0.0, 0.3333333333333333, 0.0, 0.34205573432092773, 0.1433864360144988, 0.13522203652736653, 2.0], [1.0, 0.0, 0.4, 0.25607127678950875, 0.14630218213204152, 0.04344696805435587, 9.0], [0.0, 0.6666666666666666, 0.4, 0.6563201991378786, 0.5824244721896786, 0.5281051489246974, 4.0], [0.5, 0.16666666666666666, 0.2, 0.3733076315949244, 0.3108455178468362, 0.2034869145313867, 7.0], [0.0, 0.6666666666666666, 0.4, 0.6298949669115415, 0.5810333152718248, 0.5119328500660382, 4.0], [0.0, 0.3333333333333333, 0.0, 0.4835316617084573, 0.5349456073439434, 0.3805518775394009, 5.0], [0.0, 0.5, 0.2, 0.43556857507133756, 0.4312874854032395, 0.39718586523548877, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6983637909052273, 0.5261186062953663, 0.5684084312960229, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6334618420253779, 0.5005533484054127, 0.41463154942482944, 8.0], [0.0, 0.3333333333333333, 0.0, 0.44303624552243326, 0.4332267600962943, 0.31460222522018605, 3.0], [0.5, 0.0, 0.0, 0.24269928966061555, 0.06930638007833007, 0.010872306892514127, 1.0], [0.0, 0.3333333333333333, 0.0, 0.2602073341023618, 0.12640636936348473, 0.08466964511012845, 2.0], [0.0, 0.6666666666666666, 0.4, 0.5762248800922833, 0.5863944604793536, 0.4220558997150945, 4.0], [0.5, 0.0, 0.0, 0.2706878756602514, 0.10104786440573385, 0.014347666257413306, 1.0], [0.5, 0.16666666666666666, 0.2, 0.3618860421346609, 0.22692649461408623, 0.15760984649590676, 7.0], [0.5, 0.3333333333333333, 0.4, 0.4560287778519823, 0.32904233292069157, 0.2518673925392263, 7.0], [1.0, 0.0, 0.4, 0.2459626009349766, 0.1568872541507558, 0.026063681809173494, 9.0], [0.5, 0.16666666666666666, 0.2, 0.5464756238236902, 0.3400763703090952, 0.31704681184254097, 10.0], [0.0, 0.6666666666666666, 0.4, 0.4801469248983061, 0.45031663113169823, 0.3055137000794231, 4.0], [0.0, 0.5, 0.2, 0.39226519337016563, 0.37606326862936634, 0.30615773476171976, 5.0], [0.5, 0.16666666666666666, 0.2, 0.27132535972314986, 0.24887794858765888, 0.13344469677326298, 10.0], [0.0, 0.5, 0.2, 0.3858751745492077, 0.43978342040537305, 0.32795032092637916, 2.0], [0.5, 0.0, 0.0, 0.26798615748892, 0.09455972853106907, 0.028368637251587604, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2556918219901646, 0.22724192174724334, 0.11944346679397586, 10.0], [0.0, 0.5, 0.2, 0.279164895877603, 0.12241083186452455, 0.0815551696759877, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7672879606581265, 0.7415127373898212, 0.6893349756345399, 3.0], [1.0, 0.0, 0.4, 0.19995750106247343, 0.06301936740963077, 0.01748778414491903, 9.0], [0.0, 0.3333333333333333, 0.0, 0.8261489891324144, 0.7219402842294086, 0.8156617402120677, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5282921498391111, 0.4528165050632678, 0.34668896381570724, 4.0], [0.0, 0.3333333333333333, 0.0, 0.9015238904741667, 0.7673034527478325, 0.4916196917308861, 1.0], [0.5, 0.0, 0.0, 0.27577256997146493, 0.1580556095316252, 0.012437600545784331, 1.0], [0.5, 0.16666666666666666, 0.2, 0.266984396818651, 0.13787352129889674, 0.11290369507377843, 10.0], [0.5, 0.16666666666666666, 0.2, 0.259395300831765, 0.19298490338404398, 0.11825345530510697, 7.0], [0.0, 0.5, 0.2, 0.5029825147228462, 0.47453156704404614, 0.48724585734855896, 6.0], [0.0, 0.5, 0.2, 0.48233258454252936, 0.41976160631106874, 0.43167629321041934, 5.0], [0.0, 0.3333333333333333, 0.0, 0.25016696011171147, 0.1701916887878295, 0.11153162521269397, 2.0], [0.0, 0.3333333333333333, 0.0, 0.5669965393722299, 0.6253977194974988, 0.4998928758949841, 6.0], [0.0, 0.5, 0.2, 0.4843968186509623, 0.50388094043044, 0.45628334002437076, 5.0], [0.0, 0.3333333333333333, 0.0, 0.8446663833404165, 0.740900453450079, 0.7316461821221459, 6.0], [0.0, 0.3333333333333333, 0.0, 0.40317831339930793, 0.3580115267267298, 0.2619965959403119, 4.0], [0.5, 0.0, 0.0, 0.2143919616295307, 0.15473471384345236, 0.006829995355848579, 1.0], [0.0, 0.5, 0.0, 0.39182502580292633, 0.44737485547691036, 0.26772661645713847, 8.0], [0.5, 0.3333333333333333, 0.4, 0.18590249529476044, 0.16849702110841483, 0.08555158756334925, 2.0], [0.0, 0.3333333333333333, 0.0, 0.9236233379879789, 0.7598116221551808, 0.810356115513824, 3.0], [0.0, 0.5, 0.2, 0.4063809119057738, 0.3411687844267561, 0.3122072038153471, 5.0], [0.0, 0.3333333333333333, 0.0, 0.4132262764859449, 0.38487211610651334, 0.30434293571494037, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5446542407868374, 0.529125395752272, 0.4007754921581426, 8.0], [1.0, 0.0, 0.4, 0.27162892356262525, 0.08042311157596821, 0.025328245355396437, 9.0], [0.5, 0.16666666666666666, 0.2, 0.3437556918219901, 0.2777023941502158, 0.1666081157118302, 7.0], [0.0, 0.3333333333333333, 0.0, 0.426476838079048, 0.41990393878745697, 0.284957218189285, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6900157853196527, 0.5010019535291318, 0.6139894086063175, 6.0], [1.0, 0.0, 0.4, 0.29164895877603064, 0.07733704681471971, 0.062299898198742126, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2687450670876086, 0.29376817772027153, 0.12337592697318513, 10.0], [0.5, 0.16666666666666666, 0.2, 0.27659219233804866, 0.19314766392602603, 0.11942594445777524, 10.0], [0.5, 0.16666666666666666, 0.2, 0.4764282678647319, 0.3043217600030188, 0.25623723127855297, 7.0], [0.0, 0.5, 0.2, 0.4668356505373081, 0.3792657987936267, 0.3875980763209877, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2956104668811851, 0.18939893023475848, 0.12786260482183529, 7.0], [0.5, 0.0, 0.0, 0.23202902070305395, 0.1089628003583445, 0.014937254270184568, 1.0], [0.0, 0.3333333333333333, 0.0, 0.39370712160767396, 0.4169178104964784, 0.24659052858881356, 8.0], [0.0, 0.3333333333333333, 0.0, 0.4142280371562139, 0.3840958072320707, 0.23575755312417385, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2844393175884888, 0.13944333902693856, 0.11513410610460563, 2.0], [0.0, 0.3333333333333333, 0.0, 0.3312488616356019, 0.35131023119251337, 0.1960770325171288, 8.0], [0.0, 0.5, 0.0, 0.360876692368405, 0.186590085342906, 0.20405670062860745, 5.0], [0.0, 0.5, 0.2, 0.38121546961325964, 0.4016150561455, 0.30498405650359395, 5.0], [0.0, 0.3333333333333333, 0.0, 0.27765466577621284, 0.10257065237557246, 0.09982656874549693, 2.0], [0.5, 0.16666666666666666, 0.2, 0.27426992896606145, 0.22528245208892841, 0.14238986376275176, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2927873231740636, 0.22737262039789397, 0.13726243959054715, 10.0], [0.0, 0.5, 0.2, 0.3746281342966426, 0.3489825336436714, 0.2275869069387459, 8.0], [0.5, 0.0, 0.0, 0.20316009956893932, 0.04759150881600656, 0.004637810111019794, 1.0], [0.0, 0.3333333333333333, 0.0, 0.47134357355351836, 0.44323543856298486, 0.3273444841016511, 3.0], [0.0, 0.5, 0.2, 0.41052455831461354, 0.4420661225261954, 0.3556034469975363, 5.0], [0.0, 0.3333333333333333, 0.0, 0.37286746402768506, 0.3489391487270473, 0.21597556612235366, 8.0], [0.0, 0.6666666666666666, 0.4, 0.8488707425171514, 0.7481431562953489, 0.8929637776321036, 4.0], [0.0, 0.3333333333333333, 0.0, 0.2663620909477264, 0.12241887029420849, 0.09578376360780526, 2.0], [0.5, 0.0, 0.0, 0.20246190273814582, 0.04647566458300172, 0.00875724085766989, 1.0], [0.0, 0.5, 0.2, 0.40783801833525596, 0.4572316937990628, 0.32051221431625276, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6735170906441624, 0.6043309519261713, 0.5025189675674594, 3.0], [0.0, 0.5, 0.2, 0.4223939044381032, 0.44133282419511405, 0.35707924280530456, 4.0], [0.5, 0.16666666666666666, 0.2, 0.26912452188695274, 0.2018671138934376, 0.11969271702133615, 7.0], [0.0, 0.5, 0.2, 0.3276819865217655, 0.2641059907499148, 0.21511150868068804, 2.0], [0.0, 0.5, 0.2, 0.5054337927266104, 0.5143858683162957, 0.3434186565695574, 4.0], [0.0, 0.5, 0.2, 0.9634660919191307, 0.8326435670781777, 1.0, 6.0], [0.5, 0.16666666666666666, 0.2, 0.26071580353348317, 0.19570293097322036, 0.13858916234748914, 10.0], [1.0, 0.0, 0.4, 0.2608372290692733, 0.08474358387623523, 0.037478784558925636, 9.0], [0.5, 0.16666666666666666, 0.2, 0.28481877238783315, 0.16652766940868716, 0.11907106196385193, 10.0], [0.0, 0.5, 0.2, 0.5293394450853014, 0.44253243621161703, 0.39397740085037875, 8.0], [0.0, 0.3333333333333333, 0.0, 0.4680802622791573, 0.5204648707237205, 0.3130783425111004, 8.0], [0.0, 0.5, 0.2, 0.6385465363365915, 0.5979250015781953, 0.47795507900726564, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5727187177463421, 0.6503456853223623, 0.548423395571668, 3.0], [0.0, 0.5, 0.2, 0.5351830489952037, 0.4263793106529488, 0.41146802912985275, 4.0], [0.0, 0.5, 0.2, 0.8715849068059014, 0.6636447303971785, 0.8547035873043591, 6.0], [0.0, 0.3333333333333333, 0.0, 0.37148624855807166, 0.3992154153573522, 0.25983460641019607, 8.0], [0.0, 0.3333333333333333, 0.0, 0.24313186813186818, 0.09693531053933709, 0.08831493413199622, 2.0], [0.0, 0.5, 0.2, 0.6582630077105215, 0.5785018527132374, 0.6121464552979881, 6.0], [0.0, 0.5, 0.2, 0.6893934794487281, 0.7396997606956658, 0.5846529658193885, 4.0], [0.5, 0.16666666666666666, 0.2, 0.23303078137332273, 0.12337111341130133, 0.0786268348943297, 7.0], [0.0, 0.3333333333333333, 0.0, 0.41736992289478486, 0.3422916075424741, 0.2904059784078862, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7915123550482666, 0.6337466600165733, 0.670737222955201, 3.0], [0.0, 0.5, 0.2, 0.6852498330398884, 0.5449899996071907, 0.657342706236742, 6.0], [1.0, 0.0, 0.4, 0.23691639851860838, 0.06569324014471752, 0.025767526393498354, 9.0], [0.0, 0.3333333333333333, 0.0, 0.44573796369376484, 0.3868836024574399, 0.31057895703686217, 8.0], [0.5, 0.16666666666666666, 0.2, 0.27426992896606145, 0.22528245208892841, 0.14238986376275176, 10.0], [0.0, 0.5, 0.2, 0.3467609738327971, 0.2504278397690064, 0.22328197861935206, 2.0], [0.0, 0.5, 0.2, 0.30151478355898237, 0.21314895106368598, 0.1384013784184619, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2367342602149231, 0.16995032398791948, 0.10622670894297079, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5083328273936009, 0.3461502515728287, 0.3087888088137327, 6.0], [0.5, 0.0, 0.0, 0.29076862364155176, 0.10593332953262072, 0.031332009253065396, 1.0], [0.0, 0.3333333333333333, 0.0, 0.4033300953190455, 0.4102389773580393, 0.280931363563486, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5032329548904134, 0.4282101089271501, 0.35748992578103395, 8.0], [0.0, 0.3333333333333333, 0.0, 0.3217776698439682, 0.34406220235780427, 0.20592765144819153, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7061502033877725, 0.5499387832610425, 0.612749721793512, 6.0], [0.0, 0.3333333333333333, 0.0, 0.39929269625402225, 0.3269415196964944, 0.2472395560209122, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6819865217655273, 0.5249944269595257, 0.53944943044313, 3.0], [1.0, 0.0, 0.4, 0.17410904013113954, 0.17324306398125955, 0.03777215199753741, 9.0], [0.0, 0.3333333333333333, 0.0, 0.32027502883856473, 0.22020320994840584, 0.1622046947987034, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4122852285835711, 0.4555849317700138, 0.2615417904919561, 8.0], [0.5, 0.0, 0.0, 0.2325906138060834, 0.10212349529938, 0.01419889739749407, 1.0], [0.5, 0.0, 0.0, 0.21715439256875724, 0.06768999879275223, 0.004259330138321485, 1.0], [0.5, 0.0, 0.0, 0.2091858417825268, 0.027788180370693062, 0.012217061770617784, 1.0], [0.0, 0.5, 0.2, 0.8351193005889138, 0.7809864917720986, 0.8329470111169652, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7102938497966121, 0.6245368729020928, 0.5786897983606754, 3.0], [0.0, 0.3333333333333333, 0.0, 0.634721631959201, 0.6294740863030251, 0.47088047987087656, 4.0], [0.5, 0.0, 0.0, 0.2564355533968793, 0.14911755383323297, 0.027332510257902374, 1.0], [0.5, 0.16666666666666666, 0.2, 0.29805415578896244, 0.22100102762635224, 0.13332418490621545, 10.0], [0.0, 0.6666666666666666, 0.4, 0.5186691761277397, 0.44162164963566175, 0.43540858590401227, 5.0], [0.0, 0.6666666666666666, 0.2, 0.44141217898123963, 0.44030837648379584, 0.3307408260388817, 5.0], [0.5, 0.0, 0.0, 0.24030872442474646, 0.12425007119625874, 0.008023689507190651, 1.0], [0.0, 0.3333333333333333, 0.0, 0.37550846943112126, 0.40757343266214163, 0.29522008060266386, 4.0], [0.5, 0.0, 0.0, 0.2414394997267925, 0.0843235794570768, 0.013813713633452053, 1.0], [0.5, 0.0, 0.0, 0.25649626616477444, 0.11621794228504971, 0.02417423292681185, 1.0], [0.0, 0.5, 0.2, 0.41316556371804997, 0.44177782685913297, 0.34647814884562605, 5.0], [0.5, 0.16666666666666666, 0.2, 0.3269382551150508, 0.336377837953296, 0.1694743671799256, 10.0], [0.5, 0.0, 0.0, 0.26742456438589035, 0.12676071718869636, 0.019445098790920844, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2668629712828607, 0.13952525613506134, 0.08330481152587588, 10.0], [0.5, 0.0, 0.0, 0.20698500394632993, 0.08073225912741273, 0.01022552721179394, 1.0], [1.0, 0.0, 0.4, 0.26227915730678164, 0.07473364808047281, 0.028045579497711606, 9.0], [1.0, 0.0, 0.4, 0.24257786412482543, 0.0677308266693539, 0.02616313227254528, 9.0], [0.5, 0.0, 0.0, 0.2325906138060834, 0.20129902012601705, 0.025384058538141876, 1.0], [0.0, 0.3333333333333333, 0.0, 0.40764070183959683, 0.3248824173047076, 0.2735811507619592, 2.0], [0.0, 0.3333333333333333, 0.0, 0.23404013113957864, 0.06561773682759023, 0.05888058812203029, 2.0], [0.0, 0.5, 0.2, 0.3215348187723878, 0.24611763801070805, 0.20325575835543946, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4969491834132718, 0.4920859858532538, 0.3648373012732885, 8.0], [0.5, 0.16666666666666666, 0.2, 0.4955072551757635, 0.3110174328746444, 0.2773918582816049, 10.0], [0.0, 0.5, 0.2, 0.4376479873717443, 0.4354033874380634, 0.37410205200352603, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6539372229979965, 0.6020563023623257, 0.6040646973706196, 3.0], [0.5, 0.0, 0.0, 0.21213041102543864, 0.10544829718405117, 0.010502225887374634, 1.0], [0.0, 0.5, 0.2, 0.34067451885131433, 0.27009707901336316, 0.23741026209845342, 2.0], [1.0, 0.0, 0.4, 0.2849401979236233, 0.1574774218133978, 0.04087985609910679, 9.0], [0.0, 0.3333333333333333, 0.0, 0.278034120575557, 0.22529634628153658, 0.1324875905272186, 2.0], [0.0, 0.5, 0.2, 0.5168477930908871, 0.5781504998741295, 0.4204562119806302, 5.0], [0.0, 0.3333333333333333, 0.0, 0.341236111954344, 0.14736825591201264, 0.1049608758753516, 2.0], [0.0, 0.5, 0.2, 0.5996448303078138, 0.5740656708201308, 0.4298265712082643, 4.0], [0.0, 0.5, 0.2, 0.42835893388379565, 0.45592973660884334, 0.39533090503369456, 5.0], [0.0, 0.3333333333333333, 0.0, 0.4126039706150203, 0.35061259014881685, 0.2454363713862564, 8.0], [1.0, 0.0, 0.4, 0.25657215712464326, 0.16776341904053516, 0.059538515606288415, 9.0], [0.0, 0.5, 0.2, 0.6891354501851741, 0.6217904211995174, 0.5437594725375873, 4.0], [0.0, 0.3333333333333333, 0.0, 0.36822293728371086, 0.35848455793994516, 0.22817701428728707, 8.0], [0.0, 0.3333333333333333, 0.0, 0.5558253900795338, 0.4428055097205348, 0.4661845713068233, 4.0], [0.0, 0.5, 0.2, 0.2730101390322384, 0.1190526401229855, 0.14432135665705198, 2.0], [0.0, 0.5, 0.2, 0.5713375022767287, 0.6073864664164332, 0.5602116200864087, 4.0], [0.0, 0.5, 0.2, 0.40846032420618056, 0.41076035216770135, 0.37211193448832114, 5.0], [0.0, 0.3333333333333333, 0.0, 0.7224667597595775, 0.6236056088150183, 0.5954282474547812, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2696861149899824, 0.13861312040263013, 0.11177779576722961, 10.0], [0.0, 0.5, 0.2, 0.8039281160828121, 0.605818591191171, 0.7883746560415384, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6522296764009472, 0.6023959931211104, 0.5369654620992882, 3.0], [0.5, 0.16666666666666666, 0.2, 0.27917248497358993, 0.2197566320912239, 0.148031217559002, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2668629712828607, 0.28173854761638356, 0.1442556627621014, 10.0], [0.0, 0.6666666666666666, 0.2, 0.5928601784955376, 0.6375135119610388, 0.5055437599430538, 4.0], [0.0, 0.5, 0.2, 0.42063323416914566, 0.3852456911774187, 0.36512493089920905, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5191700564628741, 0.4775495594442547, 0.35359279432648877, 8.0], [0.5, 0.0, 0.0, 0.2642219658794245, 0.11221738253344882, 0.02141762030819594, 1.0], [1.0, 0.0, 0.4, 0.2232408475502398, 0.13184525706407207, 0.029912812284349027, 9.0], [0.0, 0.6666666666666666, 0.4, 0.49106004492744815, 0.48095072641092274, 0.3954905666215025, 5.0], [0.0, 0.5, 0.2, 0.5015937101572461, 0.5408080948597429, 0.487015764825765, 5.0], [0.5, 0.0, 0.0, 0.2818590249529475, 0.09220126173819997, 0.016912783254607208, 1.0], [0.0, 0.6666666666666666, 0.4, 0.2783452735110193, 0.23394179042487268, 0.1552220958116819, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2505464149110559, 0.24460299442525024, 0.12298544849559252, 10.0], [0.0, 0.3333333333333333, 0.0, 0.4772478902313156, 0.4289104906656773, 0.3761061832845875, 5.0], [0.5, 0.16666666666666666, 0.2, 0.34519762005949844, 0.3103957401578029, 0.18713724177576657, 7.0], [0.0, 0.3333333333333333, 0.0, 0.673820654483638, 0.4817483463067679, 0.4474657129850129, 3.0], [0.5, 0.16666666666666666, 0.2, 0.32642219658794247, 0.12628530552662035, 0.12375090535330785, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2979934430210673, 0.2391967831532372, 0.14226114122437541, 7.0], [1.0, 0.0, 0.4, 0.22129803897759695, 0.03462146013921784, 0.02870477647774092, 9.0], [0.5, 0.0, 0.0, 0.24432335620180914, 0.13705194857786865, 0.025759537588798474, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6881944022827999, 0.6566518263457047, 0.5954610351256274, 3.0], [0.0, 0.5, 0.2, 0.836500516058527, 0.6937369945465611, 0.8713174357990235, 6.0], [0.0, 0.3333333333333333, 0.0, 0.27991621638030467, 0.15886755450251347, 0.12076285544276054, 5.0], [0.0, 0.5, 0.2, 0.7027502883856475, 0.5693674912157729, 0.6466316339207513, 6.0], [0.5, 0.16666666666666666, 0.2, 0.40055248618784534, 0.34112166284114886, 0.2552756639177464, 7.0], [0.5, 0.0, 0.0, 0.2838625462934855, 0.19004368575732739, 0.04047301571293019, 1.0], [0.0, 0.3333333333333333, 0.0, 0.740346669904681, 0.519245494624392, 0.6179628735575136, 6.0], [0.0, 0.5, 0.2, 0.3732469188270292, 0.40009690899139266, 0.28443822273327773, 5.0], [0.5, 0.0, 0.0, 0.23867706878756595, 0.09613250592698211, 0.019305914206753223, 1.0], [0.5, 0.16666666666666666, 0.2, 0.37142553579017673, 0.33961904864563097, 0.1822937248345782, 10.0], [0.5, 0.0, 0.0, 0.26372108554428997, 0.09487805175927919, 0.013367409273414373, 1.0], [0.0, 0.5, 0.2, 0.6923987614595348, 0.635303304043947, 0.5904958612505351, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7517758484609314, 0.7639469138995674, 0.6335383968841679, 3.0], [0.0, 0.5, 0.2, 0.8885920709125128, 0.7080674450244694, 0.8839800029903842, 6.0], [0.0, 0.3333333333333333, 0.0, 0.4155485398579321, 0.3936089143896574, 0.2705677421868691, 8.0], [0.0, 0.5, 0.2, 0.4562260943476412, 0.517830497899699, 0.3493667334830972, 5.0], [0.5, 0.16666666666666666, 0.2, 0.4682016878149474, 0.37175314457117914, 0.26141668700783943, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6199077165927994, 0.526094914825103, 0.5240328221915408, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2687450670876086, 0.29376817772027153, 0.12337592697318513, 7.0], [1.0, 0.0, 0.4, 0.27771537854410777, 0.12770903998199784, 0.026488530716567153, 9.0], [0.0, 0.3333333333333333, 0.0, 0.7248497358994597, 0.6347706980363961, 0.5663911167783444, 3.0], [0.0, 0.3333333333333333, 0.0, 0.7313763584481815, 0.6332147603736696, 0.5311123945508898, 3.0], [0.5, 0.0, 0.0, 0.24821656244308174, 0.08470673989624307, 0.019737673056179232, 1.0], [0.5, 0.16666666666666666, 0.2, 0.3061593103029568, 0.27725207962405074, 0.1635378854045705, 10.0], [0.0, 0.5, 0.2, 0.3671604638455467, 0.32426792244362, 0.30046205565655, 5.0], [0.0, 0.5, 0.2, 0.6634691275575254, 0.6649124500929537, 0.5756488929758573, 4.0], [0.0, 0.3333333333333333, 0.0, 0.2317102786716047, 0.10581734445756875, 0.08605455793856873, 2.0], [0.0, 0.3333333333333333, 0.0, 0.3881974379211947, 0.43908540498841364, 0.2852454944176111, 5.0], [0.5, 0.16666666666666666, 0.2, 0.30872442474652423, 0.2453461112249261, 0.1303090147585647, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7630836014813916, 0.6037065608963779, 0.6497004174354324, 3.0], [0.0, 0.3333333333333333, 0.0, 0.3960293849796612, 0.4214188649187736, 0.2769493622154844, 8.0], [0.5, 0.16666666666666666, 0.2, 0.38643676765223717, 0.25966162915419494, 0.20534315970686604, 10.0], [1.0, 0.0, 0.4, 0.28249650901584594, 0.10122598131514343, 0.048228061197629, 9.0], [0.0, 0.5, 0.2, 0.8744763523769049, 0.6932037174925958, 0.8603547962751864, 6.0], [0.0, 0.3333333333333333, 0.0, 0.4270991439499726, 0.36000162435614247, 0.24605581015957476, 8.0], [0.5, 0.16666666666666666, 0.2, 0.30892174124218313, 0.17422589268757127, 0.13590480166739435, 7.0], [0.5, 0.0, 0.0, 0.18087851375144195, 0.14133780194678197, 0.016200986387341257, 1.0], [0.0, 0.5, 0.2, 0.237614595349402, 0.12409893741636782, 0.1106038282407158, 2.0], [0.0, 0.5, 0.2, 0.8620454131503855, 0.8173140768253069, 0.8556825910614426, 6.0], [0.5, 0.0, 0.0, 0.2570730374597778, 0.09155109546243431, 0.007906287418967003, 1.0], [0.0, 0.5, 0.2, 0.34889350980511213, 0.3633869051818974, 0.28064942463342896, 5.0], [0.0, 0.3333333333333333, 0.0, 0.61520247708093, 0.5984378011210417, 0.4698100447148457, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2844393175884888, 0.1905974050041797, 0.13704381032506133, 7.0], [0.5, 0.16666666666666666, 0.2, 0.31035608038370477, 0.3443331850273666, 0.15520347233069234, 10.0], [0.0, 0.3333333333333333, 0.0, 0.2784135753749014, 0.21826949434512374, 0.11743722653897898, 2.0], [0.5, 0.16666666666666666, 0.2, 0.209246554550422, 0.12847454147734003, 0.09590166515163641, 7.0], [0.5, 0.16666666666666666, 0.2, 0.31035608038370477, 0.3443331850273666, 0.15520347233069234, 7.0], [0.0, 0.6666666666666666, 0.4, 0.5765436221237326, 0.48316036217265035, 0.5098738726718379, 4.0], [0.0, 0.5, 0.2, 0.8238798494323357, 0.6780052013725882, 0.8290848657071861, 6.0], [0.0, 0.3333333333333333, 0.0, 0.9394390140246495, 1.0, 0.7177088149590636, 3.0], [0.0, 0.3333333333333333, 0.0, 0.48916277093072663, 0.5503323343241676, 0.33879553005606794, 8.0], [0.5, 0.0, 0.0, 0.21583388986703902, 0.12786573285166142, 0.013211597956469171, 1.0], [1.0, 0.0, 0.4, 0.25286108918705597, 0.15834661763893249, 0.04093796130241995, 9.0], [0.5, 0.0, 0.0, 0.240938619391658, 0.06629294373009512, 0.012307643577138972, 1.0], [0.0, 0.5, 0.2, 0.42835893388379565, 0.35713477279947126, 0.3473929936698991, 5.0], [0.5, 0.16666666666666666, 0.2, 0.33847368101511743, 0.23967570544760924, 0.17735062557889492, 7.0], [0.5, 0.16666666666666666, 0.2, 0.29899520369133625, 0.16808375540798962, 0.1369827335668321, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2608372290692733, 0.14346345801561736, 0.11875891148722767, 10.0], [0.0, 0.3333333333333333, 0.0, 0.2662937890838443, 0.12913557870502448, 0.1271746952348123, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4397729342480724, 0.45360637613893445, 0.3265697935060525, 8.0], [1.0, 0.0, 0.4, 0.23579321231254927, 0.11650837823699288, 0.027824043026876258, 9.0], [0.0, 0.5, 0.2, 0.5622305870924655, 0.48977544590168964, 0.46466570919104827, 5.0], [0.0, 0.3333333333333333, 0.0, 0.7740498451824419, 0.6302061273050348, 0.6979064586741812, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2959292089126343, 0.21259674343717852, 0.1428805813663455, 7.0], [1.0, 0.0, 0.4, 0.21150810515451401, 0.09443404506941272, 0.02915643365394272, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4721024831522069, 0.31921861603684104, 0.2951023730143881, 4.0], [0.0, 0.3333333333333333, 0.0, 0.39760032784894656, 0.40131420837865867, 0.27811015997122834, 5.0], [0.0, 0.3333333333333333, 0.0, 0.28914455710035813, 0.14718159905401956, 0.10997827971367855, 2.0], [0.0, 0.5, 0.2, 0.47787019610224024, 0.48651562250090397, 0.3597781817587319, 5.0], [0.0, 0.5, 0.2, 0.5189272053912937, 0.4888275186725906, 0.4392163641171863, 4.0], [0.0, 0.5, 0.2, 0.875599538582964, 0.7101890818784629, 0.8372043280497814, 6.0], [1.0, 0.0, 0.4, 0.2013387165320867, 0.08720837267578405, 0.0156564311778825, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4882900248922349, 0.4529344962139174, 0.3467550325427144, 3.0], [0.5, 0.0, 0.0, 0.17755448970918586, 0.041579589859115605, 0.0, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2556918219901646, 0.22724192174724334, 0.11944346679397586, 7.0], [0.5, 0.0, 0.0, 0.23246918827029328, 0.1059524861418497, 0.01004430971800714, 1.0], [0.5, 0.0, 0.0, 0.24972679254447214, 0.11904365516467456, 0.02460674958407663, 1.0], [0.0, 0.6666666666666666, 0.4, 0.5229342480723697, 0.5098252956088369, 0.47649350892165504, 5.0], [0.0, 0.3333333333333333, 0.0, 0.7312549329123914, 0.6490594941910657, 0.45092139705882195, 10.0], [0.0, 0.3333333333333333, 0.0, 0.38579928358933896, 0.3767265662239214, 0.23259666942829538, 8.0], [0.5, 0.16666666666666666, 0.2, 0.3199031631352073, 0.2863380692704827, 0.16877974760667422, 7.0], [0.0, 0.3333333333333333, 0.0, 0.27162892356262525, 0.1050008222437674, 0.05303605286324244, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6799071094651206, 0.5929059558328976, 0.536796669002832, 3.0], [0.0, 0.5, 0.2, 0.4383310060105641, 0.48157648778813145, 0.31239349160533003, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2678040191852347, 0.1392189976150234, 0.12358593356287795, 7.0], [0.0, 0.3333333333333333, 0.0, 0.29687025681500817, 0.31649860356300646, 0.20900386608785887, 2.0], [0.0, 0.3333333333333333, 0.0, 0.44994232287049973, 0.40774251516771515, 0.2602697558197056, 8.0], [0.0, 0.3333333333333333, 0.0, 0.611939165806569, 0.38311472324643736, 0.5731944757898623, 6.0], [0.0, 0.6666666666666666, 0.4, 0.48529233197741484, 0.404674547468725, 0.38192538983482555, 4.0], [0.0, 0.5, 0.2, 0.4099629652115841, 0.44042466529564595, 0.35078304659412546, 5.0], [0.0, 0.5, 0.2, 0.8353166170845729, 0.7014071822126023, 0.8531492039755743, 4.0], [0.5, 0.0, 0.0, 0.24508226580049794, 0.11704421939462735, 0.020295764204675663, 1.0], [0.0, 0.3333333333333333, 0.0, 0.5509228340720053, 0.5203837447440026, 0.39262600047322216, 8.0], [0.0, 0.3333333333333333, 0.0, 0.39232590613806084, 0.34709243605734696, 0.2273894467727195, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7717958836743367, 0.6898277041710106, 0.6706322257641198, 6.0], [0.0, 0.5, 0.2, 0.669813611802562, 0.5763828435357312, 0.6387810996994001, 6.0], [0.5, 0.16666666666666666, 0.2, 0.23843421771598572, 0.06653822179014991, 0.061718226716809016, 10.0], [0.0, 0.5, 0.2, 0.9270080747981301, 0.7340119500934446, 0.9208664118043202, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6245522433367736, 0.5549807999846634, 0.47731876228353154, 4.0], [0.0, 0.5, 0.2, 0.28129743184991807, 0.15289973389054012, 0.1372982238097001, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6128802137089431, 0.6362918331129608, 0.5606318800818039, 3.0], [0.5, 0.16666666666666666, 0.2, 0.22632202052091557, 0.10480604219233297, 0.06440056457054544, 10.0], [0.0, 0.5, 0.2, 0.9251183898973955, 0.7855608032719433, 0.9224278479802308, 6.0], [0.5, 0.16666666666666666, 0.2, 0.27766984396818645, 0.20885709359527238, 0.12704769444420638, 7.0], [0.0, 0.5, 0.2, 0.41761277396636504, 0.37952734443150393, 0.35335548121243004, 5.0], [0.0, 0.3333333333333333, 0.0, 0.605215226762188, 0.5839495558446205, 0.4514641300987884, 8.0], [1.0, 0.0, 0.4, 0.27708548357719626, 0.13960825398109417, 0.04491774049741761, 9.0], [0.0, 0.5, 0.2, 0.6034697346852043, 0.49862230286049647, 0.43935531014250456, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5038552607613381, 0.4473864186661832, 0.34931342389848585, 8.0], [0.0, 0.3333333333333333, 0.0, 0.25637484062898436, 0.1286422748264376, 0.10176444909468942, 2.0], [0.0, 0.5, 0.2, 0.6473954222573008, 0.5668874520034936, 0.5782018711987098, 4.0], [0.0, 0.3333333333333333, 0.0, 0.35216441017545985, 0.36209549401585883, 0.2333917437050734, 4.0], [0.5, 0.0, 0.0, 0.2268760245279583, 0.11816954304119605, 0.01806872200906504, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6625280796551516, 0.566491223818356, 0.6663784454503302, 6.0], [0.0, 0.3333333333333333, 0.0, 0.49708578714103574, 0.5077316307948683, 0.4134723733335776, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7690941655030054, 0.611963779966028, 0.6414229968169118, 3.0], [0.0, 0.5, 0.2, 0.4446754902556007, 0.451680635392518, 0.3386129711905986, 5.0], [1.0, 0.0, 0.4, 0.2329093558375326, 0.06709372813955931, 0.021504157980038404, 9.0], [0.5, 0.0, 0.0, 0.2185356080383704, 0.07203914243404455, 0.006472621934357426, 1.0], [0.0, 0.5, 0.2, 0.6928996417946693, 0.7182759469861749, 0.6928101461031843, 6.0], [0.0, 0.5, 0.2, 0.8661890595592253, 0.7418598732319863, 0.8653142922222996, 6.0], [0.0, 0.3333333333333333, 0.0, 0.23191518426325053, 0.23256883652397423, 0.12217453421780121, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2367342602149231, 0.21171703690569504, 0.10146018596091726, 10.0], [0.5, 0.16666666666666666, 0.2, 0.259395300831765, 0.19298490338404398, 0.11825345530510697, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2621577317709915, 0.1564054993341489, 0.10300082658631401, 7.0], [0.0, 0.3333333333333333, 0.0, 0.3148108797280068, 0.055029606249953976, 0.04700694037438187, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7326361483820049, 0.5975909334820014, 0.6636030174010377, 6.0], [0.5, 0.16666666666666666, 0.2, 0.29416853864367676, 0.25066518535407445, 0.16184898823696509, 10.0], [0.0, 0.3333333333333333, 0.0, 0.3997328638212616, 0.5159736630246058, 0.2868673529843543, 8.0], [0.0, 0.3333333333333333, 0.0, 0.48433610588306714, 0.4953839317540428, 0.3132809613263632, 8.0], [0.0, 0.3333333333333333, 0.0, 0.49940805051302295, 0.515472977635457, 0.3440013780001504, 8.0], [0.0, 0.5, 0.2, 0.6069151842632506, 0.5107998315941918, 0.5603807227268863, 6.0], [0.0, 0.3333333333333333, 0.0, 0.26441928237508355, 0.09859403132186144, 0.11815471547385938, 2.0], [0.5, 0.16666666666666666, 0.2, 0.5314036791937343, 0.3431193892087501, 0.28932478456071753, 7.0], [0.5, 0.0, 0.0, 0.25016696011171147, 0.1305019069055332, 0.018106781959474624, 1.0], [0.0, 0.5, 0.2, 0.6955482362940927, 0.5956279037458652, 0.6662630584123165, 6.0], [0.0, 0.5, 0.2, 0.34506101633173447, 0.17025566423391628, 0.1587901307345062, 2.0], [0.0, 0.5, 0.2, 0.5099568939347945, 0.48553854360281956, 0.4099178076100429, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7027654665776213, 0.7386621251563866, 0.6080459158529263, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2300862121304111, 0.14804618231840874, 0.09320808938835667, 7.0], [0.0, 0.3333333333333333, 0.0, 0.21715439256875724, 0.17084456044019355, 0.10455473970264487, 2.0], [0.0, 0.3333333333333333, 0.0, 0.5319804504887379, 0.4049639168100511, 0.47671545931914167, 6.0], [1.0, 0.0, 0.4, 0.3059012810394025, 0.22580925884272648, 0.058165323143327806, 9.0], [0.5, 0.0, 0.0, 0.25475077408779073, 0.08490578639014602, 0.02032610543223477, 1.0], [1.0, 0.0, 0.4, 0.279035881245826, 0.18014267139014603, 0.05564388318522546, 9.0], [1.0, 0.0, 0.4, 0.24131807419100237, 0.08577245343024414, 0.03377538398389487, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4419737720842693, 0.4068929068338442, 0.36403902391010234, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6527988585999636, 0.6403280289610073, 0.5332325268144062, 3.0], [0.0, 0.5, 0.2, 0.5265770141460748, 0.5354856513712279, 0.5295899593540406, 5.0], [0.0, 0.5, 0.2, 0.6430089247768807, 0.5011520842712238, 0.5260848128467256, 4.0], [0.0, 0.3333333333333333, 0.0, 0.18087851375144195, 0.2086885479268307, 0.080512489500297, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2976139882217231, 0.2636607903037948, 0.1501249063297718, 10.0], [0.0, 0.3333333333333333, 0.0, 0.37751199077165926, 0.3355493146041406, 0.22320427405660662, 8.0], [0.0, 0.3333333333333333, 0.0, 0.5863942687147107, 0.5191786795924239, 0.44414182243692113, 3.0], [1.0, 0.0, 0.4, 0.29372837107643746, 0.13495114241731784, 0.07759642615921995, 9.0], [0.0, 0.5, 0.2, 0.31657154999696435, 0.184349150563666, 0.18450570981676812, 2.0], [0.5, 0.16666666666666666, 0.2, 0.24571974986339618, 0.1586056486186661, 0.09963823616378285, 10.0], [0.5, 0.0, 0.0, 0.30476291664136956, 0.22612342158316542, 0.04431397208482069, 1.0], [0.5, 0.0, 0.0, 0.24966607977657698, 0.1039404982720238, 0.015814153787846782, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2821777669843967, 0.2301903725479462, 0.13606187829233396, 7.0], [0.0, 0.3333333333333333, 0.0, 0.32542043591767345, 0.1839541443893679, 0.14260913334215952, 2.0], [0.0, 0.3333333333333333, 0.0, 0.2905864853378665, 0.1826957133887019, 0.13691479003922669, 2.0], [0.0, 0.5, 0.2, 0.641308967275818, 0.6038363624639269, 0.5887119662738457, 4.0], [0.0, 0.3333333333333333, 0.0, 0.4974500637484063, 0.47470038819470006, 0.3841138776663635, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2679406229129987, 0.17805761009757878, 0.11810776858195744, 10.0], [0.0, 0.3333333333333333, 0.0, 0.24878574464209832, 0.1159017169598414, 0.10889464766426675, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7488919919859147, 0.603843087055367, 0.6373197004107409, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3804110254386498, 0.282004762324578, 0.17473720933109116, 7.0], [0.0, 0.3333333333333333, 0.0, 0.670815372472831, 0.7185332473725231, 0.5551568707933862, 3.0], [0.0, 0.3333333333333333, 0.0, 0.39370712160767396, 0.34510216890041895, 0.273424796738028, 4.0], [1.0, 0.0, 0.4, 0.18539402586363915, 0.06841288530893562, 0.016797136779606432, 9.0], [0.0, 0.3333333333333333, 0.0, 0.3365308724424746, 0.31425700480099816, 0.20769654646300545, 3.0], [0.0, 0.3333333333333333, 0.0, 0.34173699228947846, 0.35674752957264466, 0.20207564561237407, 8.0], [0.5, 0.16666666666666666, 0.2, 0.31839293303381705, 0.2011842429345118, 0.14771791826288655, 7.0], [0.0, 0.3333333333333333, 0.0, 0.2830581021188756, 0.2127272725603138, 0.13149635165771198, 2.0], [0.0, 0.5, 0.2, 0.5628528929633901, 0.47514518601297134, 0.3914166977922324, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2570730374597778, 0.27667681625546237, 0.14356057053476598, 10.0], [1.0, 0.0, 0.4, 0.2700655697893268, 0.14726037990310936, 0.03666559065591479, 9.0], [0.0, 0.5, 0.2, 0.481953129743185, 0.5298220266945232, 0.419105071678297, 5.0], [0.5, 0.0, 0.0, 0.2526106490194888, 0.11100588946358168, 0.0068013631453672126, 1.0], [0.0, 0.5, 0.2, 0.253991864489102, 0.0992489584953484, 0.11496031807891821, 2.0], [0.0, 0.5, 0.2, 0.72070608949062, 0.6065921805617224, 0.701027615023718, 6.0], [0.0, 0.3333333333333333, 0.0, 0.791891809847611, 0.7311437493802975, 0.705815848168967, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2678040191852347, 0.1392189976150234, 0.12358593356287795, 10.0], [0.5, 0.16666666666666666, 0.2, 0.4421559103879546, 0.2529006316800067, 0.25871609916069277, 10.0], [0.0, 0.5, 0.2, 0.6578228401432822, 0.6556272091068713, 0.5908777495231013, 4.0], [0.0, 0.3333333333333333, 0.0, 0.3953311881488678, 0.4479455839844644, 0.2433968046548286, 8.0], [0.0, 0.5, 0.2, 0.39226519337016563, 0.4413688982376407, 0.2518805739144025, 8.0], [0.0, 0.5, 0.2, 0.8151599781434036, 0.8800229122087849, 0.7538371482605223, 6.0], [0.0, 0.3333333333333333, 0.0, 0.34864306963754477, 0.2879649612620092, 0.26879656890680936, 5.0], [0.0, 0.5, 0.2, 0.44875842389654547, 0.39507465635059724, 0.3377990067533953, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6111802562078804, 0.590050589765388, 0.46511397150223627, 4.0], [0.0, 0.5, 0.2, 0.6299556796794367, 0.533098908801536, 0.6197302918814027, 4.0], [0.0, 0.6666666666666666, 0.4, 0.5207485884281464, 0.5230381641967085, 0.4976548295534396, 5.0], [0.5, 0.0, 0.0, 0.224561350251958, 0.09417540259023499, 0.013928538833728698, 1.0], [0.5, 0.16666666666666666, 0.2, 0.3013326452552971, 0.33361263933298724, 0.1598837951052962, 7.0], [0.0, 0.5, 0.2, 0.5400097140428632, 0.441811025997546, 0.35987868409976903, 4.0], [0.0, 0.3333333333333333, 0.0, 0.8907929087487098, 0.7138529317300901, 0.8801853571294879, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6195282617934551, 0.5746764572668214, 0.5830520519459078, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5455952886892113, 0.608247214120789, 0.45168724905274066, 3.0], [0.0, 0.5, 0.2, 0.37827090037034783, 0.42613807299867523, 0.23545640138086263, 8.0], [1.0, 0.0, 0.4, 0.24772327120393414, 0.10001510278251945, 0.039940669534028986, 9.0], [0.0, 0.5, 0.2, 0.7445054945054945, 0.780338607054143, 0.7575418223827317, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2825572217837411, 0.16011065032669125, 0.1385436563582524, 7.0], [0.0, 0.5, 0.2, 0.6265633537732985, 0.5474184247547074, 0.5125625417324754, 7.0], [0.5, 0.16666666666666666, 0.2, 0.332584542529294, 0.29183745003944667, 0.16613199757211625, 7.0], [1.0, 0.0, 0.4, 0.22217837411207586, 0.0413534613446432, 0.01303078468603906, 9.0], [0.5, 0.16666666666666666, 0.2, 0.5087578167688666, 0.49823563885268046, 0.33117991233048644, 10.0], [0.0, 0.3333333333333333, 0.0, 0.2900173031388501, 0.0977976334368555, 0.08196566419680279, 2.0], [1.0, 0.0, 0.4, 0.26189970250743727, 0.08667730654316388, 0.028437117326626286, 9.0], [0.0, 0.5, 0.2, 0.7703539554368284, 0.6791129082848586, 0.7224271736775041, 6.0], [0.0, 0.3333333333333333, 0.0, 0.35837229069273274, 0.3724769493614037, 0.22962106552093228, 8.0], [0.5, 0.0, 0.0, 0.22229979964786595, 0.07026075641665715, 0.004978229809121541, 1.0], [0.0, 0.3333333333333333, 0.0, 0.37954586849614474, 0.5330193721422738, 0.3626308277958613, 8.0], [0.5, 0.0, 0.0, 0.2654817558132475, 0.10796582316815166, 0.017889024210257027, 1.0], [0.0, 0.5, 0.2, 0.8981391536640155, 0.8696135766506193, 0.9246217221946126, 4.0], [0.0, 0.3333333333333333, 0.0, 0.3035790176674155, 0.338952212164194, 0.20843092142074346, 8.0], [0.0, 0.3333333333333333, 0.0, 0.701186934612349, 0.7735174343756692, 0.6048550903991361, 6.0], [0.0, 0.5, 0.2, 0.22211766134418068, 0.13774278026636722, 0.12690761397457923, 2.0], [0.0, 0.5, 0.2, 0.8263463056280735, 0.7067989765821685, 0.7425103362382914, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2588944204966305, 0.13685762766345486, 0.10313002862885151, 7.0], [1.0, 0.0, 0.4, 0.21345091372715685, 0.08014231750145769, 0.040870191643174174, 9.0], [0.0, 0.5, 0.2, 0.7579989071701778, 0.7642506930796942, 0.7808910473163028, 6.0], [0.0, 0.6666666666666666, 0.4, 0.6414303928116084, 0.4386278007790906, 0.503370707718091, 4.0], [0.0, 0.5, 0.2, 0.6566844757452492, 0.4708240991754613, 0.5377762311816019, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5611529354623278, 0.6264119107941412, 0.41358027031585826, 8.0], [0.0, 0.3333333333333333, 0.0, 0.397972193552304, 0.395959830144449, 0.25053176075950534, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7115536397304353, 0.6188701967301122, 0.7486018505584547, 6.0], [1.0, 0.0, 0.4, 0.2319075951672636, 0.07579430404360074, 0.029149230035695133, 9.0], [0.0, 0.5, 0.2, 0.4705998421468034, 0.4387234496159529, 0.3328292736662953, 8.0], [0.5, 0.16666666666666666, 0.2, 0.32278701961022394, 0.2653751726205095, 0.16195421921830966, 7.0], [0.0, 0.6666666666666666, 0.4, 0.42841964665169086, 0.4446628249235879, 0.3865349595720506, 5.0], [0.0, 0.6666666666666666, 0.4, 0.34984214680347286, 0.3931362434224119, 0.3422605866687581, 5.0], [0.0, 0.5, 0.2, 0.472223908687997, 0.42929882169406036, 0.4230837640677361, 5.0], [0.0, 0.5, 0.2, 0.6698743245704571, 0.4669528677270957, 0.588097665902644, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7528990346669905, 0.798390504357002, 0.6165612185156853, 3.0], [0.0, 0.5, 0.2, 0.6022706575192762, 0.4983451183093326, 0.41921984275422414, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5483577196284378, 0.46895408353605356, 0.3795930933474006, 3.0], [0.0, 0.3333333333333333, 0.0, 0.40399793576589166, 0.38908858327614315, 0.2540136121082137, 8.0], [0.0, 0.5, 0.2, 0.857279460870621, 0.7395053408902013, 0.83291943118024, 6.0], [0.0, 0.5, 0.2, 0.2793546232772752, 0.20414139614766674, 0.14481052049070167, 2.0], [0.0, 0.5, 0.2, 0.2494839414728917, 0.10323208516745926, 0.11263843134400257, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2432153481877239, 0.203018488268191, 0.12767404050593475, 7.0], [0.5, 0.16666666666666666, 0.2, 0.3111832918462752, 0.2638791911890278, 0.14862374915115026, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2848794851557283, 0.21166627047850886, 0.12040196403586596, 7.0], [0.0, 0.6666666666666666, 0.4, 0.6358599963572339, 0.6088600560886024, 0.57349367541305, 4.0], [0.0, 0.5, 0.2, 0.7139973286382125, 0.5487671574118572, 0.6517176899166587, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2970523951186934, 0.1960207526825311, 0.1395023379924918, 10.0], [0.5, 0.16666666666666666, 0.2, 0.32259729221055194, 0.23705113696488916, 0.1603456970860586, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6217290996296522, 0.5493174649174639, 0.499829513901179, 3.0], [0.0, 0.5, 0.2, 0.4330034606277701, 0.3182721933644403, 0.37485075870930146, 5.0], [0.0, 0.5, 0.2, 0.8552607613381094, 0.7344836957230024, 0.8657801073593809, 6.0], [1.0, 0.0, 0.4, 0.2387377815554611, 0.1311659320556746, 0.02454388267524337, 9.0], [0.0, 0.3333333333333333, 0.0, 0.46865703357416055, 0.42843804573511907, 0.3078137110882929, 5.0], [0.0, 0.3333333333333333, 0.0, 0.36521765527290384, 0.3376112565818087, 0.22368783319506297, 8.0], [0.0, 0.3333333333333333, 0.0, 0.5468550786230344, 0.42855665142301147, 0.48716021970966183, 4.0], [0.0, 0.5, 0.2, 0.6465150871228219, 0.5698667780029206, 0.49333592014970823, 3.0], [0.0, 0.3333333333333333, 0.0, 0.38077530204602034, 0.3526330473307615, 0.22458972013110384, 8.0], [0.0, 0.3333333333333333, 0.0, 0.4362667719021309, 0.4029117791736847, 0.32962325885972615, 5.0], [0.0, 0.5, 0.2, 0.27458108190152397, 0.13386871629576674, 0.13026164206782556, 2.0], [0.0, 0.5, 0.2, 0.7238479752291906, 0.7434098986226165, 0.5884809370453061, 4.0], [0.5, 0.16666666666666666, 0.2, 0.3415548539857932, 0.2984480412893306, 0.1559012591791577, 10.0], [0.0, 0.6666666666666666, 0.4, 0.5403891688422074, 0.5586867279783175, 0.530171089792693, 4.0], [0.0, 0.3333333333333333, 0.0, 0.3905045231012081, 0.40161189869552744, 0.24413933862968953, 8.0], [0.0, 0.5, 0.2, 0.40211583996114375, 0.4031563014235672, 0.2769908848504528, 3.0], [0.0, 0.3333333333333333, 0.0, 0.521310181531176, 0.4693912738070757, 0.4304805457052146, 5.0], [0.0, 0.5, 0.2, 0.5360026713617873, 0.5651759516545388, 0.45999469597998954, 5.0], [1.0, 0.0, 0.4, 0.20479175520611984, 0.09445306746935879, 0.025259779519170744, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6125690607734807, 0.5676796258279098, 0.5977578649056061, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5506951611923987, 0.6492714389034243, 0.4996047225855929, 3.0], [0.0, 0.5, 0.2, 0.3570517879910145, 0.2748751413956604, 0.256163288243118, 2.0], [1.0, 0.0, 0.4, 0.27847428814279634, 0.1328793537164695, 0.04956927993027944, 9.0], [0.5, 0.16666666666666666, 0.2, 0.4802531722421226, 0.3972502029544564, 0.28041258305584593, 7.0], [0.5, 0.16666666666666666, 0.2, 0.35026713617873834, 0.26241044717833784, 0.15832168822990736, 10.0], [0.0, 0.3333333333333333, 0.0, 0.5261368465788355, 0.5436579442193588, 0.46560268465027393, 3.0], [0.5, 0.16666666666666666, 0.2, 0.30930119604152756, 0.2596472828882127, 0.16470840176539106, 10.0], [0.5, 0.0, 0.0, 0.250667840446846, 0.09258122234551508, 0.01358994357070906, 1.0], [0.0, 0.5, 0.2, 0.5168477930908871, 0.5137708295544297, 0.46905095434400534, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6018304899520368, 0.6411056799282792, 0.5116652978340221, 6.0], [0.0, 0.3333333333333333, 0.0, 0.37827090037034783, 0.311785159418625, 0.21108409313485546, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2858205330581022, 0.09761632375924104, 0.09153834571274638, 2.0], [0.0, 0.5, 0.2, 0.889844271750349, 0.6670959221081533, 0.8152246256870616, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7982970068605427, 0.6615009490114989, 0.7053882740410353, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3210339384372533, 0.24562751277303305, 0.15423428650759358, 10.0], [0.0, 0.5, 0.2, 0.9680650840871835, 0.8209776723856609, 0.9695415652721056, 6.0], [0.0, 0.3333333333333333, 0.0, 0.36257664986946764, 0.4059337837250888, 0.24304872899288119, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6860694554064719, 0.5780264410511614, 0.5612839223059404, 3.0], [1.0, 0.0, 0.4, 0.2915882460081355, 0.18171660016043387, 0.0630987882523919, 9.0], [0.5, 0.16666666666666666, 0.2, 0.38643676765223717, 0.25966162915419494, 0.20534315970686604, 7.0], [0.0, 0.6666666666666666, 0.4, 0.48923866189059567, 0.42485358420617814, 0.34796486409478633, 4.0], [0.5, 0.16666666666666666, 0.2, 0.3975320259850647, 0.29184543902360516, 0.2062463632846394, 7.0], [0.0, 0.3333333333333333, 0.0, 0.44693704085969277, 0.37624713534700344, 0.2590612349531276, 8.0], [1.0, 0.0, 0.4, 0.3096047598810029, 0.210681562842236, 0.0669737405158408, 9.0], [0.5, 0.16666666666666666, 0.2, 0.31889381336895156, 0.2771983535289932, 0.15741567497065911, 10.0], [1.0, 0.0, 0.4, 0.33740361848096656, 0.20362743816679907, 0.046411837245541335, 9.0], [0.0, 0.5, 0.2, 0.5084390747374173, 0.42729259775975464, 0.36874425067111627, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2835589824540101, 0.1944513940915099, 0.14031131289634866, 10.0], [0.0, 0.3333333333333333, 0.0, 0.2531798312185052, 0.09118332670892802, 0.12051425468218072, 2.0], [0.5, 0.0, 0.0, 0.23534545564932302, 0.15909881828797007, 0.02615629457214194, 1.0], [0.0, 0.3333333333333333, 0.0, 0.297674700989618, 0.1798245530076834, 0.12687997149704008, 10.0], [0.0, 0.3333333333333333, 0.0, 0.8220053427235747, 0.727332714327157, 0.67160689907797, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4916216380304778, 0.4351934488013025, 0.35616046186756317, 8.0], [0.5, 0.16666666666666666, 0.2, 0.30784408961204535, 0.1738376322956528, 0.12948563593756504, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7071519640580415, 0.5301047632718131, 0.6545714919487831, 6.0], [0.0, 0.5, 0.2, 0.24565903709550121, 0.24115622455696625, 0.1352285572603005, 5.0], [0.0, 0.5, 0.2, 0.8991409143342846, 0.6939166089490227, 0.846071738626443, 6.0], [0.0, 0.5, 0.2, 0.5341205755570396, 0.45501312958819595, 0.41831145095305533, 4.0], [1.0, 0.0, 0.4, 0.19976777366280124, 0.07846111313221656, 0.02558204801907058, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4925019731649565, 0.4648108946349126, 0.3783990400731239, 5.0], [0.5, 0.16666666666666666, 0.2, 0.3026379697650415, 0.22192373763755038, 0.14192566832768458, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5981877238783316, 0.5308408799978364, 0.4812648495919197, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3168295792605184, 0.2991096789269649, 0.16741563306605128, 10.0], [0.0, 0.5, 0.2, 0.7901159613866796, 0.5858451630751922, 0.7021467332255964, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7660964725881854, 0.7011667921959055, 0.7051681651712811, 3.0], [0.5, 0.16666666666666666, 0.2, 0.26009349766255835, 0.21329831893195925, 0.1042412595126722, 7.0], [0.0, 0.5, 0.2, 0.504735595895817, 0.45556464497734944, 0.4532356491791234, 5.0], [0.5, 0.16666666666666666, 0.2, 0.33026227915730677, 0.3325247247581282, 0.17420251720624783, 7.0], [0.0, 0.6666666666666666, 0.4, 0.5687572096411875, 0.4468912146666956, 0.44452809445451563, 4.0], [0.0, 0.5, 0.2, 0.5426507194462995, 0.5688631468577522, 0.49346148958535846, 6.0], [0.5, 0.16666666666666666, 0.2, 0.3323265132657397, 0.20460244741646755, 0.19596617845491193, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7236658369255053, 0.604734667576568, 0.58506948223987, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3118055977172, 0.28634234277659754, 0.13471065981816735, 7.0], [0.0, 0.3333333333333333, 0.0, 0.4773161920951977, 0.3345239910006602, 0.32846362554953384, 3.0], [1.0, 0.0, 0.4, 0.2640929512476474, 0.15201260346661602, 0.03899548085336892, 9.0], [0.0, 0.5, 0.2, 0.597565418007407, 0.4029897688943697, 0.4458894413966053, 3.0], [0.0, 0.6666666666666666, 0.4, 0.42885981421893016, 0.3726402114222851, 0.40441063768605157, 5.0], [1.0, 0.0, 0.4, 0.2417582417582417, 0.10056847591069458, 0.031623426719989696, 9.0], [0.5, 0.16666666666666666, 0.2, 0.3689818468823994, 0.3827501967066611, 0.20554881275856712, 10.0], [0.0, 0.5, 0.2, 0.5674367069394695, 0.5940056031245449, 0.4758531223898646, 5.0], [0.0, 0.6666666666666666, 0.4, 0.6459534940197923, 0.4298704049028375, 0.5106747205098955, 4.0], [0.5, 0.0, 0.0, 0.27162892356262525, 0.11563599670689974, 0.015529575798465556, 1.0], [0.0, 0.3333333333333333, 0.0, 0.344499423228705, 0.29014290244202207, 0.27590474923018077, 5.0], [0.0, 0.5, 0.2, 0.4243974257786412, 0.35160988520310105, 0.3720981931666018, 5.0], [0.0, 0.3333333333333333, 0.0, 0.3834770202173517, 0.36972688813548205, 0.22777494158456416, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2472831036366948, 0.09854143541023927, 0.08626055458012302, 2.0], [0.0, 0.5, 0.2, 0.5338701353894725, 0.5719843179419609, 0.5227016347723755, 6.0], [0.5, 0.16666666666666666, 0.2, 0.26812276121668394, 0.21170335462248097, 0.12807016601394552, 7.0], [0.0, 0.5, 0.2, 0.7520186995325118, 0.6131413110236632, 0.7483725062009514, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6781009046202416, 0.669747968175645, 0.562639340642931, 3.0], [1.0, 0.0, 0.4, 0.18540161495962595, 0.09733485863831595, 0.02412630914795436, 9.0], [0.5, 0.0, 0.0, 0.2335316617084572, 0.10978460617970597, 0.016456329280109275, 1.0], [1.0, 0.0, 0.4, 0.25374901341752176, 0.1114899329016452, 0.03171722634700051, 9.0], [0.5, 0.0, 0.0, 0.2688664926233987, 0.08581920064258837, 0.010641368014204927, 1.0], [0.5, 0.0, 0.0, 0.2817983121850526, 0.11245849304208572, 0.019860573230427836, 1.0], [0.0, 0.5, 0.2, 0.40023374415639607, 0.278075757311727, 0.26901456358278386, 2.0], [0.5, 0.0, 0.0, 0.25110800801408534, 0.12261361502741064, 0.01578760368965084, 1.0], [0.0, 0.3333333333333333, 0.0, 0.27855017910266533, 0.2987592796801305, 0.1465750287330892, 8.0], [0.0, 0.5, 0.2, 0.43757209641187533, 0.44322767561551335, 0.3390418863114781, 5.0], [0.5, 0.16666666666666666, 0.2, 0.2381913666444053, 0.24171894995306875, 0.1360555915071079, 10.0], [0.0, 0.5, 0.2, 0.47969157913909294, 0.4241907245577044, 0.2771335811842284, 8.0], [0.0, 0.5, 0.2, 0.5232529901038189, 0.462154320770033, 0.4624374323686729, 5.0], [0.0, 0.5, 0.2, 0.6779035881245825, 0.5674147602761912, 0.5837471463663093, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7100358205330581, 0.5753535996084592, 0.5487128626106876, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2829366765830855, 0.17037949702019722, 0.12054762927775374, 10.0], [0.0, 0.5, 0.2, 0.5327848946633478, 0.5078732639702558, 0.47368964016526877, 5.0], [0.0, 0.3333333333333333, 0.0, 0.4136664440531845, 0.3566589302549604, 0.22937328504887872, 8.0], [0.0, 0.3333333333333333, 0.0, 0.40399793576589166, 0.3412590366377145, 0.23855085352065408, 8.0], [0.0, 0.3333333333333333, 0.0, 0.4021993200169995, 0.37006716517692373, 0.2990188195721685, 6.0], [0.5, 0.0, 0.0, 0.19475138121546967, 0.026710762374489664, 0.006314077149631722, 1.0], [0.0, 0.5, 0.2, 0.409158521036974, 0.34391548335695765, 0.2626547893012865, 4.0], [0.0, 0.3333333333333333, 0.0, 0.7408627284317891, 0.5821826270618087, 0.5880407680348824, 3.0], [1.0, 0.0, 0.4, 0.24150021249468764, 0.14619267442080353, 0.046121869399618584, 9.0], [0.0, 0.3333333333333333, 0.0, 0.44403800619270223, 0.38949393062887466, 0.2998367854685224, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7172606399125736, 0.6444754136681518, 0.5892349199605599, 3.0], [0.5, 0.0, 0.0, 0.2559346730617448, 0.16000405283779912, 0.019074896617332155, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2665594074433853, 0.25881806023805676, 0.1338531382811386, 7.0], [0.0, 0.5, 0.2, 0.8541982878999455, 0.588724729195511, 0.817655719143225, 6.0], [0.0, 0.3333333333333333, 0.0, 0.39232590613806084, 0.42771616225673453, 0.2497052071555427, 8.0], [0.5, 0.0, 0.0, 0.29547386315342117, 0.16724972947823347, 0.02970467259885298, 1.0], [0.0, 0.6666666666666666, 0.4, 0.63145832068484, 0.5836148096383654, 0.5767412836773561, 4.0], [1.0, 0.0, 0.4, 0.2466532086697833, 0.12428713414929142, 0.028532608330108032, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6405045231012082, 0.5886197492816607, 0.5042955791095783, 10.0], [0.5, 0.0, 0.0, 0.2635465363365916, 0.1533525136293236, 0.05134723516483818, 1.0], [0.0, 0.3333333333333333, 0.0, 0.8643069637544776, 0.7309193797137964, 0.7992644683486845, 6.0], [0.5, 0.0, 0.0, 0.1944933519519155, 0.10978180897570355, 0.011320729419016724, 1.0], [0.0, 0.5, 0.2, 0.4797522919069881, 0.4833459665473191, 0.49095096845498637, 5.0], [0.0, 0.5, 0.2, 0.2446420982332584, 0.11951353599156392, 0.11879313315797375, 2.0], [0.5, 0.0, 0.0, 0.21483212919677003, 0.22458981917057974, 0.021261364108771708, 1.0], [0.0, 0.5, 0.2, 0.2740194887984943, 0.14378992562820844, 0.11246734615259524, 2.0], [0.0, 0.3333333333333333, 0.0, 0.43751138364398034, 0.3727901514459225, 0.24016644713241436, 8.0], [0.0, 0.3333333333333333, 0.0, 0.4495021553032602, 0.4200381268794642, 0.30384622599349254, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6956620727338959, 0.6533654577614814, 0.6145683285242659, 6.0], [0.0, 0.5, 0.2, 0.3834770202173517, 0.4244181104012485, 0.28773879682250036, 8.0], [0.5, 0.16666666666666666, 0.2, 0.28594195859389226, 0.21699683009681883, 0.1426262426523661, 10.0], [1.0, 0.0, 0.4, 0.2942292514115719, 0.1559254892382204, 0.09148830847092458, 9.0], [0.0, 0.5, 0.2, 0.8019777184141826, 0.8575114523430006, 0.7036692293702183, 6.0], [0.0, 0.5, 0.2, 0.5831309574403497, 0.5380823608322669, 0.44767007396500763, 3.0], [0.0, 0.5, 0.2, 0.7457501062473437, 0.71731211948887, 0.6726609768262231, 6.0], [1.0, 0.0, 0.4, 0.28374112075769536, 0.1680036889752421, 0.04302388146273545, 9.0], [0.5, 0.0, 0.0, 0.26560318134903765, 0.15529224745939882, 0.018971768444791558, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6160145103515269, 0.6538333395764195, 0.5149367115557603, 6.0], [1.0, 0.0, 0.4, 0.272448545929209, 0.17580508387447993, 0.05998107381093343, 9.0], [0.0, 0.5, 0.2, 0.8031084937162286, 0.7017054517484819, 0.7859405416771746, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5839505798069334, 0.45391668212840025, 0.5353984438010202, 4.0], [1.0, 0.0, 0.4, 0.19795397972193554, 0.09675420570747013, 0.04123076873808132, 9.0], [0.0, 0.3333333333333333, 0.0, 0.7224667597595775, 0.6599946122742909, 0.5829841544522342, 3.0], [0.0, 0.5, 0.2, 0.733759334588064, 0.6525305700668559, 0.693204037803576, 6.0], [1.0, 0.0, 0.4, 0.24576528443931747, 0.09716966113830151, 0.025217685160931664, 9.0], [0.0, 0.5, 0.2, 0.34876449517333485, 0.15764771926616428, 0.13829780699925384, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2941002367797947, 0.23087440900853964, 0.12551667314642653, 10.0], [0.5, 0.0, 0.0, 0.23579321231254927, 0.05223762228222759, 0.01122619504607289, 1.0], [0.0, 0.3333333333333333, 0.0, 0.4587912087912088, 0.5149096942112832, 0.312684534328218, 8.0], [0.0, 0.3333333333333333, 0.0, 0.5245279582296156, 0.5452380466166621, 0.45761328121794365, 4.0], [0.0, 0.5, 0.2, 0.7282344727096108, 0.5670162505332437, 0.6574840564618619, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7070912512901463, 0.5944814103508231, 0.6014915277602975, 3.0], [0.0, 0.5, 0.2, 0.7276728796065811, 0.6266977129939993, 0.6071685067319221, 4.0], [1.0, 0.0, 0.4, 0.26974682775787756, 0.08609412482688149, 0.05034673155141172, 9.0], [0.0, 0.3333333333333333, 0.0, 0.767712950033392, 0.6921117130664302, 0.6242477607772791, 3.0], [0.5, 0.16666666666666666, 0.2, 0.32233926294699766, 0.2528116862436453, 0.15747026048891166, 7.0], [0.0, 0.5, 0.2, 0.41951004796308655, 0.44441628247081477, 0.3380165829331078, 5.0], [0.5, 0.0, 0.0, 0.26472284621455894, 0.09627943683722298, 0.013163153945523663, 1.0], [0.0, 0.3333333333333333, 0.0, 0.2509865824782952, 0.1354427368934588, 0.13099329209574007, 2.0], [0.0, 0.3333333333333333, 0.0, 0.1975138121546961, 0.21630038280937602, 0.09843950171004913, 2.0], [1.0, 0.0, 0.4, 0.22782466152631906, 0.09606925803648196, 0.026866506479948638, 9.0], [0.5, 0.0, 0.0, 0.22506223058709252, 0.08536138452387135, 0.006067740888438241, 1.0], [0.0, 0.5, 0.2, 0.30470220387347463, 0.17033314537205532, 0.16417113492583124, 2.0], [0.0, 0.3333333333333333, 0.0, 0.5415730678161617, 0.5310995083497211, 0.39252317979420476, 8.0], [0.5, 0.16666666666666666, 0.2, 0.26460142067876863, 0.1917962541468638, 0.11753253026838051, 10.0], [0.0, 0.5, 0.2, 0.47548721996235804, 0.39592705482482415, 0.40861744191127525, 5.0], [0.0, 0.3333333333333333, 0.0, 0.3424351891202719, 0.27107228604513284, 0.20429345342358698, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2975532754538279, 0.17782736347721395, 0.12820980399127532, 10.0], [0.5, 0.0, 0.0, 0.2698075405257725, 0.07693179128939241, 0.013187880392141029, 1.0], [0.5, 0.16666666666666666, 0.2, 0.39200716410661157, 0.282272078961622, 0.21453972861408943, 10.0], [0.5, 0.0, 0.0, 0.24752595470827504, 0.17574931638559232, 0.01327080615299495, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6570032177766985, 0.6559169104395816, 0.5634297881106861, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2501062473438163, 0.1412885330126476, 0.10447260062644581, 7.0], [0.0, 0.5, 0.2, 0.6492775180620485, 0.6203759401210169, 0.5881725901900914, 6.0], [0.0, 0.3333333333333333, 0.0, 0.36245522433367733, 0.34177430845682577, 0.2138944875061962, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7684718596320805, 0.6523568961910763, 0.6290064816906742, 3.0], [0.5, 0.16666666666666666, 0.2, 0.21759456013599657, 0.11298668427059229, 0.056410249897574045, 7.0], [0.0, 0.5, 0.2, 0.8420860907048753, 0.6234529987330149, 0.8528110075648212, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2769109343694979, 0.21313974713233438, 0.11919955477205046, 10.0], [0.0, 0.5, 0.2, 0.3472618541679316, 0.22435145642041993, 0.19139565631458874, 2.0], [0.5, 0.16666666666666666, 0.2, 0.23172545686357834, 0.15623215744975347, 0.09354698380839714, 10.0], [1.0, 0.0, 0.4, 0.25619270232529906, 0.10605273341256435, 0.02723359334927795, 9.0], [1.0, 0.0, 0.4, 0.31047750591949486, 0.14444276196234004, 0.06264657836279787, 9.0], [0.0, 0.5, 0.2, 0.672818893813369, 0.6410553655744671, 0.549030006711117, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5011687207819805, 0.3914720483138728, 0.31212716402962437, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3419343087851376, 0.15920774678019753, 0.17953845879943103, 7.0], [0.5, 0.16666666666666666, 0.2, 0.4802531722421226, 0.3972502029544564, 0.28041258305584593, 10.0], [0.0, 0.5, 0.2, 0.3116082812215409, 0.137287139750763, 0.14293684546715058, 2.0], [0.5, 0.0, 0.0, 0.2418189545261369, 0.15225025985212862, 0.012324162547807835, 1.0], [0.0, 0.3333333333333333, 0.0, 0.5293394450853014, 0.5592130473405093, 0.3867598000624009, 8.0], [0.0, 0.5, 0.2, 0.7758029263554125, 0.6119756610193919, 0.7599176714871518, 6.0], [0.5, 0.16666666666666666, 0.2, 0.26259789933823086, 0.172911220933704, 0.10652900117175026, 7.0], [0.5, 0.16666666666666666, 0.2, 0.35655090765588004, 0.2106524464914829, 0.1454497888228644, 10.0], [0.5, 0.16666666666666666, 0.2, 0.4704632384190394, 0.3042056831005628, 0.27331013974554585, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2873838868314006, 0.23691487922446586, 0.15139938287011986, 7.0], [0.0, 0.3333333333333333, 0.0, 0.27809483334345214, 0.24538381696978767, 0.16442451625242321, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6799222876570944, 0.6727660100213788, 0.5631504099664627, 3.0], [0.0, 0.5, 0.2, 0.8395816890292028, 0.7215060183080252, 0.6957907034934335, 4.0], [0.0, 0.3333333333333333, 0.0, 0.42621880881549395, 0.3785840226999038, 0.2685153887360768, 8.0], [0.0, 0.5, 0.2, 0.4289812397547205, 0.27044691316848, 0.2624663525669108, 2.0], [0.5, 0.0, 0.0, 0.2576953433307024, 0.10849460774296162, 0.008017684741705198, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2818590249529475, 0.22911957318848608, 0.1379756252426168, 7.0], [0.0, 0.3333333333333333, 0.0, 0.27294942626434343, 0.11092048997774875, 0.1005588179961684, 2.0], [0.5, 0.0, 0.0, 0.2553123671908202, 0.1190665908247654, 0.011200061434551555, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6669145771355715, 0.6896923435136892, 0.5492072719595688, 6.0], [0.0, 0.5, 0.2, 0.3807221783741121, 0.4162546329839134, 0.27202169960588213, 5.0], [0.0, 0.5, 0.2, 0.4188725639001881, 0.38257196677890787, 0.36761355097604, 5.0], [0.0, 0.3333333333333333, 0.0, 0.4399095379758364, 0.5022557649050058, 0.41459081817243776, 6.0], [1.0, 0.0, 0.4, 0.2733895938315828, 0.10292281047037824, 0.031028784514375338, 9.0], [0.0, 0.5, 0.2, 0.5991439499726793, 0.5168431484596459, 0.517260934700066, 4.0], [0.0, 0.3333333333333333, 0.0, 0.23529233197741478, 0.12610230763749924, 0.08882205571719784, 2.0], [0.0, 1.0, 0.4, 0.11543014996053665, 0.2241492807311304, 0.20179928844143621, 5.0], [0.0, 0.5, 0.2, 0.2566935826604336, 0.2402785311647271, 0.1851975514993244, 2.0], [0.5, 0.0, 0.0, 0.18007406957683197, 0.1571995944704052, 0.04076534438268409, 1.0], [0.0, 0.3333333333333333, 0.0, 0.4813915366401553, 0.3181546684144578, 0.3003961005989211, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2558132475259547, 0.2577485605895472, 0.13036303493748874, 7.0], [0.5, 0.16666666666666666, 0.2, 0.24351891202719927, 0.13813084993983085, 0.10159157690342842, 7.0], [0.0, 0.3333333333333333, 0.0, 0.3701050330884585, 0.4869631256957737, 0.24944225303425324, 8.0], [0.5, 0.0, 0.0, 0.25135085908566573, 0.16338503896649983, 0.027592807394125125, 1.0], [0.0, 0.3333333333333333, 0.0, 0.5275332402404226, 0.594624922456172, 0.5315505477152029, 3.0], [0.0, 0.3333333333333333, 0.0, 0.48954222573007106, 0.40297373441688067, 0.33012088369346304, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6817892052698682, 0.7251931923202991, 0.5827753762535106, 3.0], [0.0, 0.5, 0.2, 0.8435431971343572, 0.7377153987471876, 0.8930662217837464, 6.0], [0.0, 0.3333333333333333, 0.0, 0.37764859449942323, 0.32322960879427953, 0.22143672805325462, 8.0], [0.0, 0.5, 0.2, 0.4288674033149171, 0.5638012318420227, 0.4336051167534381, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6775317224212251, 0.48969900311958175, 0.675798122465189, 6.0], [0.0, 0.5, 0.2, 0.6112561471677495, 0.6118313012764666, 0.4947600075063415, 4.0], [0.0, 0.5, 0.2, 0.7321276789508834, 0.8002496772990769, 0.6944047024244578, 6.0], [0.0, 0.5, 0.2, 0.7443688907777306, 0.6123493208540552, 0.6050991325185996, 3.0], [0.0, 0.5, 0.2, 0.48655212191123787, 0.42044772654737117, 0.42611514603841466, 5.0], [0.0, 0.3333333333333333, 0.0, 0.48722755145407076, 0.3553505310191595, 0.3072222080571416, 3.0], [0.5, 0.0, 0.0, 0.22129044988161004, 0.09116524377396253, 0.012477509845324638, 1.0], [0.5, 0.16666666666666666, 0.2, 0.32209641187541743, 0.2732621082785096, 0.17565247671047202, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5610922226944326, 0.5168957655622074, 0.3857764089310066, 8.0], [0.0, 0.3333333333333333, 0.0, 0.42151356930362455, 0.3997285539552292, 0.25308833304756584, 8.0], [0.5, 0.16666666666666666, 0.2, 0.304398640033999, 0.17126214909225904, 0.13440600676431702, 7.0], [0.0, 0.5, 0.2, 0.7837866553336166, 0.6544314820959273, 0.6898374842670778, 4.0], [0.0, 0.3333333333333333, 0.0, 0.42107340173638524, 0.41333660530856065, 0.26127461234506477, 8.0], [0.0, 0.5, 0.2, 0.6554398640033998, 0.530761760093716, 0.5590206907051769, 4.0], [1.0, 0.0, 0.4, 0.22349887681379385, 0.053884292483872616, 0.021001603555934167, 9.0], [0.0, 0.5, 0.2, 0.5673152814036792, 0.5390694206628147, 0.4816378535034724, 4.0], [0.0, 0.5, 0.2, 0.4572278550179102, 0.39831063994454363, 0.4022606776823631, 5.0], [0.0, 0.3333333333333333, 0.0, 0.669677008074798, 0.6465752450454895, 0.5831129295243983, 3.0], [0.0, 0.5, 0.2, 0.4001730313885009, 0.3742321313001343, 0.30771773379317874, 5.0], [0.0, 0.3333333333333333, 0.0, 0.35140550057677133, 0.34373149655733065, 0.27485558481335703, 5.0], [0.5, 0.16666666666666666, 0.2, 0.38592070912512905, 0.25447885514734875, 0.19849099103991685, 10.0], [1.0, 0.0, 0.4, 0.2732681682957927, 0.12646297036265589, 0.03249852805117783, 9.0], [0.5, 0.0, 0.0, 0.2726306842328942, 0.08713007921830077, 0.022063094119737302, 1.0], [0.0, 0.3333333333333333, 0.0, 0.720964118754174, 0.6049599201988779, 0.65400248244551, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7697923623337988, 0.6837094278892074, 0.6617803601361663, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6038491894845487, 0.46856094922807034, 0.5634767791695003, 6.0], [0.0, 0.5, 0.2, 0.33294881913666435, 0.1650784351895498, 0.1491577079600785, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7848491287717807, 0.8419344731087299, 0.6416209578239337, 3.0], [0.0, 0.3333333333333333, 0.0, 0.7595622609434765, 0.612948515856887, 0.7285789229253623, 6.0], [1.0, 0.0, 0.4, 0.21615263189848824, 0.03565910980579002, 0.02464141549140724, 9.0], [0.0, 0.5, 0.2, 0.636983182563293, 0.5932530492931837, 0.5775967925673737, 4.0], [0.0, 0.6666666666666666, 0.4, 0.7914364640883979, 0.7475141173861777, 0.774606337036305, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5789873110315099, 0.4935293713731134, 0.47306266263626584, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6453311881488677, 0.5535385799664716, 0.5620227633156286, 3.0], [0.0, 0.3333333333333333, 0.0, 0.290161495962601, 0.26991782485687177, 0.14642168640871228, 4.0], [0.5, 0.0, 0.0, 0.24370105033088454, 0.0781563379779376, 0.025673241443077022, 1.0], [1.0, 0.0, 0.4, 0.22406046991682352, 0.13897991437292356, 0.018630774106356163, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6886952826179344, 0.5473590336151802, 0.5477289711242684, 3.0], [0.5, 0.16666666666666666, 0.2, 0.44147289174913484, 0.24989265553049364, 0.2460520431886504, 7.0], [0.5, 0.0, 0.0, 0.18690425596502944, 0.08510707912362672, 0.00746927024055551, 1.0], [1.0, 0.0, 0.4, 0.24954465424078687, 0.10220353347754148, 0.026300237873482717, 9.0], [1.0, 0.0, 0.4, 0.2715682107947301, 0.08669675276189814, 0.03428774864083835, 9.0], [0.5, 0.16666666666666666, 0.2, 0.24163681622245162, 0.2470657206400294, 0.10357684453177428, 7.0], [0.0, 0.5, 0.2, 0.4916216380304778, 0.417665631684704, 0.42612541691802236, 5.0], [0.5, 0.16666666666666666, 0.2, 0.31889381336895156, 0.2771983535289932, 0.15741567497065911, 7.0], [0.0, 0.3333333333333333, 0.0, 0.35235413757513206, 0.404193167025381, 0.2512341895378679, 5.0], [1.0, 0.0, 0.4, 0.1980146924898306, 0.05812572964377704, 0.01920982095187667, 9.0], [0.0, 0.3333333333333333, 0.0, 0.35014571064294825, 0.18390084917674515, 0.16897008153162538, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4179315159978143, 0.4187279334774595, 0.2598904461446613, 8.0], [0.0, 0.3333333333333333, 0.0, 0.30288840993260885, 0.15393610503710115, 0.05861078767745963, 2.0], [0.0, 0.6666666666666666, 0.4, 0.7864883735049479, 0.6245634675310555, 0.7316385844053411, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6826088276364519, 0.5859522550193371, 0.5820970768375269, 4.0], [0.0, 0.3333333333333333, 0.0, 0.4936251593710158, 0.4309603114260013, 0.31671759942792044, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2890838443324632, 0.25022841183819394, 0.1469594956763209, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2979934430210673, 0.2391967831532372, 0.14226114122437541, 10.0], [1.0, 0.0, 0.4, 0.2497875053123671, 0.09973062148455127, 0.029135999667373683, 9.0], [0.0, 0.6666666666666666, 0.4, 0.782906320199138, 0.6088814942556414, 0.6081029651941114, 4.0], [0.0, 0.5, 0.2, 0.5761565782284015, 0.56892707992196, 0.5236154992446734, 5.0], [0.5, 0.16666666666666666, 0.2, 0.273708335863032, 0.20781490906766584, 0.16327804786383293, 10.0], [0.0, 0.3333333333333333, 0.0, 0.49186448910205827, 0.4837858904495256, 0.3592171710163562, 8.0], [0.0, 0.5, 0.2, 0.40023374415639607, 0.4198361136540436, 0.3864811656979558, 5.0], [0.5, 0.0, 0.0, 0.20774391354501848, 0.05871127768162707, 0.010369666801844585, 1.0], [0.5, 0.16666666666666666, 0.2, 0.4923805476291664, 0.4116008625249179, 0.2630962920950619, 7.0], [0.5, 0.16666666666666666, 0.2, 0.32227855017910273, 0.2297009607385648, 0.1520829893026432, 7.0], [0.0, 0.5, 0.2, 0.6534211644708882, 0.48884813745663913, 0.5944780093591618, 6.0], [0.5, 0.16666666666666666, 0.2, 0.5916611013296096, 0.4373754303870966, 0.32808135133329375, 10.0], [0.0, 0.6666666666666666, 0.4, 0.6666110132960961, 0.6096012586400846, 0.6093044658014839, 4.0], [0.0, 0.3333333333333333, 0.0, 0.814537672272479, 0.6222685311745454, 0.6808924284135979, 3.0], [0.0, 0.3333333333333333, 0.0, 0.7465090158460324, 0.6429486841835824, 0.5868153648534516, 3.0], [0.5, 0.16666666666666666, 0.2, 0.31104668811851127, 0.21409464618050028, 0.1433558215934519, 7.0], [0.5, 0.16666666666666666, 0.2, 0.29202841357537485, 0.19122952366321216, 0.13094163407272713, 10.0], [0.0, 0.3333333333333333, 0.0, 0.3012567542954283, 0.20269921144770714, 0.1318347929591884, 2.0], [0.5, 0.16666666666666666, 0.2, 0.28914455710035813, 0.20463079382975513, 0.1516792466532627, 10.0], [0.0, 0.5, 0.2, 0.7036913362880213, 0.5756344431284951, 0.6897595291648214, 6.0], [0.5, 0.0, 0.0, 0.2497875053123671, 0.066287992113919, 0.013368532822437199, 1.0], [0.0, 0.3333333333333333, 0.0, 0.3664015542468581, 0.3362248746889691, 0.21000813942624935, 8.0], [0.0, 0.5, 0.2, 0.39979357658915676, 0.4336702016944431, 0.3802331075426925, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6365430149960537, 0.6495420189451377, 0.584200979849401, 3.0], [0.0, 0.5, 0.2, 0.5973832797037217, 0.5635129714931926, 0.49753228033050606, 4.0], [0.5, 0.16666666666666666, 0.2, 0.3517849553761157, 0.15814964079344562, 0.1804228398844583, 10.0], [1.0, 0.0, 0.4, 0.25217048145224946, 0.17146883138799687, 0.03249508011619694, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2941002367797947, 0.23087440900853964, 0.12551667314642653, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7665897638273329, 0.6278003058262249, 0.6658889007062732, 3.0], [1.0, 0.0, 0.4, 0.2105670572521401, 0.09929878545755404, 0.04146534644977531, 9.0], [0.5, 0.16666666666666666, 0.2, 0.31022706575192754, 0.28639287610345016, 0.1552643407216122, 7.0], [0.0, 0.3333333333333333, 0.0, 0.2902070305385223, 0.09550887777100764, 0.10993288388541023, 2.0], [0.0, 0.5, 0.0, 0.6509774755631108, 0.5675278704471294, 0.5244725855516891, 3.0], [0.0, 0.3333333333333333, 0.0, 0.367342602149232, 0.361228784593882, 0.2043944947778621, 8.0], [0.5, 0.16666666666666666, 0.2, 0.3295033695586182, 0.20007828780656617, 0.1660477286171902, 10.0], [0.0, 0.5, 0.2, 0.23133082387226034, 0.062244344118845836, 0.036879190656862876, 2.0], [0.5, 0.3333333333333333, 0.4, 0.38235383401129264, 0.36493594872566837, 0.19147759663317404, 10.0], [0.0, 0.5, 0.2, 0.582311335073766, 0.627402318793116, 0.5108861158434813, 6.0], [0.0, 0.5, 0.2, 0.7861013296096169, 0.7618322771192266, 0.7437826603810045, 4.0], [0.0, 0.5, 0.2, 0.8127162892356262, 0.6223311857187421, 0.8247962626068398, 6.0], [0.0, 0.5, 0.2, 0.5485474470281101, 0.5574187257366835, 0.4675434265762729, 5.0], [0.0, 0.3333333333333333, 0.0, 0.35586788901706023, 0.31453694417428557, 0.271445960552347, 5.0], [1.0, 0.16666666666666666, 0.6, 0.22129803897759695, 0.08897237710895677, 0.017893789314471633, 9.0], [0.0, 0.3333333333333333, 0.0, 0.5637332280978691, 0.6062920391595282, 0.48359297852364397, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7848491287717807, 0.5810963441892846, 0.7487822921816711, 6.0], [0.5, 0.0, 0.0, 0.2040404347034181, 0.08633904264096627, 0.0225475617962434, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2707637666201202, 0.15153628765779156, 0.09977488647354561, 7.0], [1.0, 0.0, 0.4, 0.23529233197741478, 0.06524500233061482, 0.020890363261808372, 9.0], [1.0, 0.0, 0.4, 0.30502094590492385, 0.12146736885999514, 0.03886709040147668, 9.0], [1.0, 0.0, 0.4, 0.2084876449517333, 0.09734637238206346, 0.013108996759477763, 9.0], [0.0, 0.5, 0.2, 0.5884053791512354, 0.42298351205759865, 0.34189706643333506, 3.0], [0.0, 0.3333333333333333, 0.0, 0.2379257482848643, 0.07103473428776431, 0.05321185591930416, 2.0], [0.0, 0.3333333333333333, 0.0, 0.5485398579321231, 0.5830707181416529, 0.3993128623895846, 8.0], [1.0, 0.0, 0.4, 0.27627345030659944, 0.09427314933009893, 0.041846185978690296, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6890140246493837, 0.5950288500159628, 0.6122318378265237, 3.0], [0.5, 0.0, 0.0, 0.22744520672697469, 0.09023660029972899, 0.015838693830048056, 1.0], [0.0, 0.5, 0.2, 0.49124218323113344, 0.48213910722953707, 0.4509730251884478, 5.0], [0.5, 0.16666666666666666, 0.2, 0.40237386922469803, 0.2253352811008841, 0.1946745522638432, 7.0], [0.0, 0.5, 0.2, 0.6819865217655273, 0.7178710728977571, 0.5828558959927933, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6112561471677495, 0.49739089737122805, 0.5205300794042554, 3.0], [0.0, 0.5, 0.2, 0.8641096472588184, 0.7460581161937211, 0.8294419839922816, 6.0], [0.5, 0.0, 0.0, 0.17058769959322442, 0.11323860215832968, 0.03614820354979855, 1.0], [0.0, 0.3333333333333333, 0.0, 0.40193370165745845, 0.27414738802705846, 0.2006523667811764, 2.0], [0.0, 0.3333333333333333, 0.0, 0.25204905591645915, 0.1006993017069817, 0.08154436351408176, 2.0], [0.5, 0.16666666666666666, 0.2, 0.24778398397182932, 0.26228739845681515, 0.12213895518483409, 10.0], [0.5, 0.16666666666666666, 0.2, 0.27332888106368763, 0.2060100202487197, 0.12271409725764736, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6071732135268046, 0.5533053312963566, 0.48028839490530856, 4.0], [0.5, 0.16666666666666666, 0.2, 0.4704632384190394, 0.3042056831005628, 0.27331013974554585, 7.0], [0.0, 0.5, 0.2, 0.7889320624127253, 0.7790944728739341, 0.6669949403504577, 4.0], [0.5, 0.16666666666666666, 0.2, 0.26039706150203396, 0.1814975494197254, 0.11588987177552892, 10.0], [0.0, 0.5, 0.2, 0.4012355048266651, 0.4425698311560339, 0.2578993768276309, 8.0], [0.5, 0.0, 0.0, 0.22506223058709252, 0.06461922682611325, 0.01186301274779164, 1.0], [0.0, 1.0, 0.4, 0.14127861089187055, 0.30707896257552253, 0.20561115633725013, 5.0], [0.0, 0.5, 0.2, 0.4636330520308422, 0.5044714965936379, 0.37358274589332746, 5.0], [0.0, 0.5, 0.2, 0.575663286989254, 0.48495108131677594, 0.48244983252847035, 4.0], [0.5, 0.16666666666666666, 0.2, 0.24351891202719927, 0.13813084993983085, 0.10159157690342842, 10.0], [0.5, 0.16666666666666666, 0.2, 0.22858357112500763, 0.16260216796448576, 0.08823221454042673, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7126768259364944, 0.6007756915117412, 0.6584860914571149, 6.0], [0.0, 0.3333333333333333, 0.0, 0.5825693643373202, 0.351181743463208, 0.44410087484209626, 3.0], [0.5, 0.16666666666666666, 0.2, 0.24357962479509443, 0.2525682941771982, 0.10743235566135373, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2584542529293911, 0.20207390920751905, 0.1250094555696451, 10.0], [0.5, 0.0, 0.0, 0.23949669115414965, 0.07292418201861343, 0.022094982283899563, 1.0], [0.0, 0.5, 0.2, 0.5270778944812093, 0.487434864261685, 0.4969149720979256, 5.0], [0.5, 0.16666666666666666, 0.2, 0.2983121850525165, 0.25957542441266435, 0.15611785244129295, 10.0], [0.5, 0.0, 0.0, 0.3070851800133568, 0.1201821313209721, 0.03457201165374179, 1.0], [0.5, 0.16666666666666666, 0.2, 0.29649080201566397, 0.2117503278715123, 0.13237003457538968, 10.0], [1.0, 0.0, 0.4, 0.27376904863092716, 0.15010706474910615, 0.038212036935862746, 9.0], [0.0, 0.3333333333333333, 0.0, 0.49137119786291045, 0.41400283431640106, 0.2538535859798913, 8.0], [0.0, 0.5, 0.2, 0.47084269321838385, 0.47200713987734366, 0.3854957396120148, 8.0], [0.0, 0.5, 0.2, 0.2862607006253415, 0.20114910835696553, 0.17238496105269216, 2.0], [0.0, 0.6666666666666666, 0.4, 0.3025165442292514, 0.270268146403595, 0.21276667348004003, 5.0], [0.0, 0.6666666666666666, 0.4, 0.42590006678404474, 0.46278855145936043, 0.3750799910096836, 5.0], [0.0, 0.5, 0.2, 0.47800679983000416, 0.4119975145288436, 0.41031296681893337, 5.0], [1.0, 0.0, 0.4, 0.23202902070305395, 0.06236968852547162, 0.02710019345474349, 9.0], [0.5, 0.16666666666666666, 0.2, 0.6908354076862364, 0.518402335399749, 0.4130067496726101, 9.0], [0.0, 0.3333333333333333, 0.0, 0.7969082022949426, 0.6855781438176646, 0.6489677151839703, 3.0], [0.0, 0.5, 0.2, 0.4346275271689637, 0.38789996229354884, 0.366820307830076, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5782284014328214, 0.5302144122559804, 0.39013444622463533, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7264889806326271, 0.6954967184099727, 0.5974221088362343, 3.0], [0.5, 0.0, 0.0, 0.2758939955072553, 0.13967226474541322, 0.018207532306033454, 1.0], [0.0, 0.3333333333333333, 0.0, 0.4298615748891992, 0.4746003104515006, 0.27522921496800085, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2628559286017849, 0.22674582066465404, 0.13444262388677503, 10.0], [0.0, 0.3333333333333333, 0.0, 0.2524285107158035, 0.10104143648744536, 0.0905446307848829, 2.0], [0.0, 0.3333333333333333, 0.0, 0.8341175399186449, 0.624674840044962, 0.722752275802226, 1.0], [0.0, 0.5, 0.2, 0.7758181045473864, 0.6927259395089519, 0.7645752211501883, 6.0], [0.0, 0.3333333333333333, 0.0, 0.40319349159128154, 0.4342078794001599, 0.30989343356087495, 4.0], [0.0, 0.5, 0.2, 0.6403072066055491, 0.5695648494981693, 0.5387774758325444, 4.0], [0.5, 0.16666666666666666, 0.2, 0.27012628255722176, 0.22718503820221336, 0.1378022856642255, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2915882460081355, 0.14825768908468637, 0.10880182592590586, 10.0], [1.0, 0.0, 0.4, 0.2650415882460082, 0.12010265823452815, 0.05322010583957291, 9.0], [0.5, 0.0, 0.0, 0.27991621638030467, 0.1719562018035482, 0.027618787412300328, 1.0], [0.0, 0.5, 0.2, 0.39370712160767396, 0.43233240356203034, 0.2697821352795536, 8.0], [0.5, 0.0, 0.0, 0.23026835043409638, 0.11020057725672971, 0.0069114595937616085, 1.0], [0.0, 0.5, 0.2, 0.2924002792787323, 0.10134614806890616, 0.12709854061933196, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4109040131139579, 0.36664706763771365, 0.2397394185522888, 8.0], [0.0, 0.3333333333333333, 0.0, 0.464574099933216, 0.47052262274408413, 0.33723775017810853, 5.0], [1.0, 0.0, 0.4, 0.26503399915002124, 0.10863381808760969, 0.034803871814430364, 9.0], [0.0, 0.5, 0.2, 0.2715682107947301, 0.1456670896778447, 0.12459763981083274, 2.0], [0.0, 0.5, 0.2, 0.31951611923987616, 0.1519615191753385, 0.19686808051430657, 2.0], [0.5, 0.0, 0.0, 0.2786564264464816, 0.1319180126227221, 0.027156175468862988, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2588944204966305, 0.13685762766345486, 0.10313002862885151, 10.0], [1.0, 0.0, 0.4, 0.2928404468459716, 0.22161918851995838, 0.04792497966900369, 9.0], [0.0, 0.3333333333333333, 0.0, 0.682730253172242, 0.7199087936316764, 0.5639068185286874, 6.0], [0.0, 0.5, 0.2, 0.3557312852892963, 0.16862018991192762, 0.09619125634373298, 2.0], [0.0, 0.3333333333333333, 0.0, 0.27677433064173396, 0.052812723186947165, 0.0582301046006869, 2.0], [0.0, 0.3333333333333333, 0.0, 0.5973073887438527, 0.510485308607783, 0.5234410008174499, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3804110254386498, 0.282004762324578, 0.17473720933109116, 10.0], [0.5, 0.16666666666666666, 0.2, 0.44147289174913484, 0.3153841861865887, 0.2385311212526168, 10.0], [1.0, 0.0, 0.4, 0.2645407079108737, 0.11523240820213962, 0.03217887629562814, 9.0], [0.5, 0.16666666666666666, 0.2, 0.332584542529294, 0.29183745003944667, 0.16613199757211625, 10.0], [0.0, 0.3333333333333333, 0.0, 0.4029506405197013, 0.4832943948644352, 0.3471842284014633, 5.0], [1.0, 0.0, 0.4, 0.26108766923684046, 0.16622855929887775, 0.029653283213414785, 9.0], [0.0, 0.5, 0.2, 0.8521947665594074, 0.6745096994073015, 0.7620626786879411, 6.0], [0.5, 0.3333333333333333, 0.2, 0.3061593103029568, 0.222524670297414, 0.1292583440772772, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2578926598263615, 0.233457068876748, 0.1416551147762963, 10.0], [0.0, 0.5, 0.2, 0.2618389897395423, 0.14079318774023067, 0.12232909933766764, 2.0], [1.0, 0.0, 0.4, 0.30225851496569733, 0.12900694970278964, 0.05762039186891024, 9.0], [0.5, 0.16666666666666666, 0.2, 0.284621455892174, 0.20369718461205247, 0.13589350938803674, 7.0], [0.0, 0.5, 0.2, 0.44141217898123963, 0.44426330507919487, 0.39516963902839, 4.0], [0.5, 0.16666666666666666, 0.2, 0.2567542954283285, 0.1752504746081724, 0.1138596826844333, 7.0], [0.0, 0.3333333333333333, 0.0, 0.26071580353348317, 0.10051830989345838, 0.07466779734678655, 2.0], [0.0, 0.6666666666666666, 0.4, 0.41686904255965035, 0.4426318923539269, 0.42219335579439365, 5.0], [0.5, 0.16666666666666666, 0.2, 0.39200716410661157, 0.282272078961622, 0.21453972861408943, 7.0], [1.0, 0.0, 0.4, 0.19933519519154883, 0.09629649554345016, 0.021802747731887503, 9.0], [0.0, 0.3333333333333333, 0.0, 0.30690304170967153, 0.14846874377758978, 0.10900635146891595, 2.0], [0.0, 0.5, 0.2, 0.8464801772812821, 0.73846068408633, 0.854669804784863, 6.0], [0.0, 0.5, 0.2, 0.7461902738145832, 0.612228892745373, 0.6658386516265437, 6.0], [0.0, 0.5, 0.2, 0.47988130653876515, 0.4509927492445978, 0.31822412838857445, 8.0], [0.5, 0.16666666666666666, 0.2, 0.4764282678647319, 0.3043217600030188, 0.25623723127855297, 10.0], [0.0, 0.5, 0.2, 0.6047902373869225, 0.5392815490299816, 0.46081104903804326, 4.0], [0.0, 0.5, 0.2, 0.33747192034484846, 0.2692154441063932, 0.2085993373414512, 2.0], [0.0, 0.3333333333333333, 0.0, 0.701384251108008, 0.6099534026075976, 0.6999337143956202, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2584542529293911, 0.14548061647466004, 0.1154462011743892, 10.0], [0.5, 0.16666666666666666, 0.2, 0.27132535972314986, 0.24887794858765888, 0.13344469677326298, 7.0], [1.0, 0.0, 0.4, 0.2634630562807359, 0.18312156650713826, 0.04925284710662904, 9.0], [0.0, 0.5, 0.2, 0.46489284196466524, 0.4627913698543023, 0.4195423611117885, 4.0], [0.5, 0.16666666666666666, 0.2, 0.26039706150203396, 0.1814975494197254, 0.11588987177552892, 7.0], [0.0, 0.5, 0.2, 0.3825359723149779, 0.3864705627937016, 0.3388983877996373, 5.0], [0.0, 0.5, 0.2, 0.45264404104183115, 0.46925387175592415, 0.48445142016903664, 5.0], [1.0, 0.0, 0.4, 0.2660433489162772, 0.0848350934162655, 0.02491213458704994, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2748315220690911, 0.23812933902585076, 0.12806108351021972, 10.0], [1.0, 0.0, 0.4, 0.3114868556857508, 0.12044035704500808, 0.05503569182576979, 9.0], [1.0, 0.0, 0.4, 0.30005767712950043, 0.1764278926474639, 0.05723317995886795, 9.0], [1.0, 0.0, 0.4, 0.2418189545261369, 0.06078909167291516, 0.020958116958409427, 9.0], [0.0, 0.5, 0.2, 0.7704753809726186, 0.6885328742000801, 0.7091099347107213, 6.0], [0.5, 0.0, 0.0, 0.2618389897395423, 0.08964622072769275, 0.019800436670237596, 1.0], [0.5, 0.16666666666666666, 0.2, 0.29805415578896244, 0.22100102762635224, 0.13332418490621545, 7.0], [0.5, 0.0, 0.0, 0.20862424867949725, 0.0346648168012561, 0.011748566989473196, 1.0], [1.0, 0.0, 0.4, 0.2832402404225609, 0.12389339236771163, 0.029710673723898365, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6767196891506283, 0.6471849648815629, 0.6236332804209355, 3.0], [0.0, 0.3333333333333333, 0.0, 0.40902191730921, 0.4132906280336818, 0.2564213106045288, 8.0], [0.5, 0.16666666666666666, 0.2, 0.29028292149839113, 0.20435646299176555, 0.15230344263005516, 10.0], [0.0, 0.5, 0.2, 0.5021704814522493, 0.42803111612557815, 0.33670230096756376, 5.0], [0.0, 0.5, 0.2, 0.6093740513630016, 0.5195049847411463, 0.5253422961492333, 5.0], [0.0, 0.3333333333333333, 0.0, 0.658505858782102, 0.43814040917259994, 0.53592456573179, 6.0], [0.5, 0.16666666666666666, 0.2, 0.3536063384129682, 0.26418713085692574, 0.1709533434287425, 7.0], [0.0, 0.5, 0.2, 0.543151599781434, 0.5316944369100844, 0.4191805170290653, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5870165745856353, 0.5207363831667683, 0.469977528200646, 6.0], [1.0, 0.0, 0.4, 0.2841812883249347, 0.10626564584448961, 0.050628149555757035, 9.0], [0.5, 0.16666666666666666, 0.2, 0.32227855017910273, 0.2297009607385648, 0.1520829893026432, 10.0], [1.0, 0.0, 0.4, 0.28261034545564934, 0.15591751438135476, 0.04853156520635902, 9.0], [0.0, 0.3333333333333333, 0.0, 0.30872442474652423, 0.15578434345443914, 0.08699477350474438, 2.0], [0.0, 0.3333333333333333, 0.0, 0.4422773359237447, 0.4461636661438415, 0.2509387717393191, 8.0], [0.0, 0.5, 0.2, 0.498330398882885, 0.4612222231726752, 0.41429919664933307, 5.0], [0.5, 0.0, 0.0, 0.2912087912087911, 0.15432911926309448, 0.020475975943368894, 1.0], [0.0, 0.6666666666666666, 0.4, 0.6446481695100479, 0.6650674194328783, 0.5554061105878763, 4.0], [0.0, 0.3333333333333333, 0.0, 0.23579321231254927, 0.06372638897584038, 0.0469603290792334, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2450291421285897, 0.11471249556729696, 0.07420600796304394, 9.0], [0.0, 0.3333333333333333, 0.0, 0.41234594135146624, 0.47653000683994085, 0.26425564646869915, 8.0], [0.0, 0.5, 0.2, 0.6134418068119725, 0.5870833002195475, 0.5794996335514097, 10.0], [0.0, 0.3333333333333333, 0.0, 0.35422864428389284, 0.3430617710444871, 0.2166670850101331, 8.0], [1.0, 0.0, 0.4, 0.2541284682168659, 0.11685452516865177, 0.03883201016830476, 9.0], [0.0, 0.5, 0.2, 0.4376479873717443, 0.39980513094662, 0.278473393026573, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6918295792605185, 0.4865873185125835, 0.5671871190456309, 6.0], [0.0, 0.5, 0.2, 0.4976473802440654, 0.3533621710467786, 0.42300394383408374, 4.0], [0.0, 0.6666666666666666, 0.8, 0.42169570760730984, 0.26124913425299995, 0.18472118154194736, 2.0], [0.5, 0.16666666666666666, 0.2, 0.3011353287596382, 0.15407205904072618, 0.12249818224674945, 10.0], [1.0, 0.0, 0.4, 0.24490012749681267, 0.09160682056944304, 0.036921919737263345, 9.0], [1.0, 0.0, 0.4, 0.2260639912573615, 0.13142277330500238, 0.029003216170067958, 9.0], [0.5, 0.16666666666666666, 0.2, 0.30207637666201204, 0.2001475539238596, 0.14840227906736256, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7016878149474836, 0.6692375420180128, 0.6283118889003504, 3.0], [0.0, 0.3333333333333333, 0.0, 0.3737477991621637, 0.3763030087905881, 0.21565520060252527, 2.0], [1.0, 0.0, 0.4, 0.24822415153906865, 0.15518661769007328, 0.025028378375017795, 9.0], [0.0, 0.3333333333333333, 0.0, 0.3900643555339688, 0.4180937239790717, 0.28842420733513036, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6983030781373324, 0.5616299304896925, 0.5831197707022185, 3.0], [0.5, 0.16666666666666666, 0.2, 0.24571974986339618, 0.1586056486186661, 0.09963823616378285, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6910327241818955, 0.6923486772145887, 0.6109037415568983, 3.0], [0.0, 0.5, 0.2, 0.4367069394693705, 0.4015503884620591, 0.32731605813359776, 5.0], [0.0, 0.5, 0.2, 0.31845364580171204, 0.2633727489280051, 0.2465291736285638, 2.0], [0.0, 0.5, 0.2, 0.7157428207151965, 0.541240213432599, 0.6123857444941135, 6.0], [0.5, 0.16666666666666666, 0.2, 0.36923987614595344, 0.3391191473212404, 0.19065447257603382, 7.0], [0.0, 0.5, 0.2, 0.39841236111954337, 0.4089750932222977, 0.35952296437901454, 5.0], [1.0, 0.0, 0.4, 0.22361271325359725, 0.1385471530082386, 0.03212825731669112, 9.0], [0.5, 0.0, 0.0, 0.28436342662861996, 0.11684677634847325, 0.032491626053276226, 1.0], [0.5, 0.16666666666666666, 0.2, 0.3796521158399612, 0.26216822061355843, 0.18127175111810745, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5062382369012203, 0.5503319105053793, 0.40217831028926787, 3.0], [0.0, 0.5, 0.2, 0.5330429239269018, 0.5012254896853491, 0.4160074404128007, 4.0], [0.0, 0.5, 0.2, 0.33785137514419283, 0.24895982331390293, 0.24994325546927226, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6519337016574586, 0.5627733017529943, 0.6391043983812319, 6.0], [0.0, 0.3333333333333333, 0.0, 0.2320441988950276, 0.30593299895396586, 0.12130289975213025, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2300862121304111, 0.14804618231840874, 0.09320808938835667, 10.0], [0.5, 0.16666666666666666, 0.2, 0.26115597110072253, 0.2977258258195619, 0.14681308862271156, 7.0], [0.0, 0.5, 0.2, 0.47706575192763034, 0.44623717044901745, 0.4240353052598987, 5.0], [1.0, 0.0, 0.4, 0.240938619391658, 0.07976305619514334, 0.016756810168977197, 9.0], [0.0, 0.5, 0.2, 0.8480511201505677, 0.6598734001008507, 0.749690070720865, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7522160160281707, 0.6789441083251438, 0.6105138679359736, 3.0], [0.0, 0.3333333333333333, 0.0, 0.41416732438831894, 0.4597744652556502, 0.32154008230747483, 4.0], [0.0, 0.5, 0.2, 0.6875720964118753, 0.5748462673279813, 0.6569406173562828, 6.0], [0.0, 0.3333333333333333, 0.0, 0.7248497358994597, 0.5630269784887032, 0.6637433550773941, 6.0], [0.0, 0.5, 0.2, 0.5299010381883311, 0.5575709543817775, 0.4053152721792996, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7114929269625403, 0.6237276686260351, 0.5973635527712688, 3.0], [0.5, 0.16666666666666666, 0.2, 0.25513022888713494, 0.13692283924767387, 0.09475166893735905, 7.0], [0.0, 0.3333333333333333, 0.0, 0.38121546961325964, 0.36557154269876474, 0.2375817328926114, 8.0], [0.0, 0.5, 0.2, 0.8317952765466579, 0.6276623316197093, 0.8277863542563059, 6.0], [0.0, 0.6666666666666666, 0.4, 0.5228735353044744, 0.5358904053776559, 0.5035632461963502, 5.0], [0.0, 0.5, 0.2, 0.47687602452795813, 0.4222700767003934, 0.45842048195429663, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5935431971343574, 0.4813288716610947, 0.4983442175205066, 6.0], [1.0, 0.0, 0.4, 0.28932669540404343, 0.21036930022269779, 0.057777273412628054, 9.0], [1.0, 0.0, 0.4, 0.23579321231254927, 0.05649244505219438, 0.011169636939286848, 9.0], [0.0, 0.3333333333333333, 0.0, 0.37657094286928544, 0.3736255830413264, 0.3359220246804516, 5.0], [0.5, 0.16666666666666666, 0.2, 0.23899581081901516, 0.2537900012798621, 0.11866066737630887, 7.0], [0.5, 0.0, 0.0, 0.1854547386315342, 0.06791904459321695, 0.012096175936838873, 1.0], [0.5, 0.0, 0.0, 0.20961842025377933, 0.08984304923660384, 0.018580202627940603, 1.0], [1.0, 0.0, 0.4, 0.25575253475805954, 0.13930619833070643, 0.05231787062443503, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4582296156881792, 0.38070101873816586, 0.3483308127746103, 4.0], [0.5, 0.0, 0.0, 0.22229221055187903, 0.049937013817601475, 0.013083944353696244, 1.0], [1.0, 0.0, 0.4, 0.2678647319531297, 0.0800607394483655, 0.0263544139212604, 9.0], [0.5, 0.0, 0.0, 0.22418189545261363, 0.13845662531506778, 0.010258706059175358, 1.0], [0.0, 0.3333333333333333, 0.0, 0.3760093497662558, 0.3758469020743168, 0.2212210905141817, 8.0], [0.0, 0.6666666666666666, 0.4, 0.5956226094347642, 0.5043340804151932, 0.4836722260261328, 4.0], [0.5, 0.16666666666666666, 0.2, 0.4202537793698015, 0.2178755477177963, 0.21979270492102107, 10.0], [0.0, 0.5, 0.2, 0.7255479327302533, 0.6236719435190263, 0.657738479233869, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6573826725760427, 0.5624381105370118, 0.5796910504325863, 3.0], [0.0, 0.5, 0.2, 0.6101177827697165, 0.4810545337594587, 0.5225703486309, 5.0], [0.0, 0.5, 0.2, 0.6659128164653028, 0.5504827899939974, 0.4993872008457389, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6648503430271385, 0.554891670893494, 0.5209035149252166, 3.0], [0.0, 0.5, 0.2, 0.781904559528869, 0.6852372027934548, 0.8252826772016012, 6.0], [0.5, 0.0, 0.0, 0.2831795276546657, 0.0889537926550919, 0.022334825695338924, 1.0], [0.5, 0.0, 0.0, 0.25173031388500994, 0.12959713855637106, 0.011042706269767522, 1.0], [1.0, 0.0, 0.4, 0.2456514479995143, 0.15853972360615348, 0.0396799790870917, 9.0], [0.5, 0.16666666666666666, 0.2, 0.25387043895331185, 0.19534660532699683, 0.1329258416555073, 7.0], [0.0, 0.5, 0.2, 0.8083297917552061, 0.8152593468306855, 0.7673995290720773, 6.0], [1.0, 0.0, 0.4, 0.2427600024285107, 0.11892438549401367, 0.03870125221978427, 9.0], [0.5, 0.0, 0.0, 0.18878635176977723, 0.15656379565156137, 0.021611152263973938, 1.0], [0.5, 0.0, 0.0, 0.24370105033088454, 0.09530404615064506, 0.027393838946609277, 1.0], [0.5, 0.16666666666666666, 0.2, 0.3489010989010988, 0.3200814263259661, 0.1858079900150926, 7.0], [0.0, 0.5, 0.2, 0.6537399065023374, 0.6008373076999066, 0.5595737045815684, 4.0], [0.0, 0.5, 0.2, 0.6050938012263979, 0.5764944491499712, 0.5491445976122249, 5.0], [0.5, 0.16666666666666666, 0.2, 0.460172424260822, 0.2700827115564415, 0.28034786650158866, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5400097140428632, 0.513255070343712, 0.40508976595269314, 6.0], [1.0, 0.0, 0.4, 0.2714999089308482, 0.18617786506215855, 0.04642305452179189, 9.0], [0.5, 0.0, 0.0, 0.23208214437496197, 0.1340603954064005, 0.018301311744191404, 1.0], [1.0, 0.0, 0.4, 0.22135875174549213, 0.1013324234038132, 0.020964809220969757, 9.0], [0.0, 0.3333333333333333, 0.0, 0.24966607977657698, 0.09748416999741731, 0.07987755802134391, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2696861149899824, 0.2407699419860597, 0.15037532655539315, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7214042863214133, 0.726240434418779, 0.6671554146173858, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4063809119057738, 0.46329918952638677, 0.31345527980377685, 8.0], [0.5, 0.0, 0.0, 0.16744581385465357, 0.07416487620299111, 0.00561694028305082, 1.0], [1.0, 0.0, 0.4, 0.2533088458502822, 0.10833802789164167, 0.039488896517078036, 9.0], [0.0, 0.5, 0.2, 0.896378483395058, 0.6652491458656347, 0.8864613770542361, 6.0], [0.5, 0.0, 0.0, 0.1803169206484124, 0.022906508421961055, 0.012898318190914868, 1.0], [0.0, 0.3333333333333333, 0.0, 0.3546005099872503, 0.1643672813901544, 0.11160315458305925, 2.0], [0.0, 0.3333333333333333, 0.0, 0.38504037399065016, 0.48686838806930627, 0.25797556635736757, 8.0], [0.0, 0.5, 0.2, 0.3303229919252019, 0.1473654304534242, 0.1688442568188712, 2.0], [0.5, 0.0, 0.0, 0.18909750470523953, 0.0942575104168124, 0.016241807870330284, 1.0], [1.0, 0.0, 0.4, 0.27382976139882215, 0.08817374711166612, 0.045463616296499684, 9.0], [0.0, 0.5, 0.2, 0.8096502944569244, 0.6515667072513185, 0.6991175715774742, 3.0], [0.0, 0.3333333333333333, 0.0, 0.7100358205330581, 0.5889509777919733, 0.5685178243832554, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6942808572642828, 0.5953541733178258, 0.5695947341496485, 3.0], [0.0, 0.3333333333333333, 0.0, 0.5432123125493291, 0.522552665647472, 0.39310737509845683, 8.0], [0.0, 0.5, 0.2, 0.6852422439439014, 0.4380770694546955, 0.6198134822680951, 6.0], [0.0, 0.3333333333333333, 0.0, 0.42259122093376233, 0.4275190794565505, 0.2966692083435063, 5.0], [0.0, 0.5, 0.2, 0.3160099568939347, 0.29997661438562884, 0.2828714487133108, 5.0], [0.0, 0.5, 0.2, 0.7898731103150993, 0.5388123251222141, 0.7251673666977495, 4.0], [1.0, 0.0, 0.4, 0.2271416428874993, 0.09710580577420465, 0.023405731093576975, 9.0], [0.0, 0.6666666666666666, 0.4, 0.6152631898488252, 0.5816363034528115, 0.5174999720946447, 4.0], [0.0, 0.3333333333333333, 0.0, 0.268115172120697, 0.08319983100367094, 0.06642737628722778, 2.0], [0.5, 0.0, 0.0, 0.26798615748892, 0.07488393422278719, 0.011385101600537118, 1.0], [0.0, 0.5, 0.2, 0.27753324024042253, 0.23465949222454643, 0.199477371397827, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6578228401432822, 0.6897804766307062, 0.6500453371749089, 6.0], [0.5, 0.16666666666666666, 0.2, 0.4591099508226581, 0.3993170471027752, 0.2421731540648014, 7.0], [0.5, 0.0, 0.0, 0.20862424867949725, 0.08723611867912164, 0.00638007959062844, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2707637666201202, 0.15153628765779156, 0.09977488647354561, 10.0], [0.0, 0.5, 0.2, 0.4575465970493594, 0.45415152011897103, 0.36352629897046546, 4.0], [0.0, 0.5, 0.2, 0.6862515937101572, 0.5038457140254897, 0.6414031163222796, 6.0], [0.0, 0.5, 0.2, 0.24031631352073338, 0.11378149283514205, 0.11389109389392016, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7626282557221784, 0.5842299684822215, 0.6484347937566525, 6.0], [0.0, 0.6666666666666666, 0.4, 0.47286139275089545, 0.44478317533215866, 0.4125620736808547, 5.0], [0.5, 0.0, 0.0, 0.193992471616781, 0.09240881286245378, 0.0073836613080128935, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2948515572824965, 0.1483521017834161, 0.14555167118139994, 7.0], [0.5, 0.0, 0.0, 0.2455831461356322, 0.11014576336011568, 0.01473485389992136, 1.0], [0.0, 0.5, 0.2, 0.6387438528322505, 0.5699690807947584, 0.5557790105668178, 4.0], [0.5, 0.0, 0.0, 0.20968672211766132, 0.03466108719591955, 0.010761768148937955, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6863730192459475, 0.7138510669274216, 0.6039139652752403, 6.0], [1.0, 0.0, 0.4, 0.24320016999575006, 0.1299388071361675, 0.0947355751809991, 9.0], [0.0, 0.5, 0.2, 0.2813657337137999, 0.14703804456679181, 0.12176839027390479, 2.0], [0.5, 0.0, 0.0, 0.24326088276364521, 0.08491752617058064, 0.006481110365746287, 1.0], [0.0, 0.5, 0.2, 0.5238145832068484, 0.3546779517931416, 0.40050661976482677, 5.0], [0.0, 0.5, 0.2, 0.6347823447270962, 0.6003725268257692, 0.5244994147128917, 4.0], [0.0, 0.3333333333333333, 0.0, 0.368602392083055, 0.3384690940638182, 0.31732772008919913, 5.0], [1.0, 0.0, 0.4, 0.2312777002003521, 0.13956084278598163, 0.05019834998956127, 9.0], [0.5, 0.16666666666666666, 0.2, 0.3657792483759335, 0.28789122385649973, 0.18307923123463102, 10.0], [0.5, 0.16666666666666666, 0.2, 0.42621880881549395, 0.23113464787181984, 0.2628209305655756, 7.0], [1.0, 0.0, 0.4, 0.25292939105093803, 0.09512919264590496, 0.02460056813606544, 9.0], [0.0, 0.5, 0.2, 0.5057980693339809, 0.4783690766441597, 0.44358496768861005, 5.0], [0.5, 0.0, 0.0, 0.20830550664804803, 0.09372470662716047, 0.010488389219350205, 1.0], [0.0, 0.5, 0.2, 0.553017424564386, 0.5429128637259638, 0.4327067063694726, 4.0], [0.5, 0.16666666666666666, 0.2, 0.45696982575435613, 0.3632959183517061, 0.25419378693298106, 3.0], [0.0, 0.5, 0.2, 0.44673972436403364, 0.4448765284839178, 0.33366898654059285, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6190880942262157, 0.49712741629421764, 0.5081652006133554, 6.0], [1.0, 0.0, 0.4, 0.21477141642887496, 0.13512478097486513, 0.03400367405991434, 9.0], [0.0, 0.5, 0.2, 0.6120605913423594, 0.5651572400550375, 0.47304677264785117, 4.0], [0.5, 0.16666666666666666, 0.2, 0.21144739238661886, 0.22695070879418838, 0.11072557032856045, 10.0], [0.5, 0.0, 0.0, 0.2430635662679861, 0.15023563017852268, 0.024274805817259153, 1.0], [0.0, 0.5, 0.2, 0.5909097808269079, 0.5714118941592538, 0.5426258664584763, 5.0], [0.5, 0.16666666666666666, 0.2, 0.2688057798555035, 0.12632834432456747, 0.12625090170367834, 10.0], [0.0, 0.3333333333333333, 0.0, 0.297674700989618, 0.1798245530076834, 0.12687997149704008, 7.0], [0.5, 0.16666666666666666, 0.2, 0.26115597110072253, 0.2977258258195619, 0.14681308862271156, 10.0], [0.0, 0.3333333333333333, 0.0, 0.35486612834679127, 0.3185334847110445, 0.23084138107920943, 5.0], [0.5, 0.16666666666666666, 0.2, 0.316131382429725, 0.21828362870171186, 0.15493795988689438, 7.0], [0.0, 0.5, 0.2, 0.4365096229737114, 0.37012730506297675, 0.36426745616411904, 5.0], [0.0, 0.5, 0.2, 0.7708548357719629, 0.6605159164474883, 0.7487294699040236, 6.0], [0.0, 0.3333333333333333, 0.0, 0.264980875478113, 0.16351544800764517, 0.12353117695324035, 2.0], [0.0, 0.3333333333333333, 0.0, 0.7223453342237872, 0.6091061888498803, 0.5578939708373633, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4562943962115233, 0.4508749700033423, 0.30378402120341014, 6.0], [0.0, 0.5, 0.2, 0.37827090037034783, 0.42613807299867523, 0.23545640138086263, 8.0], [0.5, 0.16666666666666666, 0.2, 0.3013326452552971, 0.33361263933298724, 0.1598837951052962, 10.0], [0.0, 0.6666666666666666, 0.4, 0.5803078137332282, 0.5284058008953442, 0.47243527874104885, 4.0], [0.0, 0.5, 0.2, 0.8088913848582358, 0.7359192052770469, 0.7443726082933955, 4.0], [0.5, 0.16666666666666666, 0.2, 0.26988343148564153, 0.2076313319595342, 0.13426132857323558, 10.0], [0.0, 0.3333333333333333, 0.0, 0.5905986278914456, 0.49148335791823716, 0.4824691850371809, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6165836925505435, 0.5404556400917855, 0.4832934964778065, 3.0], [1.0, 0.0, 0.4, 0.2222390868799708, 0.14630950713343185, 0.03238045208049287, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6123186206059134, 0.4748743304890455, 0.4871402775488388, 3.0], [0.0, 0.5, 0.2, 0.6802258514965698, 0.5903240023293365, 0.6077820300814726, 4.0], [0.0, 0.3333333333333333, 0.0, 0.6341600388561716, 0.6719531043945707, 0.6009658527532068, 3.0], [0.0, 0.3333333333333333, 0.0, 0.22399975714892836, 0.18876479137283525, 0.09995990781375132, 2.0], [0.5, 0.0, 0.0, 0.22631443142492866, 0.1152650916943603, 0.025272471659617355, 1.0], [0.0, 0.5, 0.2, 0.35730222815858165, 0.1897378863743101, 0.1974228194274477, 2.0], [0.0, 0.5, 0.2, 0.8262704146682047, 0.6425841505801596, 0.8230131935872999, 6.0], [0.0, 0.3333333333333333, 0.0, 0.43042316799222885, 0.4107303528611396, 0.2578553987049925, 8.0], [0.5, 0.16666666666666666, 0.2, 0.3796521158399612, 0.26216822061355843, 0.18127175111810745, 10.0], [0.0, 0.3333333333333333, 0.0, 0.35228583571125, 0.297914644153375, 0.1970561384594371, 8.0], [1.0, 0.0, 0.4, 0.255122639791148, 0.14540747241545396, 0.052700044438788625, 9.0], [0.5, 0.16666666666666666, 0.2, 0.4554064719810577, 0.2579894309342042, 0.25354071991907823, 7.0], [0.5, 0.0, 0.0, 0.21357233926294697, 0.08958959853758218, 0.013279494034381648, 1.0], [0.0, 0.3333333333333333, 0.0, 0.5912816465302654, 0.5482664578954153, 0.49019109261751664, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4265982636148381, 0.43073376615638725, 0.3329966337366524, 5.0], [1.0, 0.0, 0.4, 0.24684293606945548, 0.11074116518479263, 0.01947651479006893, 9.0], [0.0, 0.3333333333333333, 0.0, 0.531843846760974, 0.46613896612613515, 0.3964232023718216, 8.0], [0.0, 0.3333333333333333, 0.0, 0.41592799465727653, 0.4595259449818652, 0.29852348232451814, 8.0], [1.0, 0.0, 0.4, 0.2277639487584239, 0.04527196977883841, 0.04266537675884327, 9.0], [0.5, 0.16666666666666666, 0.2, 0.3300042498937527, 0.21014081245030417, 0.19387281423994235, 7.0], [0.5, 0.16666666666666666, 0.2, 0.45420739481512956, 0.3339118907157261, 0.25705283800114404, 10.0], [0.5, 0.16666666666666666, 0.2, 0.1781160828122154, 0.0, 0.01749390763164487, 9.0], [0.5, 0.16666666666666666, 0.2, 0.24490012749681267, 0.1965517128604542, 0.09779748710564984, 10.0], [0.0, 0.3333333333333333, 0.0, 0.632399368587214, 0.5825311544423284, 0.5076606696156352, 3.0], [0.5, 0.16666666666666666, 0.2, 0.34519762005949844, 0.3103957401578029, 0.18713724177576657, 10.0], [0.0, 0.3333333333333333, 0.0, 0.4724819379515513, 0.41348126878828434, 0.3571921198606223, 3.0], [0.0, 0.3333333333333333, 0.0, 0.23416155667536875, 0.09856894124959675, 0.061360846646075475, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6723180134782345, 0.5557009104877837, 0.5843487504291232, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3575678465181226, 0.3072210548879308, 0.17809318836300714, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7156821079473014, 0.5250324505684785, 0.5401925244234208, 3.0], [0.5, 0.0, 0.0, 0.23623337987978862, 0.05168205942364646, 0.010012977958505743, 1.0], [0.0, 0.5, 0.2, 0.70018517394208, 0.5221197630098577, 0.6434355684077406, 6.0], [0.0, 0.5, 0.2, 0.3048388076012386, 0.2858876770442065, 0.14423747668063625, 2.0], [0.0, 0.5, 0.2, 0.3220356991075223, 0.2013825194909494, 0.166523036520034, 2.0], [0.5, 0.16666666666666666, 0.2, 0.24420193066601903, 0.23302319851956713, 0.10465150047029739, 10.0], [0.0, 0.3333333333333333, 0.0, 0.4810727946087061, 0.4993042060998558, 0.3285428942871998, 8.0], [0.5, 0.16666666666666666, 0.2, 0.28920526986825335, 0.18985375843101845, 0.14458661880990303, 10.0], [0.5, 0.16666666666666666, 0.2, 0.3437556918219901, 0.2777023941502158, 0.1666081157118302, 10.0], [0.0, 0.5, 0.2, 0.8135966243701049, 0.6515710655211908, 0.6775376783336248, 4.0], [0.5, 0.16666666666666666, 0.2, 0.31751259789933817, 0.18215141704624174, 0.11980892516795152, 10.0], [0.5, 0.0, 0.0, 0.17297067573310668, 0.08180305142322625, 0.014249523872402765, 1.0], [0.5, 0.16666666666666666, 0.2, 0.2873838868314006, 0.23691487922446586, 0.15139938287011986, 10.0], [0.5, 0.16666666666666666, 0.2, 0.35192155910387946, 0.345173455220603, 0.20378485100989266, 7.0], [0.5, 0.0, 0.0, 0.20974743488555647, 0.05396641443774305, 0.005051110569353002, 1.0], [0.0, 0.3333333333333333, 0.0, 0.6397456135025196, 0.5632149633122326, 0.5388699076396696, 3.0], [0.0, 0.3333333333333333, 0.0, 0.32812215408900486, 0.3159877041410606, 0.1832715736671656, 8.0], [1.0, 0.0, 0.4, 0.264980875478113, 0.07371929431996165, 0.042729570775131856, 9.0], [0.0, 0.5, 0.2, 0.5657519276303807, 0.5043602512253679, 0.4591435650362062, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5396302592435188, 0.5758524201949399, 0.4237864276157414, 4.0], [0.0, 0.5, 0.2, 0.4824615991743064, 0.4146704336716569, 0.30396387430080024, 4.0], [0.0, 0.3333333333333333, 0.0, 0.22243640337562992, 0.2369768415313084, 0.09679843586664479, 2.0], [0.0, 0.5, 0.2, 0.6010867585453221, 0.4675988028786253, 0.5011724888173238, 4.0], [0.5, 0.16666666666666666, 0.2, 0.306402161374537, 0.2349358573927195, 0.1526582895508106, 10.0], [0.5, 0.16666666666666666, 0.2, 0.513584481816526, 0.35305197101200986, 0.2728716397643864, 7.0], [0.0, 0.3333333333333333, 0.0, 0.45276546657762123, 0.46731779689472086, 0.3252366058110498, 8.0], [0.5, 0.0, 0.0, 0.21526470766802255, 0.06140675104762177, 0.012435674254003428, 1.0], [0.0, 0.3333333333333333, 0.0, 0.741864489102058, 0.668736708292288, 0.5009177844830331, 3.0], [0.0, 0.3333333333333333, 0.0, 0.7965970493594804, 0.7481473591649992, 0.7591110188350737, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6466972254265072, 0.6252907405716972, 0.43867467261685367, 8.0], [0.5, 0.0, 0.0, 0.26189970250743727, 0.14264869464978722, 0.026795212446398396, 1.0], [0.0, 0.5, 0.2, 0.5929816040313277, 0.6473751606264379, 0.4401604090091421, 8.0], [0.5, 0.16666666666666666, 0.2, 0.3011353287596382, 0.15407205904072618, 0.12249818224674945, 7.0], [0.5, 0.0, 0.0, 0.20692429117843486, 0.14057610069324109, 0.01800556479295774, 1.0], [0.0, 0.5, 0.2, 0.6252504401675673, 0.5321904108470373, 0.505945546137627, 4.0], [0.0, 0.5, 0.2, 0.2928480359419586, 0.27351983954729264, 0.2580364279911893, 5.0], [0.0, 0.5, 0.2, 0.762385404650598, 0.6331594873400349, 0.7436534275407035, 6.0], [0.5, 0.16666666666666666, 0.2, 0.22788537429421402, 0.09779067574508178, 0.0982537595453549, 10.0], [0.0, 0.3333333333333333, 0.0, 0.6686145346366341, 0.6014834900790628, 0.49885928453381784, 3.0], [0.5, 0.0, 0.0, 0.24049845182441865, 0.10216170962678733, 0.01600123053179347, 1.0], [0.0, 0.5, 0.2, 0.7801438892599114, 0.6825085867982186, 0.7558000860307866, 4.0], [0.0, 0.6666666666666666, 0.4, 0.49746524194038017, 0.5296987519363132, 0.34136775502271244, 5.0], [0.5, 0.16666666666666666, 0.2, 0.3387317102786715, 0.25924760057995094, 0.17115663871562345, 7.0], [0.0, 0.3333333333333333, 0.0, 0.34581992593042327, 0.29545267374876816, 0.1961019668723589, 8.0], [0.5, 0.0, 0.0, 0.23755388258150684, 0.07472030485228932, 0.011661831407985965, 1.0], [0.5, 0.16666666666666666, 0.2, 0.29899520369133625, 0.16808375540798962, 0.1369827335668321, 7.0], [0.0, 0.5, 0.2, 0.42301621030902803, 0.4289510854419455, 0.33463898450849205, 5.0], [0.5, 0.0, 0.0, 0.19487280675125976, 0.037760848367674966, 0.010393653353348676, 1.0], [0.0, 0.5, 0.2, 0.7543561410964726, 0.6135144764030733, 0.7499543422456953, 6.0], [0.5, 0.0, 0.0, 0.24608402647076671, 0.15057861966020913, 0.011387027212951031, 1.0], [0.5, 0.0, 0.0, 0.20654483637909046, 0.11274618829919822, 0.010525222104671907, 1.0], [0.0, 0.5, 0.2, 0.7514571064294822, 0.566467716002901, 0.6411258628821886, 4.0], [0.5, 0.16666666666666666, 0.2, 0.26630137817983124, 0.2670702288004801, 0.15070157847650623, 7.0], [0.0, 0.3333333333333333, 0.0, 0.48082235444113897, 0.39284864705635014, 0.3475095952233074, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4518244186752474, 0.3990104000821814, 0.32215152322551177, 5.0], [0.0, 0.5, 0.2, 0.6867524740452916, 0.6296757816643547, 0.536050965927888, 3.0], [0.0, 0.6666666666666666, 0.4, 0.460309027988586, 0.45901507381450524, 0.43478478202052856, 5.0], [0.0, 0.3333333333333333, 0.0, 0.8030477809483334, 0.6537260215955876, 0.7135124630682785, 6.0], [0.0, 0.5, 0.2, 0.4903618480966548, 0.4113175114103849, 0.4397194229347059, 5.0], [0.0, 0.5, 0.2, 0.6954192216623155, 0.6331335566938404, 0.7184101561589017, 6.0], [0.0, 0.3333333333333333, 0.0, 0.6512355048266651, 0.5639811499812825, 0.6119807808307223, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2603363487341388, 0.20687157320877292, 0.11535380036772179, 10.0], [0.0, 0.3333333333333333, 0.0, 0.8564143039281161, 0.8919287448446244, 0.7313960069986201, 3.0], [1.0, 0.0, 0.4, 0.17466304413818226, 0.047205480536372975, 0.013334236314086784, 9.0], [0.0, 0.3333333333333333, 0.0, 0.44755934673061737, 0.4134702353724968, 0.30211647745137066, 8.0], [0.0, 0.5, 0.2, 0.751335680893692, 0.6115834873673287, 0.6679449113141432, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2594560135996599, 0.24559836816769423, 0.11955508609181857, 7.0], [0.5, 0.16666666666666666, 0.2, 0.35192155910387946, 0.345173455220603, 0.20378485100989266, 10.0], [0.5, 0.16666666666666666, 0.2, 0.2603363487341388, 0.29119552703911245, 0.1455122647157063, 10.0], [0.0, 0.6666666666666666, 0.4, 0.747192034484852, 0.6455759368519614, 0.6855583092971719, 4.0], [0.0, 0.3333333333333333, 0.0, 0.2066662619148807, 0.06650503677902986, 0.07259866507365179, 2.0], [0.0, 0.5, 0.2, 0.4916216380304778, 0.47953750972514025, 0.39588712809344107, 5.0], [0.0, 0.3333333333333333, 0.0, 0.40117479205876994, 0.3542909911121739, 0.22703905368336674, 8.0], [0.5, 0.16666666666666666, 0.2, 0.2575663286989253, 0.05526108900845124, 0.04247787843792844, 9.0], [0.0, 0.3333333333333333, 0.0, 0.5219324874021006, 0.45275584953102227, 0.3311094201942047, 8.0], [1.0, 0.0, 0.4, 0.22688361362394502, 0.13220701465443177, 0.038448179125589045, 9.0], [0.0, 0.3333333333333333, 0.0, 0.5453524376176309, 0.5617138112915343, 0.4375573416919065, 3.0], [0.0, 0.5, 0.2, 0.3554884342177161, 0.38806414262847155, 0.3474782848266745, 5.0], [0.0, 0.3333333333333333, 0.0, 0.7958988525286868, 0.6926834304844903, 0.6854532626821425, 3.0], [0.0, 0.5, 0.2, 0.5782359905288083, 0.5167582434290658, 0.403873849355777, 4.0], [0.0, 0.5, 0.2, 0.7011262218444538, 0.5142080904619165, 0.6160157274738643, 6.0], [0.5, 0.16666666666666666, 0.2, 0.2956104668811851, 0.18939893023475848, 0.12786260482183529, 10.0], [0.0, 0.3333333333333333, 0.0, 0.30168933276668075, 0.06917537062723472, 0.050254669979458405, 2.0], [0.0, 0.3333333333333333, 0.0, 0.33829154271143214, 0.36463882350051735, 0.2752171697163354, 5.0], [0.0, 0.3333333333333333, 0.0, 0.5563262704146683, 0.4912888392217221, 0.3769606666924547, 8.0], [0.0, 0.3333333333333333, 0.0, 0.5789873110315099, 0.534900809698025, 0.43885144497463935, 3.0], [0.0, 0.6666666666666666, 0.4, 0.4239572582114019, 0.3904066950258417, 0.37553346765588574, 5.0], [0.0, 0.5, 0.2, 0.37104608099083236, 0.22142669002633397, 0.1982502931651884, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6954799344302106, 0.5898853710744342, 0.6024150410042005, 3.0], [0.5, 0.16666666666666666, 0.2, 0.41022099447513816, 0.3549010782578638, 0.2097358171701868, 10.0], [0.0, 0.3333333333333333, 0.0, 0.3456833222026593, 0.10339722615830195, 0.11158603357112827, 2.0], [0.5, 0.0, 0.0, 0.22185963208062662, 0.10524493480215454, 0.016049391759950196, 1.0], [0.0, 0.3333333333333333, 0.0, 0.3001335680893692, 0.15431687090011392, 0.14257851082505532, 2.0], [0.5, 0.0, 0.0, 0.2543106065205512, 0.1070624604846373, 0.023168987387610314, 1.0], [0.0, 0.5, 0.2, 0.7808344969947181, 0.7459929046095021, 0.8292340691363471, 4.0], [0.0, 0.3333333333333333, 0.0, 0.23246159917430637, 0.017954715654712638, 0.031149464587977668, 2.0], [0.5, 0.16666666666666666, 0.2, 0.2541284682168659, 0.18015947580510022, 0.1181576443575863, 7.0], [0.0, 0.6666666666666666, 0.4, 0.6770232529901039, 0.5872053388396248, 0.5834835826445602, 4.0], [0.0, 0.5, 0.2, 0.7020065569789328, 0.606679289450001, 0.600949721505831, 4.0], [0.5, 0.16666666666666666, 0.2, 0.27490741302895993, 0.13876599890319943, 0.12222625544611838, 7.0], [0.0, 0.3333333333333333, 0.0, 0.5246949183413272, 0.4510456630203111, 0.3200482763699513, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2897061502033878, 0.24928733634617165, 0.18323316132054626, 2.0], [0.0, 0.3333333333333333, 0.0, 0.26271932487402094, 0.10655536130449274, 0.09608007544215019, 2.0], [0.5, 0.16666666666666666, 0.2, 0.28405986278914463, 0.21730606241202097, 0.12997475740933587, 7.0], [0.0, 0.3333333333333333, 0.0, 0.3049602331370287, 0.26710880337385745, 0.18067683707519908, 2.0], [0.0, 0.5, 0.2, 0.47284621455892184, 0.45820201278747474, 0.3626832035353828, 8.0], [0.0, 0.5, 0.2, 0.4404711310788658, 0.38164558367154494, 0.34133753350879015, 5.0], [0.0, 0.5, 0.2, 0.3079123914759274, 0.2408264935397055, 0.18810740433705442, 2.0], [0.0, 0.5, 0.2, 0.7166838686175703, 0.7470952502141011, 0.6392254289610897, 4.0], [0.0, 0.5, 0.2, 0.5007892659826362, 0.5255575196652448, 0.44956514556810273, 4.0], [0.0, 0.5, 0.2, 0.6829275696679011, 0.5359553273523697, 0.5513091528740404, 4.0], [0.0, 0.5, 0.2, 0.6661708457288568, 0.5804608349799459, 0.5714796696258255, 4.0], [0.5, 0.0, 0.0, 0.2576953433307024, 0.07364653169766502, 0.01173175795451559, 1.0], [0.0, 0.3333333333333333, 0.0, 0.7454465424078683, 0.7192910141749796, 0.6461973092825983, 3.0], [0.5, 0.16666666666666666, 0.2, 0.23674184931091002, 0.14227055646326167, 0.10671704293728494, 7.0], [0.0, 0.5, 0.2, 0.33131716349948404, 0.17159396388522857, 0.16517948274912467, 2.0], [0.5, 0.16666666666666666, 0.2, 0.28469734685204307, 0.1436929135075774, 0.13353279251316147, 7.0], [0.0, 0.6666666666666666, 0.4, 0.7159401372108554, 0.5872470496720354, 0.5405423639737273, 4.0], [0.0, 0.3333333333333333, 0.0, 0.5159067451885131, 0.5328705128565465, 0.39266542330075066, 8.0], [0.5, 0.16666666666666666, 0.2, 0.27917248497358993, 0.2197566320912239, 0.148031217559002, 7.0], [0.5, 0.16666666666666666, 0.2, 0.3017576346305628, 0.33893134615251913, 0.15450951147005895, 7.0], [0.5, 0.16666666666666666, 0.2, 0.3300042498937527, 0.21014081245030417, 0.19387281423994235, 10.0], [0.0, 0.3333333333333333, 0.0, 0.6069758970311455, 0.44533601162320213, 0.5855711641683266, 6.0], [0.0, 0.3333333333333333, 0.0, 0.8075101693886224, 0.6324237520509212, 0.690727344901825, 3.0], [0.0, 0.5, 0.2, 0.6150203387772448, 0.47414255084195533, 0.5690765015018937, 6.0], [0.5, 0.0, 0.0, 0.2232408475502398, 0.04088507801080565, 0.010284328427204163, 1.0], [0.5, 0.16666666666666666, 0.2, 0.40657822840143293, 0.2868424842649682, 0.22293810540752593, 10.0], [1.0, 0.0, 0.4, 0.2954814522494081, 0.19386230010313138, 0.08420194264631005, 9.0], [0.5, 0.0, 0.0, 0.21589460263493407, 0.10313723452264817, 0.009123565423932887, 1.0], [1.0, 0.0, 0.4, 0.24011899702507428, 0.14297964061424093, 0.047839084452700846, 9.0], [0.0, 0.5, 0.2, 0.4143039281160829, 0.43579952379579684, 0.2624170262274723, 8.0], [0.0, 0.5, 0.2, 0.2731998664319106, 0.21091551787699794, 0.17454201586743487, 2.0], [0.0, 0.5, 0.2, 0.8413423592981604, 0.7690547072991253, 0.8555641762372578, 4.0], [0.0, 0.5, 0.2, 0.5752231194220144, 0.5213923698872258, 0.4051334655261893, 4.0], [0.0, 0.3333333333333333, 0.0, 0.545276546657762, 0.4615322819345144, 0.3685543001031616, 8.0], [0.0, 0.5, 0.2, 0.5336728188938133, 0.4026706474741082, 0.47826200201279434, 6.0], [1.0, 0.0, 0.4, 0.27332888106368763, 0.0814111673806683, 0.034575500764808594, 9.0], [0.5, 0.0, 0.0, 0.2678647319531297, 0.105322691422506, 0.011182161456467292, 1.0], [0.0, 0.3333333333333333, 0.0, 0.43494626920041296, 0.45054662346079005, 0.27741360182242275, 8.0], [0.0, 0.3333333333333333, 0.0, 0.2570654483637908, 0.10414792931428755, 0.059389665223570566, 2.0], [0.5, 0.16666666666666666, 0.2, 0.3733076315949244, 0.3108455178468362, 0.2034869145313867, 10.0], [1.0, 0.0, 0.4, 0.2561319895574039, 0.077155179109034, 0.03216932374805038, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6567603667051181, 0.6183958446150069, 0.5972804260987862, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3648382004735597, 0.32276003170418827, 0.17685921111337558, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7464483030781374, 0.7214584940945691, 0.6432976327077466, 3.0], [0.5, 0.0, 0.0, 0.21940835407686238, 0.13512243584423678, 0.012060292936114466, 1.0], [0.0, 0.3333333333333333, 0.0, 0.3885010017606703, 0.3694594867346803, 0.23774979672022115, 8.0], [0.5, 0.16666666666666666, 0.2, 0.26542104304535236, 0.11275609859519686, 0.0915107087835776, 10.0], [0.5, 0.16666666666666666, 0.2, 0.27709307267318317, 0.17439882488047137, 0.11190316639195816, 7.0], [0.0, 0.5, 0.2, 0.8715849068059014, 0.6636447303971785, 0.8547035873043591, 6.0], [0.5, 0.16666666666666666, 0.2, 0.34519762005949844, 0.312072953566788, 0.18840504338361103, 7.0], [0.5, 0.16666666666666666, 0.2, 0.3778307328031085, 0.25363635990547406, 0.20731397951707692, 10.0], [0.5, 0.0, 0.0, 0.26798615748892, 0.15878735386048307, 0.02684055048694225, 1.0], [0.0, 0.3333333333333333, 0.0, 0.5344848521644101, 0.4553698296076825, 0.4640224169421932, 3.0], [1.0, 0.0, 0.4, 0.2187936373019247, 0.13645099472706562, 0.06046916999519, 9.0], [0.0, 0.5, 0.2, 0.4113441806811972, 0.42261143447974514, 0.2666868493965463, 8.0], [0.0, 0.5, 0.2, 0.8208821565175156, 0.8181584933790217, 0.8179193228056781, 4.0], [0.0, 0.5, 0.2, 0.40481755813247533, 0.4550303931401708, 0.40356663682647786, 5.0], [0.5, 0.0, 0.0, 0.25122943354987565, 0.09256123222600243, 0.01863752296650901, 1.0], [0.0, 0.5, 0.2, 0.7040707910873657, 0.593454695208988, 0.6638920134862503, 6.0], [0.0, 0.5, 0.2, 0.9098111832918462, 0.7568366332346869, 0.8243878400319798, 6.0], [0.5, 0.16666666666666666, 0.2, 0.25513022888713494, 0.13692283924767387, 0.09475166893735905, 10.0], [0.0, 0.3333333333333333, 0.0, 0.3410539736506587, 0.1487889176811753, 0.1459295978400613, 2.0], [1.0, 0.0, 0.4, 0.22097929694614774, 0.14180795119223732, 0.03064466732550838, 9.0], [0.0, 0.3333333333333333, 0.0, 0.31192702325299015, 0.1343604591084835, 0.1256850704254529, 2.0], [0.5, 0.16666666666666666, 0.2, 0.22211007224819376, 0.15826411424815276, 0.09352866749302459, 10.0], [0.5, 0.16666666666666666, 0.2, 0.25387043895331185, 0.19534660532699683, 0.1329258416555073, 10.0], [0.0, 0.5, 0.2, 0.6080990832372046, 0.47666313538497745, 0.5724952802287016, 6.0], [1.0, 0.0, 0.4, 0.200716410661162, 0.1011559028785059, 0.023015668695410732, 9.0], [0.5, 0.0, 0.0, 0.23385040373990645, 0.08115240481950066, 0.014900017476395251, 1.0], [1.0, 0.0, 0.4, 0.19625402222087304, 0.08471975113304256, 0.03668002206448568, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2861999878574463, 0.25846941277554697, 0.14246437619512137, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6739420800194281, 0.6804390372733014, 0.6065691200578655, 3.0], [0.0, 0.3333333333333333, 0.0, 0.6436464088397791, 0.6523442875821258, 0.5907162204143356, 3.0], [0.5, 0.16666666666666666, 0.2, 0.23655212191123784, 0.13521927843735246, 0.07865312990323947, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2706271628923562, 0.20836783012246693, 0.12315027038332503, 7.0], [0.0, 0.5, 0.2, 0.8938589035274119, 0.6981440247706825, 0.9795498998756552, 6.0], [0.5, 0.16666666666666666, 0.2, 0.31839293303381705, 0.2011842429345118, 0.14771791826288655, 10.0], [0.0, 0.5, 0.2, 0.4015542468581143, 0.33720795062290737, 0.30797242645115924, 5.0], [0.0, 0.5, 0.2, 0.4413514662133447, 0.3920238815671172, 0.3883788608806016, 5.0], [0.0, 0.5, 0.2, 0.29416094954768984, 0.14203436931621485, 0.07355800601991418, 2.0], [0.0, 0.5, 0.2, 0.3531661708457289, 0.3688778802115611, 0.2947614517432357, 5.0], [0.0, 0.5, 0.2, 0.8424655455042195, 0.6592233750980144, 0.8462501752275507, 6.0], [0.0, 0.5, 0.2, 0.7025681500819622, 0.6996166608505778, 0.604285311558001, 6.0], [1.0, 0.0, 0.4, 0.2551909416550301, 0.12065459744246979, 0.02736442527007766, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2883401129257483, 0.18379661800942082, 0.12560360952920724, 10.0], [0.0, 0.3333333333333333, 0.0, 0.8287899945358509, 0.678813346101675, 0.6580366839371226, 3.0], [0.5, 0.16666666666666666, 0.2, 0.34519762005949844, 0.312072953566788, 0.18840504338361103, 10.0], [0.5, 0.0, 0.0, 0.27677433064173396, 0.11327206971530873, 0.02569052315939253, 1.0], [1.0, 0.0, 0.4, 0.2758939955072553, 0.13967226474541322, 0.04484202315562997, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2676825936494444, 0.19902966123337812, 0.12499558461342343, 10.0], [0.5, 0.0, 0.0, 0.26372108554428997, 0.11449077476822257, 0.014629591901382834, 1.0], [0.5, 0.16666666666666666, 0.2, 0.21038491894845482, 0.19388682508367824, 0.08644464706077591, 10.0], [0.0, 0.3333333333333333, 0.0, 0.28920526986825335, 0.13088725707510546, 0.11942828040412956, 2.0], [0.5, 0.16666666666666666, 0.2, 0.23429057130714578, 0.2427093650156902, 0.11406622964113998, 7.0], [0.5, 0.16666666666666666, 0.2, 0.4152297978264829, 0.2817548010669129, 0.19557989748095472, 10.0], [1.0, 0.0, 0.4, 0.24715408900491778, 0.14157273176475693, 0.029396326297793464, 9.0], [0.5, 0.16666666666666666, 0.2, 0.2915882460081355, 0.14825768908468637, 0.10880182592590586, 7.0], [0.0, 0.5, 0.2, 0.2698075405257725, 0.11345891729175643, 0.11203888559207495, 2.0], [0.5, 0.0, 0.0, 0.21194827272175337, 0.035703780306071874, 0.01172957712388452, 1.0], [0.0, 0.3333333333333333, 0.0, 0.45558861028474296, 0.4472001008632207, 0.35844730745398384, 8.0], [0.0, 0.3333333333333333, 0.0, 0.7261019367372958, 0.6165101688713733, 0.6733328582250981, 6.0], [0.0, 0.6666666666666666, 0.4, 0.4446147774877058, 0.3789771287533012, 0.346112448121735, 5.0], [1.0, 0.0, 0.4, 0.26742456438589035, 0.10757535891853434, 0.019305132043979895, 9.0], [0.5, 0.16666666666666666, 0.2, 0.31751259789933817, 0.18215141704624174, 0.11980892516795152, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6133203812761824, 0.5334980895908984, 0.5081987560259229, 3.0], [0.0, 0.5, 0.2, 0.5702598506465909, 0.49311670608263813, 0.5201997371812618, 5.0], [0.0, 0.3333333333333333, 0.0, 0.6270566450124462, 0.5230814714132215, 0.5110450644312984, 6.0], [0.5, 0.16666666666666666, 0.2, 0.303138850100176, 0.13354097016316435, 0.127110856009874, 7.0], [0.0, 0.3333333333333333, 0.0, 0.525635966243701, 0.4510887300728441, 0.4415585152392898, 5.0], [0.5, 0.16666666666666666, 0.2, 0.2752109768684355, 0.20786460182058855, 0.12779102073453394, 10.0], [0.5, 0.16666666666666666, 0.2, 0.31192702325299015, 0.2856339861812049, 0.16009873346726497, 10.0], [0.5, 0.16666666666666666, 0.2, 0.24578046263129133, 0.27270054838407476, 0.11478982589306812, 7.0], [1.0, 0.0, 0.4, 0.205049784469674, 0.11438135182074216, 0.05025977860906074, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6939165806569122, 0.6826084455683775, 0.5280611611781066, 3.0], [0.0, 0.5, 0.2, 0.5144648169510048, 0.47946563712229906, 0.48334762783736923, 5.0], [1.0, 0.0, 0.4, 0.19381033331309572, 0.14876224535210117, 0.050126677852951274, 9.0], [0.5, 0.16666666666666666, 0.2, 0.4202537793698015, 0.2178755477177963, 0.21979270492102107, 7.0], [0.0, 0.5, 0.2, 0.5679527654665776, 0.4836599315056568, 0.505978877119823, 5.0], [1.0, 0.0, 0.4, 0.2190364883735049, 0.13031977078128149, 0.02336560354119381, 9.0], [0.5, 0.16666666666666666, 0.2, 0.20492076983789687, 0.21070625028665163, 0.12589829342421327, 7.0], [0.0, 0.3333333333333333, 0.0, 0.6786017849553762, 0.6043649068747569, 0.5557957838308719, 3.0], [0.0, 0.5, 0.2, 0.4044988161010261, 0.3989651927447677, 0.30328060160792863, 5.0], [0.5, 0.16666666666666666, 0.2, 0.2934703418128832, 0.20197007360439706, 0.1398719169218739, 10.0], [0.0, 0.3333333333333333, 0.0, 0.46513569303624547, 0.4167595000517731, 0.31218854611806407, 8.0], [1.0, 0.0, 0.4, 0.25343027138607255, 0.14015018400198653, 0.026749386130049, 9.0], [0.0, 0.6666666666666666, 0.4, 0.45948940562200224, 0.5122673889122747, 0.4727270702943377, 5.0], [1.0, 0.0, 0.4, 0.22808269078987312, 0.0775260699942804, 0.04204617658838436, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4441746099204662, 0.3785418597941193, 0.28872166404479477, 8.0], [0.0, 0.3333333333333333, 0.0, 0.6599477870196103, 0.6153145195605404, 0.5624295039923027, 6.0], [0.0, 0.3333333333333333, 0.0, 0.66409143342845, 0.5717696042801855, 0.5425844907068654, 3.0], [0.0, 0.3333333333333333, 0.0, 0.4272812822536579, 0.439416781835302, 0.2692758060494897, 8.0], [0.0, 0.5, 0.2, 0.8788628498573251, 0.7189898767986332, 0.8527664243350911, 6.0], [0.0, 0.5, 0.2, 0.28198803958472474, 0.1355100675716192, 0.10234576482696807, 2.0], [0.0, 0.3333333333333333, 0.0, 0.35811426142917846, 0.19280012545601236, 0.1822982593178756, 2.0], [0.0, 0.3333333333333333, 0.0, 0.46507498026835054, 0.4131399675181044, 0.3018827419545244, 2.0], [0.0, 0.5, 0.2, 0.8231285289296338, 0.6405865442945483, 0.74503290785567, 6.0], [0.0, 0.6666666666666666, 0.4, 0.608615141764313, 0.5133426807508903, 0.5017743917997519, 4.0], [0.0, 0.3333333333333333, 0.0, 0.8006040920405562, 0.6675136449695016, 0.6778499346625679, 3.0], [0.0, 0.5, 0.2, 0.2121987128893206, 0.21426591135283318, 0.14343910018627742, 2.0], [0.5, 0.0, 0.0, 0.2364155181834739, 0.1528750817643568, 0.026052230623646352, 1.0], [0.0, 0.3333333333333333, 0.0, 0.44705846639548286, 0.4268781736213082, 0.3730892608945147, 5.0], [0.5, 0.16666666666666666, 0.2, 0.28469734685204307, 0.1436929135075774, 0.13353279251316147, 10.0], [0.0, 0.3333333333333333, 0.0, 0.4835164835164834, 0.3938227521592703, 0.32828749022164977, 2.0], [0.0, 0.3333333333333333, 0.0, 0.31506890899156087, 0.12304585368225662, 0.08933646857386486, 2.0], [0.5, 0.16666666666666666, 0.2, 0.30930119604152756, 0.2596472828882127, 0.16470840176539106, 7.0], [0.5, 0.16666666666666666, 0.2, 0.2650415882460082, 0.15476257992878004, 0.11758511511098564, 10.0], [0.5, 0.16666666666666666, 0.2, 0.29114807844089613, 0.13153392684586812, 0.1279837021309036, 7.0], [0.5, 0.0, 0.0, 0.21445267439742574, 0.06321444413421691, 0.010242896740011548, 1.0], [1.0, 0.0, 0.4, 0.2548114868556857, 0.13187471953350216, 0.027636626861637502, 9.0], [0.0, 0.3333333333333333, 0.0, 0.6457561775241334, 0.5502369256512855, 0.38340180137843155, 8.0], [0.0, 0.5, 0.2, 0.3838564750166961, 0.40943074786519473, 0.2985595965306881, 5.0], [0.0, 0.5, 0.2, 0.3595713678586606, 0.47361728396308783, 0.3374055934469948, 4.0], [0.0, 0.5, 0.2, 0.4936251593710158, 0.3711129662915233, 0.32829063253694546, 6.0], [0.5, 0.16666666666666666, 0.2, 0.4152297978264829, 0.2817548010669129, 0.19557989748095472, 7.0], [0.0, 0.5, 0.2, 0.4508226580049784, 0.4223100286848327, 0.3669568893340959, 5.0], [0.5, 0.0, 0.0, 0.2636527836804079, 0.10051679827311369, 0.03161575391205781, 1.0], [0.0, 0.3333333333333333, 0.0, 0.4932001699957501, 0.4323087050281204, 0.47386631560292375, 3.0], [0.5, 0.16666666666666666, 0.2, 0.3323265132657397, 0.20460244741646755, 0.19596617845491193, 10.0], [1.0, 0.0, 0.4, 0.2863745370651447, 0.14813068472113983, 0.05039855034141507, 9.0], [0.0, 0.3333333333333333, 0.0, 0.4206939469370408, 0.39613449999438094, 0.25002292784700636, 8.0], [0.0, 0.5, 0.2, 0.5784864306963754, 0.536371637484424, 0.521196578170442, 6.0], [0.5, 0.16666666666666666, 0.2, 0.28714103575982036, 0.28548917436490523, 0.16739169447686467, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7727369315767106, 0.8062976208529694, 0.6462087934961466, 3.0], [0.0, 0.5, 0.2, 0.48609677615202473, 0.45732596522486324, 0.3205892608457472, 8.0], [0.0, 0.3333333333333333, 0.0, 0.22600327848946633, 0.0808893970068038, 0.07327714486962851, 2.0], [0.0, 0.3333333333333333, 0.0, 0.6214255357901766, 0.6113354403578576, 0.5285165719009163, 3.0], [0.0, 0.3333333333333333, 0.0, 0.8105913423592982, 0.7644693553198466, 0.7038119338917297, 3.0], [0.5, 0.16666666666666666, 0.2, 0.2706271628923562, 0.2830585382960432, 0.15183626799223443, 7.0], [1.0, 0.0, 0.4, 0.16632262764859448, 0.06731737731412045, 0.029643999876782588, 9.0], [0.0, 0.5, 0.2, 0.7773207455527896, 0.5630415649186655, 0.6856295550330602, 6.0], [0.5, 0.16666666666666666, 0.2, 0.3430574949911967, 0.23035431271888876, 0.17132388675799265, 7.0], [0.0, 0.3333333333333333, 0.0, 0.7957774269928967, 0.6854927090135994, 0.6219940667333896, 3.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeqykqdXvgH1"
      },
      "source": [
        "for i in train:\n",
        "    i[-1] = int(i[-1]-1)\n",
        "for i in test:\n",
        "    i[-1] = int(i[-1]-1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrmulayvgH1"
      },
      "source": [
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0\n",
        "\n",
        "def predict(network, row):\n",
        "    outputs = forward_propagate(network, row)\n",
        "    outputs = softmax(outputs)\n",
        "    return np.argmax(outputs,axis = 0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuoiAT23vgH1"
      },
      "source": [
        "def calculate_accuracy(network,data):\n",
        "    pred = list()\n",
        "    actual = list()\n",
        "    for row in data:\n",
        "        actual.append(row[-1])\n",
        "        pred.append(predict(network,row))\n",
        "    accuracy = accuracy_metric(actual,pred)\n",
        "    return accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aps9bq5yDRe1"
      },
      "source": [
        "## 1 Hidden Layers (6-8-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLelNPRnDwWk"
      },
      "source": [
        "### lr=0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Dr879MD93p"
      },
      "source": [
        "net = initialize_network_single(6,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FImiUmGHD93p",
        "outputId": "5bd9df26-bf2a-4d70-ec93-82db8787ec58"
      },
      "source": [
        "train_network(net,train,lr = 0.3,\n",
        "              n_epochs=500,n_outputs = 10,\n",
        "              accuracy_score = accuracy_score,\n",
        "              loss_score = loss_score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 1100 | Accuracy: 75.07142857142857 | Loss:372.0331098374921\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.73546389630417\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:404.5591984866477\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.91801512860826\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:428.47258265919686\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:444.6445929349989\n",
            "##################################################\n",
            ">epoch=338, lrate=0.300, error=459.777\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.5 | Loss:1.743640404091238\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.900810598505146\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.90238548676939\n",
            "Iteration 150 | Accuracy: 74.78571428571429 | Loss:57.88903428568095\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.95292400331029\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.64101733107803\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.85653445929871\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.57166745116648\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.781684262015\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.11257174178442\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.6583082159222\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.81216455986237\n",
            "Iteration 600 | Accuracy: 74.78571428571429 | Loss:210.38959927027622\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.4675549324111\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.54022754405284\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.73176396909815\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:270.25962337723905\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:289.83343431764723\n",
            "Iteration 900 | Accuracy: 75.5 | Loss:305.6522853972177\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:322.9067358609558\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:337.3596989525661\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.6384053754266\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:372.0234972461224\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.7364850186909\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:404.52809150144526\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.908307243103\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:428.4531174766109\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.62902739735654\n",
            "##################################################\n",
            ">epoch=339, lrate=0.300, error=459.765\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.736079884629015\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.87233587899804\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.85719034032971\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.86318138221682\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.91749993082298\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.5972581947526\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.82570651376065\n",
            "Iteration 350 | Accuracy: 75.42857142857143 | Loss:121.54367915071292\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.7498321834484\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.0744371908491\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.65163947392782\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.79892476773975\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.37717073267532\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.45560300588244\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.50804618878416\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:257.6926948783147\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:270.2135382229718\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:289.76755150247845\n",
            "Iteration 900 | Accuracy: 75.5 | Loss:305.5735215921749\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.8019272655311\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:337.30739674197724\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.5981553843862\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:372.0025304273149\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.7270961831803\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:404.4909969854017\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.8925867322688\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:428.4283187544384\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.60819431265094\n",
            "##################################################\n",
            ">epoch=340, lrate=0.300, error=459.750\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.727039103737499\n",
            "Iteration 50 | Accuracy: 76.35714285714286 | Loss:16.841090477837394\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.80726264857475\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.8341723192406\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.87620781047713\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.5470026910049\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.78476728693798\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.50380222538432\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.7056364168159\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.0253275380518\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.63220412665956\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.77259193803252\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.3516853892833\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.43083343384788\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.46101086085977\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.6374816649034\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:270.15072417013215\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:289.68123282826355\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:305.47444965525756\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:322.6822339144495\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:337.2304899868883\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.53952487100435\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.9668392919685\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.7029196419164\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.4425113194932\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.86475388969694\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:428.39179017247756\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.5758791882386\n",
            "##################################################\n",
            ">epoch=341, lrate=0.300, error=459.725\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7164792621451581\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.807679215138794\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.75401080828822\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.80359571580517\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.83074335895428\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:86.49273048297349\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.73687574831521\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.45554988073717\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.65263096820286\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.96837939747653\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.60300401983537\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.73638349215398\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.31587296718317\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.3959590182178\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.40179939920537\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.5688823616094\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:270.0739754274797\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:289.577204003881\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:305.35771078492326\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.55083633704106\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:337.1326097220914\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.4621792240192\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.9133948076707\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.6600026227255\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.37755885766484\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.81894400046326\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:428.33734023904833\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:444.5260159913258\n",
            "##################################################\n",
            ">epoch=342, lrate=0.300, error=459.685\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.704655157683745\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.773398055081117\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.699909431549415\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.773699864029304\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.78414023668502\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:86.43816868940587\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.68632238702182\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.40341283049773\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.5953487924517\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.9078769342947\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.56796692265104\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.69449071655382\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.27341121368747\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.35466792135162\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.33423398874797\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:257.49079761436104\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.987245548782\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.45964386725166\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:305.22733349448845\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.41179311219884\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:337.01874570795536\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.36633182294406\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.8390513806778\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:384.5947021331832\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.2917077262628\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.7501868221171\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:428.2597807064359\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:444.4534739028663\n",
            "##################################################\n",
            ">epoch=343, lrate=0.300, error=459.623\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6919761939648201\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.739567925571155\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.64736006350259\n",
            "Iteration 150 | Accuracy: 74.78571428571429 | Loss:57.74629851608932\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.73932387412715\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.3867365702994\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.63699872008463\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.35125178812108\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.53767330674705\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.84763575113354\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.53044321946152\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.6504994792765\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.22733290186264\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.3099869446224\n",
            "Iteration 700 | Accuracy: 74.42857142857143 | Loss:243.26171193213415\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.4067116290977\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.8940660270972\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.3326028605143\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:305.0871898192265\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.2685150798294\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.8932795399706\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.25241180084765\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.74185048629323\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.5051092979493\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.18275085532866\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.6561603170845\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:428.1566999478838\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.35586206791766\n",
            "##################################################\n",
            ">epoch=344, lrate=0.300, error=459.535\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6788291713196055\n",
            "Iteration 50 | Accuracy: 76.35714285714286 | Loss:16.707054067351503\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.59799124390818\n",
            "Iteration 150 | Accuracy: 74.71428571428571 | Loss:57.722262364390495\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.698180311304\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.34059222481305\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.59144445406386\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.30138652640696\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.4819176251309\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.7900497765912\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.49249366538643\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.60664009160982\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.17933971749042\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.2635751668862\n",
            "Iteration 700 | Accuracy: 74.5 | Loss:243.186437774532\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.31890776561283\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.7967413838561\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.1990940347409\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.94015440807743\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.12312273649195\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.7591236549191\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.12109785029537\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.6215503337375\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.39139644111094\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.05090550957453\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:416.53730557949723\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:428.02851999469203\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.2336094878341\n",
            "##################################################\n",
            ">epoch=345, lrate=0.300, error=459.424\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.6655002009022022\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.676235586248918\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.55267617603057\n",
            "Iteration 150 | Accuracy: 74.71428571428571 | Loss:57.70173732817083\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.66157108872515\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:86.30069267564527\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.55086137397615\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.25467263058226\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.42891352143005\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.7361165022489\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.4550927478104\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:193.5639739795071\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.1301257475657\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:226.21606136737267\n",
            "Iteration 700 | Accuracy: 74.64285714285714 | Loss:243.10961436137814\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:257.22863820021115\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:269.69651430638584\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:289.0611329350099\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.7881979693677\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.976761332589\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:336.61797250971847\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.97351231029745\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.4793248911574\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.25526425229486\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:403.8979778781562\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:416.39581944055067\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.87744161449666\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.0889109658848\n",
            "##################################################\n",
            ">epoch=346, lrate=0.300, error=459.289\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.652189026001884\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.64719866019349\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.51185381854283\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.68456360282129\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.62977172691205\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.26728669331116\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.51555521548462\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:121.21096100886139\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.37849420868235\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.68585439701903\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.41859250651467\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:193.5228419180751\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.0799672607331\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:226.16765963885572\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:243.03191375639213\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:257.13659851227214\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.59405047861054\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.9201307755444\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.6327910861471\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.83012299316647\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.47089653600665\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.81143040130695\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.3174533749962\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.09947909341815\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:403.72671158775853\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.23486903257606\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.7066382066678\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:443.92491965844346\n",
            "##################################################\n",
            ">epoch=347, lrate=0.300, error=459.134\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.639030774288283\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.619878803718752\n",
            "Iteration 100 | Accuracy: 76.0 | Loss:39.47578243693466\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.67052448289246\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.60281197381299\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.24027276429682\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.4852497175528\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.16937496556855\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.32979995425802\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.63856132764732\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.3829115954265\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.48304131394656\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.02897209998036\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.1184367481261\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.95366026623103\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:257.04313844914765\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.48966392494737\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.77706396929585\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.47505093960433\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.6836159576759\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:336.31865063700224\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.6372555933858\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:371.13914490585495\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:383.9276630244924\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:403.540558530843\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.0582901158586\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.51993431668\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:443.74543434960697\n",
            "##################################################\n",
            ">epoch=348, lrate=0.300, error=458.963\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.6260768930797596\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.5940865336879\n",
            "Iteration 100 | Accuracy: 76.0 | Loss:39.44469884086079\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.65943680966129\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.5806399726127\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.21934005311836\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.45918957069536\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.12833372017258\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.28133746088045\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.5928583821602\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.34746487862142\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:193.4437615002828\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.97698649699325\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.06822401876602\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.87473166921941\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.9481967053641\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.38326348931906\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.63239131706206\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.31562422684556\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.53723859144355\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.16166616284187\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.45369205063105\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:370.94826717671117\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:383.7440549017932\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:403.34352248964996\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.8704015254572\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.32159004448806\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:443.5546979791911\n",
            "##################################################\n",
            ">epoch=349, lrate=0.300, error=458.780\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.6132466757296635\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.569479762696425\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.41902658837472\n",
            "Iteration 150 | Accuracy: 75.14285714285714 | Loss:57.65122452529844\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.56326686786502\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.2040642175874\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.4361797297833\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.08541973068908\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.23089474712006\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.54663570119385\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.3110500412523\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.403496689759\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.92341120404168\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.0164324907787\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.79440841836217\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.85117527216863\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.27423211684163\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.4859162519276\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.1545192202074\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:321.39042800550646\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:335.9999298379513\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.26318325125914\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.74874247179696\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.5529396549057\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:403.13965339677424\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.6754879856701\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.11575534342694\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:443.35685959674737\n",
            "##################################################\n",
            ">epoch=350, lrate=0.300, error=458.591\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.600292206054859\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.545564217060104\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.39981543049608\n",
            "Iteration 150 | Accuracy: 75.21428571428571 | Loss:57.64607809831428\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.55105840967023\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.19412883932704\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.41466204159566\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:121.03703492382387\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.17527054712724\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.4968709941108\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.27176958516736\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.36001522128083\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.86706368578382\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.9619175012312\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:242.71126343557097\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.75084443992256\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.1613261435101\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.33664847431766\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:303.9909477830131\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:321.2419848135595\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:335.8328064877847\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:349.0671855153898\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.54353887170885\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.3576266031713\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:402.93198839079366\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.4767244963305\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:426.90538162179934\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:443.15487481491124\n",
            "##################################################\n",
            ">epoch=351, lrate=0.300, error=458.397\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.5868148165745064\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.521770649184113\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.389665287355626\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.644765147630125\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.54528419931209\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.189768992663\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.39285613885411\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.97771693644208\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.1097359514911\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.43922147050617\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.2269805946125\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.31041240047824\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.80613240009467\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.9029365470464\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.62309238067934\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.6452783572118\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:269.04258971434757\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:288.1825990597214\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.82311359547\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:321.0900537573652\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:335.65872472927595\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.8653636508963\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:370.3334811526334\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.15919761343343\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:402.72117978402457\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.2747670605046\n",
            "Iteration 1300 | Accuracy: 75.42857142857143 | Loss:426.6908243560425\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:442.94906144699286\n",
            "##################################################\n",
            ">epoch=352, lrate=0.300, error=458.201\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.5723503697616077\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.497624622904034\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.394492983215216\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.649222059277946\n",
            "Iteration 200 | Accuracy: 74.64285714285714 | Loss:69.54900757728842\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.19257186445692\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.36926658337492\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.89978505304657\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.0279205125279\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.36794831333577\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:174.17373469506347\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.2518125526137\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.7387510595717\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:225.8376911696285\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.52741177404624\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.5323335027732\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.9157966192815\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.02097108575623\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.6484069591223\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.93259594932806\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:335.4751896965628\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.6554560463032\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.1169163605912\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:382.95608557109836\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:402.5050478982677\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:415.067267010846\n",
            "Iteration 1300 | Accuracy: 75.42857142857143 | Loss:426.46944182524226\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.73657897072064\n",
            "##################################################\n",
            ">epoch=353, lrate=0.300, error=457.999\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.556551503931717\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.473026561553542\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.42566952692082\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.66380397378709\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.5682898073992\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.20693108311902\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.3449747223849\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.79771389790216\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.9259838322132\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.27957157773952\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.1118358745956\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.18482754971942\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.66643850393146\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.76761803815089\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.4250424813646\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.413206430863\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.7820113583502\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.8517760723024\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.4669802118891\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:320.77059391001376\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:335.28250117851053\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:348.4378434246598\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.8944857320089\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:382.74877870537904\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:402.2836869105577\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.85409114301837\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:426.2411187253217\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.5167504732305\n",
            "##################################################\n",
            ">epoch=354, lrate=0.300, error=457.791\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.5395016758292457\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.448530428055776\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.495963995782205\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.69533382771567\n",
            "Iteration 200 | Accuracy: 74.71428571428571 | Loss:69.61076296631467\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.23934464431098\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.32674015403747\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.68264652104831\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.81448889456348\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.18364159226695\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.04964473505223\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.1189264924113\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.60039218242568\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.70345420839905\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.327451116937\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.29971058465867\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.6531545082773\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.68762388776514\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:303.2912441952232\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:320.61465523518945\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:335.09470284713166\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:348.22824868968047\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.6817617422963\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.5525086527542\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:402.0724506339364\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.6507255697003\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:426.0221412065423\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.3050313813843\n",
            "##################################################\n",
            ">epoch=355, lrate=0.300, error=457.592\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.5219266466952914\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.42486619534469\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.59378027304649\n",
            "Iteration 150 | Accuracy: 74.85714285714286 | Loss:57.73776889799235\n",
            "Iteration 200 | Accuracy: 74.78571428571429 | Loss:69.66750637279502\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.28165702186853\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.31294743664382\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.57687972168044\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.70993320267726\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.09519013380927\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.9922887328816\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.0590174503581\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.54796483353007\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.6517796827787\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.24381673802645\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.2007888652176\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.53885542570316\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.5427595239803\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:303.1346899276788\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:320.4725181378085\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.92819264140826\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.0447465562009\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:369.49491595810224\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.3829998164856\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.88655073094577\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.4726996959793\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.829355975051\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.1180659127393\n",
            "##################################################\n",
            ">epoch=356, lrate=0.300, error=457.416\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.5049146242060891\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.40181369231802\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.66780158979463\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.76295692030022\n",
            "Iteration 200 | Accuracy: 74.78571428571429 | Loss:69.70127618408385\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.30443434944891\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.28508920947678\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.48484833748158\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.61311790055487\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.01367654600213\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.92925782307114\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.99329161668285\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.49423378484843\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.59727506630585\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.16050739898898\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.1026763789255\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:268.42539160807667\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.40660505575977\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:302.98641268346955\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.3298656482969\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.7713912097656\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:347.8749348130391\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:369.3195650880913\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.2252719325241\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.7116993549203\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.3056008435233\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.64917572339505\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.9428789466157\n",
            "##################################################\n",
            ">epoch=357, lrate=0.300, error=457.250\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.4891950857932192\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.37911161828775\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.68496254720928\n",
            "Iteration 150 | Accuracy: 75.0 | Loss:57.76001198613375\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.693366926875\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.29626321746562\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.24073815572385\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.40408424206896\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.52557103825364\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:152.9388147527905\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.8600913281579\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.9201175145692\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.43056086310423\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.5314580050801\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.06855572413346\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.9965416188979\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.30318354310845\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.2679587467796\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.83569715345425\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.1781348744907\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.6104226281286\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:347.70335826944364\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:369.1406595221045\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:382.06398444736817\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.5358603337381\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.13742377742585\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.4695345385294\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.76817986564015\n",
            "##################################################\n",
            ">epoch=358, lrate=0.300, error=457.084\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.4744441162329698\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.357047562440002\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.661046152985826\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.741958176733384\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.65989184295975\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.2708954243018\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.1916296219606\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.3344266753908\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.44990450540402\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:152.87376036076364\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.79374164971335\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.84810814762182\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.36367932289224\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.46107079633882\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.9738720664334\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.88739925343458\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.1773409479099\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.12891264782513\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.68494446754767\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.02321774580525\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.44678933808194\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:347.53071486642574\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.95992489764126\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.9008886188204\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.36234170243955\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.97167324798585\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.29351960685165\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.5976144863306\n",
            "##################################################\n",
            ">epoch=359, lrate=0.300, error=456.921\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.460058738428564\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.335708985759332\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.61950606399748\n",
            "Iteration 150 | Accuracy: 75.35714285714286 | Loss:57.72144038731941\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.6189385448481\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.24255244964112\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.14642423486264\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.27718551879845\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.38726464247225\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:152.82102337909987\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:173.73655862723297\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.78381138388053\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.30153138446803\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.39402593950612\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.88401958117473\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.78188085385077\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.05499808956176\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.99485428150547\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.53958829702174\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.87230376242786\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.28646977933306\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:347.36274844853597\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.7836459297786\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.7423389369336\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.1970356458777\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.81432831934376\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.1267409291677\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.43712525089296\n",
            "##################################################\n",
            ">epoch=360, lrate=0.300, error=456.768\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4456726072979063\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.314961906110785\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.57282485589569\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.70383378031142\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.57919474285517\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.21789008544884\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.10842178278162\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.23264406718836\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.33743962403136\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.7810075866581\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.6908915535074\n",
            "Iteration 550 | Accuracy: 73.28571428571429 | Loss:192.72996236508158\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.24806339956635\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.3343371802177\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.80283343160926\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.68337682519046\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.9398994873911\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.8688316247292\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.4026517257086\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.72895823013664\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:334.133040123389\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.20288969791744\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.61541425894956\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.5919787655829\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.0426841669928\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.6680858605573\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:424.97163240386794\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.289317515339\n",
            "##################################################\n",
            ">epoch=361, lrate=0.300, error=456.628\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4311882122318658\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.294741098465934\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.52575629803777\n",
            "Iteration 150 | Accuracy: 75.71428571428571 | Loss:57.690516262523495\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.54365248423248\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.19918987732426\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.0784800844489\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.20035118017293\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.29978589097615\n",
            "Iteration 450 | Accuracy: 76.07142857142857 | Loss:152.75305713010198\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.65735300480947\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.68752590998935\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.20481367263164\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.28367760751394\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.73182587254985\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.5932860706457\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.8336067461456\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.7521241185337\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.27539473760777\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.59455723725506\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:333.9880792538197\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.05255299504444\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.4566908565324\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.4513049911025\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.9000591599088\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.5336130303654\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:424.82866981257723\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.15475558687933\n",
            "##################################################\n",
            ">epoch=362, lrate=0.300, error=456.502\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4166818351284403\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.275103084317436\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.47996703589778\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.68164822278879\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.51324219418102\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.1873027123015\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.05687585675336\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.17985499127894\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.27385789991214\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.73643813879082\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.636272845345\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.65707694428409\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.17265328204846\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.24307712280242\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.67189576635377\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.51255243495126\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.73711472169833\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.6456317259124\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.15871338878856\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.4699243559267\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:333.8526323472914\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.912623563965\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.30841044780055\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.32127994926094\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.76959185637764\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.41122572422415\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:424.69802585618834\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.03367137937073\n",
            "##################################################\n",
            ">epoch=363, lrate=0.300, error=456.389\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4023221576012086\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.256163636107143\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.436228328997885\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.67718531330514\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.48834483433178\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.18277721124879\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.04389202751634\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.1709403162983\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.25952884499594\n",
            "Iteration 450 | Accuracy: 76.07142857142857 | Loss:152.73063378389688\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.62815913404378\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.63924901430377\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.15253686817766\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.21365024555243\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.62410455794034\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.44236922439248\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.65161912392114\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.55066375051825\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:302.0539137626825\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.35604670094335\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.728002064804\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:346.78427080621196\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.1718032331466\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.2031496626611\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.65207023360665\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.3015889553749\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.58026475217537\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.9266792405119\n",
            "##################################################\n",
            ">epoch=364, lrate=0.300, error=456.291\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.3883345290834805\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.23803476515659\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.39505120738107\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.67703856513371\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.46917713452315\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.18608514193993\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.03988086133816\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.17359583238381\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.25691362727886\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.73530479155986\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.63376104251986\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.63477559521624\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.14575808477284\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.19684913829707\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.58997896260033\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.38447360525836\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.57884383105005\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.46938286813685\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.9631399070804\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.25435555033465\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.61613652337763\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.6693438103183\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.0487730416115\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.0988077590813\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.5489144050694\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.205978616929\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.47659771146374\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.83504194573794\n",
            "##################################################\n",
            ">epoch=365, lrate=0.300, error=456.207\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3749793790803206\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.220769803540282\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.35686273125566\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.68101744293901\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.4558527645311\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.19757642286031\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.04518396150331\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.18789760569452\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.26623814985254\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:152.75014385332832\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.65402409539433\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.6443929763209\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.15409003473744\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.19461805054533\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.57172838857807\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.34138927795848\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.5213069162981\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.4052666546912\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.8898150122879\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.16693957623255\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.5200280850101\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:346.5707866219358\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:367.9422937682542\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.01116383908743\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.4624827985174\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.12656930990755\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.38916817451076\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.7609624407395\n",
            "##################################################\n",
            ">epoch=366, lrate=0.300, error=456.142\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.362536803074353\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.204307447517646\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.32200275238528\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.68872666172003\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.4483492225839\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.21735712381532\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.06003721633101\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.21389232651397\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.28773080202748\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.77471073549447\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.69005282171366\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.66870979166632\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.17997450429777\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.20963208258706\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.5725709277228\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.31680685862645\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.4827234510862\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.363825845024\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.83933396824085\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.0968795347487\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.44444364962663\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.49344652821253\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8572169758623\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:380.94489966380723\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.39678551712706\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.06713785222786\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.32177056857984\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:440.70829899728665\n",
            "##################################################\n",
            ">epoch=367, lrate=0.300, error=456.097\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3513032650662304\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.188405340697415\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.29062969835591\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.69947016486283\n",
            "Iteration 200 | Accuracy: 74.64285714285714 | Loss:69.44646752630975\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.24515867086139\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.0845079084422\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.25151899767665\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.32157549182915\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.8082800951513\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.7431237324825\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.70809130773446\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.22682966961614\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.24575391261834\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.59731344181176\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.3162492190982\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.46870402525013\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.35382893306314\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.82025248188455\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.0488374883176\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.3974703494396\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.4459300171129\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8021915762449\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:380.9082971580896\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.3592992590936\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.0349073064645\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.2817664837033\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:440.6844384063154\n",
            "##################################################\n",
            ">epoch=368, lrate=0.300, error=456.080\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3416158292163907\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.172547625306553\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.2624927747991\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.71214201402841\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.44978898008362\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.28017603319343\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.11842717524965\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.30054855299493\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.36790888109826\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:152.84967761321394\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.81460828999326\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.76251037505543\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.2992070575931\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.30860968556988\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:241.65309295684364\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.3479066010475\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.48766367790586\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.3890693383907\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.84600944942696\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.0298244707285\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.39363332867595\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.44492787135613\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.79429583436087\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:380.9177255659063\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.36558338826137\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.0453617286452\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.28509952476907\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:440.7051892823299\n",
            "##################################################\n",
            ">epoch=369, lrate=0.300, error=456.106\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.333873357738701\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.15578634035672\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.23634094738285\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.72502988917308\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.45756090805291\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.32075887857198\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.16114147179083\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.36044745820922\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.42674979487091\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:152.8970504161477\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:173.9047564689841\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.83077335207878\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.40074052429915\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.40447442543308\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:241.74850059422823\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.42170179751258\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.55007745054877\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.4886173293987\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.9352005212556\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.04867922828686\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.45792510222384\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.52429665336797\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8695345976984\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.00788595224725\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.44999747543903\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.13378201622106\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.36803615650246\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:440.8066939715122\n",
            "##################################################\n",
            ">epoch=370, lrate=0.300, error=456.213\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3280239915176075\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.136321377513017\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.20875423576536\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.735455147676404\n",
            "Iteration 200 | Accuracy: 74.21428571428571 | Loss:69.46834716299902\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.36368419136137\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.21044263849424\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.42984999697791\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.49733509174655\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.94749174102145\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.0050642828887\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.90496226900592\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.52098438962946\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.52768459729967\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.88159573617867\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.53650952023224\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.6560937781613\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.6628679929427\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.0981486517451\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:319.10590704683926\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:333.6125000910662\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.7442568609185\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.10331419738117\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:381.2531301362928\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.6825739084766\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.37220545597535\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.6029282808631\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.06425845671833\n",
            "##################################################\n",
            ">epoch=371, lrate=0.300, error=456.480\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.320161804250112\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.109645752779738\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.17541159890511\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73892194564164\n",
            "Iteration 200 | Accuracy: 74.21428571428571 | Loss:69.47808991892673\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.3994763086844\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.255336163645\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.50064551131014\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.57087431770802\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.99277750319337\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.07095775882127\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.94497348046846\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.5982664431791\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.61766843316107\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.99640554826618\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.63385966106532\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.74941916196497\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.85103799436337\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:302.27594706940505\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.1548616599864\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.78138976489464\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0996286860441\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.5217621172711\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.68802612613894\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:401.0681826455567\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.7548698164824\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:424.98399662260545\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.47641162214336\n",
            "##################################################\n",
            ">epoch=372, lrate=0.300, error=456.912\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3078658181415463\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.071971166290297\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.137678333160665\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73329034547521\n",
            "Iteration 200 | Accuracy: 74.0 | Loss:69.4798001466419\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.40843983214161\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.26960911825437\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.54812172982692\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.6211577096543\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.01337432763202\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.03656093750337\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.8882852700364\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.55131093922162\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.57829359039926\n",
            "Iteration 700 | Accuracy: 74.71428571428571 | Loss:241.99213855386256\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.60680912346444\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.72384409552916\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.90449338485683\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.3232517349257\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.12093675476063\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.7865043437125\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:347.2422228203798\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.6541107184345\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.8206569419621\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.15468352852395\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.83723249093\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.06171556716686\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.59322721951816\n",
            "##################################################\n",
            ">epoch=373, lrate=0.300, error=457.038\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3033583124585133\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.039011113914892\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.105348490165504\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.72834503486874\n",
            "Iteration 200 | Accuracy: 73.92857142857143 | Loss:69.49209713385768\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.44014907255371\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.3126325960079\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.62588823839297\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.7066224331027\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.04702567669545\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:173.9517583148859\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:192.7875982126277\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.4365012959471\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.46126809576484\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.93003224112573\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.52029734106245\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.64352941389893\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:286.89302030743113\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.31209168399477\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.08678952964436\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.71280688118156\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:347.20381576454406\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.6096800932852\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:381.7877975027979\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:401.1133685741655\n",
            "Iteration 1250 | Accuracy: 73.92857142857143 | Loss:413.8141538151945\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.02410640259666\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.608965310701\n",
            "##################################################\n",
            ">epoch=374, lrate=0.300, error=457.047\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.3091457264373754\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.014508753029155\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.084911946823894\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.72363641665787\n",
            "Iteration 200 | Accuracy: 73.85714285714286 | Loss:69.52052997182588\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.50609026451065\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.40379501503348\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.75370874225028\n",
            "Iteration 400 | Accuracy: 75.57142857142857 | Loss:132.84857918405459\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.10757169484202\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.9320254827611\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:192.76862849380427\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.41894099006797\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.41711578348952\n",
            "Iteration 700 | Accuracy: 74.64285714285714 | Loss:241.96129446395085\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:255.5254698513043\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.6563344607963\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.948741196406\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:302.37982838972124\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.22160439482286\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.71223971143166\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.10438133860424\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.585104400069\n",
            "Iteration 1150 | Accuracy: 73.14285714285714 | Loss:381.81944774047\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:401.1825464236947\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.93260373531376\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.11818690408563\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.7655160007481\n",
            "##################################################\n",
            ">epoch=375, lrate=0.300, error=457.179\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3328012803038407\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.0054780970098\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.07678582787834\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73388799210075\n",
            "Iteration 200 | Accuracy: 73.57142857142858 | Loss:69.57876231887658\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.60940897592762\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.55029859322545\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.94195893336303\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.05896884723686\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:153.21552711804205\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.08623918368409\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.91793168077555\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.6436208230875\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.6184941535401\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:242.22772942881033\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:255.74358247591454\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.8858700064277\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.19365697543907\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.65642091671975\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.7225172478325\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.9285674741779\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0660234047123\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.4806499118932\n",
            "Iteration 1150 | Accuracy: 73.14285714285714 | Loss:381.73332636472105\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:401.1662278681622\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.9654710727719\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.11943138789115\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.8242899288359\n",
            "##################################################\n",
            ">epoch=376, lrate=0.300, error=457.206\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.365424436353983\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.012099307302996\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.08080903192943\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.75465215486249\n",
            "Iteration 200 | Accuracy: 73.21428571428571 | Loss:69.66707110345199\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.75675100531431\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.75771301522246\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:121.189356374016\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.34341650745083\n",
            "Iteration 450 | Accuracy: 75.21428571428571 | Loss:153.36327136367862\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.31084656891701\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.12229399740298\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.90906941528516\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.88350144468725\n",
            "Iteration 700 | Accuracy: 74.71428571428571 | Loss:242.52144146367206\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.96888836860862\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:268.1267796138477\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.4265578330751\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:302.9109927412464\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.1966446669937\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:334.2638786647981\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.38593543831\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:368.8166848363012\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.1160676688155\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:401.56251841303344\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.3872291783006\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:425.5104790331215\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:442.2728898431314\n",
            "##################################################\n",
            ">epoch=377, lrate=0.300, error=457.616\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.414993280026897\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.047177290677475\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.09191117450916\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.81083327155715\n",
            "Iteration 200 | Accuracy: 73.42857142857143 | Loss:69.73044127215553\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.78024032581472\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.81569631998133\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:121.28041569105508\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.45157469014663\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:153.39305636772403\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.35190535484452\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.12820046313345\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.9005836951714\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.8766231747436\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.5046644738905\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:255.88574290667347\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:268.05033262731007\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.34705195761734\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.8278772255761\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.18964366417845\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:334.2854202423123\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.40910434953895\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.849359868329\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.17528095431703\n",
            "Iteration 1200 | Accuracy: 73.28571428571429 | Loss:401.62252420656904\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.46414869754943\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.5621041881942\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.3807669483959\n",
            "##################################################\n",
            ">epoch=378, lrate=0.300, error=457.671\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.4749639942372343\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.12113175039645\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.12553154327287\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:57.89350394249022\n",
            "Iteration 200 | Accuracy: 73.85714285714286 | Loss:69.77356937322908\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.7112289212213\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.75144813310115\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.22560650670835\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.39532900034007\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.33940846627112\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.305684142179\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.0455914542097\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.79740624048742\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.77013588149305\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.39137616548408\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.7205616366686\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.8901803391198\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:287.1886415331816\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.6591002704157\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:320.0509149311998\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:334.21332916725277\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.3424048014681\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.79457496479654\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1457557148618\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.5828766041181\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.43480615685576\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.5097545613291\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.38078027080604\n",
            "##################################################\n",
            ">epoch=379, lrate=0.300, error=457.613\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.5304181036106752\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.21910925351643\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.191023143093254\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.96995027159836\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.78002554745412\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.52919655509596\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:103.55460468862977\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.00585336042764\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.17220017643103\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.19753293395755\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.17379499746406\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:192.88205451773518\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.6309283489089\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.58965975665484\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:242.2156882510879\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.51022766232833\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.6885071606481\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.9891003286643\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.4480277091625\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.85219931516815\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:334.1124035941646\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.26607686094883\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.740845298434\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.129077034315\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.54141604791124\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.3975349091922\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.45403597599454\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.3656982194348\n",
            "##################################################\n",
            ">epoch=380, lrate=0.300, error=457.554\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.5684636907392209\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.310642396945198\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.27804946930367\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.03232007123628\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.77745961033547\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.28167002159482\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.30855021216645\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.7094952378442\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:132.86596722829427\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:153.05677363422637\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.00984881824758\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.69449196572833\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.44400598862697\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.3749800895222\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:242.0049821785313\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.28304344143126\n",
            "Iteration 800 | Accuracy: 75.85714285714286 | Loss:267.4707968087122\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.7783141939088\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.2208158971839\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:319.6250712486773\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.98307414051555\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:347.1795353810449\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.68685462482034\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1207106858251\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.4972618756791\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.34910471955345\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.39085707973044\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:442.33125273286134\n",
            "##################################################\n",
            ">epoch=381, lrate=0.300, error=457.487\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.5964022740123862\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.386366880281848\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.37380003408529\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.06615521642851\n",
            "Iteration 200 | Accuracy: 75.35714285714286 | Loss:69.78385343759379\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:86.08376916172756\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.13514674991309\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.4750184700707\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.60540230333402\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:152.97865494845001\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.85008085951117\n",
            "Iteration 550 | Accuracy: 72.64285714285714 | Loss:192.50946436580327\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.18829198723256\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.09302832191037\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:241.6860003193686\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:254.96777624018807\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.1462606980779\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.4798590452909\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.88636479073625\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.29421373752416\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.65983891285555\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.85060671898873\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.37546209742266\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.8423403695375\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.2071467368161\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.0457030055712\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.06130636718024\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.03076512143633\n",
            "##################################################\n",
            ">epoch=382, lrate=0.300, error=457.135\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.637530472621072\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.47567780350985\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.49338972412915\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:58.07272426672367\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.80879207513202\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.01551883482095\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.02084976084753\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:120.31553977559717\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.4384551655436\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:152.98577013572842\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.91475380936956\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:192.53961659414068\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.17087188930117\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.05648263952068\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.5500154104545\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:254.84669951693257\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:266.99252495985144\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.34624199273253\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.6913475317898\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.0234385216441\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.31281448843396\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.4471726873265\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:367.97939269604814\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.473005259018\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.85451029283774\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.66399890908207\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:424.6292467341947\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.6313180469289\n",
            "##################################################\n",
            ">epoch=383, lrate=0.300, error=456.659\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.6876054243863232\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.591888391103236\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.64870825218957\n",
            "Iteration 150 | Accuracy: 75.71428571428571 | Loss:58.11574627582714\n",
            "Iteration 200 | Accuracy: 75.35714285714286 | Loss:69.90475968195133\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:86.1178920017642\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.01765053021305\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:120.30101235123323\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.47800282634904\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:153.16931829686538\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.411334640138\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:193.06903016327473\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:209.67317533757657\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.42539991876365\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:241.81508265365974\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.12203084285136\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.2419017692148\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.5427470058749\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:301.8136907543495\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:318.96548770569063\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.2900118608758\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:346.43226110989525\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:367.9645522719196\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:381.52104983731715\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.90885083231586\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.66078915131817\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:424.5758335074469\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.5945469392489\n",
            "##################################################\n",
            ">epoch=384, lrate=0.300, error=456.559\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7166151348741643\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.68487615624825\n",
            "Iteration 100 | Accuracy: 76.21428571428571 | Loss:39.77158272612467\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:58.237428104090974\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:70.08595102326196\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.317176581493\n",
            "Iteration 300 | Accuracy: 76.64285714285714 | Loss:103.13264310717875\n",
            "Iteration 350 | Accuracy: 76.78571428571429 | Loss:120.45786651642872\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.69904132479687\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.51034197167724\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.64332340198763\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:193.30713204848092\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.82068927540436\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.51418955870508\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:241.78127721207784\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.092402746672\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.18817901576904\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.32439345945284\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.5112440456784\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:318.4791274331613\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:332.92140018307265\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.1071774329197\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.6324107719011\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.29229881016323\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.694002075277\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.3663009843263\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:424.2319554835157\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.25709371847444\n",
            "##################################################\n",
            ">epoch=385, lrate=0.300, error=456.152\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7454478830474724\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.79646974219008\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.89931017899778\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:58.394465876283604\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:70.31639084455247\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.5720733341468\n",
            "Iteration 300 | Accuracy: 76.5 | Loss:103.28892400938878\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:120.77591274995766\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.1035904573632\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.03166848367243\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.79022753362528\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:193.43438200642828\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.01259793591348\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.69878642479304\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:241.96777355628842\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.27822931156214\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.37043210351203\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.4816836764936\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.62175547836245\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:318.4860698635934\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:333.0130632010353\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.2466751478479\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.79300218653884\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.51953819368595\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:400.9469991588283\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.5834865982379\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:424.4149796968191\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.45143507292056\n",
            "##################################################\n",
            ">epoch=386, lrate=0.300, error=456.316\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.7568272634184474\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.846757647102983\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.95144386319332\n",
            "Iteration 150 | Accuracy: 75.21428571428571 | Loss:58.41820352119065\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:70.3685500721894\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.64676190931745\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.31471824857478\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:120.96333652200363\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.35175917013328\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.31480801309627\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.85676156837414\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:193.47758330387464\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.16433677004255\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.8830732377439\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.2176261181695\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.51761206089196\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.62314289494856\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.8675218060255\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.9797844438267\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.74970324580124\n",
            "Iteration 1000 | Accuracy: 74.92857142857143 | Loss:333.34804221236425\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.6545247040697\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.2458122128856\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.00429692811457\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:401.44666205229174\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.08332839578185\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.8995709945167\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.95328361492716\n",
            "##################################################\n",
            ">epoch=387, lrate=0.300, error=456.815\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.758320675696666\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.851554340221167\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.95007028782442\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:58.38585864373364\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:70.3213419622008\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.60838643443475\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.26878529488381\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.01222785870037\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.4359110782344\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.39868494684322\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.8808087495814\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.48919358013043\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:210.16371716656914\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.8375100865893\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.19458553067454\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.4971171200951\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.6035738610085\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.88032554657536\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.95994749256056\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.66103651844105\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.3222410880237\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:346.69260108698336\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.2893622543288\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.0824328301111\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.5237247075594\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.15323213397284\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.94934780584714\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.01772802080023\n",
            "##################################################\n",
            ">epoch=388, lrate=0.300, error=456.868\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.762547104007464\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.8702779514685\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.96601801946799\n",
            "Iteration 150 | Accuracy: 75.35714285714286 | Loss:58.401477041570764\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:70.32464872722744\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.6226770306933\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.26669180515732\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.14793332206906\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.61944455629043\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.58739767515334\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.9620001898001\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.54999244599713\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:210.21997585292345\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.86677530945101\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.2577357978031\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.56103667690962\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.67263555179636\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.9948816185174\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.04384551051027\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.68459472281705\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.40612041011974\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:346.8270560102989\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.3939612178199\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.18856764042835\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.62272376639265\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.2543042186983\n",
            "Iteration 1300 | Accuracy: 75.21428571428571 | Loss:425.0292102894522\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.11457213760514\n",
            "##################################################\n",
            ">epoch=389, lrate=0.300, error=456.950\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7683863575067986\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.892065810014387\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.98352964470457\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.408118488863344\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:70.31533868093871\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.62367632751324\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.25643553269282\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.271960781667\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.8070721124572\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.78579582105607\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.0699016022045\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.638469757699\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:210.28052004100647\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.88281305044038\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.30029274164914\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.60757845312145\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.72034349108077\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.0677077159286\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.0855354231021\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.677786705657\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.45208456993475\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:346.90146612173316\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.4107013561903\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.18857105579133\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.6132636964509\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.2413295727769\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.9960540434382\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:442.09781829937805\n",
            "##################################################\n",
            ">epoch=390, lrate=0.300, error=456.918\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7728614840124173\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.909529775259408\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.99582674272626\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:58.401965497499546\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.29650886570687\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.61553737974444\n",
            "Iteration 300 | Accuracy: 76.5 | Loss:103.23424041521979\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.39516304984151\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.99643239307818\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.9954462481241\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:175.1874554106429\n",
            "Iteration 550 | Accuracy: 73.28571428571429 | Loss:193.7359674458653\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:210.34494743090244\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.9060694926902\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.35002498334876\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.6619305721451\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.77461374377276\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.1402375565814\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.12895799089137\n",
            "Iteration 950 | Accuracy: 75.14285714285714 | Loss:318.6859736939877\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.5022502451741\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:346.96520479255844\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.4180250750959\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.17863794223825\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.5911649710391\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.2014533433478\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:424.94103560512735\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.0571538049706\n",
            "##################################################\n",
            ">epoch=391, lrate=0.300, error=456.866\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.7742474236024335\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.915018642905054\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.99452378455486\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:58.37987362624644\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.26547198629076\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.59385281682677\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.19654663432956\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.50511091375755\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.15344265101416\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:155.18177709346372\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.2984642242642\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.82983284331186\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.39964657019542\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.92302096051327\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.3936676472575\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.71091883122338\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.82179676684257\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:287.19687060140734\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1592804471151\n",
            "Iteration 950 | Accuracy: 75.14285714285714 | Loss:318.69541606450827\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.5404565816997\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0085169524004\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.42152425373075\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.1884659551606\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.58307323922634\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.1531387382939\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.883533348795\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.0096210048146\n",
            "##################################################\n",
            ">epoch=392, lrate=0.300, error=456.815\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.7719972679146125\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.907608908055117\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.9789300022787\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.34506062891499\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.22532966984723\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.56242503253624\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.14761283956574\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.59632348256315\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.2711610037427\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:155.3441581194458\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:175.39938489779317\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.9202206477693\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.44568053820976\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.9413961985189\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.4377378127001\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.76060202313772\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.8679805103984\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.2421527352371\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1823528419592\n",
            "Iteration 950 | Accuracy: 75.07142857142857 | Loss:318.7125225398059\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.5714041373748\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.0390202702629\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:368.42693736443846\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.231730392627\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.59967801389433\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.1061100366367\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.8348690195025\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.9644030956093\n",
            "##################################################\n",
            ">epoch=393, lrate=0.300, error=456.776\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.765076289066967\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.88622920021776\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.94826590563593\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.29570589136745\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.1723559954603\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.51798323883783\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.08528956262386\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:121.65058693752242\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:134.3612991353679\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:155.50243622683348\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.47902500183284\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:194.00178278854608\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.47294316206577\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.960999193358\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.473470459001\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.7984446176429\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.9030141026814\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.263260580672\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1878700341315\n",
            "Iteration 950 | Accuracy: 75.0 | Loss:318.733463743815\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.58709345288077\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.04582036410363\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.42427395764065\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.29994017464156\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.6318450390317\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.0562973927461\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:424.79769584949236\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.92135902565263\n",
            "##################################################\n",
            ">epoch=394, lrate=0.300, error=456.756\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7500019544628307\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.843314005840003\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.89615897601323\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.2283501181883\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.1019230177991\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.45461346094939\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.00548309026664\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.64377802710568\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:134.3881051449761\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:155.60545497105034\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.4952701266113\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:194.0403043332197\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.43612270260584\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.94595285887394\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.4492111534135\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.766463727826\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.8757411710399\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.20843531152866\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1251787781009\n",
            "Iteration 950 | Accuracy: 75.0 | Loss:318.71661515568195\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.5425652067392\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:346.9740634368403\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.36834041189053\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.35311890327915\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:401.6261626876434\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.9506228278045\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:424.7366356457913\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.83792020538374\n",
            "##################################################\n",
            ">epoch=395, lrate=0.300, error=456.716\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.716604680921661\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.758333405489424\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.80562864771054\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.13885084671613\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.01182671600527\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.36620534619885\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.91184731128715\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.59056221867402\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.32830657624183\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:155.5916510666315\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.44886485352282\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:194.03278389073972\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.3453171183722\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.89372607041463\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.3544296724784\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.65545539042867\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.7751856730646\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.0530158139257\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.96555206278305\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.62582500596096\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.410790795544\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.79554520030007\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.2026468993791\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.2959643568873\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.54758061795746\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.78599097406396\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.6308989403945\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.71103711262265\n",
            "##################################################\n",
            ">epoch=396, lrate=0.300, error=456.623\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6850417478028743\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.69685795690336\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.75223852981109\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.06564866506423\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.92987973385796\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.28945644315846\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:102.83261637160582\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:121.54482550207372\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.25792777362952\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:155.51105202524684\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.4455689310883\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:194.06231906714743\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.27026013630186\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.8394474714084\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.26349932565702\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.54831714733052\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.672889961678\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.867692151801\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.77503721753595\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.4952846598703\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.2505375744877\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.59500878974325\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:367.9795392493189\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1440881708719\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.41734395508234\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.62133964607483\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:424.5349449563931\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.6021476726631\n",
            "##################################################\n",
            ">epoch=397, lrate=0.300, error=456.529\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.6684563493435194\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.66459624496214\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.72724887391053\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.003512663738924\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.86500230011207\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.23045492397561\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:102.74328570630954\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.50580259517076\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.2029264761009\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:155.416637725014\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:175.53962789476932\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:194.18772964350487\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.23209755752939\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.7968097550153\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.1971216416932\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.4690891909341\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.58527302021366\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.64571872922056\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.5492007112631\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.3187196460659\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.056880231438\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.3724125762879\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:367.7203207239366\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.94174074046396\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:401.1906936157478\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.37523756739745\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:424.324935081344\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.3827640498071\n",
            "##################################################\n",
            ">epoch=398, lrate=0.300, error=456.313\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.6582963240628898\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.653059662443745\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.716966629559934\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.93652842704121\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.79881423257716\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:86.16926616395101\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.62585396834928\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.44326375692762\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.13235517930548\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:155.30471217742377\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:175.64472729713125\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:194.3039480946159\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.38277799940505\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.92278206976866\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.33269073158655\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.55990831383946\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.6862371618359\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.79100442338637\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.69862582856814\n",
            "Iteration 950 | Accuracy: 74.71428571428571 | Loss:318.517846940113\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.21883330771414\n",
            "Iteration 1050 | Accuracy: 74.28571428571429 | Loss:346.506886863436\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:367.8259582657237\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.0978857257657\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.29198947826256\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.4571568359148\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:424.4115459758575\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.4675094531218\n",
            "##################################################\n",
            ">epoch=399, lrate=0.300, error=456.403\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.653456500441866\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.649122251591574\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.71427713089186\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.89197781341966\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.73798202394454\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.10752551726627\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.52362621471893\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:121.35964205251712\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.0292468796595\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:155.1357394359555\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.59919396670762\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:194.23261062454682\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.58355438277596\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:226.06318430714987\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.5153289000359\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.6824622236922\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.8311642061361\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:287.05751193863654\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.9847113977314\n",
            "Iteration 950 | Accuracy: 74.64285714285714 | Loss:318.87754972803253\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.53660570467065\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.80341665902245\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.10765325157683\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.4148912119762\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.53909053112756\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.68889812767674\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.6205729777709\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.6809367242277\n",
            "##################################################\n",
            ">epoch=400, lrate=0.300, error=456.635\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.6418228390062812\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:16.624093831923318\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.69814984674302\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.8572501999713\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.66860455401425\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.03273421028284\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.43661351727529\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.24749132783101\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.8694510079082\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.90910261585717\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.3846508877759\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:193.9892170576881\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.51003659104933\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.93770823656627\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.40035305568244\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.5321320219063\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.68217412326277\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.9099488088829\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.8442589629908\n",
            "Iteration 950 | Accuracy: 74.57142857142857 | Loss:318.78612727287725\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.4344473344766\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.6918969015784\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:367.98786152179315\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.309681259638\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.39552513275174\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.54412855255316\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4596650270075\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.5227313958855\n",
            "##################################################\n",
            ">epoch=401, lrate=0.300, error=456.490\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.6329907150650222\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:16.607483625331405\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.68421119056739\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.82512097966748\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.61072274926651\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:85.96701881426986\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.35254539999036\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.16641434843022\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78059968015208\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.74430087970651\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:175.1571865304533\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.72655673198443\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.60205833151565\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.97660467807245\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.42517726875383\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.53003473774217\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.67684461363405\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.88554523286575\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.82267616142445\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.8110718863129\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:333.4544688011419\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.71107921366223\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.00746884396665\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.32863743280706\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.3502790088946\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.51920634351285\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4125814536815\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.48292635523154\n",
            "##################################################\n",
            ">epoch=402, lrate=0.300, error=456.451\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.636765137169399\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.615446479347657\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.68638504778429\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.831182614298115\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.6051590126925\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:85.94431063548826\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.31853085652945\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.14161378563375\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.773173952209\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.66378268036846\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.99997253978472\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.56530825709567\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.71467941771752\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:226.1229999973393\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.53408250320305\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.62875362509843\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.7755329935599\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.9406866363211\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.8699201913605\n",
            "Iteration 950 | Accuracy: 74.85714285714286 | Loss:318.93124630077773\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.59811306807023\n",
            "Iteration 1050 | Accuracy: 74.07142857142858 | Loss:346.90811917548666\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.1748063910414\n",
            "Iteration 1150 | Accuracy: 73.5 | Loss:382.4862049166547\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.55276986879335\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.7369510081084\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.63604516243083\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.705177108904\n",
            "##################################################\n",
            ">epoch=403, lrate=0.300, error=456.658\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.658154119187069\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.66681633954397\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.721642882339346\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.905080634887575\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.69353461148495\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.01230244860018\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:102.37605400603381\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.26888872827575\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.97631685591068\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.75562240699196\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.12696296273657\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.70395648382924\n",
            "Iteration 600 | Accuracy: 74.42857142857143 | Loss:211.23039673924313\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:226.7331812625382\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:243.1302943779124\n",
            "Iteration 750 | Accuracy: 75.85714285714286 | Loss:256.23145126086814\n",
            "Iteration 800 | Accuracy: 75.92857142857142 | Loss:268.4132730631461\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.58168953430334\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.51163196977035\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:319.6756074252894\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:334.4068627400394\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:347.87065633156834\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.99637927830366\n",
            "Iteration 1150 | Accuracy: 73.71428571428571 | Loss:383.13840858243486\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:402.3484846821768\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.5395997549359\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.45789295669624\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:442.53282633382173\n",
            "##################################################\n",
            ">epoch=404, lrate=0.300, error=457.477\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.661820610042898\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.683041489713386\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.69987956143714\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.900085335364516\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.71079992538739\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.98910017526126\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.32367072372085\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:121.32173362954524\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.0818755816246\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.7638782039278\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.23428002357798\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.81206827578555\n",
            "Iteration 600 | Accuracy: 73.71428571428571 | Loss:211.65347596899142\n",
            "Iteration 650 | Accuracy: 74.14285714285714 | Loss:227.2249796269661\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:243.6525798090798\n",
            "Iteration 750 | Accuracy: 75.78571428571429 | Loss:256.78109752104405\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:268.99744694680106\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.12647125197486\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:303.05637710667264\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:320.2758290095933\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:335.02990053252375\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:348.5462665731299\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.5506505170376\n",
            "Iteration 1150 | Accuracy: 73.78571428571429 | Loss:383.5285180129198\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:402.63601495423455\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.8379556959809\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:425.7542837424652\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:442.8460407002963\n",
            "##################################################\n",
            ">epoch=405, lrate=0.300, error=457.795\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.662466368311813\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.706326987507016\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.68736311436325\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:57.84500785151608\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.6415282395697\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.89773579194664\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.26588039796538\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:121.29099600667759\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.08005535668286\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.70372708895366\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.15926414552854\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.73774727694163\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:211.61426784082664\n",
            "Iteration 650 | Accuracy: 74.0 | Loss:227.20955860202685\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:243.6204063745744\n",
            "Iteration 750 | Accuracy: 75.85714285714286 | Loss:256.78682311654154\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:268.9837907868682\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:288.07480800914504\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.99800188490474\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.2413385443958\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:335.0021505843012\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:348.5026701683686\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.4947681044108\n",
            "Iteration 1150 | Accuracy: 73.64285714285714 | Loss:383.503928426151\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:402.4333638489895\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.65091537973547\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.522282228909\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:442.63215499713647\n",
            "##################################################\n",
            ">epoch=406, lrate=0.300, error=457.581\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.6739491263820194\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.749526062312\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.696679032672364\n",
            "Iteration 150 | Accuracy: 75.64285714285714 | Loss:57.77029596915337\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.52677594744738\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.77019123494782\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.23367566786264\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:121.18806338690737\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.99751169341582\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.62047936292933\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:175.02885303622426\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.57429073531972\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:211.3654304717858\n",
            "Iteration 650 | Accuracy: 73.71428571428571 | Loss:226.98148621509466\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:243.34012351868026\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:256.5478013134045\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:268.70872607049756\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.7990146939431\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.711706422262\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.9939539608347\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:334.7790328338907\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:348.23801172047416\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:369.23069534477116\n",
            "Iteration 1150 | Accuracy: 73.71428571428571 | Loss:383.2816446110572\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.984012992102\n",
            "Iteration 1250 | Accuracy: 73.92857142857143 | Loss:414.2379420129567\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.0369482442616\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:442.17458212833435\n",
            "##################################################\n",
            ">epoch=407, lrate=0.300, error=457.100\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.693266203422017\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.798184717423197\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.70545977197226\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.7283403599963\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.4481661624363\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.66354924996828\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.17775528996535\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.04487356297042\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.8722230170928\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.5198212818045\n",
            "Iteration 500 | Accuracy: 74.71428571428571 | Loss:174.85966545961486\n",
            "Iteration 550 | Accuracy: 71.71428571428572 | Loss:193.3460310718056\n",
            "Iteration 600 | Accuracy: 73.64285714285714 | Loss:210.97396427296366\n",
            "Iteration 650 | Accuracy: 74.0 | Loss:226.5704378608803\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.895846707521\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:256.13291769141574\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:268.2556885000849\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.32669584095134\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.2130522339073\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:319.50283278074\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:334.3432141582936\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.7617070134087\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.7506464309514\n",
            "Iteration 1150 | Accuracy: 74.0 | Loss:382.80571226536296\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.44065809792113\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.7408960400091\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.52143592323665\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:441.68066841949803\n",
            "##################################################\n",
            ">epoch=408, lrate=0.300, error=456.569\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7079143563743862\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.8194538724376\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.68946647723191\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.73959533442145\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.45141017684662\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.63479597004151\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:102.13224442054579\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.99769062506306\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.85656963825272\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.50010816203724\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.8561413690425\n",
            "Iteration 550 | Accuracy: 71.64285714285714 | Loss:193.29240064956454\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:210.8925419935677\n",
            "Iteration 650 | Accuracy: 74.07142857142858 | Loss:226.44601759993475\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.781947916048\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:256.03087153078604\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:268.14059651384866\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.15844919012926\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.0214187797233\n",
            "Iteration 950 | Accuracy: 75.92857142857142 | Loss:319.30155791473624\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:334.17274216382725\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:347.5568219243982\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.5691628044874\n",
            "Iteration 1150 | Accuracy: 74.14285714285714 | Loss:382.6816406130235\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.35761115161887\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.7096727280986\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4823963904458\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:441.66222342851444\n",
            "##################################################\n",
            ">epoch=409, lrate=0.300, error=456.543\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7106679052039282\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.798361641573177\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.64176784295803\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.7167267380156\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.42504379608751\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.5893291834432\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.10137105411243\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.93302662724064\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.80121448707555\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.494923867529\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.89187989888038\n",
            "Iteration 550 | Accuracy: 71.85714285714285 | Loss:193.28356675611587\n",
            "Iteration 600 | Accuracy: 74.57142857142857 | Loss:210.47131639429315\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.93163310407186\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.33870838444105\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.5444451305559\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.6490440266383\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.60752077844063\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.45568819631154\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.7447093976819\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.6605708571599\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:347.03555558119257\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.04323285456366\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:382.1458368830069\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.8466255878596\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.1785626433336\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.95347247145094\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:441.13732477495194\n",
            "##################################################\n",
            ">epoch=410, lrate=0.300, error=456.026\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7075283198756246\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.79052795664938\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.62599555940436\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.700327039893644\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.41035274870526\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.57814489805334\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.08494859413383\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.89277245011591\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7625346342959\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.4920708024834\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.93091620733648\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.33501975621505\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.07949719904727\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.51264930191053\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.90876662129764\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.0811602773342\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.1753972978883\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.0767784522587\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:300.91988489669603\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.21357701440024\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.15528777517414\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.5250222642149\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.50492477374655\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:381.55259719987913\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:400.2547295526692\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:412.54694056338485\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.3321666445163\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.5138627990807\n",
            "##################################################\n",
            ">epoch=411, lrate=0.300, error=455.391\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7100814833964395\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.81427131129125\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.645865402701574\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.72456357035503\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43413735368166\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.60731496808091\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.08822578821088\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.90378517440638\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78052588242522\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4850065797437\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.90146196473643\n",
            "Iteration 550 | Accuracy: 71.85714285714285 | Loss:193.28740140084804\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.25371533900466\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.68459550696682\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.07240689478087\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.2462171795952\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.332496484054\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.2074611733216\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.0366076257464\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.3292274529512\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.2879356325161\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:346.647384476006\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.61136703687134\n",
            "Iteration 1150 | Accuracy: 74.28571428571429 | Loss:381.6644594985878\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:400.39158538075986\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:412.68441306633963\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.4746682544511\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6590203014051\n",
            "##################################################\n",
            ">epoch=412, lrate=0.300, error=455.532\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7120667913012302\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.82020721678926\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.63717997004581\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.724178051228826\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43642854533135\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.60729872866773\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.07194865363402\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.89211572347438\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78017647250198\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.47240519514563\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.87253411644755\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.24540897139119\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.28428472216407\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.70517873753468\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.09460245405862\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.26645212818414\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.34575362612304\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.1917737282971\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.00847614194834\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.30283079247386\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.2806671407154\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.63158364883816\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.5799770037552\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:381.63747757917923\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3939214302913\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:412.69005163976675\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.485737401575\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6725411145242\n",
            "##################################################\n",
            ">epoch=413, lrate=0.300, error=455.540\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.714624995826624\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.825843644646373\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.62681678391809\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.72287172918464\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.4393669512521\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.60466431629185\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.05332975504778\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.88059544762298\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78126773967148\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4558803328661\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.83401365948046\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.1906742208353\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:210.35337109806017\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.76579922098094\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.16033244959908\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.33519767421475\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.4081104664349\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.2298966585882\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.0334507418441\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.3322143094013\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.32913564436564\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.6690496378868\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.606015144405\n",
            "Iteration 1150 | Accuracy: 74.28571428571429 | Loss:381.6787691337354\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.47237053190196\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.77933894925377\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.579443672293\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.7687489893336\n",
            "##################################################\n",
            ">epoch=414, lrate=0.300, error=455.632\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7172218588493307\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.828746137188418\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.61114685027753\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71654634323237\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43761550820959\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.59459957670394\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.03369525891291\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.86462508834259\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.77749398283152\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4411321640857\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.80456627844782\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.1464130696629\n",
            "Iteration 600 | Accuracy: 74.14285714285714 | Loss:210.3504362000566\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.7475512684018\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.14881139249215\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.3204566203882\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.38765356714816\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.18204291700215\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.97425243207954\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.2813660668704\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.29905352775785\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.628028781314\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.55601682275864\n",
            "Iteration 1150 | Accuracy: 74.42857142857143 | Loss:381.639948188221\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:400.4705851539887\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.78521972072616\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.58989093413015\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.78106279734277\n",
            "##################################################\n",
            ">epoch=415, lrate=0.300, error=455.638\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7199156772986997\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.833624543366316\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.59848598506751\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71237187436705\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43673493378574\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.58511455169395\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.01787011347533\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.8503454151921\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7737259293148\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.42858219242575\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.77988657783987\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.10704356009208\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.32677267615298\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.70571938264663\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.11404669590755\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.27939865606896\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.3412597535371\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.106219681808\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.88814525086775\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.20648014956805\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.2462094311374\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.5646414922878\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.4848268997222\n",
            "Iteration 1150 | Accuracy: 74.57142857142857 | Loss:381.5764746516278\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.44270305589873\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.7619227917393\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.571393199779\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.76386760174773\n",
            "##################################################\n",
            ">epoch=416, lrate=0.300, error=455.615\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.722653471360539\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.84074550047381\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58918749890751\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71119806766675\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43738499334272\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.5772477793765\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.00593448256396\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.83798741455819\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.770835501204\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4193082839039\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.75813859248788\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.0712777214932\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.28798025637656\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.64706556262846\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.06229069266723\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.21896279356557\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.27553556005444\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.0083439272292\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:300.780894131265\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.1121378779132\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.1753842090691\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.4850254737279\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.3960105174239\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.4901770680624\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3890202554984\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.7095996273969\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.52456231771527\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.71770114953046\n",
            "##################################################\n",
            ">epoch=417, lrate=0.300, error=455.561\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.72548111226933\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.850505118137093\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58347825917471\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71404112396627\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.44102484790298\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.57230976762222\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.99729825214679\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.82835108840519\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.77072792988048\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.41320926857708\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.73587806438053\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.03579055350804\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.2511404239119\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.59007053747536\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.01070331237625\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.15840293743855\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.2095490898947\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:285.9077660752871\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:300.6715603567493\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.01635431353435\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.10372025109535\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.40638969415784\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.3062305685011\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.39902166260117\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3278739034736\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.64826419661415\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.46929519243025\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6625641833569\n",
            "##################################################\n",
            ">epoch=418, lrate=0.300, error=455.497\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7284337149541673\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.862436787850267\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58029876482119\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.72045523996539\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.44755575102306\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56973191422672\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.99133115703033\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.82151001723699\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7739135305554\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.4106949201794\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.71428666486216\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:193.00156926583097\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.2144611345316\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.53224845760693\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.95763663028706\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.09586124250922\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.1416269307064\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.8031445986486\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.5587986001318\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:317.9174707765711\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.02892901133276\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.3263309256414\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.2137011191605\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.30253027232175\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.25943214806597\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.578929854004\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.4064895141142\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.5995306599806\n",
            "##################################################\n",
            ">epoch=419, lrate=0.300, error=455.423\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.731363562925913\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.875504584437863\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.578628782892245\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.728920372361856\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.45546099447557\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56797923335809\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.98690486772307\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.81612254604435\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.77912078761685\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.41147053994223\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.69354824399628\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.9690082035064\n",
            "Iteration 600 | Accuracy: 74.14285714285714 | Loss:210.17070427535188\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.46574340324386\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.89589864293728\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.0234240643169\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.06385733558034\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.68595015632644\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.43423807113305\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:317.8070617653722\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.9425069915314\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.2365756152494\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.10998153193106\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.1923906726377\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.17534366694787\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.493256324641\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.32799958169477\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.520435761285\n",
            "##################################################\n",
            ">epoch=420, lrate=0.300, error=455.333\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7340949648961144\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.888951603279658\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.5780099295389\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.73834544839799\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.46355129994507\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56603134622787\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.98274117005562\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.8109431192986\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78533496621768\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.4147157866851\n",
            "Iteration 500 | Accuracy: 74.64285714285714 | Loss:174.67197386417106\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.93704776291455\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:210.11966158127842\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.3904484245535\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.82472116063323\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.94038134207142\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:266.9752392075879\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.554098773881\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:300.2959714674069\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.68321269710634\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.8423665132096\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.1349921700502\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:366.99264686865104\n",
            "Iteration 1150 | Accuracy: 74.64285714285714 | Loss:381.06636142985906\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.0731699074421\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.38894283404915\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.2316976500238\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.42305462954755\n",
            "##################################################\n",
            ">epoch=421, lrate=0.300, error=455.223\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7365105906116005\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.902221388091853\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.57818625739288\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.74820114658043\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.4711346321908\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56328237047228\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.97795561174202\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.80545599270602\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7921399543528\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.41972752240088\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.648746254242\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.90553127412028\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:210.06254958174372\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.30748154294784\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.74455131440564\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.8472505621524\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:266.8759704189244\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.4068394329424\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:300.1434277490296\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.54548574939344\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.7278082129127\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.0204942757246\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.860841499218\n",
            "Iteration 1150 | Accuracy: 74.64285714285714 | Loss:380.92420214164804\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:399.9526645429766\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.2659389559546\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.11760698039575\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.3073743097611\n",
            "##################################################\n",
            ">epoch=422, lrate=0.300, error=455.095\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.738501416680483\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.91468641566326\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.57899925602211\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.75812406787425\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.47764527839858\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.5592743391222\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.9720299344505\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.79938860017255\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.7992071298918\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.42607722404298\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.62386694043138\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.87519152496182\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.99911003548806\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.2162264577256\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.65426139915243\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.74275609141165\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:266.76442624939284\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.24152178019943\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.97415797163455\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.3916145802019\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:332.59649554860675\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.8903273047085\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:366.71216680921606\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:380.76410363390033\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:399.8120060388054\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:412.1224535061976\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.984039781295\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:440.1716796485055\n",
            "##################################################\n",
            ">epoch=423, lrate=0.300, error=454.947\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7399637017128837\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.92583943211659\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.580573466631584\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.76811109366748\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.48298607296678\n",
            "Iteration 250 | Accuracy: 77.28571428571429 | Loss:85.55406183374673\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.96477681369336\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.7927433200829\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.80651704546406\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.43351211064976\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.59753208138122\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.8472140170452\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.93018231862166\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.1171643960089\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.5534328738084\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.62639182840041\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:266.6396535643407\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.0561829956505\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.78641973212774\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:317.22002450988754\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:332.4468651628753\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.7425028211283\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:366.5449428124679\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:380.58490821128265\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:399.6499759265954\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:411.95723280116\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.8298668299282\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:440.01479135919\n",
            "##################################################\n",
            ">epoch=424, lrate=0.300, error=454.779\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.740826379879552\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.93546532367107\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.583349237601745\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.77868323217361\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.4877611624148\n",
            "Iteration 250 | Accuracy: 77.28571428571429 | Loss:85.54837087827646\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.95646303590947\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.78600050269362\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8145423497064\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.44187200451776\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.57058915338132\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.82363806381534\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.8576620603792\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.0117550978394\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.44253160760775\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.49857564698286\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:266.50165323860256\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:284.8500784648831\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:299.5797046942662\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.0301628895098\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:332.2783135053784\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:345.57623682237863\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.35847057656395\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:380.38610860999836\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.46589091804105\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:411.7694598037857\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.6544734760449\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:439.8360302731601\n",
            "##################################################\n",
            ">epoch=425, lrate=0.300, error=454.591\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.741051110273862\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.943704348921475\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.58798800054719\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.79072098076268\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.49314906073649\n",
            "Iteration 250 | Accuracy: 77.35714285714286 | Loss:85.54343230551925\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.94765143929928\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.77986055524183\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.82401020516576\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.45082077107475\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.5444500440675\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.80734205020383\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:209.78339992473244\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.90148561183076\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.32217537367856\n",
            "Iteration 750 | Accuracy: 75.92857142857142 | Loss:254.35995300478157\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:266.3507781784013\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:284.62278930548797\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:299.35390180304375\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:316.8212972534161\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:332.08985923402935\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:345.3909723467304\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.1516887965344\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:380.1659380760679\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.25743066785617\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:411.556476391558\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.45561251415484\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:439.6330458135815\n",
            "##################################################\n",
            ">epoch=426, lrate=0.300, error=454.381\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7406177785621177\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.951078473695468\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.595212643103174\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.80520615979194\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.50065737859288\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54071434431154\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.93881009980429\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.77484302770006\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.8353123629999\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4587955555357\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.52048972992802\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.8015134484661\n",
            "Iteration 600 | Accuracy: 74.35714285714286 | Loss:209.70841612783238\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.7875405489802\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.19313131866787\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.21154176371567\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:266.1879683606164\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:284.3742052127098\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.10936988018204\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:316.5921943016193\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:331.8795061363049\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.18602910051595\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.9226225683589\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:379.920234636965\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.0191487342617\n",
            "Iteration 1250 | Accuracy: 74.42857142857143 | Loss:411.3122016564531\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:422.22793331363147\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:439.4003399022002\n",
            "##################################################\n",
            ">epoch=427, lrate=0.300, error=454.145\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.73950310353199\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.95841409829476\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.60557298461984\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.82288312041358\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.5117425656321\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54154543615653\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.92991579675724\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.77082868470524\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.84724625047195\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4611916742048\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.49851718293013\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.80761622245518\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:209.63064299404402\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:224.66918834081974\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.05569528861872\n",
            "Iteration 750 | Accuracy: 75.92857142857142 | Loss:254.05403906325878\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:266.01419684756763\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:284.10460763646006\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.8470633537784\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:316.34109540593306\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.6438325668289\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:344.96033093746126\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.66842154988797\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:379.64199178204836\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:398.7416003192822\n",
            "Iteration 1250 | Accuracy: 74.5 | Loss:411.02614587479\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:421.9619884078095\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:439.128317254658\n",
            "##################################################\n",
            ">epoch=428, lrate=0.300, error=453.874\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7376744460177593\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.96656928781076\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.61917952363831\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.843913213519926\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.52726173296873\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54661352984289\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.92026560438686\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.76666978993956\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.85484704761697\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.44815829724445\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:174.47265417705879\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.81886482569726\n",
            "Iteration 600 | Accuracy: 74.78571428571429 | Loss:209.54056628051964\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.53891778419455\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:240.9058044643624\n",
            "Iteration 750 | Accuracy: 75.78571428571429 | Loss:253.88307610212237\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:265.8259110004553\n",
            "Iteration 850 | Accuracy: 76.14285714285714 | Loss:283.8139230272157\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.56739587099753\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:316.06562566028913\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.37764822246965\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:344.7113159473361\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.38622041102093\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:379.3233345921691\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:398.41367039780454\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:410.6858447591517\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:421.6459613186677\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:438.8051886200718\n",
            "##################################################\n",
            ">epoch=429, lrate=0.300, error=453.554\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7351920746665306\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.97581886581921\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.63558485125889\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.86799238646749\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.54687527583435\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.55536591020622\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.90944143272954\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.76092479358759\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.84888330603323\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.4053052377356\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.42772882112277\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.81111763560858\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.42358267588668\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.38133218898346\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:240.73217980343605\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:253.68625880997254\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:265.61264489377214\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:283.5051377429661\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.27207774614567\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.76782689407514\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.0797593238945\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:344.4373254595321\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:365.07997550391104\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:378.9691160662485\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:398.0399904017731\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:410.29568565876417\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:421.28223498051443\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:438.4341042863216\n",
            "##################################################\n",
            ">epoch=430, lrate=0.300, error=453.188\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7324948855304352\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.985465101578864\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.65388969738075\n",
            "Iteration 150 | Accuracy: 75.78571428571429 | Loss:57.89525296015186\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.5691545929701\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56591380701825\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.90030615666855\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.75527526118535\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.8262449234442\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.32870669332274\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.35487735163375\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.7599572044935\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.2798693785166\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:224.19451433212714\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:240.53513366853383\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:253.4651603807772\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:265.3794191174006\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:283.1986042889671\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.97764217281104\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.4694626097221\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:330.7715105556883\n",
            "Iteration 1050 | Accuracy: 75.5 | Loss:344.1529441835665\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:364.7741724610756\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:378.6169293250874\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:397.66517031362963\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.902999022923\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:420.91311719025873\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:438.05923281866137\n",
            "##################################################\n",
            ">epoch=431, lrate=0.300, error=452.817\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7302471923153546\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.994265878397307\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.672120704921795\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.92501858350008\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.59199950195465\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.57586149674597\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.89811775925372\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.7548242358379\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.80247214117614\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.24467830699072\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.27763091895574\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.68668359790976\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.12220993740064\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.99602535914562\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:240.3316418555592\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:253.2376236198551\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:265.14498859506193\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:282.90782033685286\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.6959869511396\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.1842766229322\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:330.47031136693937\n",
            "Iteration 1050 | Accuracy: 75.5 | Loss:343.8709609298238\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:364.48358353813376\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:378.29056543957404\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:397.3189698743181\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.53953507413826\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:420.568358298671\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:437.7118241351311\n",
            "##################################################\n",
            ">epoch=432, lrate=0.300, error=452.472\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7285753579629337\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:17.001817318142276\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.68861894723043\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.95476132241196\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.61342376446088\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.5840638275777\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.90385963420604\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.76032515761995\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.79081584333295\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.18167482230345\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.2197494212115\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.62667990194913\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:208.9614406486671\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.802499416955\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:240.13540957670645\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:253.01609174785426\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:264.91915796974706\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:282.63294509083516\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.4281825215869\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:314.91087786070483\n",
            "Iteration 1000 | Accuracy: 76.14285714285714 | Loss:330.1785891107855\n",
            "Iteration 1050 | Accuracy: 75.57142857142857 | Loss:343.5966072409185\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:364.20880457282306\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.98726198793094\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:396.9987986173517\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.20249240720665\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:420.24678711441555\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:437.3902496798069\n",
            "##################################################\n",
            ">epoch=433, lrate=0.300, error=452.154\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7273330689928683\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:17.009035753745533\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.70376334156251\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.98358046717614\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.633509435216\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.59143069138705\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.91523541749396\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.76899778536142\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.789549714103\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.14183601942307\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.17984419060622\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.58510721838945\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:208.81234590635907\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.6292882689234\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:239.96003990040776\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:252.814990988508\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.71490630898495\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.3899344164631\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.1899336421045\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.6659655816455\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.9147094865657\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:343.35049736306263\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.9666784918599\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:377.7209133098051\n",
            "Iteration 1200 | Accuracy: 74.28571428571429 | Loss:396.71874829977907\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:408.9064877348478\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.96398950008137\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:437.10881410479635\n",
            "##################################################\n",
            ">epoch=434, lrate=0.300, error=451.874\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.726460578972619\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.015948115183466\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.717525426660345\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:58.01121000326874\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.65264678716252\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.59834136665361\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.92984631110085\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.77901121411483\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.79575407085764\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.11844598572105\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.15383719230252\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.55882290743463\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:208.6799477981297\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.4793365031139\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.80797068882922\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:252.63781080107213\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.5353799892894\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.18303158128435\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.98555694599975\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.45510106614773\n",
            "Iteration 1000 | Accuracy: 76.14285714285714 | Loss:329.684462198578\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:343.1394199905911\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.76236066588956\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.4952144834649\n",
            "Iteration 1200 | Accuracy: 74.28571428571429 | Loss:396.4825615355627\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:408.65549526615655\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.72461691770036\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:436.87150769216055\n",
            "##################################################\n",
            ">epoch=435, lrate=0.300, error=451.636\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7258783554608899\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.022332734060576\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.72992723770049\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.037186130635334\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.670609406272\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.60451515576266\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.94620740854718\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.78906599447134\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8066705170682\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.10673042795028\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.13758322172328\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.54352608175654\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:208.5676420009107\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.35401879344252\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.6800080915763\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.48626044615256\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.38202697252086\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.0115331940871\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:296.81468246393325\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.2790684228841\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.4890625739406\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.96431777232635\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.59595374990664\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.3097626154108\n",
            "Iteration 1200 | Accuracy: 74.35714285714286 | Loss:396.28966624115\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.4490648506875\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.528542336975\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:436.67787450930257\n",
            "##################################################\n",
            ">epoch=436, lrate=0.300, error=451.441\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.725495976082387\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.02800166181375\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74073600048872\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:58.06087930446231\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.68695444911185\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.60937189379531\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.96288759813527\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.79798488461626\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.8199364718207\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10272234864502\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.12749637499667\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.53529422184536\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.47425696666184\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.25068415261228\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.57339607618468\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.3578975679747\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:264.25219089580065\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.8697534294385\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:296.6720634836098\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.1329020285969\n",
            "Iteration 1000 | Accuracy: 76.21428571428571 | Loss:329.32397135261476\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.82008483042534\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.4616988089185\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.158385736961\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:396.13343983310153\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.28045600786095\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.3692269522798\n",
            "Iteration 1350 | Accuracy: 77.14285714285715 | Loss:436.52121603939116\n",
            "##################################################\n",
            ">epoch=437, lrate=0.300, error=451.282\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.725245752291163\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.03303317389379\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74974943627684\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:58.081835911794705\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.7013475605118\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.61240340307725\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:101.97878703501925\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80480611515294\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.83332666541665\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10312810709624\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.12027173867324\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.53049647560354\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.39722713729842\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.1658570610789\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.48483455790375\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.2494145141114\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.14242482059245\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.7518141513146\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.55216407598255\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.0109455143415\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.1838754732597\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.7007975433074\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.3529422604383\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:377.03408655973794\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:396.0064148546754\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.1420306864751\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.23910748700445\n",
            "Iteration 1350 | Accuracy: 77.14285714285715 | Loss:436.3938611016317\n",
            "##################################################\n",
            ">epoch=438, lrate=0.300, error=451.152\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.72509072124367\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.03756844831194\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.75669872529815\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.09974716622006\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.7135378294424\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.61315120051857\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:101.9930868357824\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80887303174353\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.84515699077855\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10535311602004\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.11352553629683\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.5264359519684\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.3321496294253\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.09457931579374\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.4096771905551\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.1558962325651\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:264.0476868969714\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.6511646464652\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.44873488639655\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.9065634891628\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:329.0622449272972\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.5994353579446\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.262000615395\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.9289297828826\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:395.9002980626805\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:408.02530468196954\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.1297459515603\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.2873036489193\n",
            "##################################################\n",
            ">epoch=439, lrate=0.300, error=451.042\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7250126421759622\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.041785587328658\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76141404184362\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.11449476234787\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.72335380795606\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.61131742316704\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.00538475397117\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80991448983565\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.85432570480887\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10771956036263\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.10578825656194\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.52138581282398\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.2750023433873\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.03251285988966\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.34382694915\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.07293483564254\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.96343982205985\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.5624040568588\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.3566239024343\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.8142315552231\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.9535321141246\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.51006143656906\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.18238424239746\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.83633998486687\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:395.80827472928297\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.92331303711074\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.03421608049695\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.19456740868014\n",
            "##################################################\n",
            ">epoch=440, lrate=0.300, error=450.945\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7249998226367627\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.045833012570238\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.7638181403802\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.12609214440372\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73064708498039\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.60672776079944\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.01551304828375\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80793382481531\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.8602389168256\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.10920585583324\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.09632938092554\n",
            "Iteration 550 | Accuracy: 72.28571428571429 | Loss:192.51439872125263\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.2220036336419\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.97571598033295\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:239.28347479978206\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:251.996412018743\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.88542063219484\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.4808300657901\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.27135998451246\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.72917145761704\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.85285054441334\n",
            "Iteration 1050 | Accuracy: 75.64285714285714 | Loss:342.4274765350535\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.1085133816025\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.7508068209553\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:395.7246618391182\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:407.83025312716427\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:418.9467748172373\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.1098724433069\n",
            "##################################################\n",
            ">epoch=441, lrate=0.300, error=450.857\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.725041009493403\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.049867715997525\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76399417843802\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.1346971781755\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73531698432267\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.59936623959305\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.02346719309493\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.8031265495044\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.86267482094394\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10926553917344\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.08488291505117\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.50504154579602\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.17016327642062\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.92115293256103\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.2255791137914\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.92303925030762\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.8101964241822\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.40276113090994\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.1894709778523\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.64772284262887\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:328.7564189043575\n",
            "Iteration 1050 | Accuracy: 75.64285714285714 | Loss:342.3476283086354\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.03610172718874\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.66823761042474\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.64520331447795\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.74178027636333\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:418.8631535665369\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:436.02891859669626\n",
            "##################################################\n",
            ">epoch=442, lrate=0.300, error=450.772\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7251231532286573\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.05405234183872\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76217040663417\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.14058260161189\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73732339749067\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.58934825234671\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.02929843129144\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.79578009938167\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.86167547078355\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10761766814846\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.07144204572572\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.49318987282774\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.11711336516936\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.86649158880851\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.16768146185927\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.85018099969346\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.73500094431995\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.32528464371796\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:296.10823564677196\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.567083539096\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.6613243692\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.26735618902103\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:362.9618593746275\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.5856186936908\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.5667044640855\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.6546336379133\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.7801772630195\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.9485004377251\n",
            "##################################################\n",
            ">epoch=443, lrate=0.300, error=450.688\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7252317594075721\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.05855832921182\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.758715313941465\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.14412375042832\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73672757001471\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.57691780675738\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.03310353938059\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.78623780933735\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.85749195555215\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.10417500114744\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.056162000256\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.478940653306\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.06120494623678\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.8101673921254\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.10798486617222\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.77594015418947\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.657833033525\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.2462889757955\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.02570824433866\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.4853120116287\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.5655420684962\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.18441580423104\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:362.8834686563346\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.50094797080374\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.48695842128285\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.56656131035817\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.69567836328554\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:435.86641840917207\n",
            "##################################################\n",
            ">epoch=444, lrate=0.300, error=450.602\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7253521772663754\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.063543923403046\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.75410605515534\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.145776139658686\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73372489992877\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56242852313743\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.0350440225195\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.77489466929899\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.85055685988655\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.0990231301448\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.039333373283\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.4625892409524\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:208.00149695190584\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.75134012653152\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:239.0453401231819\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.69913616246745\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.5774421815792\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.1644267552204\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.9406752217484\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.40124545392524\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.4678543594787\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.0974210269125\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:362.7994968378394\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.4130990874752\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.40462092232883\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.47619282447783\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.60836200325457\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.78134396499746\n",
            "##################################################\n",
            ">epoch=445, lrate=0.300, error=450.514\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7254716637202683\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.069131041639533\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74889232114871\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.14606217358013\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.72867344416478\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.54633027608328\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.03539804370892\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.76222320671351\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.84146957346388\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.09244903149255\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.02139146943318\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.44463914196757\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.93783433175906\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.6899443124086\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.97933326225717\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.6193799208391\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.4934058627189\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:281.0791663892939\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.85269808785574\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.314504216826\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:328.36785370875396\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.0058796734166\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.7094238319098\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:376.3217950760513\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.3192016607561\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.38302796488307\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.5177914213215\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.6928081352485\n",
            "##################################################\n",
            ">epoch=446, lrate=0.300, error=450.423\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7255816471840075\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.075383424927473\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74364325778622\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.145553098918256\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.72209238462497\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.529143122682\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.034589092931\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.74878347174833\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.83095500487497\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.0849499782332\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.0029000901936\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.42577734377767\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.87087819373048\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.62670087266483\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.910344649365\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.53711435377141\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.40616722522356\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.99080136707033\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.7621159390194\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.2254630160934\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.2659103755758\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.9101885359463\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.6136430453264\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:376.22755991138456\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.2310369844418\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.28740490152956\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.4243557278798\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.6011752576811\n",
            "##################################################\n",
            ">epoch=447, lrate=0.300, error=450.328\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7256796075822582\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.08229635545304\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.73888148203066\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.14483477867593\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.71461369136335\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.51140922344382\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.03315672075134\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.73518409475138\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.8197752043303\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.0771801738105\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.98447770942948\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.40678129801023\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.8020136461889\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.56301260008243\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.839492598283\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.45353648229772\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.316949977414\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.90033988840827\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.6699328965889\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.135121326688\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.1630385390241\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.8115064383771\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.51334016000374\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:376.1315691996352\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.1411613478913\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:407.19036560880727\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.3291352116467\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.5075153109223\n",
            "##################################################\n",
            ">epoch=448, lrate=0.300, error=450.233\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7257697683575068\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.089800834092134\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.73501588310036\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.14444946749371\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.70688749790177\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.49361936199885\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.0316664849505\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.7219947821072\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.80860805212305\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.06982634781255\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.96667890960788\n",
            "Iteration 550 | Accuracy: 72.42857142857143 | Loss:192.3883711283475\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.73306682546664\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.5006686110816\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.76837424948414\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.37031716264877\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.2274698157618\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.8092166562641\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.57753498517\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.0448200472838\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.0606068351389\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.7114432025498\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.410177463298\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:376.0353400962443\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.0510137405265\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.09335568439286\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.23359963046556\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.41330745711747\n",
            "##################################################\n",
            ">epoch=449, lrate=0.300, error=450.136\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.725862177016936\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.09778058513584\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.73229677443806\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.14482897378206\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.69947607811068\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.47613676017004\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03060983033987\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.70965973596971\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.79794821964688\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.0634670974724\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.9498927554512\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.37107717126747\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.66591447449323\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.4414387020258\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.69867416884685\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.28919364953023\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.1395211998336\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.71891390522586\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:295.48632262174306\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:312.95588730020637\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:327.95997667338645\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.61165557688156\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.3058762986869\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.94034932166693\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.9620635628803\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.99784484002544\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.13922701740535\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.32006017522303\n",
            "##################################################\n",
            ">epoch=450, lrate=0.300, error=450.041\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7259705098835023\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.10609473235502\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.73081014425253\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.146248628327726\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.69278312984487\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.45915236521529\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03035419301895\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.69846562321385\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78807900656528\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.0584886797627\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.93431272851888\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.35518901818386\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:207.60216766313135\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.38674335343092\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.6318267097071\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.21162345374802\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.0546290788417\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.63066320149505\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:295.39742584439597\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:312.8693720529011\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:327.86222926244255\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.5135307546611\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.2018887379361\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.8477513701012\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.87552552669973\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.9050395751674\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.0472174304078\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.22902255799596\n",
            "##################################################\n",
            ">epoch=451, lrate=0.300, error=449.948\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7261095319910438\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.11459759481388\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.73050663681017\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.148820342202974\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.68704021795897\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.44268819410323\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03115935545983\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.68857244640893\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7791137693336\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.05508345612503\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.9199774529775\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.3407903685649\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.54304898213263\n",
            "Iteration 650 | Accuracy: 74.21428571428571 | Loss:222.3375239098621\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.56886846055792\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.13863464681955\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.9738991634775\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.54533420498365\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.3116038836872\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.78595900365923\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:327.76807686985177\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.41806987271866\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:362.0992786782976\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.75829730873744\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.79226521717544\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.8157903954177\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:417.95840530283084\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.14109239364177\n",
            "##################################################\n",
            ">epoch=452, lrate=0.300, error=449.857\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.726293067605209\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.123150683820086\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.731245164349446\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.152518895427946\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.68233675115205\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.42663670836156\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03322843358544\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.68007368586136\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7710668245879\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.053298779713\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.9068390807352\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.3278313414796\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.48942996998457\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.29428365356\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.5104663570199\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.07085551726482\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.8980480724809\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.4634812276383\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.2292984911215\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.70603121227975\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:327.6779252479066\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.325941711207\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:361.9987811681494\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.6724152770972\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.7128604919925\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.73065762661906\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.87333299224747\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.0568854102702\n",
            "##################################################\n",
            ">epoch=453, lrate=0.300, error=449.770\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7265327762350848\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.131627458239734\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.73283363543944\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.15722380008647\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67866688610187\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.41081379174938\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.0367550181892\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.6730507955527\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.76391800143713\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.05309106290116\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.89482204078672\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.31619200513225\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4419228992214\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.25719735723612\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.45702570567974\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.00862644462305\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.82751570614215\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.3854566070584\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.15075144780434\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.6297923828835\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.5919985930601\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.2376109707943\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.9009382129748\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.5903546862016\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.6377248978885\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.6500399446833\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.79238723142566\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.9768679940061\n",
            "##################################################\n",
            ">epoch=454, lrate=0.300, error=449.688\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7268375281323802\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.13991400120212\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.73506051482101\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.16276270579102\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67597491948537\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.39501038646945\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.04194815067328\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66760760439493\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.75765840112814\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.0543630270991\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.88386143355928\n",
            "Iteration 550 | Accuracy: 72.42857142857143 | Loss:192.30572156863175\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.40095718409336\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.22621938622356\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.4088032738166\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.95211914468948\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.7625844603119\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.31152355022834\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.0761205765297\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.5573849249912\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.5104624102429\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.1534684939249\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.80623404996544\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.5123237262302\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.5672256152731\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.57429640119335\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.7159276080137\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.9014824363023\n",
            "##################################################\n",
            ">epoch=455, lrate=0.300, error=449.610\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.727213032162887\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.14790804434584\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.737717391681386\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.16894851139073\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67419082003735\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.37903561567761\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.04903351023539\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66388393845828\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7523180764824\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.05698376213456\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8739246731682\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.29625762140626\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:207.36682466711488\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.2011692012823\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.36599364020927\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.9014310920243\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.7034721232339\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.24193903009296\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.00556546180144\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.4889751595822\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.4335144154952\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.07392913332666\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.71519410844616\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.43858825652916\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.50176603020077\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.50383123542036\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.6443756513595\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.8312330839858\n",
            "##################################################\n",
            ">epoch=456, lrate=0.300, error=449.536\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7276615039712544\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.15551747207141\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.7406134215471\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.17560554070079\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67325231956369\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.36274651118045\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.05823553725331\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66205148723272\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.74797788152793\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.06079838847512\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.86502058209658\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.2876334422744\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.33969899562632\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.1817931604668\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.32877854146085\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.8566433392621\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.65038600068283\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:280.1769974646405\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.93929360784824\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.42479575704897\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:327.3614316219854\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.99948387966464\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.6284339268039\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.3695191623091\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.44182161006773\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.43913032128245\n",
            "Iteration 1300 | Accuracy: 75.21428571428571 | Loss:417.5782531199084\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.7667217178091\n",
            "##################################################\n",
            ">epoch=457, lrate=0.300, error=449.469\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.728181357156321\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.16265910388826\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.74358211331568\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.182582474521695\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67311257567455\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.34606071593565\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.06974792769282\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66229626191856\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.74476718568252\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.06563423826074\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.85719801421533\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.27967959146537\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.31963456804425\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.16780486273785\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.29733755542782\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.81783825969654\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:262.6035349735911\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:280.1170363224265\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.87756824311225\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.3651464317929\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.2945724637476\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.9307046582223\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.5466562833997\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.30558600967976\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.3879277049003\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.38074867078836\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.5181688444815\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.70863122549656\n",
            "##################################################\n",
            ">epoch=458, lrate=0.300, error=449.408\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.72876702885614\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.169258794562545\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.74648139571931\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.18975243301316\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.67373501133204\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.32895125637461\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.08370246551347\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.6647940749774\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74285016481403\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.0713089997475\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.85053564288512\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.27222368917108\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.30654741390353\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.15890560942142\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.27182411816904\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.78508006751488\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:262.56310349356727\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.0624117964795\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:294.8206862200596\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.3103622361602\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.2333417253762\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.8682092511739\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.4706042110342\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.24730458996794\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.340626219692\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.3292564824785\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.4647617774056\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.65766509903864\n",
            "##################################################\n",
            ">epoch=459, lrate=0.300, error=449.355\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7294091013137254\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.175254060188312\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.74918887797067\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.19700319341275\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.67507938955326\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.31142621317295\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.10014784180608\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.66968731513002\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74240508590506\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.07764404094843\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.8451251553258\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.26508949222537\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.30017981042113\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.15478490637537\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.2523151837025\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.7583662059857\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.5291975871316\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.01345625925927\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:294.7689379849204\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.26076347419354\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.17813201917124\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.81259977351766\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.40098440402903\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.19515397026896\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.3003845833164\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.2851565489382\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.4186135633094\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.6144563087192\n",
            "##################################################\n",
            ">epoch=460, lrate=0.300, error=449.310\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7300948782121788\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.180600241021793\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.75159496449359\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.2042223876639\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.67708485035966\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.29349966506463\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.11904926515774\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.67707091751329\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74360173622554\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:154.08448356599754\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.84105043707538\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.25809350501484\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.3000545856003\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.1551010557939\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.23874709322067\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.73756264933303\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.50177818200564\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.9704302245793\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.7225621183329\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.21660250515225\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.12925833374527\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.7643911881486\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.33837989063403\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.1494842359712\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:394.2675053163799\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.2487896387852\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.3801480887362\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5794636010698\n",
            "##################################################\n",
            ">epoch=461, lrate=0.300, error=449.273\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7308095255597653\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.185280616204707\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.75359640781798\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.21128315639199\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.67965592012962\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.27516230141728\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.14031523235505\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.68699146734063\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.7465806182823\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.09171770485509\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.83836430518878\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.25103549476046\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.3054322744264\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.1594455494682\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.23085402816912\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.72234051320484\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.48060066379736\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.9334802479171\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.68170501976755\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:312.1780205564319\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.0869011983061\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.7239459154478\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.28317190168156\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.11043768458137\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2420470734066\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.22024733784104\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.3495385493147\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5528764207897\n",
            "##################################################\n",
            ">epoch=462, lrate=0.300, error=449.245\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.731537773186673\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.189319931498\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.755092055807204\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.218034972189294\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68265627840954\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.25635970921252\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.16385072046587\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.69945634260334\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.7514334168335\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.09930475344854\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.8370611617276\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.24367870608566\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.31528884525054\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.16730014064788\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.22812480068302\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.71213124999568\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.46517757065124\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.9026087128432\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.6463905566031\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.1450204793985\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:327.0510672408554\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.6914243744569\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.2354857119504\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.07790054983445\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.22377502620174\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1993108913013\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3266416541657\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.53454840367135\n",
            "##################################################\n",
            ">epoch=463, lrate=0.300, error=449.227\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7322659938822964\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.192799466520167\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75598145658531\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.22430216450386\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68591255204322\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.23698326315005\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.18962955878777\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.71444193280121\n",
            "Iteration 400 | Accuracy: 76.28571428571429 | Loss:133.75817795431846\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.10728411504545\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.83703806378819\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.23571457342499\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.32832727805743\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.1779975945422\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.22978466615876\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.7061086701352\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.45477002860986\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.8776506181943\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.6164939703666\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.1174485145762\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:327.02156271590974\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.66674839683384\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.1951621332263\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.05148778131434\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2121469290801\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1854258679907\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3109697123922\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.52397000576906\n",
            "##################################################\n",
            ">epoch=464, lrate=0.300, error=449.216\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7329843044052244\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.195870164626253\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75616572894267\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.22988886097287\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68922669907671\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.21687294658604\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.21777677051462\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.73188308225029\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.76671227586698\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.1157672122149\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.8380278983015\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.22670232531675\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.34301938012803\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.19069225067264\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.2347917249814\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.70318747939933\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.4483933996527\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.85823756277006\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.59170002968443\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0949615417351\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.99795810230324\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6495569978504\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.16173717256527\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.0305423264102\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2063213629341\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1777042975816\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3016930159273\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.520272258373\n",
            "##################################################\n",
            ">epoch=465, lrate=0.300, error=449.213\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.733688299458397\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.198759245318012\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75554826996333\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.234583606304966\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.69239078715599\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.19582423621935\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.24865482767635\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.75161911487793\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.77672020242787\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.12488791048114\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.83947773627455\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.2159654522086\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.35764672200472\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.2043343192725\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.24181690659842\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.70200362270612\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.4447970664407\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.8437094447103\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.5714064433978\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0769362723837\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.97950076083856\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.63911231417075\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.13438888260765\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.01410513063496\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.20514701161534\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1749171423031\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.297636260594\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.522225188387\n",
            "##################################################\n",
            ">epoch=466, lrate=0.300, error=449.217\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7343802038807092\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.201766295575208\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.75403016081123\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.23815071724004\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.69519258433847\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.1735839073346\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.28294820179902\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.77326386273923\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78748518984455\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.13468188425455\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:173.8403411456097\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.20242399362954\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.37028708085234\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.21763343312028\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.24916121921186\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.70081978340957\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4423519138438\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.83290381247446\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.55450410165236\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0622483190983\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.9649040944704\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.63408277424026\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.1117811619727\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:375.00078119023686\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2070531946687\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.17539609821307\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:417.29718883754515\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5281510219366\n",
            "##################################################\n",
            ">epoch=467, lrate=0.300, error=449.225\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7350693897399667\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.205245954068104\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.751491490745536\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.240289670138594\n",
            "Iteration 200 | Accuracy: 75.85714285714286 | Loss:69.69739404804801\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.14981210602707\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.32171594522951\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.79597075995787\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.7975690716051\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.14483818131993\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.83878940193867\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.18437784326488\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.37872006901432\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.22902609344547\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.2545768263875\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.6973033591063\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4387681013281\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.82371200229\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.53892672678256\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0488138546271\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.95191264241527\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6320963331843\n",
            "Iteration 1100 | Accuracy: 76.28571428571429 | Loss:361.09170786190936\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:374.9883964637354\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.2097138806559\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1767041382343\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:417.2979853237262\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5356092216788\n",
            "##################################################\n",
            ">epoch=468, lrate=0.300, error=449.234\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7357716021096576\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.209566523299614\n",
            "Iteration 100 | Accuracy: 77.07142857142857 | Loss:39.747745841638775\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.24054106743174\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.69865733310155\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.12397992335897\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.36628299345922\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.81814215402552\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.80441421243626\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.15423125083103\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.83203153546702\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.15941280536848\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.38037024434504\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.23674893687075\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.255046005391\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.68821555457205\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4306338169076\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.812295499391\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.5208657531971\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.03280279299236\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.93658809005785\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6289923071251\n",
            "Iteration 1100 | Accuracy: 76.28571428571429 | Loss:361.07047763582017\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9733673900246\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.2093523494611\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1749084635848\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:417.29616557317263\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5406636806724\n",
            "##################################################\n",
            ">epoch=469, lrate=0.300, error=449.242\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7365034766230658\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.21498956103353\n",
            "Iteration 100 | Accuracy: 77.07142857142857 | Loss:39.742461732215325\n",
            "Iteration 150 | Accuracy: 76.57142857142857 | Loss:58.238144262517416\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.69840661348317\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.09519876406674\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.4175882541805\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.8374433132947\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.80439946069214\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.16022684845063\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.81700137120538\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:192.12501597336612\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.37271675076315\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.23913273483768\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.24684326906552\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.66943014737794\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.41318869721493\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.79225171229484\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.4939234185522\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.00784239630445\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.912748289682\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:340.6181728551556\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.0423602296437\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9500908010138\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.19993703856943\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1636696242121\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:417.2853399439114\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:434.5368603911041\n",
            "##################################################\n",
            ">epoch=470, lrate=0.300, error=449.241\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7372635959895337\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.221292472212866\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.73512306036116\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.23205754185876\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.69579902368353\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.06226264301148\n",
            "Iteration 300 | Accuracy: 75.5 | Loss:102.47435608382604\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.85207093568683\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.79502899514156\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.1587964932283\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:173.79350059019131\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.0811549563223\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.35540808039795\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.23541553689478\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.227361205279\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.63816642944136\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.38253635852914\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.75633609724997\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.4507823881574\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.96678604912046\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.8741919694572\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:340.5927042961346\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.0013258626248\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9126606713888\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.17475309205906\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.13575960277836\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.2577616882633\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.5164332092048\n",
            "##################################################\n",
            ">epoch=471, lrate=0.300, error=449.222\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.737996867856922\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.22698486753347\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.72535989888404\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.222005552211535\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.69063748997493\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.02504432898624\n",
            "Iteration 300 | Accuracy: 75.64285714285714 | Loss:102.53105383136884\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.86366551330818\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78049875732808\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.14916855153334\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:173.76913942540756\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.03487231342305\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.33587639378243\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.22944643514103\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.20169805430004\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.6003014945476\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3438330732523\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.70670611119766\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.39354733234774\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.911766317688\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.82448497727216\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5553704516749\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.9500435713128\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.8638686930588\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.13582527383744\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.09284108659773\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.21402548424766\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.4800366341103\n",
            "##################################################\n",
            ">epoch=472, lrate=0.300, error=449.185\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7386034710756213\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22960366644507\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.71387286878675\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.210674592406576\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.68543579670053\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:84.98702387495906\n",
            "Iteration 300 | Accuracy: 75.57142857142857 | Loss:102.58224762000805\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.87780760168138\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7723010422284\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.13967486477415\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.75607038860517\n",
            "Iteration 550 | Accuracy: 72.64285714285714 | Loss:191.99840197769817\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.32896026759832\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.23259145040504\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.18435988809986\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:250.57119246479243\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.3130833369264\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.66104974860764\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.3401847374339\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.8600320207293\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.7809693690626\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5236799207775\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.9051498202277\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:374.8200242057332\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0991656134235\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.0508551516017\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.1695421130635\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.4430597240451\n",
            "##################################################\n",
            ">epoch=473, lrate=0.300, error=449.145\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7390636931683434\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22916497359005\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.70218743396689\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.20148790200404\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.68329117231538\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:84.95180061660038\n",
            "Iteration 300 | Accuracy: 75.42857142857143 | Loss:102.6311228422499\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.89782009955819\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.77573332265234\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.137783717626\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.75780804068492\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:191.9762648248166\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.3379427286665\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:222.24947867958878\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.17950027047723\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:250.55520848571211\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.29538117541165\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.6267289090111\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.29824340566677\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.81860846536256\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.75008495978443\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5048382218005\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.87411224497373\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:374.7876819795761\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.07095485047523\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.0155917818677\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.1302074596414\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:434.4110901310685\n",
            "##################################################\n",
            ">epoch=474, lrate=0.300, error=449.108\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.739412822917803\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22748400111724\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.690630722791155\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.19419134604255\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68353360570252\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:84.91821405461752\n",
            "Iteration 300 | Accuracy: 75.28571428571429 | Loss:102.67986013144966\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.92312366792345\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.78908382301944\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.14278767717607\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.7708907312811\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:191.9651362091594\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.35785138243017\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:222.27641440975106\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.1831824484314\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.54883986471793\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.28755344372286\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.6011312232985\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.26523768203685\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.78514220682627\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.72908250587335\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.4964560961463\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.85537579714077\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:374.7649059905978\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0493741470872\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:405.98500813540943\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.0941913914694\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:434.38206978352383\n",
            "##################################################\n",
            ">epoch=475, lrate=0.300, error=449.073\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7396381905718052\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22539079948636\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.67970705993471\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.18919051452842\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68621997851027\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.8860323830724\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.72919140022617\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:120.95274615879289\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8107080809424\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.1538580947894\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.79275803732975\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:191.96263786360285\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.3842090485662\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.31005144831911\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.19221797890557\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.54965953840036\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.28718133016406\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.5812819750898\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.2383105874039\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.7571438392133\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.71523326929173\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.49575909470315\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.847003091506\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.74986665439707\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0332639356291\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.95800087539703\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.0606169224287\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.35498371571197\n",
            "##################################################\n",
            ">epoch=476, lrate=0.300, error=449.037\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.739717933190355\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.223180433147274\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.669755989280894\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.186911353860914\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.6912917584378\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.85532386159473\n",
            "Iteration 300 | Accuracy: 75.28571428571429 | Loss:102.77733552641247\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:120.98566119606286\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.8396236111319\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.17046778788452\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8210670304029\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:191.96668500124923\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.4134954272939\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.34798473459932\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.205152114308\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.5570153782738\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.2937755479872\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.5673466803611\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.21792396066377\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.73562064198165\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.708758189952\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.5026847962034\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.84939086110023\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.7435750723684\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0249272074019\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.9372476203779\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.0327212723921\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.33309373231435\n",
            "##################################################\n",
            ">epoch=477, lrate=0.300, error=449.006\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7396782309265317\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:17.22179935574941\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.66118905218548\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.187303187494145\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.69819745763557\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.82568829864366\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.8237575364841\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:121.0196947520559\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.87283184066112\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.19012302209015\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8530717021551\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.97425448165257\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4392700785803\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.3839855813235\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.21692633426932\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:250.56666969249008\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.302600852888\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.553076791409\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.1978825538542\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.71489419309916\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.7037651242656\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:340.5106338779205\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.85632065703913\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.74055402878724\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.02005500769775\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.91894271067054\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.0069409059266\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.31298921979374\n",
            "##################################################\n",
            ">epoch=478, lrate=0.300, error=448.976\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7395298590951505\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.221157195048182\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.65351095705405\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.189706421866724\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.7054373776205\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.79622670844182\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.86147399164064\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:121.0534734216196\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.91013578696231\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.21324532914034\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.88324960287667\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.98085955765364\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.45970294864122\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.4179525716538\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.22935670462698\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.58036222855432\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3166893507673\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.54760045452525\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.1881670071756\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.7064635738409\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.70851498567765\n",
            "Iteration 1050 | Accuracy: 76.07142857142857 | Loss:340.5273273418039\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.87529492435885\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.7498123104104\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.0293424545049\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.9144987426622\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:416.99640236402524\n",
            "Iteration 1350 | Accuracy: 76.42857142857142 | Loss:434.3082234755898\n",
            "##################################################\n",
            ">epoch=479, lrate=0.300, error=448.964\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7394720759926234\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.2251456708484\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.64804744186901\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.19271910222114\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.71212627856515\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.76511621577522\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.90487179236047\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:121.08509455125285\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.9459827497908\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.22755547917697\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.93389875130262\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.99813092630043\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4702276077975\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.43009789419648\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.2255611569068\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.58014740433245\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.31321058051674\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.50711562899124\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.14223485341574\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.65886068455336\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:326.6791095803085\n",
            "Iteration 1050 | Accuracy: 76.07142857142857 | Loss:340.50633669861855\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.86071983059276\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.7252726766649\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.00567341583826\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.876407539746\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:416.9491145111278\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.2677548047352\n",
            "##################################################\n",
            ">epoch=480, lrate=0.300, error=448.914\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7391567643920045\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.223061764544628\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.63768368258132\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.1961150972653\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.71305025672848\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.73094638989822\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.88250236692059\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.11213912547967\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:134.00179553179163\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.27478134437965\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.9194604438948\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.98179360169894\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4812216405907\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:222.47923690298617\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.26001076650718\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.62247760651022\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.3669767574657\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.58687569107116\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.227532528282\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.76173139546245\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.76718872598997\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:340.60011500637125\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.96398162931325\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.8273645104057\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.1152958886562\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.97487435290043\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.05478970030833\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.38038882748674\n",
            "##################################################\n",
            ">epoch=481, lrate=0.300, error=449.037\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7403116091616444\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.259164571129816\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.65617848228901\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.20920181560139\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.73769066271453\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.70895626075198\n",
            "Iteration 300 | Accuracy: 75.64285714285714 | Loss:103.08308542862929\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.30155452275432\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:134.26627987743402\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.4593987943609\n",
            "Iteration 500 | Accuracy: 75.64285714285714 | Loss:174.8490487624398\n",
            "Iteration 550 | Accuracy: 73.92857142857143 | Loss:193.07461474838314\n",
            "Iteration 600 | Accuracy: 76.42857142857142 | Loss:207.59853923782035\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.4703394917417\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.0275684296515\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.34208779545358\n",
            "Iteration 800 | Accuracy: 77.0 | Loss:261.8829459488726\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.9869659670695\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:293.6692400972205\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:311.0937918713401\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.27171500946207\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:339.9202320116711\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.4648475629232\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.38424829479385\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.64106990681273\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.45974484630653\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:416.4815835364534\n",
            "Iteration 1350 | Accuracy: 76.42857142857142 | Loss:433.77854012443726\n",
            "##################################################\n",
            ">epoch=482, lrate=0.300, error=448.307\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.730534466929628\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.073923150427373\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.64498458156139\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.28482420374998\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.66701262040544\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.6673821319879\n",
            "Iteration 300 | Accuracy: 74.64285714285714 | Loss:101.33607693843148\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:120.29365370401752\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.41321230600244\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.6727896737141\n",
            "Iteration 500 | Accuracy: 75.5 | Loss:173.44444596122995\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:191.58738863703567\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:206.6722358268722\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.69741490115302\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.3454212225485\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:249.71286660850913\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.4067602646101\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.62601770607273\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:293.31719814320246\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.84137978176494\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:325.8338801861585\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:339.5740465770079\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:359.9403233171779\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:373.82898386845005\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.0869150291898\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:404.8874439982767\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:415.9530090683576\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.2739363788163\n",
            "##################################################\n",
            ">epoch=483, lrate=0.300, error=447.932\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.748807778218683\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.45480516362455\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.796176627537974\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.32891470677883\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.74200566488479\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.72738193567078\n",
            "Iteration 300 | Accuracy: 74.85714285714286 | Loss:101.88019523312441\n",
            "Iteration 350 | Accuracy: 75.0 | Loss:120.73686531785698\n",
            "Iteration 400 | Accuracy: 76.5 | Loss:133.8543446011615\n",
            "Iteration 450 | Accuracy: 75.0 | Loss:153.90398522520678\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:173.98746190415125\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.8920340177319\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.10118175302338\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:221.98522031554378\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:237.85401363453917\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:250.20222450359563\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.988245456542\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:279.42953692304366\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.130761229092\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.66826639971504\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.61012014338525\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:340.3920790211411\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:360.7784073948229\n",
            "Iteration 1150 | Accuracy: 75.35714285714286 | Loss:374.66608323102804\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.9394128210179\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.74235382715096\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.82774708128693\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:434.1787775560002\n",
            "##################################################\n",
            ">epoch=484, lrate=0.300, error=448.903\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.74754344604716\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:17.46137402872083\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.91870990380931\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.5334806679516\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:70.03229264885783\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.93795743836311\n",
            "Iteration 300 | Accuracy: 75.42857142857143 | Loss:103.25577278715093\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:121.48010037695991\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:134.31105034392056\n",
            "Iteration 450 | Accuracy: 74.92857142857143 | Loss:154.55691091826554\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:174.30209360839115\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.2543708615067\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.60086427156742\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.4758474435213\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.3092273572393\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.6674854685705\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4175091782304\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.6145851961348\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:294.25812567137626\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.8386099530381\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.8264778720453\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:340.6644193144674\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:361.1288175999882\n",
            "Iteration 1150 | Accuracy: 75.5 | Loss:374.9742272596896\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.25285085407455\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:406.0534026954993\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.13074845138834\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.49540885701185\n",
            "##################################################\n",
            ">epoch=485, lrate=0.300, error=449.191\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7442299997795523\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.402477460430894\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.77475820554672\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.31626542268356\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.8004734633196\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.6669682993611\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.71885583093633\n",
            "Iteration 350 | Accuracy: 75.14285714285714 | Loss:121.36039030264138\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.40155981878678\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:154.35595721633922\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:174.43444046025928\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:192.27913966298604\n",
            "Iteration 600 | Accuracy: 75.5 | Loss:207.60069487641297\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.22162888922506\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.27562119404266\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.64904825786618\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.44334364727115\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:279.75666191109093\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:294.43320384918746\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.9823795883817\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.9145492889192\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:340.7159293549809\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:361.19568282421886\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:375.05498985108034\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.35269733800646\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.13663496148484\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:417.2194622483539\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.6158159100435\n",
            "##################################################\n",
            ">epoch=486, lrate=0.300, error=449.353\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7438110237472841\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.431066792405726\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.87367705732485\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.48633329286699\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.98866119997079\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.78106516268942\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.29716830323568\n",
            "Iteration 350 | Accuracy: 76.92857142857143 | Loss:121.60686252028583\n",
            "Iteration 400 | Accuracy: 75.42857142857143 | Loss:134.37216567286953\n",
            "Iteration 450 | Accuracy: 74.35714285714286 | Loss:154.2934567618397\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.5719217767984\n",
            "Iteration 550 | Accuracy: 74.35714285714286 | Loss:192.42113937200975\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:207.45342935196135\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.1203608938283\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.05055717731128\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:250.45966025714444\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.17432195884936\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:279.2570252437099\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:293.8608207907498\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:311.3214629338071\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:326.39890864882375\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:340.2127103361495\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.7819077203876\n",
            "Iteration 1150 | Accuracy: 75.42857142857143 | Loss:374.57582796658625\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.88363986065923\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.6731849626364\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:416.7114025094275\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.1345827191351\n",
            "##################################################\n",
            ">epoch=487, lrate=0.300, error=448.785\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7383464837673748\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.268529274047406\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.587579082012766\n",
            "Iteration 150 | Accuracy: 76.64285714285714 | Loss:58.190633409316916\n",
            "Iteration 200 | Accuracy: 75.85714285714286 | Loss:69.57662205294979\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.38616085465738\n",
            "Iteration 300 | Accuracy: 74.85714285714286 | Loss:101.42578098445787\n",
            "Iteration 350 | Accuracy: 75.35714285714286 | Loss:120.07389427976909\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.2612663557755\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:153.25271026346945\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.13488585169222\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.07781539634726\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:206.48842710207745\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.5361890634098\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:237.22620996685907\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.58801923672408\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.341218518208\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.5319865788366\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.19150094232384\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.76101744839366\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:325.72273039916263\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:339.54173726204147\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.0475615004376\n",
            "Iteration 1150 | Accuracy: 75.5 | Loss:373.87724168588113\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.1913854395558\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:404.9923277862228\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.06897787458564\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.48581728831493\n",
            "##################################################\n",
            ">epoch=488, lrate=0.300, error=448.197\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.746001316715153\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.434355364818078\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.83133996147133\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.428449732940265\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.91971133499469\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.70361763962283\n",
            "Iteration 300 | Accuracy: 75.35714285714286 | Loss:102.91485612617045\n",
            "Iteration 350 | Accuracy: 75.42857142857143 | Loss:121.41495020820045\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.47515390554827\n",
            "Iteration 450 | Accuracy: 74.64285714285714 | Loss:154.39744364644383\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.31215694427632\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.16129471145027\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.521101460341\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.24155475872698\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.23858053567764\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:250.62683965244483\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.42229743367255\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:279.64369224773964\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:294.3056003447377\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.900302856645\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.823285330672\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:340.64023092264057\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.19290573205313\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:375.03293922474313\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.38203019472417\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.16641447980123\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.2538646944101\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.6997433541862\n",
            "##################################################\n",
            ">epoch=489, lrate=0.300, error=449.451\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.745001432022466\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.443529802856933\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.89158109603906\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.49727298098512\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:70.00677577718213\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.74407096927047\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:103.15370596909294\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.44740733505573\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.2926612723455\n",
            "Iteration 450 | Accuracy: 74.78571428571429 | Loss:154.4545078940986\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.09013517487364\n",
            "Iteration 550 | Accuracy: 73.78571428571429 | Loss:192.00050363790848\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.41517304019249\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.31252662039557\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.1694423217171\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.56230967838442\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3454241839714\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:279.4389866525946\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:294.0548493631666\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.6872727036838\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.6470843641092\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:340.50707067543186\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.09086899245796\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.9142074435313\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.29073741674125\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.09071238067105\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.1823849409479\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.6358060563811\n",
            "##################################################\n",
            ">epoch=490, lrate=0.300, error=449.366\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7437863021671076\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.39470616924946\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.76610592804974\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.30143841180427\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.8178394373367\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.53118850416011\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.91496677550184\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:121.20961114175886\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.0945206710508\n",
            "Iteration 450 | Accuracy: 74.85714285714286 | Loss:154.20144763807716\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.80598450366477\n",
            "Iteration 550 | Accuracy: 73.71428571428571 | Loss:191.72921798775093\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.19896559286119\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.13213604812736\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.95638415701245\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:250.35415083015485\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.13959397735994\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:279.2042548434685\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.81786439684527\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.47358279675694\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:326.4172096527967\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:340.2630781772591\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.85385532435265\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.692035556964\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.0891504444156\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.89455065511527\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.9934480422561\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.45540627473764\n",
            "##################################################\n",
            ">epoch=491, lrate=0.300, error=449.187\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7447105875515843\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.391867413139067\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.76210922863524\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.29419513250581\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.834682192703\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.51774986821687\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.15521462363338\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.46057850518932\n",
            "Iteration 400 | Accuracy: 74.85714285714286 | Loss:134.16725261317808\n",
            "Iteration 450 | Accuracy: 74.78571428571429 | Loss:153.85395014114064\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.88882036461257\n",
            "Iteration 550 | Accuracy: 74.5 | Loss:191.69323651140584\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:206.82883047098042\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:221.43979819547246\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.29279952070897\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.76805807577423\n",
            "Iteration 800 | Accuracy: 76.92857142857143 | Loss:261.4798436299979\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.5067973718144\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:293.07149989756164\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.5679900195079\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:325.69246948949217\n",
            "Iteration 1050 | Accuracy: 76.42857142857142 | Loss:339.5272846028676\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.15371798532516\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.9080296378945\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:393.33738671366973\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:405.2043396980068\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.23084503875305\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.7076628017146\n",
            "##################################################\n",
            ">epoch=492, lrate=0.300, error=448.327\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7303600608529042\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.11949659265292\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.51297607858554\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.20925405780861\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.6432893946846\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.32870147030545\n",
            "Iteration 300 | Accuracy: 75.0 | Loss:101.40304762401831\n",
            "Iteration 350 | Accuracy: 75.28571428571429 | Loss:119.99202675772901\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.22975284190161\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:153.0939088152898\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:172.9317713337487\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:190.85084609629783\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:206.6996100562723\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:221.7139509148843\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.38282550671806\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:249.85526380565958\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:261.64643914680624\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:278.681088702366\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.28820880428606\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:310.934901875396\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:325.9253331464844\n",
            "Iteration 1050 | Accuracy: 76.64285714285714 | Loss:339.7388833745412\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.2782043490689\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.0905323033818\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.4693079484765\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.2835293570097\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.3543027207895\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.82372451553783\n",
            "##################################################\n",
            ">epoch=493, lrate=0.300, error=448.517\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7512281368267126\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.45140025441434\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.75645818395222\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.24455301522509\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.75669425161209\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.43722167969057\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.86263401400761\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:121.1652135993296\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.99999626394845\n",
            "Iteration 450 | Accuracy: 75.07142857142857 | Loss:154.11783648621008\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:173.6922996714558\n",
            "Iteration 550 | Accuracy: 73.92857142857143 | Loss:191.60206374458468\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:206.9620051929589\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:221.9258574546992\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.7155231185836\n",
            "Iteration 750 | Accuracy: 76.78571428571429 | Loss:250.1294492208549\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.91097814755153\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:278.90997263595216\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.5096673152875\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.2278265075366\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:326.1757002110357\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:339.9843362508403\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.5607612098717\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:374.3994101670483\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:393.8018115800919\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:405.61245919835574\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:416.7031249043519\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.1857230689733\n",
            "##################################################\n",
            ">epoch=494, lrate=0.300, error=448.894\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7510149431468907\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.43469933712102\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.763975079140245\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.27515734471674\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.810461057198\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.45137308405431\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.06834857387611\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.30165724210953\n",
            "Iteration 400 | Accuracy: 75.0 | Loss:133.96253232122197\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.8856734169864\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.74680498343184\n",
            "Iteration 550 | Accuracy: 74.42857142857143 | Loss:191.6111790429854\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:206.67699380467033\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:221.69311187869175\n",
            "Iteration 700 | Accuracy: 75.71428571428571 | Loss:237.37742482823242\n",
            "Iteration 750 | Accuracy: 76.57142857142857 | Loss:249.7565231406065\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.4291542626899\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.4016628735526\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:292.99056987520345\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.5620533192718\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:325.6331676529158\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:339.443029667666\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.04676613326416\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.80328175432146\n",
            "Iteration 1200 | Accuracy: 74.35714285714286 | Loss:393.2466061680071\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:405.0893772402236\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:416.1099109332951\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:433.593821119629\n",
            "##################################################\n",
            ">epoch=495, lrate=0.300, error=448.204\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7375477875314007\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.178362169843343\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.531126113485186\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.23343249561609\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68386348665467\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.30267781377775\n",
            "Iteration 300 | Accuracy: 75.07142857142857 | Loss:101.7397210440669\n",
            "Iteration 350 | Accuracy: 75.07142857142857 | Loss:120.40295040763111\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.61804813446378\n",
            "Iteration 450 | Accuracy: 74.64285714285714 | Loss:153.33476793369675\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.2606367111693\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.09253849234824\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:206.8226819706782\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.92632686216214\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:237.56710869084588\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.0200769925619\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.8033257054427\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.82472136171106\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:293.44157301985985\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.11329683078185\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.0677506863867\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:339.83158094464255\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.3661245997768\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:374.21772545530234\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.62946211466\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.42447063448077\n",
            "Iteration 1300 | Accuracy: 74.21428571428571 | Loss:416.4863961100888\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:433.9844008451272\n",
            "##################################################\n",
            ">epoch=496, lrate=0.300, error=448.686\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7554149860576693\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.457291226892973\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.82973237560957\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.41522157948153\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.95283466318557\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.55018580399535\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.37547854959618\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:120.67195153211455\n",
            "Iteration 400 | Accuracy: 75.21428571428571 | Loss:133.22550800871838\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:153.61789427032684\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.2917436747498\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:191.28239453317428\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:206.41092412047993\n",
            "Iteration 650 | Accuracy: 75.0 | Loss:221.55652738838964\n",
            "Iteration 700 | Accuracy: 75.78571428571429 | Loss:237.19369304589515\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.66977449062233\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.3256809208545\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.22161346240847\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:292.8192559765531\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.4566284604338\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:325.52080424113177\n",
            "Iteration 1050 | Accuracy: 76.28571428571429 | Loss:339.28644543509535\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:359.86294639951285\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.668105797192\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.101916210665\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:404.93799823656667\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:415.93998310786105\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.4202353632953\n",
            "##################################################\n",
            ">epoch=497, lrate=0.300, error=448.013\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.7335545739270328\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.132802384834285\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.55251983896989\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.31549288366629\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.814866095038\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.35167479737699\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.93526386874738\n",
            "Iteration 350 | Accuracy: 76.78571428571429 | Loss:121.07789056149441\n",
            "Iteration 400 | Accuracy: 75.0 | Loss:133.75581654563567\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.05252493395804\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.69673462438044\n",
            "Iteration 550 | Accuracy: 74.28571428571429 | Loss:191.65162308261213\n",
            "Iteration 600 | Accuracy: 76.35714285714286 | Loss:206.5281217951835\n",
            "Iteration 650 | Accuracy: 75.42857142857143 | Loss:221.70932907748258\n",
            "Iteration 700 | Accuracy: 75.92857142857142 | Loss:237.2017069525275\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:249.49413780885425\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:261.1081949440538\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.03548963198466\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:292.6497130079347\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.2491231009306\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:325.3421231919299\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:339.06541719206757\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:359.5926468239555\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.43069854156096\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:392.88977655906854\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:404.7326582233498\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:415.7264378980942\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.1769339425501\n",
            "##################################################\n",
            ">epoch=498, lrate=0.300, error=447.739\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.7348390241026967\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.10630752289006\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.544148381467984\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.31958819259994\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.7932001148663\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.32775296012662\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.50395655361413\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.9582082056121\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.9446860601708\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.98857484430386\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.50084792684538\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:191.55086895201828\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:207.15456551807154\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:222.22807342815972\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.74010627642892\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.16280551497826\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.9053628132463\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.79223683431434\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:293.4110727207193\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.12315960874577\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.09527273500373\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:339.72015804963985\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.16208050879226\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.1123346479926\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:393.50186686862156\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:405.27783140928466\n",
            "Iteration 1300 | Accuracy: 74.07142857142858 | Loss:416.33180996619643\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.81090470243805\n",
            "##################################################\n",
            ">epoch=499, lrate=0.300, error=448.484\n",
            "##################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDWIu34bERyN",
        "outputId": "d2c2705e-3b51-4c52-ddcc-d2f303c8f3dd"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'weights': [-6.078553109080566, 2.4934096799347754, 3.807194287620623, 21.66199467578668, 10.274447808550104, -21.307413331874436, -9.819169129403278], 'output': 0.884998972585034, 'delta': -0.0007396889076164534}, {'weights': [11.84494427926206, 2.074320927486859, 10.8132249058571, -6.533845391731627, -11.36626787103271, 25.726275155280746, -4.896549214262629], 'output': 0.2324431563566603, 'delta': 8.714850982685043e-05}, {'weights': [5.7647528503597485, -1.9761247855597883, 2.992248822582852, -0.793268749399849, -17.30145182056697, 10.699120568278216, 5.329531382428484], 'output': 0.23757817116237495, 'delta': 0.00042476507324922723}, {'weights': [-5.17592206891633, 5.871406765819814, 1.2656194736807977, -0.756074289557698, 4.432380207396611, 8.217008565149914, -0.04327115598403503], 'output': 0.9999222156120263, 'delta': 5.654000482292983e-07}, {'weights': [3.2226109817393764, 3.1692610516011945, 10.873034558060404, -5.277485292209415, 14.559146012648618, -21.72514357475252, 3.8816150880809475], 'output': 0.057608343968132913, 'delta': 0.00046562952452166363}, {'weights': [4.005839011430371, 0.7862037422271424, 0.5745219135773116, -12.49693269651463, 0.20155861066996594, -1.5811998865500971, 5.165216133375101], 'output': 0.004665853226319138, 'delta': -1.9349403265001477e-05}, {'weights': [-7.373623945769268, 2.0172505127587845, -4.640483295603088, 0.04711001871112972, 3.869167693125737, 4.299280849513221, 1.2235882415097425], 'output': 0.9992973171461047, 'delta': 7.2035397465916285e-06}, {'weights': [-1.282506457856001, 0.8333917237466099, -2.641797607676581, -2.7426099168150984, 15.834409443914987, 15.574652278034305, -7.631182652884476], 'output': 0.9999833955159416, 'delta': -1.4253921030348073e-07}]\n",
            "[{'weights': [5.31700228014527, 9.848994333486337, -3.030533186965795, -4.153263987580531, 4.944809933724765, 3.3339907021242348, -4.432267365204261, 1.006617716520797, -3.1607580432427955], 'output': 0.015350943341831942, 'delta': 0.00010900031557390247}, {'weights': [7.855484141375599, 0.41922024935794255, -0.8444203929697766, -5.3138440334456485, -8.501190535219354, 3.0279599407001534, -8.988053833814194, 5.762716981979492, 6.446970407469958], 'output': 0.9864729703044965, 'delta': -0.001164479975373096}, {'weights': [6.644060896291788, -21.354450640768018, -2.0106450201997657, -6.417428207773722, 8.848670241329451, 0.4945065392252563, 2.2192113766486643, -12.019111414952295, 5.954786243783538], 'output': 9.025872575889129e-05, 'delta': 5.233448730047368e-06}, {'weights': [5.517619476170539, -5.325104750791348, -7.366003940206978, 6.1348480084394375, -5.167343915652828, 1.4323364363564652, 2.305075141400675, 9.401579917188323, -2.320375235438344], 'output': 0.9999999633985301, 'delta': -3.7791681481797674e-10}, {'weights': [-5.445937279451242, 16.288056991765547, 4.77460186745691, -7.644770243401249, -7.25957265312365, -0.41737243671773067, -9.707575283651309, 3.5900867335080493, -0.28126668043392367], 'output': 5.82702336961058e-07, 'delta': -1.4840695442111382e-08}, {'weights': [-0.4185906112050151, 4.978872967349762, -6.332900180317697, 2.2212975812537894, -14.602851918703477, -5.505044952939193, -0.9050153576958645, 10.559359614714987, -1.2808326076091476], 'output': 0.9998778895220348, 'delta': -2.1773612904978865e-06}, {'weights': [5.402816044427846, 0.1111464049593699, 7.2145195079032085, 6.719114507207456, -8.286411829596178, -4.350486465989169, 1.1195942894103217, -8.104588762690572, 0.1454478007290935], 'output': 0.9972727166365055, 'delta': 0.000234102104422174}, {'weights': [-14.721418046356078, 7.526788011288182, 6.039011325809572, -1.5114254463763008, -4.428394323605567, 5.728717448957034, -0.9907301088237551, 1.0535757467953515, -2.390468536763627], 'output': 9.091203603017798e-07, 'delta': 1.5602258605316758e-09}]\n",
            "[{'weights': [2.1353111176556108, -4.7444897061437095, 7.053163504928763, -7.652567111107018, -0.40125623704133057, -2.825331471490688, -11.404011872067981, -1.9795317785676816, -1.9968441474269985], 'output': 4.2181710112711644e-13, 'delta': -1.7792966680320894e-25}, {'weights': [-5.012880215733337, -2.21341984078837, 0.18856729293505425, -7.483140817616475, -3.9695619848326884, -3.2950282524332755, 5.856926946137229, -1.1116120224034158, 0.10757136061228052], 'output': 0.0008329878331523248, 'delta': -6.932907459697607e-07}, {'weights': [-5.50909583560708, 2.0390953605005584, -6.761735035931511, 2.4499442895155124, -4.255553432368887, 1.5528770590496541, 1.4038068606653975, -1.404715996280127, -3.526183042698855], 'output': 0.9781627811717243, 'delta': 0.0004664507398798201}, {'weights': [2.923634078647218, -1.1387788953303475, -1.9844362764690486, 4.060997735575597, -1.3109714215680959, -1.3281066364705163, 1.7010069397231218, -1.9024261992964981, -6.319851740054044], 'output': 0.04899953951480293, 'delta': -0.0022833091895064373}, {'weights': [1.666711260124929, -22.26255014698157, -5.599776861876085, 2.028023632047349, -8.055659750870165, -60.240902221458434, -9.002427396584025, 6.07757381782271, -2.7466449288033403], 'output': 1.267489242304844e-40, 'delta': -1.6065289793585074e-80}, {'weights': [0.8402060269686114, -1.1958437235027786, -3.5460127682011473, 7.698239563519808, 4.550296974247738, 3.251952171491927, -1.9463901998873718, 0.4375844352975591, -10.49700505694819], 'output': 0.06603153661052522, 'delta': -0.004072255509766978}, {'weights': [6.928410404465123, -12.598564891355151, -4.925996082654113, -23.125366015381037, 3.301990260446502, -17.454015306281384, -1.3346089326138693, 2.5242079107007136, -11.569704234184679], 'output': 2.6506867041080597e-29, 'delta': -7.026140003335248e-58}, {'weights': [-2.6699713690305487, -12.407153605036761, 6.950799811149303, 6.153175528507768, -3.568535315599872, -30.063971265159935, -4.163486897134035, -7.773105390289238, -6.061102041510371], 'output': 7.05853951166703e-21, 'delta': -4.982298003776465e-41}, {'weights': [-2.2569615778735583, 10.862798337786725, -4.788806839628161, -3.3134289945517845, 0.9027686997936187, 0.9447654907837316, -9.244556258413796, 0.021714127159222406, -1.315802469123125], 'output': 0.09885407630482668, 'delta': -0.008806113675360666}, {'weights': [0.7281632929645173, -6.662691753306422, -4.872996716431465, -1.6431399345702042, 3.513811344779828, 0.2978386951279658, -1.249226968408596, -1.4108904395863753, -2.807750810861706], 'output': 6.39022474811912e-06, 'delta': -4.0834711386823286e-11}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "hwNL9YzuD93p",
        "outputId": "e364fe6a-fff1-47e5-d4d6-14903e3886d7"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h1-0.3.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h1-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "InCJSbu3D93r",
        "outputId": "dd2d34c5-ffa1-4f9a-ff26-14177763bbd3"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h1-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_xBwF2e2D93r",
        "outputId": "30c1d656-e2cc-4a08-c05a-f635a04ab2f7"
      },
      "source": [
        "# plt.plot(loss_score)\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h1-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ncgrdYD93r",
        "outputId": "cd3e2fcb-6370-49a0-bac5-adf2aa565ed4"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 76.07142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm91yIIwD93s",
        "outputId": "5509483d-2550-485e-e6a2-4e38f27c0485"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 73.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrh33Uw-DYIs"
      },
      "source": [
        "### lr=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqBSuhmKvgH2"
      },
      "source": [
        "net = initialize_network_single(6,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h6mt5_g1vgH2",
        "outputId": "0e7d2af6-1a87-42fe-9e92-761dc06377a5"
      },
      "source": [
        "train_network(net,train,0.1,500,10,accuracy_score,loss_score)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:8.645193140234495\n",
            "Iteration 50 | Accuracy: 10.142857142857142 | Loss:414.5060201608964\n",
            "Iteration 100 | Accuracy: 10.142857142857142 | Loss:667.9569578231936\n",
            "Iteration 150 | Accuracy: 10.142857142857142 | Loss:812.7396812835261\n",
            "Iteration 200 | Accuracy: 10.142857142857142 | Loss:925.193916639066\n",
            "Iteration 250 | Accuracy: 10.142857142857142 | Loss:1037.857784409908\n",
            "Iteration 300 | Accuracy: 10.142857142857142 | Loss:1128.4680876987711\n",
            "Iteration 350 | Accuracy: 10.142857142857142 | Loss:1177.7350006741965\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:1223.4707456878712\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:1268.566722520112\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:1313.8086177043042\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:1358.8864528733536\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:1404.1110931030432\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:1449.410367150181\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:1494.625610776241\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:1539.912664788666\n",
            "Iteration 800 | Accuracy: 10.071428571428571 | Loss:1585.1430375717096\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:1630.4755423111897\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:1675.5379355309344\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:1720.1931969334487\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:1765.5398376193534\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:1810.5620805296405\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:1855.7247476718007\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1901.0579054745222\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1946.2592949380326\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1991.3821450803773\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:2036.7324357262862\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:2081.6464630766145\n",
            "##################################################\n",
            ">epoch=0, lrate=0.100, error=2125.995\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882790855792202\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.086667347019414\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.21164377521549\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.69281031848845\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.70509574548532\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8793708386603\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9990044511737\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.16773451241903\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.524428612489\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.54692301464877\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.71778823123105\n",
            "Iteration 550 | Accuracy: 13.357142857142856 | Loss:497.7887538492335\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0539696809865\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3685450846967\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5627195430745\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.85261456271\n",
            "Iteration 800 | Accuracy: 19.142857142857142 | Loss:724.0825281147162\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.4164400136826\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4778031074795\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.1378556998311\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4820048710292\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.5055391128544\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6680599465957\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9999095058738\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.201120021986\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.3228057713095\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.671429526724\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5850142558088\n",
            "##################################################\n",
            ">epoch=1, lrate=0.100, error=1264.933\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882711292762078\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08606444923407\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.21039880474349\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.69047168057728\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.70158290983898\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8748758243745\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.99340607614\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1610486899136\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.51643851552814\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.53803446660686\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.7079595951847\n",
            "Iteration 550 | Accuracy: 12.285714285714286 | Loss:497.7783100642466\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0422736519669\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3555453010827\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5486574852149\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8376199626006\n",
            "Iteration 800 | Accuracy: 18.857142857142858 | Loss:724.0664285263999\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3995911850645\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4596434447129\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.1186379889867\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4617564028439\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.483552797106\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6452660444075\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9762174127557\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1766464051545\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.297363376218\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.6443511393725\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5574076497953\n",
            "##################################################\n",
            ">epoch=2, lrate=0.100, error=1264.904\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882623683921751\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08525227630182\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20886124861934\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68780709560897\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.69758016612488\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.86983077189277\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9871926491336\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1536804838331\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.50768588714254\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5283204732933\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.69724627986596\n",
            "Iteration 550 | Accuracy: 11.714285714285715 | Loss:497.7669425603501\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0295627321761\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3414427087199\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5334184300638\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8213906882257\n",
            "Iteration 800 | Accuracy: 18.642857142857142 | Loss:724.0490216391375\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3813800330287\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.440042123385\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0979139911175\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.439924413133\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4598690103664\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6207193660266\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9507119749587\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1503016217064\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.269998532629\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.6152324981533\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5277248165705\n",
            "##################################################\n",
            ">epoch=3, lrate=0.100, error=1264.873\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.888252571437705\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.084385142588566\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20721757841588\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68496353278468\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.69330706864505\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.86443583090826\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.98054627106325\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1458046163757\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4983348046103\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5179384578639\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.685797060453\n",
            "Iteration 550 | Accuracy: 11.214285714285714 | Loss:497.75479439065725\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.015972558172\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3263660591388\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5171223539699\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8040415379676\n",
            "Iteration 800 | Accuracy: 18.071428571428573 | Loss:724.0304144700357\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3619079216268\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4190923890114\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0757702820855\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4165879848864\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4345558315114\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5944826375807\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9234490543827\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1221355437283\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.2407545320818\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5841058477338\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4959944164111\n",
            "##################################################\n",
            ">epoch=4, lrate=0.100, error=1264.840\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882416681364984\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08345718164733\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20545632190282\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68192186711627\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.68873540068267\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.85865494898442\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.97342263463634\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1373691607979\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4883241286163\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5068195996823\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.67353610762876\n",
            "Iteration 550 | Accuracy: 10.857142857142858 | Loss:497.74178517056083\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0014129832117\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3102161697934\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4996616598858\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7854583711292\n",
            "Iteration 800 | Accuracy: 17.71428571428571 | Loss:724.0104848008859\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3410466423637\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3966571573883\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0520625173712\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3915949627874\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4074493784955\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5663862557809\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.8942516205057\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.091964665823\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.2094407365514\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5507689131819\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4620104844757\n",
            "##################################################\n",
            ">epoch=5, lrate=0.100, error=1264.804\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882295854790587\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08246203634134\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20356499643768\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6786614022505\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.68383483471393\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8524493862256\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9657742185862\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1283184870017\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.47758847989417\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.49489011718333\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.6603820961851\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.7278287256189\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.985787367634\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2928869773893\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4809212177719\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7655191534188\n",
            "Iteration 800 | Accuracy: 17.357142857142858 | Loss:723.9891020774588\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3186592782106\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3725902860638\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.026636976678\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.364783373769\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3783754922304\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5362500788148\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.862931628391\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.0595939890088\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.1758545200046\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5150069622384\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4255545393194\n",
            "##################################################\n",
            ">epoch=6, lrate=0.100, error=1264.766\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882162515073831\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08139288508632\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20153013598866\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.67515994274856\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.67857310935247\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.84577795249217\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9575506074737\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.11859362407654\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4660587162425\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.4820717235062\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.64624869600004\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.7128336171018\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9689931787149\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2742662722748\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.460779156424\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7440948180572\n",
            "Iteration 800 | Accuracy: 17.142857142857142 | Loss:723.9661283708482\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2946012442047\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3467377516795\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9993318262915\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3359827930043\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3471512841477\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5038850533906\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.82929173764\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.0248187858708\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.139783072649\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.4765948253278\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.3863976884998\n",
            "##################################################\n",
            ">epoch=7, lrate=0.100, error=1264.725\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882016003097302\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08024248692139\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.19933735785663\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.671393926661\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.67291630797186\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.83859739672351\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9486990096328\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.10813283785643\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.45366268066994\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.46828236915894\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.6310453796713\n",
            "Iteration 550 | Accuracy: 10.214285714285715 | Loss:497.6967040017268\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9509229728945\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2542368590329\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4391081267582\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7210506264855\n",
            "Iteration 800 | Accuracy: 16.857142857142858 | Loss:723.9414198803407\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2687219102858\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3189394499608\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9699790259117\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3050164002261\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3135874239034\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.4690956068156\n",
            "Iteration 1150 | Accuracy: 9.928571428571429 | Loss:1039.79312784435\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.987427208151\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.1010060704648\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.4352998543511\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.3443036902463\n",
            "##################################################\n",
            ">epoch=8, lrate=0.100, error=1264.681\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881855791429323\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.07900325563096\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1969714833694\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.66733863946922\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.6668292638495\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.83086297463748\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.93916499986113\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0968724454395\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4403262445554\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.453437298902\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.61467857522933\n",
            "Iteration 550 | Accuracy: 10.142857142857142 | Loss:497.6793408516281\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.931465788984\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2326781640957\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4157770626052\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6962480515647\n",
            "Iteration 800 | Accuracy: 16.642857142857142 | Loss:723.9148289974968\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2408668286528\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2890316288706\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9384068794585\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.2717037261714\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.2774911494485\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.4316827802461\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1039.7542324033336\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.94720371366\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.0592991813796\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.3908857838703\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.2990329249326\n",
            "##################################################\n",
            ">epoch=9, lrate=0.100, error=1264.634\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881681580746892\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.077667362682\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1944167132066\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.66296850225447\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.6602760720153\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.82252917458726\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9288934591968\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0847478237564\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.42597459350407\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.43745037078094\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.5970531070308\n",
            "Iteration 550 | Accuracy: 10.214285714285715 | Loss:497.66064347035336\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9105088810536\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2094681969743\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.390653343385\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6695470760833\n",
            "Iteration 800 | Accuracy: 16.142857142857142 | Loss:723.886206809967\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2108804391429\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2568498002537\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9044430530911\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.2358639032047\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.238669774313\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3914478630053\n",
            "Iteration 1150 | Accuracy: 16.5 | Loss:1039.7123982910148\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.903933055287\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.0144381356126\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.34311719425\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.2503469564258\n",
            "##################################################\n",
            ">epoch=10, lrate=0.100, error=1264.583\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.88814934233999\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.07622686152091\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.19165684479282\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.65825740233123\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.65322064549196\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.81355052686763\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.91782961482517\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0716944879005\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.41053360367124\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.42023548076\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.5780737531921\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.6405111183339\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.887939581376\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1844856133439\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.363605091396\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6408086160392\n",
            "Iteration 800 | Accuracy: 15.571428571428573 | Loss:723.8554057236033\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1786089135549\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2222317404518\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.8679176347481\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1973189705577\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.196934174353\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3481959833227\n",
            "Iteration 1150 | Accuracy: 19.642857142857142 | Loss:1039.6674226379612\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.857404241958\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.9662027410438\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.291763900872\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.198012976065\n",
            "##################################################\n",
            ">epoch=11, lrate=0.100, error=1264.529\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881291872009689\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.074673814599734\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18867549836234\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.65317899824333\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.64562719314696\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8038823429841\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.90591998363334\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0576490010294\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.3939310165382\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.4017077896179\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.55764658677936\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.61884439063704\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8636468905946\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1576114108357\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.3345030992961\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6098965265026\n",
            "Iteration 800 | Accuracy: 15.071428571428571 | Loss:723.8222816086758\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1439025092035\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1850198737228\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.8286654779861\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1558964336374\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.1521013524479\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3017387134284\n",
            "Iteration 1150 | Accuracy: 19.428571428571427 | Loss:1039.619109639871\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.8074134462213\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.9143797725937\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.236604106474\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.1418069227097\n",
            "##################################################\n",
            ">epoch=12, lrate=0.100, error=1264.470\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881078144506404\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.073000389731824\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18545629030041\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.64770688521043\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.63746042320534\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.79348113444308\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8931129014676\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0425493425127\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.37609695460594\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.3817842738962\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.53567957609795\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.59554578828903\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8375221638323\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1287295364807\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.3032216066362\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.5766783566315\n",
            "Iteration 800 | Accuracy: 14.714285714285714 | Loss:723.7866945627973\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1066164676675\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1450619747444\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.78652670416\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1114298865142\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.1039947613272\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.2518943166706\n",
            "Iteration 1150 | Accuracy: 19.28571428571429 | Loss:1039.5672709003827\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.753764361207\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.858763176878\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.1774246317777\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.0815135424034\n",
            "##################################################\n",
            ">epoch=13, lrate=0.100, error=1264.407\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880854288493136\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.071198876262024\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18198286117092\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.64181446033965\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.62868520645574\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.78230436544874\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.879358202478\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.02633423577527\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.356963167801\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.3603829590489\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.51208174022054\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.5705187388273\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8094580507098\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0977254605266\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.2696368951268\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.5410237616289\n",
            "Iteration 800 | Accuracy: 14.428571428571429 | Loss:723.748507108853\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.0666092011613\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1022088232785\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.7413439328293\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.0637561846677\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.0524407335876\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.1984839283884\n",
            "Iteration 1150 | Accuracy: 18.928571428571427 | Loss:1039.5117215032703\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.6962641409193\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.799149656351\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.1140161426372\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.016921256567\n",
            "##################################################\n",
            ">epoch=14, lrate=0.100, error=1264.340\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880623319080015\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06926155884955\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.17823864022228\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6354742952962\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.61926539433662\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.77030913666508\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.864605545033\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0089408748509\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.33646032611557\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.33742010805634\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.48676006340634\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.5436642304696\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7793447430879\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0644816753812\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.2336225605212\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.502799369587\n",
            "Iteration 800 | Accuracy: 14.071428571428571 | Loss:723.7075785374425\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.0237363915699\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.056307344143\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.6929547264233\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.0127075657572\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.9972593049544\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.141321907895\n",
            "Iteration 1150 | Accuracy: 18.285714285714285 | Loss:1039.4522699541985\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.6347129980281\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.7353276452084\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.0461612515198\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.947809685923\n",
            "##################################################\n",
            ">epoch=15, lrate=0.100, error=1264.268\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880389298819751\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06718038428231\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.17420622108843\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6286568290893\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.60916151425076\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.75744942406465\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.84880092038765\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.99030055273386\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.31451275667973\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.31280471392506\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.4596134554199\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.51487432054637\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7470626924228\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0288692267441\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1950404723847\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.4618590738743\n",
            "Iteration 800 | Accuracy: 13.714285714285715 | Loss:723.6637543033132\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.9778398391935\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.0071880321807\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.64117803796\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.9580974348695\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.9382481081814\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.0801990163427\n",
            "Iteration 1150 | Accuracy: 17.42857142857143 | Loss:1039.388700575103\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.568885991291\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.667058177924\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.9736139161885\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.8739282596387\n",
            "##################################################\n",
            ">epoch=16, lrate=0.100, error=1264.191\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880157330549876\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06494637133787\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1698662477997\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.62132825354115\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.59832718403786\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.7436716443566\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8318810721257\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9703319299336\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2910303178166\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.2864299380428\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.4305233673378\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.48402212663035\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7124713515535\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.9907348497004\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1537269341053\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.4180292604163\n",
            "Iteration 800 | Accuracy: 13.0 | Loss:723.6168499798986\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.9287305318124\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.9546461846872\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.5857942245354\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.8996993461196\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.8751589434622\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.0148580450125\n",
            "Iteration 1150 | Accuracy: 16.142857142857142 | Loss:1039.3207479624361\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.4985065977073\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.5940472664424\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.8960697746866\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.7949656039843\n",
            "##################################################\n",
            ">epoch=17, lrate=0.100, error=1264.108\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879933447220564\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06254874758185\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.16519577121021\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.61344758068907\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.58670429460432\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.72890858361782\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8137658919866\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9489320723661\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2658975877485\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.25816163038746\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.39934121394117\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.4509484825653\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.6753941446018\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.9498840209675\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1094743589424\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.3710893309793\n",
            "Iteration 800 | Accuracy: 12.785714285714286 | Loss:723.5666302017738\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.8761663922303\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.8984175527464\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.5265193289126\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.8372199132037\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.8076679546701\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.9449628870387\n",
            "Iteration 1150 | Accuracy: 14.285714285714285 | Loss:1039.248064569818\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.423213161545\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.5159109596175\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.8131287353474\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.7105111280582\n",
            "##################################################\n",
            ">epoch=18, lrate=0.100, error=1264.020\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879724406724129\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05997384396729\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1601661227942\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.60496302872343\n",
            "Iteration 200 | Accuracy: 10.428571428571429 | Loss:181.57421725125286\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.7130720430614\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7943492557789\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9259658294302\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.23896109104464\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.22782463271756\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.36587337204895\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.4154460877627\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.6356005997053\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.906061043394\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.0620096613911\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.3207488099195\n",
            "Iteration 800 | Accuracy: 12.5 | Loss:723.5127840179605\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.8198262223291\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.83815015627\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.4629754930502\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.7702676057019\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.7353416464331\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.8700633819996\n",
            "Iteration 1150 | Accuracy: 11.928571428571429 | Loss:1039.1701838880574\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.3425207689552\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.4321357589163\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.7242527396093\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.6200118396769\n",
            "##################################################\n",
            ">epoch=19, lrate=0.100, error=1263.926\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879537428313322\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05720382300051\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1547404374157\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5958079887242\n",
            "Iteration 200 | Accuracy: 11.5 | Loss:181.5607667469191\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.69604480556984\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7734890695722\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9012544418144\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2100156759316\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.1951879836054\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.3298649805868\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.37724244506114\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.592787107775\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.8589278285714\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.0109711761307\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.2666229534892\n",
            "Iteration 800 | Accuracy: 12.357142857142858 | Loss:723.4548987397882\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.7592820670693\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.7733747173676\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.394660064983\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.6983201252071\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.6576017060602\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.7895589913435\n",
            "Iteration 1150 | Accuracy: 10.642857142857142 | Loss:1039.0864824609214\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.2557818823525\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.3420378528099\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.6287224321911\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.5227282160458\n",
            "##################################################\n",
            ">epoch=20, lrate=0.100, error=1263.825\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879379930272028\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05421534057784\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.14887100394758\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5858968813512\n",
            "Iteration 200 | Accuracy: 14.642857142857144 | Loss:181.54622357178482\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.67767258639591\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7509973590707\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.87456429964607\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.17879118820304\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.1599502051818\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.2909838357689\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.33598293552393\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.5465578312594\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.808043051979\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.955885944423\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.2082087913373\n",
            "Iteration 800 | Accuracy: 12.285714285714286 | Loss:723.3924343494002\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.6939722037839\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.703476066734\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.320915805337\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.6206928979436\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.5736913225081\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.7026640537551\n",
            "Iteration 1150 | Accuracy: 10.214285714285715 | Loss:1038.996143641377\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.1621487179905\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.24472423338\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.5255960101458\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.4176924262688\n",
            "##################################################\n",
            ">epoch=21, lrate=0.100, error=1263.715\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879259336806078\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05097823381085\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.14249660935194\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.57512115188587\n",
            "Iteration 200 | Accuracy: 19.071428571428573 | Loss:181.53042280789083\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.65775644918838\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7266309930148\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.8455964607265\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.1449401990355\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.12172548189574\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.248805275369\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.29121494342945\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.4964067959925\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.7528427495557\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.8961485659053\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.144862839022\n",
            "Iteration 800 | Accuracy: 12.0 | Loss:723.3246997641285\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.623176141707\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.6276669119048\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.2409035525365\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.5365101270487\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.4826444132151\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.6083760257302\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.8981245678897\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.0605388736985\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.1390571984236\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.4136718249802\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.3036704242397\n",
            "##################################################\n",
            ">epoch=22, lrate=0.100, error=1263.596\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879183012705998\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.04745429089993\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.13553997312808\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.56334550547302\n",
            "Iteration 200 | Accuracy: 20.214285714285715 | Loss:181.51315846737685\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.63604580570905\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.70008316669526\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.8139769928795\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.10802687076364\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.0800308692631\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.20279822142214\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.24237317730626\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.4417013327403\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.692622422083\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.8310017345003\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.075780579173\n",
            "Iteration 800 | Accuracy: 11.785714285714285 | Loss:723.2508310087576\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.545991694729\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.5449638802922\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.1535771509359\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.4446782205762\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.3832573495907\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.5054462272508\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.791125849952\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.9496036568469\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.0236216000155\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.2914540140725\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.1791270646377\n",
            "##################################################\n",
            ">epoch=23, lrate=0.100, error=1263.467\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879158362429499\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.04359611320334\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.12790527894022\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.55040431795402\n",
            "Iteration 200 | Accuracy: 21.857142857142858 | Loss:181.49417832927992\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.61223172507155\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.6709752760428\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.77924764664164\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.06751636393875\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.0342739709699\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.1523118018642\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.18876555145954\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.3816661519508\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.6265197228221\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.7595175040796\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.9999766849185\n",
            "Iteration 800 | Accuracy: 11.428571428571429 | Loss:723.1697701391579\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.4613129078275\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.454164363314\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.057659008714\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.3438599044192\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.2740611357018\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.3923509299042\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.6735616834615\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.8276967372815\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.8966923237306\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.1571184467123\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.0421913721964\n",
            "##################################################\n",
            ">epoch=24, lrate=0.100, error=1263.324\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879193105937121\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.03934604898134\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.11947574547142\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5360980477873\n",
            "Iteration 200 | Accuracy: 23.857142857142858 | Loss:181.4731785381253\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.5859400177686\n",
            "Iteration 300 | Accuracy: 10.571428571428571 | Loss:271.63884848777496\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.74085601647215\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.0227637741784\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.9837400751433\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.0965615018865\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.1295585113219\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.3153667902271\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.5534962121292\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.6805776856554\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.9162642932232\n",
            "Iteration 800 | Accuracy: 11.214285714285714 | Loss:723.0802430559568\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.3678068738611\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.3538219216966\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.9516138742903\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.2324465102927\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.1532911434649\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.2672597566877\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.5435272116094\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.6928398157374\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.7561985490943\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.0084753001165\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.8906181323878\n",
            "##################################################\n",
            ">epoch=25, lrate=0.100, error=1263.166\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879295725933084\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.03463518162451\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.11011117574274\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.52018946970412\n",
            "Iteration 200 | Accuracy: 24.357142857142858 | Loss:181.4497975168663\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.5567235239745\n",
            "Iteration 300 | Accuracy: 12.642857142857142 | Loss:271.6031542694664\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.6981443224978\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.97300157517276\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.92757769023723\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.03461376010233\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.0637606593597\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.241691135136\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.4723166475841\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.5928517589065\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.8232316265625\n",
            "Iteration 800 | Accuracy: 11.071428571428571 | Loss:722.9807343492248\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.2638874887616\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.242218074443\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.8336185020013\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.1085260095095\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.0188516407854\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.1279985033183\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1038.3987601035772\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.5426821562146\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.5996815447693\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.8429248243353\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.7217422492906\n",
            "##################################################\n",
            ">epoch=26, lrate=0.100, error=1262.990\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879476073953018\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.02938239579552\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.09964549240587\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.50239964676874\n",
            "Iteration 200 | Accuracy: 25.357142857142854 | Loss:181.4236089001921\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.52405320943006\n",
            "Iteration 300 | Accuracy: 18.285714285714285 | Loss:271.5632433630943\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.6503361943944\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.917324878421\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.864781711751\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.9653682556413\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.9902038852072\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.1593281284255\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.3815247261397\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.4947711643457\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.7192147724826\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.8694578685222\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.1476847945663\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.1173289774778\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.7015255891322\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.9698451049732\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.8682731787856\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.9720043336663\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1038.236594212423\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.3744517383998\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.424243716144\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.6574039007708\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.5324233969723\n",
            "##################################################\n",
            ">epoch=27, lrate=0.100, error=1262.793\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.88797461243983\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.02349360423235\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.08788437566298\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.4824036848596\n",
            "Iteration 200 | Accuracy: 26.071428571428573 | Loss:181.3941134045137\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.48730792577\n",
            "Iteration 300 | Accuracy: 20.214285714285715 | Loss:271.51835300514676\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.5965211553544\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.85467424978526\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.79417381183185\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.8875375212852\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.9075215882874\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.0667431946731\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.2794146887986\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.3844993715203\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.6022659731801\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.7443222861399\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.0170091892313\n",
            "Iteration 900 | Accuracy: 9.928571428571429 | Loss:812.976786172922\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.5528210400315\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.8137644001096\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.6986616601044\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.7962720457874\n",
            "Iteration 1150 | Accuracy: 11.071428571428571 | Loss:1038.0539039479638\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.1848965651452\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.2264874107047\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.4483218444527\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.3189793378135\n",
            "##################################################\n",
            ">epoch=28, lrate=0.100, error=1262.570\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880120872087763\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.016861245849206\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.07460318295183\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.45982631667383\n",
            "Iteration 200 | Accuracy: 26.857142857142858 | Loss:181.3607296038585\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.44576276042872\n",
            "Iteration 300 | Accuracy: 20.07142857142857 | Loss:271.46759229169623\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.5356364857805\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.7838158696996\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.71437954511504\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.79962336195473\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.8141233556366\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.9621497227506\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.1639979535402\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.2598968292314\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.4701164315345\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.6028905280089\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.8693093932534\n",
            "Iteration 900 | Accuracy: 10.714285714285714 | Loss:812.8178301140815\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.3845730494887\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.6372050765133\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.5066372302113\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.5972893403925\n",
            "Iteration 1150 | Accuracy: 19.5 | Loss:1037.8470371790697\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.9702137716233\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.002440964161\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.2114828085926\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.0771051079641\n",
            "##################################################\n",
            ">epoch=29, lrate=0.100, error=1262.318\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880619378208519\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.009364063312994\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.05954516610792\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.43423695859508\n",
            "Iteration 200 | Accuracy: 26.857142857142858 | Loss:181.32278310132722\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.39857531612319\n",
            "Iteration 300 | Accuracy: 19.642857142857142 | Loss:271.4099248881639\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.4664451063122\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.70331767220216\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.6238002026519\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.69988783357\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.7081635308173\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.8434738216397\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.0329616422546\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.1184773473038\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.3201298722591\n",
            "Iteration 800 | Accuracy: 10.928571428571429 | Loss:722.4423289478766\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.701619913151\n",
            "Iteration 900 | Accuracy: 17.285714285714285 | Loss:812.637251666775\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.1933677341344\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.4365815666331\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.2882567948693\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.3709544543052\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.6117296614539\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.725959125207\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1127.7474639946195\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.9419863206886\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.801769198881\n",
            "##################################################\n",
            ">epoch=30, lrate=0.100, error=1262.031\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881265987012659\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.00086677433745\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.04241930780991\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.405142635378\n",
            "Iteration 200 | Accuracy: 26.42857142857143 | Loss:181.27949198416303\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.34476727853914\n",
            "Iteration 300 | Accuracy: 19.28571428571429 | Loss:271.3441458846884\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.38750500153014\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.61151649590914\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.5205732606296\n",
            "Iteration 500 | Accuracy: 10.5 | Loss:451.58631172698574\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.58749588458915\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.7083037781148\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.8836095692072\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.9573455084973\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.1492356724898\n",
            "Iteration 800 | Accuracy: 10.857142857142858 | Loss:722.2593341396804\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.5104852981597\n",
            "Iteration 900 | Accuracy: 19.5 | Loss:812.4313075591822\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.9752162778746\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.2077044512076\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.0389027931993\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.1124578714705\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.3429817679535\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.446916723508\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1127.4561103119674\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.6340829958297\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.4870628776255\n",
            "##################################################\n",
            ">epoch=31, lrate=0.100, error=1261.703\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882091778816338\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.99121837727369\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.02289549069305\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.37197458357022\n",
            "Iteration 200 | Accuracy: 25.5 | Loss:181.22994302296217\n",
            "Iteration 250 | Accuracy: 13.357142857142856 | Loss:226.28319434840702\n",
            "Iteration 300 | Accuracy: 18.571428571428573 | Loss:271.2688443883287\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.2971192840956\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.5064637875146\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.40250685004855\n",
            "Iteration 500 | Accuracy: 10.5 | Loss:451.4565239859546\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.44959641619334\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.5538042521699\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.7127638884664\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.7730911263561\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.9538159841916\n",
            "Iteration 800 | Accuracy: 10.785714285714286 | Loss:722.0500098813916\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.2918321491319\n",
            "Iteration 900 | Accuracy: 19.428571428571427 | Loss:812.1955781019495\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.7254000279906\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.9456183115019\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.7530996861071\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:991.8160878341932\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.0348553404071\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.12688469155\n",
            "Iteration 1250 | Accuracy: 11.5 | Loss:1127.1219014636984\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.2809356309583\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.1259511130122\n",
            "##################################################\n",
            ">epoch=32, lrate=0.100, error=1261.327\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8883136424136178\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.98024641983574\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.00059199232778\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.33406028764637\n",
            "Iteration 200 | Accuracy: 24.21428571428571 | Loss:181.17304749867978\n",
            "Iteration 250 | Accuracy: 19.857142857142858 | Loss:226.21249056175884\n",
            "Iteration 300 | Accuracy: 18.285714285714285 | Loss:271.1823348305532\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.1932457656757\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.3858254672193\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.26696053878254\n",
            "Iteration 500 | Accuracy: 10.785714285714286 | Loss:451.30767093004084\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.2914209426339\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.3765578756991\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.5165866792606\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.5615961247398\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.729499557639\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.8096435435593\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.0407352650278\n",
            "Iteration 900 | Accuracy: 19.0 | Loss:811.9247092491721\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.4381925687724\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.644310356724\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.4241882294965\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:991.4748867915392\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1036.6801146443556\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1081.7582972491984\n",
            "Iteration 1250 | Accuracy: 14.142857142857142 | Loss:1126.7369269958192\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1171.874196875289\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1216.7098334630828\n",
            "##################################################\n",
            ">epoch=33, lrate=0.100, error=1260.893\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8884450788943591\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.96774296620639\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.9750469833428\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.29056806661026\n",
            "Iteration 200 | Accuracy: 23.42857142857143 | Loss:181.10745875760918\n",
            "Iteration 250 | Accuracy: 20.357142857142858 | Loss:226.13096425960828\n",
            "Iteration 300 | Accuracy: 18.0 | Loss:271.0825292071656\n",
            "Iteration 350 | Accuracy: 10.857142857142858 | Loss:316.07333254196\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.2466973368768\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:406.11062926875684\n",
            "Iteration 500 | Accuracy: 11.0 | Loss:451.13617754331744\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.10914686341084\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.1722770683745\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.2902588736233\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.3176855972716\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.4707903133612\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.5323050313159\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.7509965165389\n",
            "Iteration 900 | Accuracy: 19.142857142857142 | Loss:811.6119517940161\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.1063673106389\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.2961933280021\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.0437522788969\n",
            "Iteration 1100 | Accuracy: 10.357142857142858 | Loss:991.0800490929724\n",
            "Iteration 1150 | Accuracy: 19.857142857142858 | Loss:1036.2695974376147\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1081.331563571011\n",
            "Iteration 1250 | Accuracy: 14.714285714285714 | Loss:1126.291146618026\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1171.4032716140844\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1216.227779071028\n",
            "##################################################\n",
            ">epoch=34, lrate=0.100, error=1260.391\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8886100912103123\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.95343711752795\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.94566332840365\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.24040819231456\n",
            "Iteration 200 | Accuracy: 22.357142857142858 | Loss:181.0314281079527\n",
            "Iteration 250 | Accuracy: 19.857142857142858 | Loss:226.036415474793\n",
            "Iteration 300 | Accuracy: 17.642857142857142 | Loss:270.9667131388754\n",
            "Iteration 350 | Accuracy: 13.214285714285715 | Loss:315.934035740466\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.08528602179683\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:405.9291748572402\n",
            "Iteration 500 | Accuracy: 11.5 | Loss:450.93734056732535\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.8977357167697\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:540.9353135369844\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.0274362981615\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.0345361547091\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.1704393389208\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.2101705506229\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.4144332443185\n",
            "Iteration 900 | Accuracy: 21.642857142857146 | Loss:811.2483879875904\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:855.7203754466285\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:900.8912406598591\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:945.6006641749303\n",
            "Iteration 1100 | Accuracy: 12.785714285714286 | Loss:990.6199196849531\n",
            "Iteration 1150 | Accuracy: 19.857142857142858 | Loss:1035.7911709430946\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1080.8339704369985\n",
            "Iteration 1250 | Accuracy: 16.142857142857142 | Loss:1125.7712362648838\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1170.8540971951975\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1215.6652637706213\n",
            "##################################################\n",
            ">epoch=35, lrate=0.100, error=1259.805\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8888174291770741\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.93694954236246\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.91161601418938\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.1820742340813\n",
            "Iteration 200 | Accuracy: 21.857142857142858 | Loss:180.94257318657048\n",
            "Iteration 250 | Accuracy: 19.357142857142858 | Loss:225.92584030426872\n",
            "Iteration 300 | Accuracy: 17.357142857142858 | Loss:270.83118316360475\n",
            "Iteration 350 | Accuracy: 14.571428571428571 | Loss:315.7707692884232\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.896399631912\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:405.71664220305536\n",
            "Iteration 500 | Accuracy: 11.714285714285715 | Loss:450.7046868046323\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.6502464993407\n",
            "Iteration 600 | Accuracy: 10.071428571428571 | Loss:540.6578838825327\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:585.7193907403642\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:630.7027424445738\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:675.818455962882\n",
            "Iteration 800 | Accuracy: 10.642857142857142 | Loss:720.832458856875\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.019757909723\n",
            "Iteration 900 | Accuracy: 21.21428571428571 | Loss:810.8217202220959\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:855.2670615230869\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:900.4156321339759\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:945.079590855571\n",
            "Iteration 1100 | Accuracy: 17.785714285714285 | Loss:990.0784267379992\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1035.2280999141346\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1080.2479649684203\n",
            "Iteration 1250 | Accuracy: 16.92857142857143 | Loss:1125.1587897644022\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1170.2072421031585\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1215.002202758922\n",
            "##################################################\n",
            ">epoch=36, lrate=0.100, error=1259.114\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8890789771323999\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.91772558362033\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.871712384296\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.1134073679147\n",
            "Iteration 200 | Accuracy: 21.642857142857146 | Loss:180.83752885089805\n",
            "Iteration 250 | Accuracy: 18.5 | Loss:225.79498116284108\n",
            "Iteration 300 | Accuracy: 16.714285714285715 | Loss:270.6706940005059\n",
            "Iteration 350 | Accuracy: 15.5 | Loss:315.5770247014844\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.6726810629583\n",
            "Iteration 450 | Accuracy: 10.642857142857142 | Loss:405.4645820292593\n",
            "Iteration 500 | Accuracy: 12.071428571428571 | Loss:450.4290144474388\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.35681188782155\n",
            "Iteration 600 | Accuracy: 11.714285714285715 | Loss:540.3289077466608\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:585.3537167147689\n",
            "Iteration 700 | Accuracy: 10.714285714285714 | Loss:630.3089133927401\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:675.4006214488498\n",
            "Iteration 800 | Accuracy: 10.428571428571429 | Loss:720.3838314785186\n",
            "Iteration 850 | Accuracy: 10.142857142857142 | Loss:765.5508928857172\n",
            "Iteration 900 | Accuracy: 20.214285714285715 | Loss:810.3144550823164\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:854.7277373562242\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:899.8497171559775\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:944.4587428957511\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:989.432714951086\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1034.5565845753545\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1079.5485576535993\n",
            "Iteration 1250 | Accuracy: 17.92857142857143 | Loss:1124.4276088819886\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1169.4350386365777\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1214.2099817544356\n",
            "##################################################\n",
            ">epoch=37, lrate=0.100, error=1258.290\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8894112914477537\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.89494136089685\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.82419012197455\n",
            "Iteration 150 | Accuracy: 9.928571428571429 | Loss:136.0312538707002\n",
            "Iteration 200 | Accuracy: 21.21428571428571 | Loss:180.71143017974336\n",
            "Iteration 250 | Accuracy: 18.071428571428573 | Loss:225.63765392971743\n",
            "Iteration 300 | Accuracy: 15.785714285714286 | Loss:270.47762982895415\n",
            "Iteration 350 | Accuracy: 15.714285714285714 | Loss:315.3433536367159\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.40346804470386\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:405.16074271609824\n",
            "Iteration 500 | Accuracy: 12.5 | Loss:450.09697022322325\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.00311724314537\n",
            "Iteration 600 | Accuracy: 13.285714285714286 | Loss:539.9322712984803\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:584.9123887458213\n",
            "Iteration 700 | Accuracy: 20.214285714285715 | Loss:629.8335651006464\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:674.8962559528497\n",
            "Iteration 800 | Accuracy: 10.357142857142858 | Loss:719.8419844708479\n",
            "Iteration 850 | Accuracy: 15.785714285714286 | Loss:764.984433402962\n",
            "Iteration 900 | Accuracy: 19.57142857142857 | Loss:809.7011736646992\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:854.0752798845957\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:899.164935759303\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:943.7064605538801\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:988.6495441010567\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1033.7420144239497\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1078.6993583807985\n",
            "Iteration 1250 | Accuracy: 17.71428571428571 | Loss:1123.5395761331217\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1168.4972104508745\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1213.2469213987567\n",
            "##################################################\n",
            ">epoch=38, lrate=0.100, error=1257.287\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.889838020066996\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.86736667142233\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.76641606197556\n",
            "Iteration 150 | Accuracy: 16.142857142857142 | Loss:135.93094655783682\n",
            "Iteration 200 | Accuracy: 20.92857142857143 | Loss:180.55711788360813\n",
            "Iteration 250 | Accuracy: 17.71428571428571 | Loss:225.4447046500777\n",
            "Iteration 300 | Accuracy: 15.142857142857144 | Loss:270.2407170909071\n",
            "Iteration 350 | Accuracy: 16.428571428571427 | Loss:315.0557850412139\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.0730300928384\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:404.7870373133156\n",
            "Iteration 500 | Accuracy: 12.5 | Loss:449.68884307977896\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:494.56803410108864\n",
            "Iteration 600 | Accuracy: 14.357142857142858 | Loss:539.4441126551246\n",
            "Iteration 650 | Accuracy: 11.214285714285714 | Loss:584.3687102281403\n",
            "Iteration 700 | Accuracy: 20.285714285714285 | Loss:629.2478120168353\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:674.2747049769064\n",
            "Iteration 800 | Accuracy: 10.285714285714285 | Loss:719.1738497322522\n",
            "Iteration 850 | Accuracy: 29.57142857142857 | Loss:764.2856445925494\n",
            "Iteration 900 | Accuracy: 19.28571428571429 | Loss:808.9442262973841\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:853.2695380963983\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:898.3189293115211\n",
            "Iteration 1050 | Accuracy: 10.357142857142858 | Loss:942.7757769402132\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:987.6795331103334\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1032.7329781767621\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1077.6462183873973\n",
            "Iteration 1250 | Accuracy: 17.642857142857142 | Loss:1122.4380417417203\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1167.3338564026208\n",
            "Iteration 1350 | Accuracy: 10.214285714285715 | Loss:1212.0509811395755\n",
            "##################################################\n",
            ">epoch=39, lrate=0.100, error=1256.042\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8903938847427512\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.83314433306157\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.69439852302258\n",
            "Iteration 150 | Accuracy: 17.57142857142857 | Loss:135.80545589490262\n",
            "Iteration 200 | Accuracy: 20.785714285714285 | Loss:180.3638284578966\n",
            "Iteration 250 | Accuracy: 17.285714285714285 | Loss:225.2022787683169\n",
            "Iteration 300 | Accuracy: 14.428571428571429 | Loss:269.9428873221189\n",
            "Iteration 350 | Accuracy: 17.357142857142858 | Loss:314.69319164162624\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:359.6576474345143\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:404.3161614116813\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:449.1748939920013\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:494.01966641258144\n",
            "Iteration 600 | Accuracy: 15.571428571428573 | Loss:538.8282706767156\n",
            "Iteration 650 | Accuracy: 18.071428571428573 | Loss:583.682180398425\n",
            "Iteration 700 | Accuracy: 20.357142857142858 | Loss:628.5078002269147\n",
            "Iteration 750 | Accuracy: 10.0 | Loss:673.4894132307178\n",
            "Iteration 800 | Accuracy: 10.214285714285715 | Loss:718.3291726459244\n",
            "Iteration 850 | Accuracy: 29.142857142857142 | Loss:763.4016909654707\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:807.9864516591595\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:852.2495363655299\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:897.2472142929668\n",
            "Iteration 1050 | Accuracy: 16.57142857142857 | Loss:941.5951443682254\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:986.4473106284263\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1031.4510065837806\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1076.3063151199444\n",
            "Iteration 1250 | Accuracy: 16.92857142857143 | Loss:1121.036477531667\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1165.8533965122203\n",
            "Iteration 1350 | Accuracy: 14.428571428571429 | Loss:1210.5271907561348\n",
            "##################################################\n",
            ">epoch=40, lrate=0.100, error=1254.455\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 12.928571428571429 | Loss:0.8911317236536767\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.789398314850644\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.60192396000897\n",
            "Iteration 150 | Accuracy: 18.0 | Loss:135.64388573301954\n",
            "Iteration 200 | Accuracy: 20.642857142857142 | Loss:180.11486991881603\n",
            "Iteration 250 | Accuracy: 16.28571428571429 | Loss:224.88873584576282\n",
            "Iteration 300 | Accuracy: 14.142857142857142 | Loss:269.55746629208784\n",
            "Iteration 350 | Accuracy: 27.642857142857142 | Loss:314.22259180689923\n",
            "Iteration 400 | Accuracy: 9.785714285714285 | Loss:359.1204124876047\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:403.70555752377487\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:448.50880055258267\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:493.3082573729185\n",
            "Iteration 600 | Accuracy: 16.5 | Loss:538.0280914193017\n",
            "Iteration 650 | Accuracy: 20.285714285714285 | Loss:582.78922677712\n",
            "Iteration 700 | Accuracy: 20.285714285714285 | Loss:627.544660168903\n",
            "Iteration 750 | Accuracy: 18.428571428571427 | Loss:672.4671957043857\n",
            "Iteration 800 | Accuracy: 10.214285714285715 | Loss:717.2288577259011\n",
            "Iteration 850 | Accuracy: 28.285714285714285 | Loss:762.2493459157592\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:806.7379631104088\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:850.9192644467755\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:895.8479563295241\n",
            "Iteration 1050 | Accuracy: 19.92857142857143 | Loss:940.051464962072\n",
            "Iteration 1100 | Accuracy: 19.857142857142858 | Loss:984.8334398476517\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1029.771732052392\n",
            "Iteration 1200 | Accuracy: 10.285714285714285 | Loss:1074.5480630950092\n",
            "Iteration 1250 | Accuracy: 16.642857142857142 | Loss:1119.1976111226563\n",
            "Iteration 1300 | Accuracy: 10.071428571428571 | Loss:1163.9103725864227\n",
            "Iteration 1350 | Accuracy: 19.92857142857143 | Loss:1208.5244387360267\n",
            "##################################################\n",
            ">epoch=41, lrate=0.100, error=1252.370\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 15.571428571428573 | Loss:0.8921361196648566\n",
            "Iteration 50 | Accuracy: 10.571428571428571 | Loss:45.73148121494074\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.47890543855567\n",
            "Iteration 150 | Accuracy: 18.285714285714285 | Loss:135.42861139368057\n",
            "Iteration 200 | Accuracy: 20.642857142857142 | Loss:179.7831999540552\n",
            "Iteration 250 | Accuracy: 15.5 | Loss:224.46875834323643\n",
            "Iteration 300 | Accuracy: 14.000000000000002 | Loss:269.0408949814919\n",
            "Iteration 350 | Accuracy: 28.357142857142858 | Loss:313.5901889699657\n",
            "Iteration 400 | Accuracy: 11.5 | Loss:358.40132275905484\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:402.88589017638935\n",
            "Iteration 500 | Accuracy: 12.571428571428573 | Loss:447.6151242300056\n",
            "Iteration 550 | Accuracy: 10.714285714285714 | Loss:492.352564560394\n",
            "Iteration 600 | Accuracy: 17.57142857142857 | Loss:536.9506187597011\n",
            "Iteration 650 | Accuracy: 20.357142857142858 | Loss:581.5852641717042\n",
            "Iteration 700 | Accuracy: 20.214285714285715 | Loss:626.2450749305917\n",
            "Iteration 750 | Accuracy: 26.21428571428571 | Loss:671.0874023355653\n",
            "Iteration 800 | Accuracy: 12.071428571428571 | Loss:715.7422747508498\n",
            "Iteration 850 | Accuracy: 26.285714285714285 | Loss:760.6910558729405\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:805.0504130501868\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:849.1198460457615\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:893.9520354897908\n",
            "Iteration 1050 | Accuracy: 19.92857142857143 | Loss:937.9567207694374\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:982.6387746143004\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1027.4876847046387\n",
            "Iteration 1200 | Accuracy: 12.071428571428571 | Loss:1072.151384938392\n",
            "Iteration 1250 | Accuracy: 16.428571428571427 | Loss:1116.6922044597154\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1161.2615113220943\n",
            "Iteration 1350 | Accuracy: 19.78571428571429 | Loss:1205.7893842776084\n",
            "##################################################\n",
            ">epoch=42, lrate=0.100, error=1249.521\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 26.71428571428571 | Loss:0.8935526881406133\n",
            "Iteration 50 | Accuracy: 13.857142857142858 | Loss:45.65141795229294\n",
            "Iteration 100 | Accuracy: 10.571428571428571 | Loss:90.30797386282298\n",
            "Iteration 150 | Accuracy: 18.5 | Loss:135.12941784966034\n",
            "Iteration 200 | Accuracy: 21.142857142857142 | Loss:179.32236220580646\n",
            "Iteration 250 | Accuracy: 15.071428571428571 | Loss:223.88124974627846\n",
            "Iteration 300 | Accuracy: 14.071428571428571 | Loss:268.31776742488864\n",
            "Iteration 350 | Accuracy: 28.57142857142857 | Loss:312.7030197198196\n",
            "Iteration 400 | Accuracy: 13.5 | Loss:357.39695405726\n",
            "Iteration 450 | Accuracy: 10.857142857142858 | Loss:401.7373697988739\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:446.3635181087403\n",
            "Iteration 550 | Accuracy: 10.857142857142858 | Loss:491.0116621954389\n",
            "Iteration 600 | Accuracy: 18.5 | Loss:535.433692300224\n",
            "Iteration 650 | Accuracy: 20.357142857142858 | Loss:579.8871983420094\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:624.4107440156873\n",
            "Iteration 750 | Accuracy: 29.142857142857142 | Loss:669.138197037121\n",
            "Iteration 800 | Accuracy: 17.142857142857142 | Loss:713.6394708948453\n",
            "Iteration 850 | Accuracy: 24.785714285714285 | Loss:758.484549956561\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:802.6627396756371\n",
            "Iteration 950 | Accuracy: 10.214285714285715 | Loss:846.5704039341645\n",
            "Iteration 1000 | Accuracy: 11.285714285714285 | Loss:891.2591678145152\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:934.9767743774652\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:979.5082159180051\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1024.2285326290971\n",
            "Iteration 1200 | Accuracy: 14.499999999999998 | Loss:1068.7225044005088\n",
            "Iteration 1250 | Accuracy: 16.357142857142858 | Loss:1113.1107375974434\n",
            "Iteration 1300 | Accuracy: 13.285714285714286 | Loss:1157.4713571800125\n",
            "Iteration 1350 | Accuracy: 27.285714285714285 | Loss:1201.8670782769047\n",
            "##################################################\n",
            ">epoch=43, lrate=0.100, error=1245.434\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 29.714285714285715 | Loss:0.8956588207056959\n",
            "Iteration 50 | Accuracy: 15.642857142857142 | Loss:45.53439898488019\n",
            "Iteration 100 | Accuracy: 13.857142857142858 | Loss:90.05681473761898\n",
            "Iteration 150 | Accuracy: 18.642857142857142 | Loss:134.6904416589316\n",
            "Iteration 200 | Accuracy: 21.571428571428573 | Loss:178.64625988950758\n",
            "Iteration 250 | Accuracy: 15.071428571428571 | Loss:223.01236798389883\n",
            "Iteration 300 | Accuracy: 14.499999999999998 | Loss:267.24746185143545\n",
            "Iteration 350 | Accuracy: 28.714285714285715 | Loss:311.3883196828172\n",
            "Iteration 400 | Accuracy: 15.285714285714286 | Loss:355.9151406887098\n",
            "Iteration 450 | Accuracy: 15.5 | Loss:400.036979266181\n",
            "Iteration 500 | Accuracy: 17.285714285714285 | Loss:444.51106724886216\n",
            "Iteration 550 | Accuracy: 14.428571428571429 | Loss:489.0214534488608\n",
            "Iteration 600 | Accuracy: 18.285714285714285 | Loss:533.1714476163693\n",
            "Iteration 650 | Accuracy: 30.07142857142857 | Loss:577.3480974471657\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:621.6664494748933\n",
            "Iteration 750 | Accuracy: 31.071428571428573 | Loss:666.2165343913633\n",
            "Iteration 800 | Accuracy: 25.71428571428571 | Loss:710.4813439970695\n",
            "Iteration 850 | Accuracy: 23.214285714285715 | Loss:755.1671509213801\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:799.0761021603053\n",
            "Iteration 950 | Accuracy: 12.928571428571429 | Loss:842.7302192411678\n",
            "Iteration 1000 | Accuracy: 14.214285714285715 | Loss:887.1883392549724\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:930.4648944643495\n",
            "Iteration 1100 | Accuracy: 28.92857142857143 | Loss:974.7522040447541\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1019.2736842418183\n",
            "Iteration 1200 | Accuracy: 16.428571428571427 | Loss:1063.4942404159656\n",
            "Iteration 1250 | Accuracy: 16.357142857142858 | Loss:1107.6565629805577\n",
            "Iteration 1300 | Accuracy: 18.642857142857142 | Loss:1151.6905971863105\n",
            "Iteration 1350 | Accuracy: 23.42857142857143 | Loss:1195.8663678249059\n",
            "##################################################\n",
            ">epoch=44, lrate=0.100, error=1239.175\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 35.5 | Loss:0.8990546210254405\n",
            "Iteration 50 | Accuracy: 26.785714285714285 | Loss:45.35010667109499\n",
            "Iteration 100 | Accuracy: 16.642857142857142 | Loss:89.65936753092629\n",
            "Iteration 150 | Accuracy: 29.07142857142857 | Loss:133.99858128607136\n",
            "Iteration 200 | Accuracy: 19.57142857142857 | Loss:177.58014999810692\n",
            "Iteration 250 | Accuracy: 16.071428571428573 | Loss:221.6308254974743\n",
            "Iteration 300 | Accuracy: 16.071428571428573 | Loss:265.54404932855357\n",
            "Iteration 350 | Accuracy: 28.714285714285715 | Loss:309.2975117457845\n",
            "Iteration 400 | Accuracy: 17.42857142857143 | Loss:353.5659761294791\n",
            "Iteration 450 | Accuracy: 26.21428571428571 | Loss:397.33204394286264\n",
            "Iteration 500 | Accuracy: 17.42857142857143 | Loss:441.5634601409667\n",
            "Iteration 550 | Accuracy: 16.642857142857142 | Loss:485.84038934796257\n",
            "Iteration 600 | Accuracy: 28.214285714285715 | Loss:529.5328424524181\n",
            "Iteration 650 | Accuracy: 30.0 | Loss:573.2483103385201\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:617.2365173979804\n",
            "Iteration 750 | Accuracy: 30.357142857142854 | Loss:661.4816639814384\n",
            "Iteration 800 | Accuracy: 27.57142857142857 | Loss:705.3474469347082\n",
            "Iteration 850 | Accuracy: 30.571428571428573 | Loss:749.7698690026089\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:793.2421061674509\n",
            "Iteration 950 | Accuracy: 14.714285714285714 | Loss:836.4497702715557\n",
            "Iteration 1000 | Accuracy: 17.285714285714285 | Loss:880.4978033225659\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:923.0412989297097\n",
            "Iteration 1100 | Accuracy: 30.0 | Loss:966.8969469538908\n",
            "Iteration 1150 | Accuracy: 21.142857142857142 | Loss:1011.0777970359163\n",
            "Iteration 1200 | Accuracy: 18.857142857142858 | Loss:1054.8253229113363\n",
            "Iteration 1250 | Accuracy: 26.64285714285714 | Loss:1098.627560414546\n",
            "Iteration 1300 | Accuracy: 22.142857142857142 | Loss:1142.0992002377548\n",
            "Iteration 1350 | Accuracy: 33.57142857142857 | Loss:1185.8673430988827\n",
            "##################################################\n",
            ">epoch=45, lrate=0.100, error=1228.728\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 31.71428571428571 | Loss:0.9051944486791735\n",
            "Iteration 50 | Accuracy: 37.857142857142854 | Loss:45.029970781172345\n",
            "Iteration 100 | Accuracy: 28.642857142857142 | Loss:88.96787398288546\n",
            "Iteration 150 | Accuracy: 31.071428571428573 | Loss:132.80547467213177\n",
            "Iteration 200 | Accuracy: 19.78571428571429 | Loss:175.73998136325724\n",
            "Iteration 250 | Accuracy: 22.285714285714285 | Loss:219.2334990436181\n",
            "Iteration 300 | Accuracy: 22.642857142857142 | Loss:262.5857321060745\n",
            "Iteration 350 | Accuracy: 28.57142857142857 | Loss:305.6869201290392\n",
            "Iteration 400 | Accuracy: 24.428571428571427 | Loss:349.5013644350522\n",
            "Iteration 450 | Accuracy: 27.21428571428571 | Loss:392.64165430992557\n",
            "Iteration 500 | Accuracy: 18.571428571428573 | Loss:436.44403503182394\n",
            "Iteration 550 | Accuracy: 38.357142857142854 | Loss:480.2769975904801\n",
            "Iteration 600 | Accuracy: 29.85714285714286 | Loss:523.128921153612\n",
            "Iteration 650 | Accuracy: 30.0 | Loss:565.9959124586576\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:609.4184891533012\n",
            "Iteration 750 | Accuracy: 30.857142857142854 | Loss:653.0606754166082\n",
            "Iteration 800 | Accuracy: 36.714285714285715 | Loss:696.175380856973\n",
            "Iteration 850 | Accuracy: 29.85714285714286 | Loss:740.1286590816613\n",
            "Iteration 900 | Accuracy: 27.785714285714285 | Loss:782.7998306702564\n",
            "Iteration 950 | Accuracy: 15.285714285714286 | Loss:825.1001876966764\n",
            "Iteration 1000 | Accuracy: 26.142857142857146 | Loss:868.3375166871006\n",
            "Iteration 1050 | Accuracy: 29.85714285714286 | Loss:909.5663525537918\n",
            "Iteration 1100 | Accuracy: 30.07142857142857 | Loss:952.6000923671025\n",
            "Iteration 1150 | Accuracy: 30.0 | Loss:996.1212497642646\n",
            "Iteration 1200 | Accuracy: 19.857142857142858 | Loss:1039.022336283751\n",
            "Iteration 1250 | Accuracy: 27.0 | Loss:1082.1986407441468\n",
            "Iteration 1300 | Accuracy: 32.57142857142858 | Loss:1124.5995003194012\n",
            "Iteration 1350 | Accuracy: 38.857142857142854 | Loss:1167.5270924465258\n",
            "##################################################\n",
            ">epoch=46, lrate=0.100, error=1209.521\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.357142857142854 | Loss:0.9173910630814293\n",
            "Iteration 50 | Accuracy: 41.57142857142857 | Loss:44.41383318247879\n",
            "Iteration 100 | Accuracy: 38.857142857142854 | Loss:87.65065469347559\n",
            "Iteration 150 | Accuracy: 37.714285714285715 | Loss:130.57685390535107\n",
            "Iteration 200 | Accuracy: 24.857142857142858 | Loss:172.30537499699358\n",
            "Iteration 250 | Accuracy: 24.5 | Loss:214.78538673568536\n",
            "Iteration 300 | Accuracy: 25.785714285714285 | Loss:257.0994076934556\n",
            "Iteration 350 | Accuracy: 29.142857142857142 | Loss:299.102774476857\n",
            "Iteration 400 | Accuracy: 38.92857142857143 | Loss:341.9777661449157\n",
            "Iteration 450 | Accuracy: 38.142857142857146 | Loss:383.96684985316426\n",
            "Iteration 500 | Accuracy: 38.642857142857146 | Loss:426.9353954829593\n",
            "Iteration 550 | Accuracy: 38.57142857142858 | Loss:469.84908708802936\n",
            "Iteration 600 | Accuracy: 34.07142857142857 | Loss:511.12168699377776\n",
            "Iteration 650 | Accuracy: 30.142857142857142 | Loss:552.3361184112817\n",
            "Iteration 700 | Accuracy: 22.071428571428573 | Loss:594.7811285001682\n",
            "Iteration 750 | Accuracy: 35.785714285714285 | Loss:637.0900394796103\n",
            "Iteration 800 | Accuracy: 38.142857142857146 | Loss:678.6999990162241\n",
            "Iteration 850 | Accuracy: 34.0 | Loss:721.7937974294397\n",
            "Iteration 900 | Accuracy: 39.285714285714285 | Loss:762.8468537077932\n",
            "Iteration 950 | Accuracy: 17.214285714285715 | Loss:803.1940765632119\n",
            "Iteration 1000 | Accuracy: 39.85714285714286 | Loss:844.7906001788185\n",
            "Iteration 1050 | Accuracy: 30.142857142857142 | Loss:883.6909902961517\n",
            "Iteration 1100 | Accuracy: 30.28571428571429 | Loss:925.2007149890619\n",
            "Iteration 1150 | Accuracy: 36.5 | Loss:967.3879485219369\n",
            "Iteration 1200 | Accuracy: 26.71428571428571 | Loss:1008.9221875232191\n",
            "Iteration 1250 | Accuracy: 36.5 | Loss:1050.9764281917317\n",
            "Iteration 1300 | Accuracy: 38.642857142857146 | Loss:1091.303914981897\n",
            "Iteration 1350 | Accuracy: 39.42857142857143 | Loss:1132.542862158415\n",
            "##################################################\n",
            ">epoch=47, lrate=0.100, error=1172.838\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.57142857142858 | Loss:0.9389687634945457\n",
            "Iteration 50 | Accuracy: 42.785714285714285 | Loss:43.215211656587044\n",
            "Iteration 100 | Accuracy: 41.57142857142857 | Loss:85.17043534428643\n",
            "Iteration 150 | Accuracy: 39.285714285714285 | Loss:126.52150998013089\n",
            "Iteration 200 | Accuracy: 40.14285714285714 | Loss:166.11085188190197\n",
            "Iteration 250 | Accuracy: 35.57142857142857 | Loss:206.9432827350961\n",
            "Iteration 300 | Accuracy: 39.714285714285715 | Loss:247.46552248579042\n",
            "Iteration 350 | Accuracy: 38.714285714285715 | Loss:287.84678827379753\n",
            "Iteration 400 | Accuracy: 39.214285714285715 | Loss:328.77157184180385\n",
            "Iteration 450 | Accuracy: 38.714285714285715 | Loss:368.81711275917496\n",
            "Iteration 500 | Accuracy: 39.214285714285715 | Loss:410.24706435989697\n",
            "Iteration 550 | Accuracy: 39.214285714285715 | Loss:451.4584755543082\n",
            "Iteration 600 | Accuracy: 36.92857142857143 | Loss:490.20516763118195\n",
            "Iteration 650 | Accuracy: 34.5 | Loss:528.673561952748\n",
            "Iteration 700 | Accuracy: 34.92857142857143 | Loss:569.5869088838685\n",
            "Iteration 750 | Accuracy: 39.85714285714286 | Loss:609.4009921330387\n",
            "Iteration 800 | Accuracy: 39.42857142857143 | Loss:648.5397303579215\n",
            "Iteration 850 | Accuracy: 40.07142857142857 | Loss:690.2031663691654\n",
            "Iteration 900 | Accuracy: 39.357142857142854 | Loss:728.5308153833446\n",
            "Iteration 950 | Accuracy: 29.78571428571429 | Loss:765.8941412354573\n",
            "Iteration 1000 | Accuracy: 42.07142857142857 | Loss:805.0355719640381\n",
            "Iteration 1050 | Accuracy: 37.214285714285715 | Loss:840.7642814877051\n",
            "Iteration 1100 | Accuracy: 38.07142857142857 | Loss:880.1307459580198\n",
            "Iteration 1150 | Accuracy: 39.357142857142854 | Loss:920.2243055531089\n",
            "Iteration 1200 | Accuracy: 33.92857142857143 | Loss:960.0861083689518\n",
            "Iteration 1250 | Accuracy: 37.57142857142857 | Loss:1000.4499900148329\n",
            "Iteration 1300 | Accuracy: 39.214285714285715 | Loss:1037.7718521405875\n",
            "Iteration 1350 | Accuracy: 39.85714285714286 | Loss:1076.6650932141522\n",
            "##################################################\n",
            ">epoch=48, lrate=0.100, error=1114.617\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.85714285714286 | Loss:0.9663622827764417\n",
            "Iteration 50 | Accuracy: 42.714285714285715 | Loss:41.511897149055955\n",
            "Iteration 100 | Accuracy: 42.642857142857146 | Loss:81.72043320004724\n",
            "Iteration 150 | Accuracy: 39.357142857142854 | Loss:121.04372529438734\n",
            "Iteration 200 | Accuracy: 42.07142857142857 | Loss:157.93472008387158\n",
            "Iteration 250 | Accuracy: 40.42857142857143 | Loss:196.7605542044664\n",
            "Iteration 300 | Accuracy: 43.214285714285715 | Loss:235.0415406794008\n",
            "Iteration 350 | Accuracy: 39.14285714285714 | Loss:273.54873917540556\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:311.90761056421644\n",
            "Iteration 450 | Accuracy: 39.214285714285715 | Loss:349.81994364372156\n",
            "Iteration 500 | Accuracy: 39.357142857142854 | Loss:389.4192001968162\n",
            "Iteration 550 | Accuracy: 39.57142857142858 | Loss:428.68084719398144\n",
            "Iteration 600 | Accuracy: 40.285714285714285 | Loss:464.7263953681459\n",
            "Iteration 650 | Accuracy: 39.07142857142858 | Loss:500.3903409675333\n",
            "Iteration 700 | Accuracy: 39.214285714285715 | Loss:539.5017081499601\n",
            "Iteration 750 | Accuracy: 40.14285714285714 | Loss:576.7397270454983\n",
            "Iteration 800 | Accuracy: 40.0 | Loss:613.4153435189427\n",
            "Iteration 850 | Accuracy: 41.214285714285715 | Loss:653.3958992725791\n",
            "Iteration 900 | Accuracy: 38.92857142857143 | Loss:688.9150970737526\n",
            "Iteration 950 | Accuracy: 40.5 | Loss:723.8582465169744\n",
            "Iteration 1000 | Accuracy: 42.57142857142857 | Loss:760.829179359178\n",
            "Iteration 1050 | Accuracy: 39.285714285714285 | Loss:793.6225463444213\n",
            "Iteration 1100 | Accuracy: 39.92857142857143 | Loss:830.9883565245423\n",
            "Iteration 1150 | Accuracy: 39.57142857142858 | Loss:868.959004961999\n",
            "Iteration 1200 | Accuracy: 39.785714285714285 | Loss:907.2763567527287\n",
            "Iteration 1250 | Accuracy: 37.5 | Loss:945.8022142812245\n",
            "Iteration 1300 | Accuracy: 39.357142857142854 | Loss:980.3395152172234\n",
            "Iteration 1350 | Accuracy: 39.57142857142858 | Loss:1017.0993237548574\n",
            "##################################################\n",
            ">epoch=49, lrate=0.100, error=1052.996\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.64285714285714 | Loss:0.9915280983127853\n",
            "Iteration 50 | Accuracy: 42.92857142857143 | Loss:39.95746574027437\n",
            "Iteration 100 | Accuracy: 43.142857142857146 | Loss:78.50294444273563\n",
            "Iteration 150 | Accuracy: 40.285714285714285 | Loss:115.97560644740693\n",
            "Iteration 200 | Accuracy: 42.142857142857146 | Loss:150.51027597036446\n",
            "Iteration 250 | Accuracy: 43.42857142857143 | Loss:187.50782012779183\n",
            "Iteration 300 | Accuracy: 43.142857142857146 | Loss:223.77971171386034\n",
            "Iteration 350 | Accuracy: 39.285714285714285 | Loss:260.5539608966089\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:296.750119092378\n",
            "Iteration 450 | Accuracy: 40.14285714285714 | Loss:333.0432470604687\n",
            "Iteration 500 | Accuracy: 40.14285714285714 | Loss:371.14801616265873\n",
            "Iteration 550 | Accuracy: 40.57142857142857 | Loss:408.8881370701077\n",
            "Iteration 600 | Accuracy: 44.07142857142857 | Loss:442.7214932025026\n",
            "Iteration 650 | Accuracy: 40.0 | Loss:476.20993450036224\n",
            "Iteration 700 | Accuracy: 39.92857142857143 | Loss:513.6878591926185\n",
            "Iteration 750 | Accuracy: 39.57142857142858 | Loss:549.0358673715576\n",
            "Iteration 800 | Accuracy: 40.0 | Loss:583.8182773229978\n",
            "Iteration 850 | Accuracy: 41.214285714285715 | Loss:622.2983792913286\n",
            "Iteration 900 | Accuracy: 38.857142857142854 | Loss:655.5880879011764\n",
            "Iteration 950 | Accuracy: 41.14285714285714 | Loss:688.9462257138949\n",
            "Iteration 1000 | Accuracy: 42.642857142857146 | Loss:724.3117180655352\n",
            "Iteration 1050 | Accuracy: 39.214285714285715 | Loss:754.7905484874447\n",
            "Iteration 1100 | Accuracy: 40.92857142857143 | Loss:790.6348685920404\n",
            "Iteration 1150 | Accuracy: 39.42857142857143 | Loss:826.8947069105722\n",
            "Iteration 1200 | Accuracy: 40.714285714285715 | Loss:863.9642153060308\n",
            "Iteration 1250 | Accuracy: 39.07142857142858 | Loss:900.836681413144\n",
            "Iteration 1300 | Accuracy: 39.57142857142858 | Loss:933.2518717766247\n",
            "Iteration 1350 | Accuracy: 39.85714285714286 | Loss:968.3894209954652\n",
            "##################################################\n",
            ">epoch=50, lrate=0.100, error=1002.699\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.92857142857143 | Loss:1.0103402138091797\n",
            "Iteration 50 | Accuracy: 43.42857142857143 | Loss:38.749624197452235\n",
            "Iteration 100 | Accuracy: 43.714285714285715 | Loss:75.93961411362295\n",
            "Iteration 150 | Accuracy: 41.714285714285715 | Loss:111.9365515541249\n",
            "Iteration 200 | Accuracy: 41.85714285714286 | Loss:144.65003885549456\n",
            "Iteration 250 | Accuracy: 43.57142857142857 | Loss:180.20822549800323\n",
            "Iteration 300 | Accuracy: 43.214285714285715 | Loss:214.91742050575985\n",
            "Iteration 350 | Accuracy: 39.42857142857143 | Loss:250.25247573706568\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:284.8630131549927\n",
            "Iteration 450 | Accuracy: 41.35714285714286 | Loss:319.9843764058668\n",
            "Iteration 500 | Accuracy: 41.5 | Loss:356.9524932501777\n",
            "Iteration 550 | Accuracy: 41.785714285714285 | Loss:393.62855196302104\n",
            "Iteration 600 | Accuracy: 44.07142857142857 | Loss:425.77869546204477\n",
            "Iteration 650 | Accuracy: 41.14285714285714 | Loss:457.6930447394858\n",
            "Iteration 700 | Accuracy: 41.214285714285715 | Loss:493.8510774359571\n",
            "Iteration 750 | Accuracy: 40.64285714285714 | Loss:527.8849585752747\n",
            "Iteration 800 | Accuracy: 40.14285714285714 | Loss:561.3083271604155\n",
            "Iteration 850 | Accuracy: 42.57142857142857 | Loss:598.5939513518756\n",
            "Iteration 900 | Accuracy: 38.857142857142854 | Loss:630.2446337567004\n",
            "Iteration 950 | Accuracy: 41.85714285714286 | Loss:662.5525259063771\n",
            "Iteration 1000 | Accuracy: 42.785714285714285 | Loss:696.7711266044863\n",
            "Iteration 1050 | Accuracy: 39.214285714285715 | Loss:725.5482994770792\n",
            "Iteration 1100 | Accuracy: 41.642857142857146 | Loss:760.3304159481247\n",
            "Iteration 1150 | Accuracy: 40.214285714285715 | Loss:795.311605494827\n",
            "Iteration 1200 | Accuracy: 40.92857142857143 | Loss:831.4428798517636\n",
            "Iteration 1250 | Accuracy: 40.785714285714285 | Loss:866.9574217444823\n",
            "Iteration 1300 | Accuracy: 39.785714285714285 | Loss:897.8611955632639\n",
            "Iteration 1350 | Accuracy: 40.714285714285715 | Loss:931.8285252898373\n",
            "##################################################\n",
            ">epoch=51, lrate=0.100, error=964.956\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 42.42857142857142 | Loss:1.0234374952315328\n",
            "Iteration 50 | Accuracy: 45.92857142857143 | Loss:37.84730836939063\n",
            "Iteration 100 | Accuracy: 47.42857142857143 | Loss:73.99968809425918\n",
            "Iteration 150 | Accuracy: 42.0 | Loss:108.88989590454479\n",
            "Iteration 200 | Accuracy: 41.714285714285715 | Loss:140.25586174419178\n",
            "Iteration 250 | Accuracy: 43.714285714285715 | Loss:174.74062049255514\n",
            "Iteration 300 | Accuracy: 46.285714285714285 | Loss:208.30569568239707\n",
            "Iteration 350 | Accuracy: 40.07142857142857 | Loss:242.53761139980966\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:276.03632183931734\n",
            "Iteration 450 | Accuracy: 42.0 | Loss:310.31535248762486\n",
            "Iteration 500 | Accuracy: 41.92857142857142 | Loss:346.4225339054717\n",
            "Iteration 550 | Accuracy: 47.214285714285715 | Loss:382.36806155000403\n",
            "Iteration 600 | Accuracy: 44.21428571428571 | Loss:413.2794943739554\n",
            "Iteration 650 | Accuracy: 41.785714285714285 | Loss:444.09989575192475\n",
            "Iteration 700 | Accuracy: 41.785714285714285 | Loss:479.25070024817495\n",
            "Iteration 750 | Accuracy: 41.714285714285715 | Loss:512.3721462169113\n",
            "Iteration 800 | Accuracy: 40.85714285714286 | Loss:544.8359486525297\n",
            "Iteration 850 | Accuracy: 44.21428571428571 | Loss:581.2115006917667\n",
            "Iteration 900 | Accuracy: 42.214285714285715 | Loss:611.688644298916\n",
            "Iteration 950 | Accuracy: 42.285714285714285 | Loss:643.2726401633136\n",
            "Iteration 1000 | Accuracy: 43.0 | Loss:676.6768348760436\n",
            "Iteration 1050 | Accuracy: 39.85714285714286 | Loss:704.234623852125\n",
            "Iteration 1100 | Accuracy: 42.642857142857146 | Loss:738.286826976301\n",
            "Iteration 1150 | Accuracy: 39.285714285714285 | Loss:772.3300379728827\n",
            "Iteration 1200 | Accuracy: 43.0 | Loss:807.7787466295048\n",
            "Iteration 1250 | Accuracy: 42.42857142857142 | Loss:842.2431923986271\n",
            "Iteration 1300 | Accuracy: 40.214285714285715 | Loss:872.0802213518301\n",
            "Iteration 1350 | Accuracy: 46.14285714285714 | Loss:905.1991775054755\n",
            "##################################################\n",
            ">epoch=52, lrate=0.100, error=937.462\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 46.785714285714285 | Loss:1.0322032462064035\n",
            "Iteration 50 | Accuracy: 49.714285714285715 | Loss:37.17929355605468\n",
            "Iteration 100 | Accuracy: 49.785714285714285 | Loss:72.5564643945795\n",
            "Iteration 150 | Accuracy: 42.642857142857146 | Loss:106.63428268163095\n",
            "Iteration 200 | Accuracy: 42.42857142857142 | Loss:137.01408774469766\n",
            "Iteration 250 | Accuracy: 43.857142857142854 | Loss:170.69533701883836\n",
            "Iteration 300 | Accuracy: 48.714285714285715 | Loss:203.4342222360119\n",
            "Iteration 350 | Accuracy: 43.28571428571429 | Loss:236.8578854292899\n",
            "Iteration 400 | Accuracy: 40.64285714285714 | Loss:269.5848214508732\n",
            "Iteration 450 | Accuracy: 42.142857142857146 | Loss:303.2554021880896\n",
            "Iteration 500 | Accuracy: 42.642857142857146 | Loss:338.7042210379701\n",
            "Iteration 550 | Accuracy: 50.28571428571429 | Loss:374.1382909975226\n",
            "Iteration 600 | Accuracy: 44.642857142857146 | Loss:404.13882782551025\n",
            "Iteration 650 | Accuracy: 42.07142857142857 | Loss:434.20307367577465\n",
            "Iteration 700 | Accuracy: 42.285714285714285 | Loss:468.60582071257267\n",
            "Iteration 750 | Accuracy: 41.642857142857146 | Loss:501.0814763888517\n",
            "Iteration 800 | Accuracy: 41.85714285714286 | Loss:532.8604412432941\n",
            "Iteration 850 | Accuracy: 44.92857142857143 | Loss:568.5513528411199\n",
            "Iteration 900 | Accuracy: 44.5 | Loss:598.189454886437\n",
            "Iteration 950 | Accuracy: 42.714285714285715 | Loss:629.2518823637848\n",
            "Iteration 1000 | Accuracy: 43.57142857142857 | Loss:662.0620204212403\n",
            "Iteration 1050 | Accuracy: 40.85714285714286 | Loss:688.741510657458\n",
            "Iteration 1100 | Accuracy: 43.214285714285715 | Loss:722.2803326686089\n",
            "Iteration 1150 | Accuracy: 40.14285714285714 | Loss:755.6319006720291\n",
            "Iteration 1200 | Accuracy: 46.5 | Loss:790.5838131155667\n",
            "Iteration 1250 | Accuracy: 43.857142857142854 | Loss:824.2584174273258\n",
            "Iteration 1300 | Accuracy: 41.642857142857146 | Loss:853.3306222638915\n",
            "Iteration 1350 | Accuracy: 48.642857142857146 | Loss:885.8177292315615\n",
            "##################################################\n",
            ">epoch=53, lrate=0.100, error=917.449\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 48.214285714285715 | Loss:1.0384137905373958\n",
            "Iteration 50 | Accuracy: 51.57142857142857 | Loss:36.67840411282978\n",
            "Iteration 100 | Accuracy: 50.78571428571429 | Loss:71.47563096322288\n",
            "Iteration 150 | Accuracy: 45.5 | Loss:104.95266372282647\n",
            "Iteration 200 | Accuracy: 45.357142857142854 | Loss:134.60202164973768\n",
            "Iteration 250 | Accuracy: 44.785714285714285 | Loss:167.66361048079236\n",
            "Iteration 300 | Accuracy: 50.21428571428571 | Loss:199.7956555645743\n",
            "Iteration 350 | Accuracy: 45.92857142857143 | Loss:232.63103281305666\n",
            "Iteration 400 | Accuracy: 43.785714285714285 | Loss:264.8142569081928\n",
            "Iteration 450 | Accuracy: 44.857142857142854 | Loss:298.0363332616307\n",
            "Iteration 500 | Accuracy: 45.64285714285714 | Loss:332.973621031452\n",
            "Iteration 550 | Accuracy: 51.857142857142854 | Loss:368.033918929481\n",
            "Iteration 600 | Accuracy: 45.07142857142858 | Loss:397.3542736597991\n",
            "Iteration 650 | Accuracy: 42.92857142857143 | Loss:426.88515661981796\n",
            "Iteration 700 | Accuracy: 44.642857142857146 | Loss:460.73359381212975\n",
            "Iteration 750 | Accuracy: 41.714285714285715 | Loss:492.73790016662787\n",
            "Iteration 800 | Accuracy: 42.714285714285715 | Loss:524.0149378276352\n",
            "Iteration 850 | Accuracy: 47.35714285714286 | Loss:559.1864265695901\n",
            "Iteration 900 | Accuracy: 46.42857142857143 | Loss:588.2113861960491\n",
            "Iteration 950 | Accuracy: 43.142857142857146 | Loss:618.881495762857\n",
            "Iteration 1000 | Accuracy: 43.857142857142854 | Loss:651.239912745161\n",
            "Iteration 1050 | Accuracy: 41.85714285714286 | Loss:677.2737256746442\n",
            "Iteration 1100 | Accuracy: 43.42857142857143 | Loss:710.4358674618034\n",
            "Iteration 1150 | Accuracy: 42.714285714285715 | Loss:743.2666129303185\n",
            "Iteration 1200 | Accuracy: 47.85714285714286 | Loss:777.8480945891757\n",
            "Iteration 1250 | Accuracy: 44.42857142857143 | Loss:810.9261479339453\n",
            "Iteration 1300 | Accuracy: 43.92857142857143 | Loss:839.4353070885938\n",
            "Iteration 1350 | Accuracy: 50.21428571428571 | Loss:871.4331526974645\n",
            "##################################################\n",
            ">epoch=54, lrate=0.100, error=902.594\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 49.214285714285715 | Loss:1.0433755379491427\n",
            "Iteration 50 | Accuracy: 53.214285714285715 | Loss:36.290339037369975\n",
            "Iteration 100 | Accuracy: 51.714285714285715 | Loss:70.64396596433627\n",
            "Iteration 150 | Accuracy: 47.14285714285714 | Loss:103.66535185191567\n",
            "Iteration 200 | Accuracy: 47.14285714285714 | Loss:132.7578492208629\n",
            "Iteration 250 | Accuracy: 46.64285714285714 | Loss:165.32348049157383\n",
            "Iteration 300 | Accuracy: 50.92857142857142 | Loss:196.99225463795352\n",
            "Iteration 350 | Accuracy: 47.42857142857143 | Loss:229.38796807544466\n",
            "Iteration 400 | Accuracy: 45.357142857142854 | Loss:261.1743511324345\n",
            "Iteration 450 | Accuracy: 47.0 | Loss:294.05387543238317\n",
            "Iteration 500 | Accuracy: 47.214285714285715 | Loss:328.5851025543832\n",
            "Iteration 550 | Accuracy: 53.0 | Loss:363.3563881070406\n",
            "Iteration 600 | Accuracy: 45.857142857142854 | Loss:392.15716050984076\n",
            "Iteration 650 | Accuracy: 44.285714285714285 | Loss:421.2975384419265\n",
            "Iteration 700 | Accuracy: 45.92857142857143 | Loss:454.72748256462506\n",
            "Iteration 750 | Accuracy: 42.07142857142857 | Loss:486.37468515939923\n",
            "Iteration 800 | Accuracy: 44.21428571428571 | Loss:517.2703480942256\n",
            "Iteration 850 | Accuracy: 49.642857142857146 | Loss:552.0372833117622\n",
            "Iteration 900 | Accuracy: 47.85714285714286 | Loss:580.5949553425171\n",
            "Iteration 950 | Accuracy: 43.57142857142857 | Loss:610.9567548082289\n",
            "Iteration 1000 | Accuracy: 44.285714285714285 | Loss:642.9561598793676\n",
            "Iteration 1050 | Accuracy: 42.35714285714286 | Loss:668.5009685054674\n",
            "Iteration 1100 | Accuracy: 43.57142857142857 | Loss:701.3722652541359\n",
            "Iteration 1150 | Accuracy: 43.714285714285715 | Loss:733.7982884818108\n",
            "Iteration 1200 | Accuracy: 49.785714285714285 | Loss:768.0921526339399\n",
            "Iteration 1250 | Accuracy: 44.785714285714285 | Loss:800.707638552943\n",
            "Iteration 1300 | Accuracy: 45.57142857142858 | Loss:828.7883976127886\n",
            "Iteration 1350 | Accuracy: 51.5 | Loss:860.3898105817535\n",
            "##################################################\n",
            ">epoch=55, lrate=0.100, error=891.188\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 49.642857142857146 | Loss:1.0477682694753463\n",
            "Iteration 50 | Accuracy: 54.214285714285715 | Loss:35.97552543097599\n",
            "Iteration 100 | Accuracy: 52.28571428571429 | Loss:69.97720926818532\n",
            "Iteration 150 | Accuracy: 48.214285714285715 | Loss:102.64056968002294\n",
            "Iteration 200 | Accuracy: 49.28571428571429 | Loss:131.29173720065063\n",
            "Iteration 250 | Accuracy: 48.07142857142857 | Loss:163.44549856605434\n",
            "Iteration 300 | Accuracy: 51.42857142857142 | Loss:194.74219790266866\n",
            "Iteration 350 | Accuracy: 48.0 | Loss:226.79284636288045\n",
            "Iteration 400 | Accuracy: 47.07142857142857 | Loss:258.27505919931036\n",
            "Iteration 450 | Accuracy: 48.35714285714286 | Loss:290.88017095623104\n",
            "Iteration 500 | Accuracy: 48.285714285714285 | Loss:325.0800950068373\n",
            "Iteration 550 | Accuracy: 54.0 | Loss:359.61395990374774\n",
            "Iteration 600 | Accuracy: 46.714285714285715 | Loss:388.00704586999194\n",
            "Iteration 650 | Accuracy: 46.07142857142857 | Loss:416.84758742453704\n",
            "Iteration 700 | Accuracy: 48.214285714285715 | Loss:449.95069351572846\n",
            "Iteration 750 | Accuracy: 44.285714285714285 | Loss:481.31614585727414\n",
            "Iteration 800 | Accuracy: 45.92857142857143 | Loss:511.9100642691658\n",
            "Iteration 850 | Accuracy: 50.28571428571429 | Loss:546.3497772481488\n",
            "Iteration 900 | Accuracy: 48.57142857142857 | Loss:574.531773273971\n",
            "Iteration 950 | Accuracy: 44.42857142857143 | Loss:604.640109387086\n",
            "Iteration 1000 | Accuracy: 44.357142857142854 | Loss:636.3417618414142\n",
            "Iteration 1050 | Accuracy: 42.785714285714285 | Loss:661.5029692123072\n",
            "Iteration 1100 | Accuracy: 43.92857142857143 | Loss:694.1376003471581\n",
            "Iteration 1150 | Accuracy: 45.42857142857143 | Loss:726.2373340204045\n",
            "Iteration 1200 | Accuracy: 51.07142857142857 | Loss:760.2967690430961\n",
            "Iteration 1250 | Accuracy: 44.92857142857143 | Loss:792.5400785380378\n",
            "Iteration 1300 | Accuracy: 46.785714285714285 | Loss:820.2829205320028\n",
            "Iteration 1350 | Accuracy: 52.642857142857146 | Loss:851.5479097170663\n",
            "##################################################\n",
            ">epoch=56, lrate=0.100, error=882.057\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 50.42857142857143 | Loss:1.051906878564522\n",
            "Iteration 50 | Accuracy: 55.42857142857143 | Loss:35.70711585792435\n",
            "Iteration 100 | Accuracy: 53.0 | Loss:69.41726672808862\n",
            "Iteration 150 | Accuracy: 49.214285714285715 | Loss:101.78815483315434\n",
            "Iteration 200 | Accuracy: 50.0 | Loss:130.07448317861892\n",
            "Iteration 250 | Accuracy: 48.92857142857142 | Loss:161.87452360037602\n",
            "Iteration 300 | Accuracy: 52.0 | Loss:192.8561148666238\n",
            "Iteration 350 | Accuracy: 48.857142857142854 | Loss:224.62010838804093\n",
            "Iteration 400 | Accuracy: 47.57142857142857 | Loss:255.8559064576742\n",
            "Iteration 450 | Accuracy: 49.57142857142857 | Loss:288.2295264461452\n",
            "Iteration 500 | Accuracy: 49.5 | Loss:322.15037821967877\n",
            "Iteration 550 | Accuracy: 54.42857142857142 | Loss:356.47786497268504\n",
            "Iteration 600 | Accuracy: 48.07142857142857 | Loss:384.54204040228075\n",
            "Iteration 650 | Accuracy: 47.42857142857143 | Loss:413.1403108406574\n",
            "Iteration 700 | Accuracy: 48.785714285714285 | Loss:445.97709190711225\n",
            "Iteration 750 | Accuracy: 45.857142857142854 | Loss:477.1108543014862\n",
            "Iteration 800 | Accuracy: 47.5 | Loss:507.45603562046944\n",
            "Iteration 850 | Accuracy: 51.28571428571429 | Loss:541.6195963287325\n",
            "Iteration 900 | Accuracy: 49.42857142857143 | Loss:569.4824090100989\n",
            "Iteration 950 | Accuracy: 46.0 | Loss:599.3730084145845\n",
            "Iteration 1000 | Accuracy: 44.714285714285715 | Loss:630.8178773760806\n",
            "Iteration 1050 | Accuracy: 43.142857142857146 | Loss:655.6668601469643\n",
            "Iteration 1100 | Accuracy: 44.285714285714285 | Loss:688.0993384944525\n",
            "Iteration 1150 | Accuracy: 47.07142857142857 | Loss:719.9258233328557\n",
            "Iteration 1200 | Accuracy: 53.0 | Loss:753.7846639080772\n",
            "Iteration 1250 | Accuracy: 45.285714285714285 | Loss:785.7165831666169\n",
            "Iteration 1300 | Accuracy: 48.142857142857146 | Loss:813.1831871411467\n",
            "Iteration 1350 | Accuracy: 52.78571428571428 | Loss:844.1502643626231\n",
            "##################################################\n",
            ">epoch=57, lrate=0.100, error=874.420\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 50.78571428571429 | Loss:1.055961271987922\n",
            "Iteration 50 | Accuracy: 55.85714285714286 | Loss:35.46763335238392\n",
            "Iteration 100 | Accuracy: 53.42857142857142 | Loss:68.92562588890972\n",
            "Iteration 150 | Accuracy: 49.92857142857143 | Loss:101.04855234335479\n",
            "Iteration 200 | Accuracy: 50.71428571428571 | Loss:129.02074958461827\n",
            "Iteration 250 | Accuracy: 50.0 | Loss:160.50808266006445\n",
            "Iteration 300 | Accuracy: 52.92857142857142 | Loss:191.20968017006797\n",
            "Iteration 350 | Accuracy: 49.0 | Loss:222.72275986690903\n",
            "Iteration 400 | Accuracy: 48.35714285714286 | Loss:253.7474237947977\n",
            "Iteration 450 | Accuracy: 50.21428571428571 | Loss:285.91636597147857\n",
            "Iteration 500 | Accuracy: 50.42857142857143 | Loss:319.5940868613223\n",
            "Iteration 550 | Accuracy: 54.785714285714285 | Loss:353.73355434317915\n",
            "Iteration 600 | Accuracy: 49.42857142857143 | Loss:381.5253196043795\n",
            "Iteration 650 | Accuracy: 48.5 | Loss:409.91807924223167\n",
            "Iteration 700 | Accuracy: 49.57142857142857 | Loss:442.52782938931153\n",
            "Iteration 750 | Accuracy: 47.07142857142857 | Loss:473.4633173142399\n",
            "Iteration 800 | Accuracy: 48.57142857142857 | Loss:503.59531125098016\n",
            "Iteration 850 | Accuracy: 52.142857142857146 | Loss:537.515800631182\n",
            "Iteration 900 | Accuracy: 50.21428571428571 | Loss:565.0935371050612\n",
            "Iteration 950 | Accuracy: 47.14285714285714 | Loss:594.7895309472176\n",
            "Iteration 1000 | Accuracy: 45.64285714285714 | Loss:626.0052596353514\n",
            "Iteration 1050 | Accuracy: 43.714285714285715 | Loss:650.5908564775643\n",
            "Iteration 1100 | Accuracy: 44.57142857142857 | Loss:682.8433461725135\n",
            "Iteration 1150 | Accuracy: 47.5 | Loss:714.4324992557715\n",
            "Iteration 1200 | Accuracy: 54.142857142857146 | Loss:748.1120867642401\n",
            "Iteration 1250 | Accuracy: 46.07142857142857 | Loss:779.7738070313935\n",
            "Iteration 1300 | Accuracy: 49.0 | Loss:807.0069987402081\n",
            "Iteration 1350 | Accuracy: 53.642857142857146 | Loss:837.7004687221988\n",
            "##################################################\n",
            ">epoch=58, lrate=0.100, error=867.763\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 51.42857142857142 | Loss:1.0600557541175535\n",
            "Iteration 50 | Accuracy: 55.85714285714286 | Loss:35.24577499598658\n",
            "Iteration 100 | Accuracy: 53.92857142857142 | Loss:68.4769379991772\n",
            "Iteration 150 | Accuracy: 50.642857142857146 | Loss:100.3826460077288\n",
            "Iteration 200 | Accuracy: 51.714285714285715 | Loss:128.07436991877847\n",
            "Iteration 250 | Accuracy: 50.78571428571429 | Loss:159.27839657581063\n",
            "Iteration 300 | Accuracy: 53.07142857142857 | Loss:189.72117099172678\n",
            "Iteration 350 | Accuracy: 49.5 | Loss:221.00520926371735\n",
            "Iteration 400 | Accuracy: 49.07142857142857 | Loss:251.83937759989058\n",
            "Iteration 450 | Accuracy: 51.42857142857142 | Loss:283.8203511171355\n",
            "Iteration 500 | Accuracy: 51.214285714285715 | Loss:317.2790319816175\n",
            "Iteration 550 | Accuracy: 55.214285714285715 | Loss:351.2409346630525\n",
            "Iteration 600 | Accuracy: 49.57142857142857 | Loss:378.8016469922232\n",
            "Iteration 650 | Accuracy: 49.214285714285715 | Loss:407.01246342153075\n",
            "Iteration 700 | Accuracy: 50.5 | Loss:439.4201357667693\n",
            "Iteration 750 | Accuracy: 48.214285714285715 | Loss:470.1796596311337\n",
            "Iteration 800 | Accuracy: 49.28571428571429 | Loss:500.12232337932784\n",
            "Iteration 850 | Accuracy: 53.07142857142857 | Loss:533.820419323799\n",
            "Iteration 900 | Accuracy: 50.71428571428571 | Loss:561.1328234863932\n",
            "Iteration 950 | Accuracy: 48.285714285714285 | Loss:590.6490055010029\n",
            "Iteration 1000 | Accuracy: 46.785714285714285 | Loss:621.6542888322366\n",
            "Iteration 1050 | Accuracy: 44.857142857142854 | Loss:646.0103053002018\n",
            "Iteration 1100 | Accuracy: 45.57142857142858 | Loss:678.0970244198201\n",
            "Iteration 1150 | Accuracy: 48.35714285714286 | Loss:709.4729790478464\n",
            "Iteration 1200 | Accuracy: 54.714285714285715 | Loss:742.9864689180727\n",
            "Iteration 1250 | Accuracy: 46.57142857142857 | Loss:774.406237467131\n",
            "Iteration 1300 | Accuracy: 50.357142857142854 | Loss:801.4362997672258\n",
            "Iteration 1350 | Accuracy: 53.92857142857142 | Loss:831.8707054822855\n",
            "##################################################\n",
            ">epoch=59, lrate=0.100, error=861.749\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 51.92857142857142 | Loss:1.0642923367851354\n",
            "Iteration 50 | Accuracy: 56.14285714285714 | Loss:35.033972306186755\n",
            "Iteration 100 | Accuracy: 54.214285714285715 | Loss:68.05415074122392\n",
            "Iteration 150 | Accuracy: 51.214285714285715 | Loss:99.76420186114503\n",
            "Iteration 200 | Accuracy: 52.35714285714286 | Loss:127.19769146046197\n",
            "Iteration 250 | Accuracy: 51.78571428571429 | Loss:158.13952042844983\n",
            "Iteration 300 | Accuracy: 53.35714285714286 | Loss:188.33557955433704\n",
            "Iteration 350 | Accuracy: 50.142857142857146 | Loss:219.40379685874214\n",
            "Iteration 400 | Accuracy: 49.857142857142854 | Loss:250.05845540227804\n",
            "Iteration 450 | Accuracy: 52.0 | Loss:281.86168942776595\n",
            "Iteration 500 | Accuracy: 51.642857142857146 | Loss:315.11652875543115\n",
            "Iteration 550 | Accuracy: 55.42857142857143 | Loss:348.9061364015379\n",
            "Iteration 600 | Accuracy: 50.642857142857146 | Loss:376.2664640631022\n",
            "Iteration 650 | Accuracy: 50.21428571428571 | Loss:404.3102781734059\n",
            "Iteration 700 | Accuracy: 51.5 | Loss:436.53106038029256\n",
            "Iteration 750 | Accuracy: 49.357142857142854 | Loss:467.12934687670304\n",
            "Iteration 800 | Accuracy: 49.714285714285715 | Loss:496.89839818557726\n",
            "Iteration 850 | Accuracy: 53.714285714285715 | Loss:530.3860463506606\n",
            "Iteration 900 | Accuracy: 51.0 | Loss:557.4433424115031\n",
            "Iteration 950 | Accuracy: 49.142857142857146 | Loss:586.7888903139246\n",
            "Iteration 1000 | Accuracy: 48.07142857142857 | Loss:617.5962022666617\n",
            "Iteration 1050 | Accuracy: 46.14285714285714 | Loss:641.7463222457673\n",
            "Iteration 1100 | Accuracy: 46.35714285714286 | Loss:673.6761288960939\n",
            "Iteration 1150 | Accuracy: 50.142857142857146 | Loss:704.8545233814071\n",
            "Iteration 1200 | Accuracy: 54.85714285714286 | Loss:738.2094933865696\n",
            "Iteration 1250 | Accuracy: 47.214285714285715 | Loss:769.4068880276618\n",
            "Iteration 1300 | Accuracy: 51.0 | Loss:796.2554981521554\n",
            "Iteration 1350 | Accuracy: 54.285714285714285 | Loss:826.4381000124436\n",
            "##################################################\n",
            ">epoch=60, lrate=0.100, error=856.147\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 52.714285714285715 | Loss:1.0687461977907464\n",
            "Iteration 50 | Accuracy: 56.49999999999999 | Loss:34.82678954369093\n",
            "Iteration 100 | Accuracy: 54.57142857142857 | Loss:67.6452562116683\n",
            "Iteration 150 | Accuracy: 51.92857142857142 | Loss:99.17487714019863\n",
            "Iteration 200 | Accuracy: 52.42857142857142 | Loss:126.36453991488452\n",
            "Iteration 250 | Accuracy: 52.5 | Loss:157.05891032859503\n",
            "Iteration 300 | Accuracy: 53.57142857142857 | Loss:187.01422506001083\n",
            "Iteration 350 | Accuracy: 51.0 | Loss:217.87413291259924\n",
            "Iteration 400 | Accuracy: 50.357142857142854 | Loss:248.35374607971568\n",
            "Iteration 450 | Accuracy: 52.28571428571429 | Loss:279.9850680699982\n",
            "Iteration 500 | Accuracy: 52.42857142857142 | Loss:313.04427593301716\n",
            "Iteration 550 | Accuracy: 55.92857142857143 | Loss:346.6630266478211\n",
            "Iteration 600 | Accuracy: 51.0 | Loss:373.84569589411024\n",
            "Iteration 650 | Accuracy: 50.642857142857146 | Loss:401.7314765065041\n",
            "Iteration 700 | Accuracy: 52.0 | Loss:433.7737509468207\n",
            "Iteration 750 | Accuracy: 50.142857142857146 | Loss:464.22009885130507\n",
            "Iteration 800 | Accuracy: 50.357142857142854 | Loss:493.8251999354607\n",
            "Iteration 850 | Accuracy: 53.78571428571428 | Loss:527.1079638535163\n",
            "Iteration 900 | Accuracy: 51.28571428571429 | Loss:553.9135905764343\n",
            "Iteration 950 | Accuracy: 49.857142857142854 | Loss:583.0937218517732\n",
            "Iteration 1000 | Accuracy: 48.857142857142854 | Loss:613.7109997226404\n",
            "Iteration 1050 | Accuracy: 47.14285714285714 | Loss:637.6720189883421\n",
            "Iteration 1100 | Accuracy: 47.214285714285715 | Loss:669.449868333793\n",
            "Iteration 1150 | Accuracy: 51.28571428571429 | Loss:700.4396762294579\n",
            "Iteration 1200 | Accuracy: 55.14285714285714 | Loss:733.6396621904721\n",
            "Iteration 1250 | Accuracy: 48.35714285714286 | Loss:764.6281642038423\n",
            "Iteration 1300 | Accuracy: 51.28571428571429 | Loss:791.3107842951059\n",
            "Iteration 1350 | Accuracy: 54.714285714285715 | Loss:821.2427049210336\n",
            "##################################################\n",
            ">epoch=61, lrate=0.100, error=850.791\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.214285714285715 | Loss:1.0734635067580571\n",
            "Iteration 50 | Accuracy: 56.57142857142857 | Loss:34.619957491544525\n",
            "Iteration 100 | Accuracy: 55.14285714285714 | Loss:67.24121050135213\n",
            "Iteration 150 | Accuracy: 52.35714285714286 | Loss:98.60106052371495\n",
            "Iteration 200 | Accuracy: 52.5 | Loss:125.55572267097888\n",
            "Iteration 250 | Accuracy: 53.142857142857146 | Loss:156.01207554798503\n",
            "Iteration 300 | Accuracy: 53.78571428571428 | Loss:185.72812317994007\n",
            "Iteration 350 | Accuracy: 51.5 | Loss:216.38316524788817\n",
            "Iteration 400 | Accuracy: 50.92857142857142 | Loss:246.68746870750732\n",
            "Iteration 450 | Accuracy: 52.85714285714286 | Loss:278.1494905232647\n",
            "Iteration 500 | Accuracy: 52.78571428571428 | Loss:311.0154578542129\n",
            "Iteration 550 | Accuracy: 56.07142857142857 | Loss:344.4613924594303\n",
            "Iteration 600 | Accuracy: 51.714285714285715 | Loss:371.4829900004405\n",
            "Iteration 650 | Accuracy: 51.0 | Loss:399.2151970287808\n",
            "Iteration 700 | Accuracy: 52.57142857142857 | Loss:431.0823348887576\n",
            "Iteration 750 | Accuracy: 51.714285714285715 | Loss:461.3818161263631\n",
            "Iteration 800 | Accuracy: 51.714285714285715 | Loss:490.82761565718124\n",
            "Iteration 850 | Accuracy: 54.285714285714285 | Loss:523.9060187586246\n",
            "Iteration 900 | Accuracy: 52.0 | Loss:550.4579396725884\n",
            "Iteration 950 | Accuracy: 50.71428571428571 | Loss:579.4748163422962\n",
            "Iteration 1000 | Accuracy: 49.5 | Loss:609.9064806848685\n",
            "Iteration 1050 | Accuracy: 48.0 | Loss:633.690388541868\n",
            "Iteration 1100 | Accuracy: 48.0 | Loss:665.3180851235155\n",
            "Iteration 1150 | Accuracy: 52.28571428571429 | Loss:696.1223460880772\n",
            "Iteration 1200 | Accuracy: 55.85714285714286 | Loss:729.1676735789191\n",
            "Iteration 1250 | Accuracy: 48.642857142857146 | Loss:759.9559156728101\n",
            "Iteration 1300 | Accuracy: 51.5 | Loss:786.4831413606474\n",
            "Iteration 1350 | Accuracy: 55.00000000000001 | Loss:816.1595727001499\n",
            "##################################################\n",
            ">epoch=62, lrate=0.100, error=845.551\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.57142857142857 | Loss:1.0784736851343195\n",
            "Iteration 50 | Accuracy: 56.714285714285715 | Loss:34.40974859697765\n",
            "Iteration 100 | Accuracy: 55.214285714285715 | Loss:66.83450248484948\n",
            "Iteration 150 | Accuracy: 53.214285714285715 | Loss:98.03172402630608\n",
            "Iteration 200 | Accuracy: 52.714285714285715 | Loss:124.75601336239619\n",
            "Iteration 250 | Accuracy: 53.85714285714286 | Loss:154.97897632748118\n",
            "Iteration 300 | Accuracy: 54.214285714285715 | Loss:184.45345858169986\n",
            "Iteration 350 | Accuracy: 51.92857142857142 | Loss:214.90388482057438\n",
            "Iteration 400 | Accuracy: 51.5 | Loss:245.02867914101316\n",
            "Iteration 450 | Accuracy: 53.214285714285715 | Loss:276.3214456150049\n",
            "Iteration 500 | Accuracy: 53.35714285714286 | Loss:308.9913345955265\n",
            "Iteration 550 | Accuracy: 55.92857142857143 | Loss:342.258831316505\n",
            "Iteration 600 | Accuracy: 52.214285714285715 | Loss:369.1311551666685\n",
            "Iteration 650 | Accuracy: 51.714285714285715 | Loss:396.7104249369051\n",
            "Iteration 700 | Accuracy: 52.85714285714286 | Loss:428.4016530904523\n",
            "Iteration 750 | Accuracy: 52.28571428571429 | Loss:458.555618002373\n",
            "Iteration 800 | Accuracy: 52.714285714285715 | Loss:487.84197113071633\n",
            "Iteration 850 | Accuracy: 55.14285714285714 | Loss:520.7119662990651\n",
            "Iteration 900 | Accuracy: 52.5 | Loss:547.0029997973367\n",
            "Iteration 950 | Accuracy: 51.42857142857142 | Loss:575.8560995338817\n",
            "Iteration 1000 | Accuracy: 50.71428571428571 | Loss:606.1035918242077\n",
            "Iteration 1050 | Accuracy: 48.42857142857142 | Loss:629.7187332786059\n",
            "Iteration 1100 | Accuracy: 48.5 | Loss:661.1952377896494\n",
            "Iteration 1150 | Accuracy: 52.85714285714286 | Loss:691.8109464078066\n",
            "Iteration 1200 | Accuracy: 56.785714285714285 | Loss:724.6990359187515\n",
            "Iteration 1250 | Accuracy: 49.42857142857143 | Loss:755.2909449293252\n",
            "Iteration 1300 | Accuracy: 51.642857142857146 | Loss:781.6691200370564\n",
            "Iteration 1350 | Accuracy: 55.35714285714286 | Loss:811.078871720289\n",
            "##################################################\n",
            ">epoch=63, lrate=0.100, error=840.314\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.92857142857142 | Loss:1.0838161017978123\n",
            "Iteration 50 | Accuracy: 57.07142857142857 | Loss:34.19250070514256\n",
            "Iteration 100 | Accuracy: 55.42857142857143 | Loss:66.41805474596718\n",
            "Iteration 150 | Accuracy: 53.5 | Loss:97.45675318384541\n",
            "Iteration 200 | Accuracy: 53.642857142857146 | Loss:123.95192132175552\n",
            "Iteration 250 | Accuracy: 54.50000000000001 | Loss:153.9412837399523\n",
            "Iteration 300 | Accuracy: 54.64285714285714 | Loss:183.16810420918378\n",
            "Iteration 350 | Accuracy: 52.214285714285715 | Loss:213.41130237308525\n",
            "Iteration 400 | Accuracy: 52.142857142857146 | Loss:243.3485659617821\n",
            "Iteration 450 | Accuracy: 53.5 | Loss:274.4697550140776\n",
            "Iteration 500 | Accuracy: 53.78571428571428 | Loss:306.93562998880094\n",
            "Iteration 550 | Accuracy: 56.35714285714286 | Loss:340.0145850630281\n",
            "Iteration 600 | Accuracy: 52.85714285714286 | Loss:366.7457746332957\n",
            "Iteration 650 | Accuracy: 52.642857142857146 | Loss:394.16906681621583\n",
            "Iteration 700 | Accuracy: 53.142857142857146 | Loss:425.67955744443964\n",
            "Iteration 750 | Accuracy: 53.57142857142857 | Loss:455.6856413198381\n",
            "Iteration 800 | Accuracy: 53.78571428571428 | Loss:484.8071752391379\n",
            "Iteration 850 | Accuracy: 55.714285714285715 | Loss:517.4599208691808\n",
            "Iteration 900 | Accuracy: 52.85714285714286 | Loss:543.4774983487113\n",
            "Iteration 950 | Accuracy: 52.78571428571428 | Loss:572.1636193922399\n",
            "Iteration 1000 | Accuracy: 51.28571428571429 | Loss:602.225497962285\n",
            "Iteration 1050 | Accuracy: 49.57142857142857 | Loss:625.6768237865716\n",
            "Iteration 1100 | Accuracy: 49.57142857142857 | Loss:656.9983166891739\n",
            "Iteration 1150 | Accuracy: 53.35714285714286 | Loss:687.4158493714576\n",
            "Iteration 1200 | Accuracy: 57.285714285714285 | Loss:720.1411276950587\n",
            "Iteration 1250 | Accuracy: 49.857142857142854 | Loss:750.5352658267502\n",
            "Iteration 1300 | Accuracy: 52.0 | Loss:776.7665738891945\n",
            "Iteration 1350 | Accuracy: 55.64285714285714 | Loss:805.8914213209528\n",
            "##################################################\n",
            ">epoch=64, lrate=0.100, error=834.965\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 54.35714285714286 | Loss:1.0895710944135348\n",
            "Iteration 50 | Accuracy: 57.49999999999999 | Loss:33.96434461445791\n",
            "Iteration 100 | Accuracy: 55.785714285714285 | Loss:65.98455092005867\n",
            "Iteration 150 | Accuracy: 53.714285714285715 | Loss:96.86575696858499\n",
            "Iteration 200 | Accuracy: 53.92857142857142 | Loss:123.130119928318\n",
            "Iteration 250 | Accuracy: 54.64285714285714 | Loss:152.88042376904374\n",
            "Iteration 300 | Accuracy: 54.85714285714286 | Loss:181.84917045250307\n",
            "Iteration 350 | Accuracy: 53.0 | Loss:211.87961170879848\n",
            "Iteration 400 | Accuracy: 52.5 | Loss:241.61734733702656\n",
            "Iteration 450 | Accuracy: 53.57142857142857 | Loss:272.56200086966516\n",
            "Iteration 500 | Accuracy: 54.285714285714285 | Loss:304.8108130418399\n",
            "Iteration 550 | Accuracy: 56.64285714285714 | Loss:337.6856942291387\n",
            "Iteration 600 | Accuracy: 53.35714285714286 | Loss:364.28105970268\n",
            "Iteration 650 | Accuracy: 53.0 | Loss:391.5414529173614\n",
            "Iteration 700 | Accuracy: 53.214285714285715 | Loss:422.86192234991955\n",
            "Iteration 750 | Accuracy: 54.142857142857146 | Loss:452.71380072735053\n",
            "Iteration 800 | Accuracy: 54.85714285714286 | Loss:481.6591572403979\n",
            "Iteration 850 | Accuracy: 56.285714285714285 | Loss:514.0806402378638\n",
            "Iteration 900 | Accuracy: 53.142857142857146 | Loss:539.806533036197\n",
            "Iteration 950 | Accuracy: 53.714285714285715 | Loss:568.3195116165185\n",
            "Iteration 1000 | Accuracy: 52.35714285714286 | Loss:598.1911087521479\n",
            "Iteration 1050 | Accuracy: 50.142857142857146 | Loss:621.4794229946008\n",
            "Iteration 1100 | Accuracy: 50.28571428571429 | Loss:652.6393219139546\n",
            "Iteration 1150 | Accuracy: 53.642857142857146 | Loss:682.8420259492201\n",
            "Iteration 1200 | Accuracy: 57.785714285714285 | Loss:715.3957035871734\n",
            "Iteration 1250 | Accuracy: 49.92857142857143 | Loss:745.5845262375658\n",
            "Iteration 1300 | Accuracy: 52.142857142857146 | Loss:771.666640685039\n",
            "Iteration 1350 | Accuracy: 56.00000000000001 | Loss:800.481256204731\n",
            "##################################################\n",
            ">epoch=65, lrate=0.100, error=829.383\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 54.92857142857142 | Loss:1.0958662386701779\n",
            "Iteration 50 | Accuracy: 57.64285714285714 | Loss:33.72136619998432\n",
            "Iteration 100 | Accuracy: 56.00000000000001 | Loss:65.52654329890787\n",
            "Iteration 150 | Accuracy: 54.285714285714285 | Loss:96.24776900202194\n",
            "Iteration 200 | Accuracy: 54.57142857142857 | Loss:122.27674010822035\n",
            "Iteration 250 | Accuracy: 55.214285714285715 | Loss:151.77685139697468\n",
            "Iteration 300 | Accuracy: 55.285714285714285 | Loss:180.4722418358194\n",
            "Iteration 350 | Accuracy: 53.35714285714286 | Loss:210.28132317368681\n",
            "Iteration 400 | Accuracy: 53.28571428571428 | Loss:239.80353207004234\n",
            "Iteration 450 | Accuracy: 54.0 | Loss:270.5634236401191\n",
            "Iteration 500 | Accuracy: 54.214285714285715 | Loss:302.57735137644886\n",
            "Iteration 550 | Accuracy: 57.49999999999999 | Loss:335.22692638912224\n",
            "Iteration 600 | Accuracy: 53.714285714285715 | Loss:361.6890170704528\n",
            "Iteration 650 | Accuracy: 53.42857142857142 | Loss:388.7752321529268\n",
            "Iteration 700 | Accuracy: 53.78571428571428 | Loss:419.8915669713499\n",
            "Iteration 750 | Accuracy: 55.50000000000001 | Loss:449.57870485163124\n",
            "Iteration 800 | Accuracy: 56.49999999999999 | Loss:478.32990174383826\n",
            "Iteration 850 | Accuracy: 56.714285714285715 | Loss:510.50119170328617\n",
            "Iteration 900 | Accuracy: 53.714285714285715 | Loss:535.9114658658684\n",
            "Iteration 950 | Accuracy: 54.64285714285714 | Loss:564.2413858834277\n",
            "Iteration 1000 | Accuracy: 53.714285714285715 | Loss:593.9140837097087\n",
            "Iteration 1050 | Accuracy: 50.857142857142854 | Loss:617.034404541999\n",
            "Iteration 1100 | Accuracy: 51.142857142857146 | Loss:648.0233104361943\n",
            "Iteration 1150 | Accuracy: 54.35714285714286 | Loss:677.9874896224776\n",
            "Iteration 1200 | Accuracy: 58.214285714285715 | Loss:710.3574405045555\n",
            "Iteration 1250 | Accuracy: 50.357142857142854 | Loss:740.3273807090027\n",
            "Iteration 1300 | Accuracy: 53.642857142857146 | Loss:766.2524084312869\n",
            "Iteration 1350 | Accuracy: 56.714285714285715 | Loss:794.7250684237542\n",
            "##################################################\n",
            ">epoch=66, lrate=0.100, error=823.439\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 55.214285714285715 | Loss:1.1028229029353889\n",
            "Iteration 50 | Accuracy: 57.785714285714285 | Loss:33.45996022269725\n",
            "Iteration 100 | Accuracy: 56.14285714285714 | Loss:65.03684484577566\n",
            "Iteration 150 | Accuracy: 54.57142857142857 | Loss:95.59146080013826\n",
            "Iteration 200 | Accuracy: 54.64285714285714 | Loss:121.37681057815057\n",
            "Iteration 250 | Accuracy: 55.285714285714285 | Loss:150.609672029552\n",
            "Iteration 300 | Accuracy: 55.64285714285714 | Loss:179.0111336183459\n",
            "Iteration 350 | Accuracy: 54.142857142857146 | Loss:208.58708762929717\n",
            "Iteration 400 | Accuracy: 54.07142857142857 | Loss:237.87361832830638\n",
            "Iteration 450 | Accuracy: 54.50000000000001 | Loss:268.4365264349684\n",
            "Iteration 500 | Accuracy: 54.85714285714286 | Loss:300.19357112067223\n",
            "Iteration 550 | Accuracy: 57.92857142857143 | Loss:332.5913851846809\n",
            "Iteration 600 | Accuracy: 53.85714285714286 | Loss:358.91887312243995\n",
            "Iteration 650 | Accuracy: 53.92857142857142 | Loss:385.8142651901405\n",
            "Iteration 700 | Accuracy: 54.214285714285715 | Loss:416.70731028329095\n",
            "Iteration 750 | Accuracy: 56.285714285714285 | Loss:446.2145856844512\n",
            "Iteration 800 | Accuracy: 57.35714285714286 | Loss:474.74633367063143\n",
            "Iteration 850 | Accuracy: 56.85714285714286 | Loss:506.64421184560064\n",
            "Iteration 900 | Accuracy: 54.142857142857146 | Loss:531.7085250379519\n",
            "Iteration 950 | Accuracy: 54.785714285714285 | Loss:559.8400165854559\n",
            "Iteration 1000 | Accuracy: 54.42857142857142 | Loss:589.300191286771\n",
            "Iteration 1050 | Accuracy: 51.92857142857142 | Loss:612.23979651376\n",
            "Iteration 1100 | Accuracy: 52.07142857142857 | Loss:643.0448896162142\n",
            "Iteration 1150 | Accuracy: 54.85714285714286 | Loss:672.7390569144954\n",
            "Iteration 1200 | Accuracy: 58.14285714285714 | Loss:704.9093596133785\n",
            "Iteration 1250 | Accuracy: 50.92857142857142 | Loss:734.6415369723263\n",
            "Iteration 1300 | Accuracy: 54.35714285714286 | Loss:760.3938594741558\n",
            "Iteration 1350 | Accuracy: 57.57142857142858 | Loss:788.4863685045182\n",
            "##################################################\n",
            ">epoch=67, lrate=0.100, error=816.990\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 55.42857142857143 | Loss:1.1104852732681576\n",
            "Iteration 50 | Accuracy: 57.99999999999999 | Loss:33.17633818957266\n",
            "Iteration 100 | Accuracy: 56.14285714285714 | Loss:64.50746141683364\n",
            "Iteration 150 | Accuracy: 55.00000000000001 | Loss:94.88400681726417\n",
            "Iteration 200 | Accuracy: 54.785714285714285 | Loss:120.41210317667952\n",
            "Iteration 250 | Accuracy: 55.714285714285715 | Loss:149.35397207406808\n",
            "Iteration 300 | Accuracy: 55.57142857142857 | Loss:177.43458397931838\n",
            "Iteration 350 | Accuracy: 55.07142857142857 | Loss:206.76204895334638\n",
            "Iteration 400 | Accuracy: 54.714285714285715 | Loss:235.78745337565732\n",
            "Iteration 450 | Accuracy: 55.00000000000001 | Loss:266.1363330219206\n",
            "Iteration 500 | Accuracy: 55.07142857142857 | Loss:297.6100089038756\n",
            "Iteration 550 | Accuracy: 58.5 | Loss:329.7240812124801\n",
            "Iteration 600 | Accuracy: 54.0 | Loss:355.9099090880165\n",
            "Iteration 650 | Accuracy: 54.785714285714285 | Loss:382.5906876082074\n",
            "Iteration 700 | Accuracy: 55.07142857142857 | Loss:413.23538170267267\n",
            "Iteration 750 | Accuracy: 56.42857142857143 | Loss:442.54213925248797\n",
            "Iteration 800 | Accuracy: 57.714285714285715 | Loss:470.82029437016047\n",
            "Iteration 850 | Accuracy: 57.42857142857143 | Loss:502.4166387271545\n",
            "Iteration 900 | Accuracy: 54.714285714285715 | Loss:527.0960721880822\n",
            "Iteration 950 | Accuracy: 54.92857142857142 | Loss:555.0060346388381\n",
            "Iteration 1000 | Accuracy: 55.00000000000001 | Loss:584.2335682808831\n",
            "Iteration 1050 | Accuracy: 53.85714285714286 | Loss:606.9702660530972\n",
            "Iteration 1100 | Accuracy: 53.57142857142857 | Loss:637.5738827145107\n",
            "Iteration 1150 | Accuracy: 55.35714285714286 | Loss:666.9563663015251\n",
            "Iteration 1200 | Accuracy: 58.785714285714285 | Loss:698.9055600563497\n",
            "Iteration 1250 | Accuracy: 52.0 | Loss:728.3758259071096\n",
            "Iteration 1300 | Accuracy: 56.285714285714285 | Loss:753.9292188800031\n",
            "Iteration 1350 | Accuracy: 57.92857142857143 | Loss:781.5949873251768\n",
            "##################################################\n",
            ">epoch=68, lrate=0.100, error=809.859\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 56.14285714285714 | Loss:1.118838245443174\n",
            "Iteration 50 | Accuracy: 58.07142857142858 | Loss:32.86522294544965\n",
            "Iteration 100 | Accuracy: 56.35714285714286 | Loss:63.927332392135405\n",
            "Iteration 150 | Accuracy: 55.42857142857143 | Loss:94.10855074784985\n",
            "Iteration 200 | Accuracy: 55.57142857142857 | Loss:119.35826297251353\n",
            "Iteration 250 | Accuracy: 56.07142857142857 | Loss:147.97671797421884\n",
            "Iteration 300 | Accuracy: 55.92857142857143 | Loss:175.70100905175659\n",
            "Iteration 350 | Accuracy: 55.714285714285715 | Loss:204.75994332627147\n",
            "Iteration 400 | Accuracy: 55.285714285714285 | Loss:233.49164232686408\n",
            "Iteration 450 | Accuracy: 55.285714285714285 | Loss:263.6032994801315\n",
            "Iteration 500 | Accuracy: 55.57142857142857 | Loss:294.7611766194097\n",
            "Iteration 550 | Accuracy: 58.785714285714285 | Loss:326.5523026358165\n",
            "Iteration 600 | Accuracy: 54.0 | Loss:352.58179767835077\n",
            "Iteration 650 | Accuracy: 55.57142857142857 | Loss:379.01508608123\n",
            "Iteration 700 | Accuracy: 55.35714285714286 | Loss:409.3786402132309\n",
            "Iteration 750 | Accuracy: 56.57142857142857 | Loss:438.45724732367773\n",
            "Iteration 800 | Accuracy: 58.785714285714285 | Loss:466.4367282745511\n",
            "Iteration 850 | Accuracy: 57.49999999999999 | Loss:497.69669920042224\n",
            "Iteration 900 | Accuracy: 54.85714285714286 | Loss:521.9419033445345\n",
            "Iteration 950 | Accuracy: 55.35714285714286 | Loss:549.5977261588962\n",
            "Iteration 1000 | Accuracy: 55.35714285714286 | Loss:578.5640202698223\n",
            "Iteration 1050 | Accuracy: 54.785714285714285 | Loss:601.0644403633119\n",
            "Iteration 1100 | Accuracy: 54.785714285714285 | Loss:631.4425076782298\n",
            "Iteration 1150 | Accuracy: 55.714285714285715 | Loss:660.4595278161324\n",
            "Iteration 1200 | Accuracy: 59.0 | Loss:692.1577113359536\n",
            "Iteration 1250 | Accuracy: 52.642857142857146 | Loss:721.3364152490999\n",
            "Iteration 1300 | Accuracy: 56.214285714285715 | Loss:746.6513845120178\n",
            "Iteration 1350 | Accuracy: 58.14285714285714 | Loss:773.8342230166518\n",
            "##################################################\n",
            ">epoch=69, lrate=0.100, error=801.823\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 56.714285714285715 | Loss:1.1278626636065945\n",
            "Iteration 50 | Accuracy: 58.285714285714285 | Loss:32.51967848098914\n",
            "Iteration 100 | Accuracy: 56.49999999999999 | Loss:63.28229969381463\n",
            "Iteration 150 | Accuracy: 56.14285714285714 | Loss:93.24396572274397\n",
            "Iteration 200 | Accuracy: 56.00000000000001 | Loss:118.18531194263488\n",
            "Iteration 250 | Accuracy: 56.35714285714286 | Loss:146.4370888822282\n",
            "Iteration 300 | Accuracy: 56.35714285714286 | Loss:173.75921824442295\n",
            "Iteration 350 | Accuracy: 56.285714285714285 | Loss:202.524086384593\n",
            "Iteration 400 | Accuracy: 55.85714285714286 | Loss:230.9218942904688\n",
            "Iteration 450 | Accuracy: 55.85714285714286 | Loss:260.76536813743917\n",
            "Iteration 500 | Accuracy: 56.64285714285714 | Loss:291.56875822196815\n",
            "Iteration 550 | Accuracy: 58.64285714285714 | Loss:322.9900221192042\n",
            "Iteration 600 | Accuracy: 54.785714285714285 | Loss:348.8387929872194\n",
            "Iteration 650 | Accuracy: 56.00000000000001 | Loss:374.981955991011\n",
            "Iteration 700 | Accuracy: 56.00000000000001 | Loss:405.0228549819649\n",
            "Iteration 750 | Accuracy: 56.99999999999999 | Loss:433.8378168521279\n",
            "Iteration 800 | Accuracy: 59.14285714285714 | Loss:461.46244353251325\n",
            "Iteration 850 | Accuracy: 57.85714285714286 | Loss:492.34451142661015\n",
            "Iteration 900 | Accuracy: 55.285714285714285 | Loss:516.0974721178458\n",
            "Iteration 950 | Accuracy: 55.714285714285715 | Loss:543.4568980709965\n",
            "Iteration 1000 | Accuracy: 56.00000000000001 | Loss:572.1232755736237\n",
            "Iteration 1050 | Accuracy: 55.85714285714286 | Loss:594.341346791012\n",
            "Iteration 1100 | Accuracy: 55.714285714285715 | Loss:624.4630379431642\n",
            "Iteration 1150 | Accuracy: 57.07142857142857 | Loss:653.0515574179459\n",
            "Iteration 1200 | Accuracy: 59.285714285714285 | Loss:684.4582280417359\n",
            "Iteration 1250 | Accuracy: 53.642857142857146 | Loss:713.3124521139807\n",
            "Iteration 1300 | Accuracy: 56.785714285714285 | Loss:738.3351714479683\n",
            "Iteration 1350 | Accuracy: 58.357142857142854 | Loss:764.9733672415674\n",
            "##################################################\n",
            ">epoch=70, lrate=0.100, error=792.643\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.42857142857143 | Loss:1.1374794774696435\n",
            "Iteration 50 | Accuracy: 58.357142857142854 | Loss:32.13360257246522\n",
            "Iteration 100 | Accuracy: 56.49999999999999 | Loss:62.55995831090837\n",
            "Iteration 150 | Accuracy: 56.64285714285714 | Loss:92.27084179108397\n",
            "Iteration 200 | Accuracy: 56.57142857142857 | Loss:116.86560890187883\n",
            "Iteration 250 | Accuracy: 56.49999999999999 | Loss:144.69737513692408\n",
            "Iteration 300 | Accuracy: 56.49999999999999 | Loss:171.5630494818215\n",
            "Iteration 350 | Accuracy: 56.785714285714285 | Loss:200.0040303342858\n",
            "Iteration 400 | Accuracy: 56.49999999999999 | Loss:228.0235561072838\n",
            "Iteration 450 | Accuracy: 56.64285714285714 | Loss:257.5601461712143\n",
            "Iteration 500 | Accuracy: 57.214285714285715 | Loss:287.96830554567316\n",
            "Iteration 550 | Accuracy: 58.785714285714285 | Loss:318.9699406120175\n",
            "Iteration 600 | Accuracy: 55.42857142857143 | Loss:344.60235101544555\n",
            "Iteration 650 | Accuracy: 56.285714285714285 | Loss:370.40589991905966\n",
            "Iteration 700 | Accuracy: 56.14285714285714 | Loss:400.07693410462275\n",
            "Iteration 750 | Accuracy: 57.214285714285715 | Loss:428.58683199694326\n",
            "Iteration 800 | Accuracy: 59.92857142857143 | Loss:455.79511994082816\n",
            "Iteration 850 | Accuracy: 58.14285714285714 | Loss:486.25638027528976\n",
            "Iteration 900 | Accuracy: 55.50000000000001 | Loss:509.458852773537\n",
            "Iteration 950 | Accuracy: 55.714285714285715 | Loss:536.473948036255\n",
            "Iteration 1000 | Accuracy: 56.214285714285715 | Loss:564.7934694143983\n",
            "Iteration 1050 | Accuracy: 56.214285714285715 | Loss:586.6719938828944\n",
            "Iteration 1100 | Accuracy: 56.35714285714286 | Loss:616.5028233643983\n",
            "Iteration 1150 | Accuracy: 57.714285714285715 | Loss:644.6023149271177\n",
            "Iteration 1200 | Accuracy: 59.71428571428572 | Loss:675.6683160622898\n",
            "Iteration 1250 | Accuracy: 54.57142857142857 | Loss:704.1689579867981\n",
            "Iteration 1300 | Accuracy: 57.49999999999999 | Loss:728.835720935064\n",
            "Iteration 1350 | Accuracy: 58.71428571428572 | Loss:754.8748753698086\n",
            "##################################################\n",
            ">epoch=71, lrate=0.100, error=782.184\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.57142857142858 | Loss:1.1474128863973785\n",
            "Iteration 50 | Accuracy: 58.71428571428572 | Loss:31.70712680235618\n",
            "Iteration 100 | Accuracy: 56.57142857142857 | Loss:61.760011997065135\n",
            "Iteration 150 | Accuracy: 56.85714285714286 | Loss:91.18549756767327\n",
            "Iteration 200 | Accuracy: 56.92857142857143 | Loss:115.39227069375093\n",
            "Iteration 250 | Accuracy: 56.64285714285714 | Loss:142.74861255417787\n",
            "Iteration 300 | Accuracy: 56.92857142857143 | Loss:169.1046207403419\n",
            "Iteration 350 | Accuracy: 56.99999999999999 | Loss:197.19227971087534\n",
            "Iteration 400 | Accuracy: 56.99999999999999 | Loss:224.79421782570944\n",
            "Iteration 450 | Accuracy: 56.785714285714285 | Loss:253.9825468183468\n",
            "Iteration 500 | Accuracy: 57.714285714285715 | Loss:283.9633309230012\n",
            "Iteration 550 | Accuracy: 59.07142857142858 | Loss:314.50544250657595\n",
            "Iteration 600 | Accuracy: 55.92857142857143 | Loss:339.87750187581287\n",
            "Iteration 650 | Accuracy: 57.49999999999999 | Loss:365.29425471424844\n",
            "Iteration 700 | Accuracy: 56.92857142857143 | Loss:394.55234761961253\n",
            "Iteration 750 | Accuracy: 57.714285714285715 | Loss:422.71743957979345\n",
            "Iteration 800 | Accuracy: 60.42857142857143 | Loss:449.4576192335143\n",
            "Iteration 850 | Accuracy: 58.42857142857143 | Loss:479.46536840697064\n",
            "Iteration 900 | Accuracy: 56.49999999999999 | Loss:502.07499149361956\n",
            "Iteration 950 | Accuracy: 56.00000000000001 | Loss:528.7031314346103\n",
            "Iteration 1000 | Accuracy: 56.42857142857143 | Loss:556.6298582494593\n",
            "Iteration 1050 | Accuracy: 56.35714285714286 | Loss:578.1104443308079\n",
            "Iteration 1100 | Accuracy: 56.85714285714286 | Loss:607.6208517559934\n",
            "Iteration 1150 | Accuracy: 58.07142857142858 | Loss:635.1936198562165\n",
            "Iteration 1200 | Accuracy: 59.857142857142854 | Loss:665.8707731437397\n",
            "Iteration 1250 | Accuracy: 55.07142857142857 | Loss:694.0031130703925\n",
            "Iteration 1300 | Accuracy: 57.785714285714285 | Loss:718.2551140179419\n",
            "Iteration 1350 | Accuracy: 58.71428571428572 | Loss:743.6679339235965\n",
            "##################################################\n",
            ">epoch=72, lrate=0.100, error=770.588\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.92857142857143 | Loss:1.1571293345995008\n",
            "Iteration 50 | Accuracy: 58.857142857142854 | Loss:31.252628457474998\n",
            "Iteration 100 | Accuracy: 56.92857142857143 | Loss:60.9059496505929\n",
            "Iteration 150 | Accuracy: 56.99999999999999 | Loss:90.01669595007152\n",
            "Iteration 200 | Accuracy: 57.285714285714285 | Loss:113.80194338765544\n",
            "Iteration 250 | Accuracy: 57.214285714285715 | Loss:140.64208917784686\n",
            "Iteration 300 | Accuracy: 57.07142857142857 | Loss:166.4536226518273\n",
            "Iteration 350 | Accuracy: 57.49999999999999 | Loss:194.16690780872747\n",
            "Iteration 400 | Accuracy: 57.214285714285715 | Loss:221.33073861414354\n",
            "Iteration 450 | Accuracy: 57.285714285714285 | Loss:250.1382547970567\n",
            "Iteration 500 | Accuracy: 58.357142857142854 | Loss:279.68189062779635\n",
            "Iteration 550 | Accuracy: 59.285714285714285 | Loss:309.7512052280615\n",
            "Iteration 600 | Accuracy: 56.714285714285715 | Loss:334.82153629420867\n",
            "Iteration 650 | Accuracy: 57.64285714285714 | Loss:359.8210556600079\n",
            "Iteration 700 | Accuracy: 57.285714285714285 | Loss:388.6422015073197\n",
            "Iteration 750 | Accuracy: 57.714285714285715 | Loss:416.4371298089592\n",
            "Iteration 800 | Accuracy: 60.92857142857143 | Loss:442.68723175691605\n",
            "Iteration 850 | Accuracy: 58.42857142857143 | Loss:472.2322771450733\n",
            "Iteration 900 | Accuracy: 56.785714285714285 | Loss:494.240205501262\n",
            "Iteration 950 | Accuracy: 56.214285714285715 | Loss:520.4594577299614\n",
            "Iteration 1000 | Accuracy: 56.49999999999999 | Loss:547.96432333377\n",
            "Iteration 1050 | Accuracy: 56.714285714285715 | Loss:569.0066316308765\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:598.1835220586738\n",
            "Iteration 1150 | Accuracy: 58.14285714285714 | Loss:625.2327823837253\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:655.4898327417752\n",
            "Iteration 1250 | Accuracy: 56.07142857142857 | Loss:683.2612527890325\n",
            "Iteration 1300 | Accuracy: 58.07142857142858 | Loss:707.0660526218164\n",
            "Iteration 1350 | Accuracy: 58.857142857142854 | Loss:731.8679121901407\n",
            "##################################################\n",
            ">epoch=73, lrate=0.100, error=758.398\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.42857142857143 | Loss:1.1659533288160733\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:30.794873254569882\n",
            "Iteration 100 | Accuracy: 57.14285714285714 | Loss:60.0456187226934\n",
            "Iteration 150 | Accuracy: 57.49999999999999 | Loss:88.82805714686728\n",
            "Iteration 200 | Accuracy: 57.785714285714285 | Loss:112.17900190477836\n",
            "Iteration 250 | Accuracy: 57.49999999999999 | Loss:138.49454745135696\n",
            "Iteration 300 | Accuracy: 57.14285714285714 | Loss:163.76131602805015\n",
            "Iteration 350 | Accuracy: 57.92857142857143 | Loss:191.09565469167737\n",
            "Iteration 400 | Accuracy: 57.57142857142858 | Loss:217.8297352628996\n",
            "Iteration 450 | Accuracy: 57.85714285714286 | Loss:246.2451946789412\n",
            "Iteration 500 | Accuracy: 58.42857142857143 | Loss:275.37152668384414\n",
            "Iteration 550 | Accuracy: 59.42857142857143 | Loss:304.99075307719244\n",
            "Iteration 600 | Accuracy: 56.92857142857143 | Loss:329.73568359362383\n",
            "Iteration 650 | Accuracy: 57.57142857142858 | Loss:354.3159612728997\n",
            "Iteration 700 | Accuracy: 57.64285714285714 | Loss:382.7062689608902\n",
            "Iteration 750 | Accuracy: 57.99999999999999 | Loss:410.1302754914914\n",
            "Iteration 800 | Accuracy: 61.07142857142858 | Loss:435.90938684737654\n",
            "Iteration 850 | Accuracy: 58.71428571428572 | Loss:465.0120157215407\n",
            "Iteration 900 | Accuracy: 56.85714285714286 | Loss:486.44926872801346\n",
            "Iteration 950 | Accuracy: 56.285714285714285 | Loss:512.267856435977\n",
            "Iteration 1000 | Accuracy: 56.57142857142857 | Loss:539.3510625638559\n",
            "Iteration 1050 | Accuracy: 56.49999999999999 | Loss:559.9503147403317\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:588.8031633325028\n",
            "Iteration 1150 | Accuracy: 58.857142857142854 | Loss:615.3742362245298\n",
            "Iteration 1200 | Accuracy: 60.21428571428571 | Loss:645.2089586315344\n",
            "Iteration 1250 | Accuracy: 56.285714285714285 | Loss:672.6477821342231\n",
            "Iteration 1300 | Accuracy: 58.5 | Loss:696.0120447020321\n",
            "Iteration 1350 | Accuracy: 59.14285714285714 | Loss:720.2594708842283\n",
            "##################################################\n",
            ">epoch=74, lrate=0.100, error=746.429\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.71428571428572 | Loss:1.173300826011294\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:30.361517919818635\n",
            "Iteration 100 | Accuracy: 57.14285714285714 | Loss:59.232941221162164\n",
            "Iteration 150 | Accuracy: 57.85714285714286 | Loss:87.69464908847397\n",
            "Iteration 200 | Accuracy: 58.42857142857143 | Loss:110.6246358747803\n",
            "Iteration 250 | Accuracy: 57.92857142857143 | Loss:136.44454803359764\n",
            "Iteration 300 | Accuracy: 57.35714285714286 | Loss:161.2030941502378\n",
            "Iteration 350 | Accuracy: 58.14285714285714 | Loss:188.17344636700693\n",
            "Iteration 400 | Accuracy: 58.14285714285714 | Loss:214.5129260123499\n",
            "Iteration 450 | Accuracy: 58.285714285714285 | Loss:242.5505117950299\n",
            "Iteration 500 | Accuracy: 59.07142857142858 | Loss:271.3030498404105\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:300.52472670500015\n",
            "Iteration 600 | Accuracy: 57.14285714285714 | Loss:324.9465570073864\n",
            "Iteration 650 | Accuracy: 57.785714285714285 | Loss:349.134086660892\n",
            "Iteration 700 | Accuracy: 57.99999999999999 | Loss:377.1279823605907\n",
            "Iteration 750 | Accuracy: 58.57142857142858 | Loss:404.20429202591316\n",
            "Iteration 800 | Accuracy: 61.5 | Loss:429.5652957989723\n",
            "Iteration 850 | Accuracy: 58.785714285714285 | Loss:458.2691552231866\n",
            "Iteration 900 | Accuracy: 57.214285714285715 | Loss:479.1959068954311\n",
            "Iteration 950 | Accuracy: 56.14285714285714 | Loss:504.6480007573925\n",
            "Iteration 1000 | Accuracy: 56.64285714285714 | Loss:531.337851235795\n",
            "Iteration 1050 | Accuracy: 56.57142857142857 | Loss:551.526030612083\n",
            "Iteration 1100 | Accuracy: 57.214285714285715 | Loss:580.0823116930809\n",
            "Iteration 1150 | Accuracy: 59.285714285714285 | Loss:606.2459079018583\n",
            "Iteration 1200 | Accuracy: 60.21428571428571 | Loss:635.6838784582982\n",
            "Iteration 1250 | Accuracy: 56.57142857142857 | Loss:662.8303257696073\n",
            "Iteration 1300 | Accuracy: 59.0 | Loss:685.7936710087836\n",
            "Iteration 1350 | Accuracy: 59.21428571428572 | Loss:709.5667152888044\n",
            "##################################################\n",
            ">epoch=75, lrate=0.100, error=735.422\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.785714285714285 | Loss:1.1788586004279564\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:29.971524183603005\n",
            "Iteration 100 | Accuracy: 56.99999999999999 | Loss:58.50487309390355\n",
            "Iteration 150 | Accuracy: 58.07142857142858 | Loss:86.67122769289878\n",
            "Iteration 200 | Accuracy: 58.5 | Loss:109.2136526924919\n",
            "Iteration 250 | Accuracy: 57.92857142857143 | Loss:134.59283167773597\n",
            "Iteration 300 | Accuracy: 57.714285714285715 | Loss:158.9036948174213\n",
            "Iteration 350 | Accuracy: 58.42857142857143 | Loss:185.5404923082666\n",
            "Iteration 400 | Accuracy: 58.5 | Loss:211.53464157481213\n",
            "Iteration 450 | Accuracy: 58.857142857142854 | Loss:239.22744950703455\n",
            "Iteration 500 | Accuracy: 59.14285714285714 | Loss:267.65929918291295\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:296.5495950196137\n",
            "Iteration 600 | Accuracy: 57.49999999999999 | Loss:320.6727085543315\n",
            "Iteration 650 | Accuracy: 58.07142857142858 | Loss:344.5116281210979\n",
            "Iteration 700 | Accuracy: 58.357142857142854 | Loss:372.15930224525084\n",
            "Iteration 750 | Accuracy: 58.785714285714285 | Loss:398.92509205222683\n",
            "Iteration 800 | Accuracy: 61.357142857142854 | Loss:423.93590541553596\n",
            "Iteration 850 | Accuracy: 58.92857142857143 | Loss:452.29501348991124\n",
            "Iteration 900 | Accuracy: 57.14285714285714 | Loss:472.7818366512408\n",
            "Iteration 950 | Accuracy: 56.35714285714286 | Loss:497.91398223782835\n",
            "Iteration 1000 | Accuracy: 56.714285714285715 | Loss:524.2546471018113\n",
            "Iteration 1050 | Accuracy: 56.92857142857143 | Loss:544.0859604279997\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:572.3806900519307\n",
            "Iteration 1150 | Accuracy: 59.71428571428572 | Loss:598.2117972151514\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:627.2947882025617\n",
            "Iteration 1250 | Accuracy: 56.85714285714286 | Loss:654.1905031604223\n",
            "Iteration 1300 | Accuracy: 59.357142857142854 | Loss:676.8081978156811\n",
            "Iteration 1350 | Accuracy: 59.285714285714285 | Loss:700.1901847357422\n",
            "##################################################\n",
            ">epoch=76, lrate=0.100, error=725.784\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.0 | Loss:1.1826121042186484\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:29.63137309562996\n",
            "Iteration 100 | Accuracy: 57.07142857142857 | Loss:57.87343227528526\n",
            "Iteration 150 | Accuracy: 58.07142857142858 | Loss:85.77903095006812\n",
            "Iteration 200 | Accuracy: 58.64285714285714 | Loss:107.97587808537415\n",
            "Iteration 250 | Accuracy: 58.214285714285715 | Loss:132.97776496640995\n",
            "Iteration 300 | Accuracy: 57.85714285714286 | Loss:156.90834609839334\n",
            "Iteration 350 | Accuracy: 58.42857142857143 | Loss:183.24963105983312\n",
            "Iteration 400 | Accuracy: 58.71428571428572 | Loss:208.94827270576906\n",
            "Iteration 450 | Accuracy: 59.21428571428572 | Loss:236.33770264639534\n",
            "Iteration 500 | Accuracy: 59.21428571428572 | Loss:264.4993761513083\n",
            "Iteration 550 | Accuracy: 59.64285714285714 | Loss:293.1233737809973\n",
            "Iteration 600 | Accuracy: 57.785714285714285 | Loss:316.9836323721279\n",
            "Iteration 650 | Accuracy: 58.285714285714285 | Loss:340.5225902051293\n",
            "Iteration 700 | Accuracy: 58.14285714285714 | Loss:367.8765212435516\n",
            "Iteration 750 | Accuracy: 59.14285714285714 | Loss:394.3719229484416\n",
            "Iteration 800 | Accuracy: 61.357142857142854 | Loss:419.09887001584053\n",
            "Iteration 850 | Accuracy: 59.42857142857143 | Loss:447.1663131155384\n",
            "Iteration 900 | Accuracy: 57.35714285714286 | Loss:467.27954911724726\n",
            "Iteration 950 | Accuracy: 56.714285714285715 | Loss:492.13773856094514\n",
            "Iteration 1000 | Accuracy: 56.85714285714286 | Loss:518.1762289195076\n",
            "Iteration 1050 | Accuracy: 57.285714285714285 | Loss:537.709984906122\n",
            "Iteration 1100 | Accuracy: 57.49999999999999 | Loss:565.7771605895836\n",
            "Iteration 1150 | Accuracy: 59.785714285714285 | Loss:591.3412836350075\n",
            "Iteration 1200 | Accuracy: 60.07142857142858 | Loss:620.1151143099747\n",
            "Iteration 1250 | Accuracy: 57.714285714285715 | Loss:646.7964423658628\n",
            "Iteration 1300 | Accuracy: 59.64285714285714 | Loss:669.1241095082697\n",
            "Iteration 1350 | Accuracy: 59.357142857142854 | Loss:692.1890666442449\n",
            "##################################################\n",
            ">epoch=77, lrate=0.100, error=717.568\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.285714285714285 | Loss:1.1847640873935905\n",
            "Iteration 50 | Accuracy: 59.285714285714285 | Loss:29.338751825330863\n",
            "Iteration 100 | Accuracy: 57.07142857142857 | Loss:57.332961103639\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:85.01350227783587\n",
            "Iteration 200 | Accuracy: 59.0 | Loss:106.90616497471275\n",
            "Iteration 250 | Accuracy: 58.357142857142854 | Loss:131.59012845983617\n",
            "Iteration 300 | Accuracy: 57.92857142857143 | Loss:155.20284888435634\n",
            "Iteration 350 | Accuracy: 58.64285714285714 | Loss:181.28727162246832\n",
            "Iteration 400 | Accuracy: 58.57142857142858 | Loss:206.7329628868486\n",
            "Iteration 450 | Accuracy: 59.42857142857143 | Loss:233.86046796102877\n",
            "Iteration 500 | Accuracy: 59.92857142857143 | Loss:261.79404942419916\n",
            "Iteration 550 | Accuracy: 59.64285714285714 | Loss:290.2080544765454\n",
            "Iteration 600 | Accuracy: 58.285714285714285 | Loss:313.84314045495483\n",
            "Iteration 650 | Accuracy: 58.57142857142858 | Loss:337.1265634386249\n",
            "Iteration 700 | Accuracy: 58.5 | Loss:364.23345451892214\n",
            "Iteration 750 | Accuracy: 59.357142857142854 | Loss:390.4949847216301\n",
            "Iteration 800 | Accuracy: 61.42857142857143 | Loss:414.99439846300015\n",
            "Iteration 850 | Accuracy: 59.64285714285714 | Loss:442.81651577607425\n",
            "Iteration 900 | Accuracy: 57.785714285714285 | Loss:462.6118412406578\n",
            "Iteration 950 | Accuracy: 56.785714285714285 | Loss:487.234460473361\n",
            "Iteration 1000 | Accuracy: 56.99999999999999 | Loss:513.0129355556162\n",
            "Iteration 1050 | Accuracy: 57.285714285714285 | Loss:532.3028715049237\n",
            "Iteration 1100 | Accuracy: 57.57142857142858 | Loss:560.1716361023925\n",
            "Iteration 1150 | Accuracy: 59.857142857142854 | Loss:585.5201639741637\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:614.0274429755606\n",
            "Iteration 1250 | Accuracy: 57.714285714285715 | Loss:640.5232591453049\n",
            "Iteration 1300 | Accuracy: 59.857142857142854 | Loss:662.608959173879\n",
            "Iteration 1350 | Accuracy: 59.42857142857143 | Loss:685.417566164\n",
            "##################################################\n",
            ">epoch=78, lrate=0.100, error=710.619\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.5 | Loss:1.1856288707246416\n",
            "Iteration 50 | Accuracy: 59.357142857142854 | Loss:29.08767596666912\n",
            "Iteration 100 | Accuracy: 57.42857142857143 | Loss:56.8706102167316\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:84.35804225293323\n",
            "Iteration 200 | Accuracy: 58.92857142857143 | Loss:105.98291899757801\n",
            "Iteration 250 | Accuracy: 58.42857142857143 | Loss:130.3988969218619\n",
            "Iteration 300 | Accuracy: 57.99999999999999 | Loss:153.74640104345028\n",
            "Iteration 350 | Accuracy: 59.07142857142858 | Loss:179.60913869269552\n",
            "Iteration 400 | Accuracy: 59.285714285714285 | Loss:204.83515515359358\n",
            "Iteration 450 | Accuracy: 59.92857142857143 | Loss:231.73804319405744\n",
            "Iteration 500 | Accuracy: 61.0 | Loss:259.4763542504491\n",
            "Iteration 550 | Accuracy: 59.42857142857143 | Loss:287.7260353216468\n",
            "Iteration 600 | Accuracy: 58.64285714285714 | Loss:311.16989004816554\n",
            "Iteration 650 | Accuracy: 58.64285714285714 | Loss:334.23457059586974\n",
            "Iteration 700 | Accuracy: 58.785714285714285 | Loss:361.1327343426046\n",
            "Iteration 750 | Accuracy: 59.357142857142854 | Loss:387.1911292671521\n",
            "Iteration 800 | Accuracy: 61.57142857142858 | Loss:411.5075777694103\n",
            "Iteration 850 | Accuracy: 59.92857142857143 | Loss:439.1226060544861\n",
            "Iteration 900 | Accuracy: 58.07142857142858 | Loss:458.6444172330019\n",
            "Iteration 950 | Accuracy: 56.92857142857143 | Loss:483.0604218079418\n",
            "Iteration 1000 | Accuracy: 57.14285714285714 | Loss:508.6136907400457\n",
            "Iteration 1050 | Accuracy: 57.42857142857143 | Loss:527.704158468441\n",
            "Iteration 1100 | Accuracy: 57.785714285714285 | Loss:555.3983306192108\n",
            "Iteration 1150 | Accuracy: 59.92857142857143 | Loss:580.5693600547376\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:608.8468342649411\n",
            "Iteration 1250 | Accuracy: 57.99999999999999 | Loss:635.1791632254339\n",
            "Iteration 1300 | Accuracy: 59.92857142857143 | Loss:657.0613554088524\n",
            "Iteration 1350 | Accuracy: 59.64285714285714 | Loss:679.6617682693808\n",
            "##################################################\n",
            ">epoch=79, lrate=0.100, error=704.715\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.71428571428572 | Loss:1.1855502224822305\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.87169149204512\n",
            "Iteration 100 | Accuracy: 57.64285714285714 | Loss:56.472949004718025\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:83.79367962380225\n",
            "Iteration 200 | Accuracy: 59.14285714285714 | Loss:105.18122728644788\n",
            "Iteration 250 | Accuracy: 58.42857142857143 | Loss:129.36915718297172\n",
            "Iteration 300 | Accuracy: 57.99999999999999 | Loss:152.49399646743507\n",
            "Iteration 350 | Accuracy: 59.07142857142858 | Loss:178.1652310194137\n",
            "Iteration 400 | Accuracy: 59.71428571428572 | Loss:203.1966507786846\n",
            "Iteration 450 | Accuracy: 60.07142857142858 | Loss:229.90680128720987\n",
            "Iteration 500 | Accuracy: 61.07142857142858 | Loss:257.4748378314655\n",
            "Iteration 550 | Accuracy: 59.14285714285714 | Loss:285.59621600927784\n",
            "Iteration 600 | Accuracy: 58.785714285714285 | Loss:308.877005415036\n",
            "Iteration 650 | Accuracy: 58.857142857142854 | Loss:331.75202567887476\n",
            "Iteration 700 | Accuracy: 59.0 | Loss:358.47180225014415\n",
            "Iteration 750 | Accuracy: 59.64285714285714 | Loss:384.35223832291985\n",
            "Iteration 800 | Accuracy: 61.92857142857143 | Loss:408.5199118188261\n",
            "Iteration 850 | Accuracy: 59.857142857142854 | Loss:435.9588149932243\n",
            "Iteration 900 | Accuracy: 58.42857142857143 | Loss:455.24207288325044\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:479.4719147418865\n",
            "Iteration 1000 | Accuracy: 57.214285714285715 | Loss:504.8277998770217\n",
            "Iteration 1050 | Accuracy: 57.64285714285714 | Loss:523.7538594018127\n",
            "Iteration 1100 | Accuracy: 57.85714285714286 | Loss:551.2928371348172\n",
            "Iteration 1150 | Accuracy: 59.785714285714285 | Loss:576.3139097988723\n",
            "Iteration 1200 | Accuracy: 60.285714285714285 | Loss:604.3923279078747\n",
            "Iteration 1250 | Accuracy: 58.42857142857143 | Loss:630.5779523505315\n",
            "Iteration 1300 | Accuracy: 59.92857142857143 | Loss:652.2863660964582\n",
            "Iteration 1350 | Accuracy: 59.57142857142858 | Loss:674.7166787571098\n",
            "##################################################\n",
            ">epoch=80, lrate=0.100, error=699.643\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.92857142857143 | Loss:1.1848507169988405\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.68512658673095\n",
            "Iteration 100 | Accuracy: 57.714285714285715 | Loss:56.12849974548719\n",
            "Iteration 150 | Accuracy: 58.5 | Loss:83.30342409101725\n",
            "Iteration 200 | Accuracy: 59.14285714285714 | Loss:104.47879987146133\n",
            "Iteration 250 | Accuracy: 58.57142857142858 | Loss:128.47007207363677\n",
            "Iteration 300 | Accuracy: 58.14285714285714 | Loss:151.40620257014712\n",
            "Iteration 350 | Accuracy: 59.285714285714285 | Loss:176.91107396805631\n",
            "Iteration 400 | Accuracy: 59.92857142857143 | Loss:201.76676245676978\n",
            "Iteration 450 | Accuracy: 60.07142857142858 | Loss:228.31079705929986\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:255.72765879365247\n",
            "Iteration 550 | Accuracy: 59.357142857142854 | Loss:283.74890745109997\n",
            "Iteration 600 | Accuracy: 58.785714285714285 | Loss:306.88898076518376\n",
            "Iteration 650 | Accuracy: 59.285714285714285 | Loss:329.59699943540465\n",
            "Iteration 700 | Accuracy: 59.14285714285714 | Loss:356.16223169190556\n",
            "Iteration 750 | Accuracy: 59.857142857142854 | Loss:381.88534492047563\n",
            "Iteration 800 | Accuracy: 62.142857142857146 | Loss:405.9302826126628\n",
            "Iteration 850 | Accuracy: 60.0 | Loss:433.21819978119385\n",
            "Iteration 900 | Accuracy: 58.57142857142858 | Loss:452.2907149419106\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:476.34820270516207\n",
            "Iteration 1000 | Accuracy: 57.214285714285715 | Loss:501.52891954821416\n",
            "Iteration 1050 | Accuracy: 57.85714285714286 | Loss:520.3178810439957\n",
            "Iteration 1100 | Accuracy: 57.92857142857143 | Loss:547.7177613566645\n",
            "Iteration 1150 | Accuracy: 60.07142857142858 | Loss:572.6086862049742\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:600.5135909695742\n",
            "Iteration 1250 | Accuracy: 58.285714285714285 | Loss:626.5656674664914\n",
            "Iteration 1300 | Accuracy: 60.0 | Loss:648.1230809655008\n",
            "Iteration 1350 | Accuracy: 59.5 | Loss:670.4137925507624\n",
            "##################################################\n",
            ">epoch=81, lrate=0.100, error=695.230\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.14285714285714 | Loss:1.1838046042807107\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.52330908428921\n",
            "Iteration 100 | Accuracy: 57.85714285714286 | Loss:55.82809413010223\n",
            "Iteration 150 | Accuracy: 58.42857142857143 | Loss:82.87339837750723\n",
            "Iteration 200 | Accuracy: 59.21428571428572 | Loss:103.85753802735805\n",
            "Iteration 250 | Accuracy: 58.64285714285714 | Loss:127.67688477558356\n",
            "Iteration 300 | Accuracy: 58.357142857142854 | Loss:150.45149057078768\n",
            "Iteration 350 | Accuracy: 59.5 | Loss:175.81066953447672\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:200.50512367435462\n",
            "Iteration 450 | Accuracy: 60.14285714285714 | Loss:226.90510296438222\n",
            "Iteration 500 | Accuracy: 61.357142857142854 | Loss:254.185682604724\n",
            "Iteration 550 | Accuracy: 59.5 | Loss:282.12884392555105\n",
            "Iteration 600 | Accuracy: 59.07142857142858 | Loss:305.1455239039332\n",
            "Iteration 650 | Accuracy: 59.357142857142854 | Loss:327.704307231465\n",
            "Iteration 700 | Accuracy: 59.57142857142858 | Loss:354.1338852980674\n",
            "Iteration 750 | Accuracy: 59.92857142857143 | Loss:379.71683103584274\n",
            "Iteration 800 | Accuracy: 62.0 | Loss:403.65897817605014\n",
            "Iteration 850 | Accuracy: 60.07142857142858 | Loss:430.8165829462969\n",
            "Iteration 900 | Accuracy: 58.57142857142858 | Loss:449.70094981196576\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:473.5952006847477\n",
            "Iteration 1000 | Accuracy: 57.35714285714286 | Loss:498.6188309955503\n",
            "Iteration 1050 | Accuracy: 57.92857142857143 | Loss:517.2919916624546\n",
            "Iteration 1100 | Accuracy: 58.14285714285714 | Loss:544.5664855199038\n",
            "Iteration 1150 | Accuracy: 60.14285714285714 | Loss:569.3416355263987\n",
            "Iteration 1200 | Accuracy: 60.42857142857143 | Loss:597.0943094376061\n",
            "Iteration 1250 | Accuracy: 58.42857142857143 | Loss:623.0236511395192\n",
            "Iteration 1300 | Accuracy: 60.0 | Loss:644.4476531443598\n",
            "Iteration 1350 | Accuracy: 59.57142857142858 | Loss:666.6236130427233\n",
            "##################################################\n",
            ">epoch=82, lrate=0.100, error=691.343\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.357142857142854 | Loss:1.1826258745866114\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.382418618852597\n",
            "Iteration 100 | Accuracy: 57.92857142857143 | Loss:55.56447370547478\n",
            "Iteration 150 | Accuracy: 58.42857142857143 | Loss:82.49262756459008\n",
            "Iteration 200 | Accuracy: 59.357142857142854 | Loss:103.303264276609\n",
            "Iteration 250 | Accuracy: 58.92857142857143 | Loss:126.97044443034022\n",
            "Iteration 300 | Accuracy: 58.57142857142858 | Loss:149.60551520041574\n",
            "Iteration 350 | Accuracy: 59.71428571428572 | Loss:174.83592718096327\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:199.38067909850304\n",
            "Iteration 450 | Accuracy: 60.21428571428571 | Loss:225.6548867702356\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:252.81114767964823\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:280.69351267698255\n",
            "Iteration 600 | Accuracy: 59.07142857142858 | Loss:303.6000934005576\n",
            "Iteration 650 | Accuracy: 59.357142857142854 | Loss:326.02384023939607\n",
            "Iteration 700 | Accuracy: 59.64285714285714 | Loss:352.33297293447674\n",
            "Iteration 750 | Accuracy: 59.57142857142858 | Loss:377.79028065450893\n",
            "Iteration 800 | Accuracy: 62.28571428571429 | Loss:401.64509845976886\n",
            "Iteration 850 | Accuracy: 60.07142857142858 | Loss:428.68965402804207\n",
            "Iteration 900 | Accuracy: 58.64285714285714 | Loss:447.404675387519\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:471.14189160584095\n",
            "Iteration 1000 | Accuracy: 57.42857142857143 | Loss:496.02360858448634\n",
            "Iteration 1050 | Accuracy: 58.07142857142858 | Loss:514.5977234464415\n",
            "Iteration 1100 | Accuracy: 58.357142857142854 | Loss:541.7587980681616\n",
            "Iteration 1150 | Accuracy: 60.42857142857143 | Loss:566.4288106886812\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:594.047097749594\n",
            "Iteration 1250 | Accuracy: 58.785714285714285 | Loss:619.863084496233\n",
            "Iteration 1300 | Accuracy: 60.285714285714285 | Loss:641.1675122893465\n",
            "Iteration 1350 | Accuracy: 59.785714285714285 | Loss:663.2493082452953\n",
            "##################################################\n",
            ">epoch=83, lrate=0.100, error=687.882\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.285714285714285 | Loss:1.1814663729420578\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.259281462709243\n",
            "Iteration 100 | Accuracy: 57.99999999999999 | Loss:55.331789250747214\n",
            "Iteration 150 | Accuracy: 58.92857142857143 | Loss:82.15247128090975\n",
            "Iteration 200 | Accuracy: 59.42857142857143 | Loss:102.80494498137102\n",
            "Iteration 250 | Accuracy: 58.92857142857143 | Loss:126.33605874665334\n",
            "Iteration 300 | Accuracy: 58.5 | Loss:148.8495985701681\n",
            "Iteration 350 | Accuracy: 59.857142857142854 | Loss:173.96509828001226\n",
            "Iteration 400 | Accuracy: 60.285714285714285 | Loss:198.36969043466578\n",
            "Iteration 450 | Accuracy: 59.92857142857143 | Loss:224.53333928622888\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:251.57522024297722\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:279.41037161386504\n",
            "Iteration 600 | Accuracy: 59.14285714285714 | Loss:302.2170526034896\n",
            "Iteration 650 | Accuracy: 59.64285714285714 | Loss:324.5174050194233\n",
            "Iteration 700 | Accuracy: 59.57142857142858 | Loss:350.718567184772\n",
            "Iteration 750 | Accuracy: 59.71428571428572 | Loss:376.06276383323785\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:399.8424083355313\n",
            "Iteration 850 | Accuracy: 60.21428571428571 | Loss:426.78850802622804\n",
            "Iteration 900 | Accuracy: 58.71428571428572 | Loss:445.35018073211285\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:468.93519989917843\n",
            "Iteration 1000 | Accuracy: 57.49999999999999 | Loss:493.688167400239\n",
            "Iteration 1050 | Accuracy: 58.285714285714285 | Loss:512.1765615015206\n",
            "Iteration 1100 | Accuracy: 58.357142857142854 | Loss:539.2348572668651\n",
            "Iteration 1150 | Accuracy: 60.357142857142854 | Loss:563.8078366794094\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:591.3067855477434\n",
            "Iteration 1250 | Accuracy: 58.92857142857143 | Loss:617.0179601915866\n",
            "Iteration 1300 | Accuracy: 60.42857142857143 | Loss:638.2139746708938\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:660.2188829436212\n",
            "##################################################\n",
            ">epoch=84, lrate=0.100, error=684.773\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.357142857142854 | Loss:1.1804208092310937\n",
            "Iteration 50 | Accuracy: 59.5 | Loss:28.151208641938712\n",
            "Iteration 100 | Accuracy: 58.07142857142858 | Loss:55.125209085263684\n",
            "Iteration 150 | Accuracy: 59.21428571428572 | Loss:81.8460817229333\n",
            "Iteration 200 | Accuracy: 59.64285714285714 | Loss:102.35392762677014\n",
            "Iteration 250 | Accuracy: 58.857142857142854 | Loss:125.762378002045\n",
            "Iteration 300 | Accuracy: 58.71428571428572 | Loss:148.1692861831395\n",
            "Iteration 350 | Accuracy: 59.785714285714285 | Loss:173.1812231099879\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:197.45385321459747\n",
            "Iteration 450 | Accuracy: 60.0 | Loss:223.51967025089922\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:250.45570328067188\n",
            "Iteration 550 | Accuracy: 59.857142857142854 | Loss:278.254289535002\n",
            "Iteration 600 | Accuracy: 59.14285714285714 | Loss:300.9689530772783\n",
            "Iteration 650 | Accuracy: 59.57142857142858 | Loss:323.15571887392434\n",
            "Iteration 700 | Accuracy: 59.92857142857143 | Loss:349.25932337322155\n",
            "Iteration 750 | Accuracy: 59.71428571428572 | Loss:374.50136598949285\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:398.2155330883608\n",
            "Iteration 850 | Accuracy: 60.42857142857143 | Loss:425.0755829076635\n",
            "Iteration 900 | Accuracy: 59.14285714285714 | Loss:443.4977649478782\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:466.93535845513213\n",
            "Iteration 1000 | Accuracy: 57.785714285714285 | Loss:491.57132754549303\n",
            "Iteration 1050 | Accuracy: 58.214285714285715 | Loss:509.9846943240728\n",
            "Iteration 1100 | Accuracy: 58.5 | Loss:536.9497823006415\n",
            "Iteration 1150 | Accuracy: 60.57142857142858 | Loss:561.4321251172277\n",
            "Iteration 1200 | Accuracy: 60.785714285714285 | Loss:588.8244779451167\n",
            "Iteration 1250 | Accuracy: 59.0 | Loss:614.4389013676517\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:635.5357525523724\n",
            "Iteration 1350 | Accuracy: 60.07142857142858 | Loss:657.4783846920465\n",
            "##################################################\n",
            ">epoch=85, lrate=0.100, error=681.962\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.5 | Loss:1.1795362199707478\n",
            "Iteration 50 | Accuracy: 59.57142857142858 | Loss:28.055891149899633\n",
            "Iteration 100 | Accuracy: 58.14285714285714 | Loss:54.94066164869113\n",
            "Iteration 150 | Accuracy: 59.14285714285714 | Loss:81.56798593742457\n",
            "Iteration 200 | Accuracy: 59.92857142857143 | Loss:101.94333549857289\n",
            "Iteration 250 | Accuracy: 59.07142857142858 | Loss:125.24050352086411\n",
            "Iteration 300 | Accuracy: 58.857142857142854 | Loss:147.55320626278424\n",
            "Iteration 350 | Accuracy: 60.0 | Loss:172.47088447503904\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:196.6188190000583\n",
            "Iteration 450 | Accuracy: 60.14285714285714 | Loss:222.5975126059007\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:249.43523038523426\n",
            "Iteration 550 | Accuracy: 59.785714285714285 | Loss:277.2055435699271\n",
            "Iteration 600 | Accuracy: 59.285714285714285 | Loss:299.8343598082103\n",
            "Iteration 650 | Accuracy: 59.57142857142858 | Loss:321.9160103913961\n",
            "Iteration 700 | Accuracy: 60.14285714285714 | Loss:347.93087334334894\n",
            "Iteration 750 | Accuracy: 59.785714285714285 | Loss:373.08043883642335\n",
            "Iteration 800 | Accuracy: 62.5 | Loss:396.73697280462096\n",
            "Iteration 850 | Accuracy: 60.71428571428571 | Loss:423.52148727172204\n",
            "Iteration 900 | Accuracy: 59.285714285714285 | Loss:441.81635118764234\n",
            "Iteration 950 | Accuracy: 57.35714285714286 | Loss:465.1122016198119\n",
            "Iteration 1000 | Accuracy: 57.92857142857143 | Loss:489.64186795701806\n",
            "Iteration 1050 | Accuracy: 58.14285714285714 | Loss:507.9888357832779\n",
            "Iteration 1100 | Accuracy: 58.5 | Loss:534.8693720611585\n",
            "Iteration 1150 | Accuracy: 60.785714285714285 | Loss:559.2663199425\n",
            "Iteration 1200 | Accuracy: 60.92857142857143 | Loss:586.5628898442167\n",
            "Iteration 1250 | Accuracy: 59.14285714285714 | Loss:612.0883154646722\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:633.0938707851581\n",
            "Iteration 1350 | Accuracy: 60.14285714285714 | Loss:654.9866249125228\n",
            "##################################################\n",
            ">epoch=86, lrate=0.100, error=679.407\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.71428571428571 | Loss:1.1788237206239118\n",
            "Iteration 50 | Accuracy: 59.857142857142854 | Loss:27.97133862025076\n",
            "Iteration 100 | Accuracy: 58.14285714285714 | Loss:54.77468054902796\n",
            "Iteration 150 | Accuracy: 59.357142857142854 | Loss:81.31378415321369\n",
            "Iteration 200 | Accuracy: 60.42857142857143 | Loss:101.5676204523774\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:124.76332374177271\n",
            "Iteration 300 | Accuracy: 59.07142857142858 | Loss:146.99223036263126\n",
            "Iteration 350 | Accuracy: 60.14285714285714 | Loss:171.8232878319075\n",
            "Iteration 400 | Accuracy: 60.57142857142858 | Loss:195.85312002579596\n",
            "Iteration 450 | Accuracy: 60.285714285714285 | Loss:221.75374550220937\n",
            "Iteration 500 | Accuracy: 61.357142857142854 | Loss:248.49993401041314\n",
            "Iteration 550 | Accuracy: 59.857142857142854 | Loss:276.2483510903521\n",
            "Iteration 600 | Accuracy: 59.357142857142854 | Loss:298.7962259779384\n",
            "Iteration 650 | Accuracy: 59.64285714285714 | Loss:320.7802314612808\n",
            "Iteration 700 | Accuracy: 60.0 | Loss:346.71389197205616\n",
            "Iteration 750 | Accuracy: 59.857142857142854 | Loss:371.7795623877308\n",
            "Iteration 800 | Accuracy: 62.28571428571429 | Loss:395.3849012524969\n",
            "Iteration 850 | Accuracy: 60.642857142857146 | Loss:422.1026820955752\n",
            "Iteration 900 | Accuracy: 59.42857142857143 | Loss:440.2810292415866\n",
            "Iteration 950 | Accuracy: 57.49999999999999 | Loss:463.44228952712484\n",
            "Iteration 1000 | Accuracy: 58.07142857142858 | Loss:487.8754890110901\n",
            "Iteration 1050 | Accuracy: 58.5 | Loss:506.16303527297583\n",
            "Iteration 1100 | Accuracy: 58.785714285714285 | Loss:532.9668544203466\n",
            "Iteration 1150 | Accuracy: 60.857142857142854 | Loss:557.2828532000935\n",
            "Iteration 1200 | Accuracy: 61.142857142857146 | Loss:584.4928287918447\n",
            "Iteration 1250 | Accuracy: 59.42857142857143 | Loss:609.9367449427457\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:630.8578447489632\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:652.71123713311\n",
            "##################################################\n",
            ">epoch=87, lrate=0.100, error=677.073\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 61.0 | Loss:1.1782706748965908\n",
            "Iteration 50 | Accuracy: 59.785714285714285 | Loss:27.895843616778116\n",
            "Iteration 100 | Accuracy: 58.285714285714285 | Loss:54.62431251650644\n",
            "Iteration 150 | Accuracy: 59.5 | Loss:81.07992814681451\n",
            "Iteration 200 | Accuracy: 60.357142857142854 | Loss:101.22223627938479\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:124.32503024986707\n",
            "Iteration 300 | Accuracy: 59.14285714285714 | Loss:146.47887186767576\n",
            "Iteration 350 | Accuracy: 60.285714285714285 | Loss:171.22960462595458\n",
            "Iteration 400 | Accuracy: 60.14285714285714 | Loss:195.14740977933076\n",
            "Iteration 450 | Accuracy: 60.357142857142854 | Loss:220.9776519029289\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:247.63848845026112\n",
            "Iteration 550 | Accuracy: 59.92857142857143 | Loss:275.3698224724745\n",
            "Iteration 600 | Accuracy: 59.357142857142854 | Loss:297.8407149015878\n",
            "Iteration 650 | Accuracy: 59.785714285714285 | Loss:319.7337649577789\n",
            "Iteration 700 | Accuracy: 60.07142857142858 | Loss:345.59270701459684\n",
            "Iteration 750 | Accuracy: 60.14285714285714 | Loss:370.5820800039319\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:394.14158573577265\n",
            "Iteration 850 | Accuracy: 60.71428571428571 | Loss:420.79984537936303\n",
            "Iteration 900 | Accuracy: 59.57142857142858 | Loss:438.8713278340475\n",
            "Iteration 950 | Accuracy: 57.92857142857143 | Loss:461.9067032704521\n",
            "Iteration 1000 | Accuracy: 58.214285714285715 | Loss:486.2525144247897\n",
            "Iteration 1050 | Accuracy: 58.64285714285714 | Loss:504.48628728374814\n",
            "Iteration 1100 | Accuracy: 58.857142857142854 | Loss:531.2204649331566\n",
            "Iteration 1150 | Accuracy: 60.71428571428571 | Loss:555.4593900881547\n",
            "Iteration 1200 | Accuracy: 61.57142857142858 | Loss:582.5905928576043\n",
            "Iteration 1250 | Accuracy: 59.64285714285714 | Loss:607.9601763273657\n",
            "Iteration 1300 | Accuracy: 60.642857142857146 | Loss:628.8028659958375\n",
            "Iteration 1350 | Accuracy: 59.92857142857143 | Loss:650.6257920047863\n",
            "##################################################\n",
            ">epoch=88, lrate=0.100, error=674.933\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 61.0 | Loss:1.177851742144664\n",
            "Iteration 50 | Accuracy: 59.92857142857143 | Loss:27.82795658661447\n",
            "Iteration 100 | Accuracy: 58.42857142857143 | Loss:54.487056167906985\n",
            "Iteration 150 | Accuracy: 59.857142857142854 | Loss:80.86354635347459\n",
            "Iteration 200 | Accuracy: 60.57142857142858 | Loss:100.9033957959345\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:123.920766446746\n",
            "Iteration 300 | Accuracy: 59.285714285714285 | Loss:146.00685858347035\n",
            "Iteration 350 | Accuracy: 60.357142857142854 | Loss:170.6825038093048\n",
            "Iteration 400 | Accuracy: 60.14285714285714 | Loss:194.49392752655382\n",
            "Iteration 450 | Accuracy: 60.357142857142854 | Loss:220.2603185081537\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:246.8414287006591\n",
            "Iteration 550 | Accuracy: 60.285714285714285 | Loss:274.55922175121157\n",
            "Iteration 600 | Accuracy: 59.42857142857143 | Loss:296.95635982267754\n",
            "Iteration 650 | Accuracy: 59.857142857142854 | Loss:318.76450491323885\n",
            "Iteration 700 | Accuracy: 60.0 | Loss:344.5543161955366\n",
            "Iteration 750 | Accuracy: 60.21428571428571 | Loss:369.4740673531608\n",
            "Iteration 800 | Accuracy: 62.857142857142854 | Loss:392.99226981280646\n",
            "Iteration 850 | Accuracy: 61.0 | Loss:419.596748190856\n",
            "Iteration 900 | Accuracy: 59.785714285714285 | Loss:437.5700262511859\n",
            "Iteration 950 | Accuracy: 57.99999999999999 | Loss:460.4894267892836\n",
            "Iteration 1000 | Accuracy: 58.285714285714285 | Loss:484.7562221744558\n",
            "Iteration 1050 | Accuracy: 58.92857142857143 | Loss:502.9408052015385\n",
            "Iteration 1100 | Accuracy: 58.857142857142854 | Loss:529.6117088713188\n",
            "Iteration 1150 | Accuracy: 60.785714285714285 | Loss:553.7770020614445\n",
            "Iteration 1200 | Accuracy: 61.642857142857146 | Loss:580.8361087485956\n",
            "Iteration 1250 | Accuracy: 59.92857142857143 | Loss:606.1381328619592\n",
            "Iteration 1300 | Accuracy: 60.71428571428571 | Loss:626.9078077680076\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:648.7077612833455\n",
            "##################################################\n",
            ">epoch=89, lrate=0.100, error=672.965\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.92857142857143 | Loss:1.1775376589735598\n",
            "Iteration 50 | Accuracy: 60.07142857142858 | Loss:27.76646117027676\n",
            "Iteration 100 | Accuracy: 58.5 | Loss:54.36081031048093\n",
            "Iteration 150 | Accuracy: 59.92857142857143 | Loss:80.66229543075214\n",
            "Iteration 200 | Accuracy: 60.857142857142854 | Loss:100.60788656758885\n",
            "Iteration 250 | Accuracy: 59.5 | Loss:123.54637496513439\n",
            "Iteration 300 | Accuracy: 59.357142857142854 | Loss:145.57083069470818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e00e2c4d0cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-7b03cfe96db7>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, train, lr, n_epochs, n_outputs, accuracy_score, loss_score)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# store accuracy and loss every 50 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0maccuracy_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mloss_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-84545ac55474>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(network, data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-3d8116f75108>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(network, row)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1cf82b1a902f>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0me_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0me_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPa6iTOQEWNs"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssSbMK9j2BpH"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h1-0.1-68810.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h1-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9w89nb1NvOr"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h1-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "621bjxBBN4Lt"
      },
      "source": [
        "# plt.plot(loss_score)\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h1-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZvAhuGYvgH3"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUu6q5LCvgH3"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9rF8f6F6Rz"
      },
      "source": [
        "### lr=0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37KevaftGDg0"
      },
      "source": [
        "net = initialize_network_single(6,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ida_AR74GDg-"
      },
      "source": [
        "train_network(net,train,lr = 0.05,n_epochs=500,n_outputs=10,accuracy_score,loss_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDxJl3JpGDg_"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MliDqb20GDhA"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h1-0.05.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h1-0.05.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwjIdZt8GDhA"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h1-0.05.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h1-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh3gadk6GDhB"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqy3r_RvGDhB"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4sqAz6Ig4IP"
      },
      "source": [
        "### 2 Hidden Layer (6-8-8-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eXc6UKAg4IW"
      },
      "source": [
        "### lr=0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrhC6XAyg4IX"
      },
      "source": [
        "net = initialize_network_double(6,8,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZoPaiN8g4IY",
        "outputId": "5bd9df26-bf2a-4d70-ec93-82db8787ec58"
      },
      "source": [
        "train_network(net,train,lr = 0.3,\n",
        "              n_epochs=500,n_outputs = 10,\n",
        "              accuracy_score = accuracy_score,\n",
        "              loss_score = loss_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 1100 | Accuracy: 75.07142857142857 | Loss:372.0331098374921\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.73546389630417\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:404.5591984866477\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.91801512860826\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:428.47258265919686\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:444.6445929349989\n",
            "##################################################\n",
            ">epoch=338, lrate=0.300, error=459.777\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.5 | Loss:1.743640404091238\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.900810598505146\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.90238548676939\n",
            "Iteration 150 | Accuracy: 74.78571428571429 | Loss:57.88903428568095\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.95292400331029\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.64101733107803\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.85653445929871\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.57166745116648\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.781684262015\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.11257174178442\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.6583082159222\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.81216455986237\n",
            "Iteration 600 | Accuracy: 74.78571428571429 | Loss:210.38959927027622\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.4675549324111\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.54022754405284\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.73176396909815\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:270.25962337723905\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:289.83343431764723\n",
            "Iteration 900 | Accuracy: 75.5 | Loss:305.6522853972177\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:322.9067358609558\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:337.3596989525661\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.6384053754266\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:372.0234972461224\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.7364850186909\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:404.52809150144526\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.908307243103\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:428.4531174766109\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.62902739735654\n",
            "##################################################\n",
            ">epoch=339, lrate=0.300, error=459.765\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.736079884629015\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.87233587899804\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.85719034032971\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.86318138221682\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.91749993082298\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.5972581947526\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.82570651376065\n",
            "Iteration 350 | Accuracy: 75.42857142857143 | Loss:121.54367915071292\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.7498321834484\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.0744371908491\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.65163947392782\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.79892476773975\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.37717073267532\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.45560300588244\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.50804618878416\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:257.6926948783147\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:270.2135382229718\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:289.76755150247845\n",
            "Iteration 900 | Accuracy: 75.5 | Loss:305.5735215921749\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.8019272655311\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:337.30739674197724\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.5981553843862\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:372.0025304273149\n",
            "Iteration 1150 | Accuracy: 73.07142857142857 | Loss:384.7270961831803\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:404.4909969854017\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.8925867322688\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:428.4283187544384\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.60819431265094\n",
            "##################################################\n",
            ">epoch=340, lrate=0.300, error=459.750\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.727039103737499\n",
            "Iteration 50 | Accuracy: 76.35714285714286 | Loss:16.841090477837394\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.80726264857475\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.8341723192406\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.87620781047713\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.5470026910049\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.78476728693798\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.50380222538432\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.7056364168159\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.0253275380518\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.63220412665956\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.77259193803252\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.3516853892833\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:226.43083343384788\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.46101086085977\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.6374816649034\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:270.15072417013215\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:289.68123282826355\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:305.47444965525756\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:322.6822339144495\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:337.2304899868883\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.53952487100435\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.9668392919685\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.7029196419164\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.4425113194932\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.86475388969694\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:428.39179017247756\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:444.5758791882386\n",
            "##################################################\n",
            ">epoch=341, lrate=0.300, error=459.725\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7164792621451581\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.807679215138794\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.75401080828822\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.80359571580517\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.83074335895428\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:86.49273048297349\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.73687574831521\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.45554988073717\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.65263096820286\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.96837939747653\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.60300401983537\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.73638349215398\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.31587296718317\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.3959590182178\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.40179939920537\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.5688823616094\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:270.0739754274797\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:289.577204003881\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:305.35771078492326\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.55083633704106\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:337.1326097220914\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.4621792240192\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.9133948076707\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.6600026227255\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.37755885766484\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:416.81894400046326\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:428.33734023904833\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:444.5260159913258\n",
            "##################################################\n",
            ">epoch=342, lrate=0.300, error=459.685\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.704655157683745\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.773398055081117\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.699909431549415\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.773699864029304\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.78414023668502\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:86.43816868940587\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.68632238702182\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.40341283049773\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.5953487924517\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.9078769342947\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.56796692265104\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.69449071655382\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.27341121368747\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.35466792135162\n",
            "Iteration 700 | Accuracy: 74.35714285714286 | Loss:243.33423398874797\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:257.49079761436104\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.987245548782\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.45964386725166\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:305.22733349448845\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.41179311219884\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:337.01874570795536\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.36633182294406\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.8390513806778\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:384.5947021331832\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.2917077262628\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.7501868221171\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:428.2597807064359\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:444.4534739028663\n",
            "##################################################\n",
            ">epoch=343, lrate=0.300, error=459.623\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6919761939648201\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:16.739567925571155\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.64736006350259\n",
            "Iteration 150 | Accuracy: 74.78571428571429 | Loss:57.74629851608932\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.73932387412715\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.3867365702994\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.63699872008463\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.35125178812108\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.53767330674705\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.84763575113354\n",
            "Iteration 500 | Accuracy: 73.78571428571429 | Loss:174.53044321946152\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.6504994792765\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.22733290186264\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.3099869446224\n",
            "Iteration 700 | Accuracy: 74.42857142857143 | Loss:243.26171193213415\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.4067116290977\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.8940660270972\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.3326028605143\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:305.0871898192265\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.2685150798294\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.8932795399706\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:350.25241180084765\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.74185048629323\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.5051092979493\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.18275085532866\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.6561603170845\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:428.1566999478838\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.35586206791766\n",
            "##################################################\n",
            ">epoch=344, lrate=0.300, error=459.535\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6788291713196055\n",
            "Iteration 50 | Accuracy: 76.35714285714286 | Loss:16.707054067351503\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.59799124390818\n",
            "Iteration 150 | Accuracy: 74.71428571428571 | Loss:57.722262364390495\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.698180311304\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.34059222481305\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.59144445406386\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.30138652640696\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.4819176251309\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.7900497765912\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.49249366538643\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.60664009160982\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.17933971749042\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.2635751668862\n",
            "Iteration 700 | Accuracy: 74.5 | Loss:243.186437774532\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:257.31890776561283\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:269.7967413838561\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:289.1990940347409\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.94015440807743\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:322.12312273649195\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.7591236549191\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:350.12109785029537\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.6215503337375\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.39139644111094\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:404.05090550957453\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:416.53730557949723\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:428.02851999469203\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.2336094878341\n",
            "##################################################\n",
            ">epoch=345, lrate=0.300, error=459.424\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.6655002009022022\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.676235586248918\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.55267617603057\n",
            "Iteration 150 | Accuracy: 74.71428571428571 | Loss:57.70173732817083\n",
            "Iteration 200 | Accuracy: 74.42857142857143 | Loss:69.66157108872515\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:86.30069267564527\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.55086137397615\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.25467263058226\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.42891352143005\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.7361165022489\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.4550927478104\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:193.5639739795071\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.1301257475657\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:226.21606136737267\n",
            "Iteration 700 | Accuracy: 74.64285714285714 | Loss:243.10961436137814\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:257.22863820021115\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:269.69651430638584\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:289.0611329350099\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.7881979693677\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.976761332589\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:336.61797250971847\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.97351231029745\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.4793248911574\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.25526425229486\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:403.8979778781562\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:416.39581944055067\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.87744161449666\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:444.0889109658848\n",
            "##################################################\n",
            ">epoch=346, lrate=0.300, error=459.289\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.652189026001884\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:16.64719866019349\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.51185381854283\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.68456360282129\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.62977172691205\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.26728669331116\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.51555521548462\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:121.21096100886139\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.37849420868235\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.68585439701903\n",
            "Iteration 500 | Accuracy: 73.85714285714286 | Loss:174.41859250651467\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:193.5228419180751\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.0799672607331\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:226.16765963885572\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:243.03191375639213\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:257.13659851227214\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.59405047861054\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.9201307755444\n",
            "Iteration 900 | Accuracy: 75.42857142857143 | Loss:304.6327910861471\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.83012299316647\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.47089653600665\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.81143040130695\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:371.3174533749962\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:384.09947909341815\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:403.72671158775853\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.23486903257606\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.7066382066678\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:443.92491965844346\n",
            "##################################################\n",
            ">epoch=347, lrate=0.300, error=459.134\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.639030774288283\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.619878803718752\n",
            "Iteration 100 | Accuracy: 76.0 | Loss:39.47578243693466\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.67052448289246\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.60281197381299\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.24027276429682\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.4852497175528\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.16937496556855\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.32979995425802\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.63856132764732\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.3829115954265\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.48304131394656\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.02897209998036\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.1184367481261\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.95366026623103\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:257.04313844914765\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.48966392494737\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.77706396929585\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.47505093960433\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.6836159576759\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:336.31865063700224\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.6372555933858\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:371.13914490585495\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:383.9276630244924\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:403.540558530843\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:416.0582901158586\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.51993431668\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:443.74543434960697\n",
            "##################################################\n",
            ">epoch=348, lrate=0.300, error=458.963\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.6260768930797596\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.5940865336879\n",
            "Iteration 100 | Accuracy: 76.0 | Loss:39.44469884086079\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.65943680966129\n",
            "Iteration 200 | Accuracy: 74.5 | Loss:69.5806399726127\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.21934005311836\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.45918957069536\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.12833372017258\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.28133746088045\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.5928583821602\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.34746487862142\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:193.4437615002828\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.97698649699325\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.06822401876602\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.87473166921941\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.9481967053641\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.38326348931906\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.63239131706206\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.31562422684556\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:321.53723859144355\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:336.16166616284187\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.45369205063105\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:370.94826717671117\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:383.7440549017932\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:403.34352248964996\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.8704015254572\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.32159004448806\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:443.5546979791911\n",
            "##################################################\n",
            ">epoch=349, lrate=0.300, error=458.780\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.6132466757296635\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.569479762696425\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.41902658837472\n",
            "Iteration 150 | Accuracy: 75.14285714285714 | Loss:57.65122452529844\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.56326686786502\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.2040642175874\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.4361797297833\n",
            "Iteration 350 | Accuracy: 75.5 | Loss:121.08541973068908\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.23089474712006\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.54663570119385\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.3110500412523\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.403496689759\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.92341120404168\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:226.0164324907787\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.79440841836217\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.85117527216863\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.27423211684163\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.4859162519276\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:304.1545192202074\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:321.39042800550646\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:335.9999298379513\n",
            "Iteration 1050 | Accuracy: 75.35714285714286 | Loss:349.26318325125914\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.74874247179696\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.5529396549057\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:403.13965339677424\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.6754879856701\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:427.11575534342694\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:443.35685959674737\n",
            "##################################################\n",
            ">epoch=350, lrate=0.300, error=458.591\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.600292206054859\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.545564217060104\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.39981543049608\n",
            "Iteration 150 | Accuracy: 75.21428571428571 | Loss:57.64607809831428\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.55105840967023\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.19412883932704\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.41466204159566\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:121.03703492382387\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.17527054712724\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.4968709941108\n",
            "Iteration 500 | Accuracy: 73.92857142857143 | Loss:174.27176958516736\n",
            "Iteration 550 | Accuracy: 73.0 | Loss:193.36001522128083\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.86706368578382\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.9619175012312\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:242.71126343557097\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:256.75084443992256\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:269.1613261435101\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.33664847431766\n",
            "Iteration 900 | Accuracy: 75.35714285714286 | Loss:303.9909477830131\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:321.2419848135595\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:335.8328064877847\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:349.0671855153898\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.54353887170885\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.3576266031713\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:402.93198839079366\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.4767244963305\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:426.90538162179934\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:443.15487481491124\n",
            "##################################################\n",
            ">epoch=351, lrate=0.300, error=458.397\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.5868148165745064\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.521770649184113\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.389665287355626\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.644765147630125\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.54528419931209\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.189768992663\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.39285613885411\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.97771693644208\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.1097359514911\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:153.43922147050617\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.2269805946125\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.31041240047824\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.80613240009467\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.9029365470464\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.62309238067934\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.6452783572118\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:269.04258971434757\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:288.1825990597214\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.82311359547\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:321.0900537573652\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:335.65872472927595\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.8653636508963\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:370.3334811526334\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:383.15919761343343\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:402.72117978402457\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:415.2747670605046\n",
            "Iteration 1300 | Accuracy: 75.42857142857143 | Loss:426.6908243560425\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:442.94906144699286\n",
            "##################################################\n",
            ">epoch=352, lrate=0.300, error=458.201\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.5723503697616077\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.497624622904034\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.394492983215216\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.649222059277946\n",
            "Iteration 200 | Accuracy: 74.64285714285714 | Loss:69.54900757728842\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:86.19257186445692\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.36926658337492\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.89978505304657\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.0279205125279\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.36794831333577\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:174.17373469506347\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.2518125526137\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.7387510595717\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:225.8376911696285\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.52741177404624\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.5323335027732\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.9157966192815\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.02097108575623\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.6484069591223\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.93259594932806\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:335.4751896965628\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.6554560463032\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:370.1169163605912\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:382.95608557109836\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:402.5050478982677\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:415.067267010846\n",
            "Iteration 1300 | Accuracy: 75.42857142857143 | Loss:426.46944182524226\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.73657897072064\n",
            "##################################################\n",
            ">epoch=353, lrate=0.300, error=457.999\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.556551503931717\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.473026561553542\n",
            "Iteration 100 | Accuracy: 76.07142857142857 | Loss:39.42566952692082\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:57.66380397378709\n",
            "Iteration 200 | Accuracy: 74.57142857142857 | Loss:69.5682898073992\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.20693108311902\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.3449747223849\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.79771389790216\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.9259838322132\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.27957157773952\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.1118358745956\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.18482754971942\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.66643850393146\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.76761803815089\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.4250424813646\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.413206430863\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.7820113583502\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.8517760723024\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:303.4669802118891\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:320.77059391001376\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:335.28250117851053\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:348.4378434246598\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.8944857320089\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:382.74877870537904\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:402.2836869105577\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.85409114301837\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:426.2411187253217\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.5167504732305\n",
            "##################################################\n",
            ">epoch=354, lrate=0.300, error=457.791\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.5395016758292457\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.448530428055776\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.495963995782205\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.69533382771567\n",
            "Iteration 200 | Accuracy: 74.71428571428571 | Loss:69.61076296631467\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.23934464431098\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.32674015403747\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.68264652104831\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.81448889456348\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.18364159226695\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:174.04964473505223\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.1189264924113\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.60039218242568\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.70345420839905\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.327451116937\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.29971058465867\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:268.6531545082773\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.68762388776514\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:303.2912441952232\n",
            "Iteration 950 | Accuracy: 75.78571428571429 | Loss:320.61465523518945\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:335.09470284713166\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:348.22824868968047\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.6817617422963\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.5525086527542\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:402.0724506339364\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.6507255697003\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:426.0221412065423\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.3050313813843\n",
            "##################################################\n",
            ">epoch=355, lrate=0.300, error=457.592\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.5219266466952914\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.42486619534469\n",
            "Iteration 100 | Accuracy: 76.14285714285714 | Loss:39.59378027304649\n",
            "Iteration 150 | Accuracy: 74.85714285714286 | Loss:57.73776889799235\n",
            "Iteration 200 | Accuracy: 74.78571428571429 | Loss:69.66750637279502\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.28165702186853\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.31294743664382\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.57687972168044\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.70993320267726\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.09519013380927\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.9922887328816\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.0590174503581\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.54796483353007\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.6517796827787\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.24381673802645\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.2007888652176\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.53885542570316\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.5427595239803\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:303.1346899276788\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:320.4725181378085\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.92819264140826\n",
            "Iteration 1050 | Accuracy: 75.21428571428571 | Loss:348.0447465562009\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:369.49491595810224\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.3829998164856\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.88655073094577\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:414.4726996959793\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.829355975051\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.1180659127393\n",
            "##################################################\n",
            ">epoch=356, lrate=0.300, error=457.416\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.5049146242060891\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.40181369231802\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.66780158979463\n",
            "Iteration 150 | Accuracy: 74.92857142857143 | Loss:57.76295692030022\n",
            "Iteration 200 | Accuracy: 74.78571428571429 | Loss:69.70127618408385\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.30443434944891\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.28508920947678\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.48484833748158\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.61311790055487\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:153.01367654600213\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.92925782307114\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.99329161668285\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:209.49423378484843\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.59727506630585\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.16050739898898\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:256.1026763789255\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:268.42539160807667\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.40660505575977\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:302.98641268346955\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.3298656482969\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.7713912097656\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:347.8749348130391\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:369.3195650880913\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:382.2252719325241\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.7116993549203\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.3056008435233\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.64917572339505\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.9428789466157\n",
            "##################################################\n",
            ">epoch=357, lrate=0.300, error=457.250\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.4891950857932192\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.37911161828775\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.68496254720928\n",
            "Iteration 150 | Accuracy: 75.0 | Loss:57.76001198613375\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.693366926875\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.29626321746562\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.24073815572385\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.40408424206896\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.52557103825364\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:152.9388147527905\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.8600913281579\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.9201175145692\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:209.43056086310423\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.5314580050801\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.06855572413346\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.9965416188979\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.30318354310845\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.2679587467796\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.83569715345425\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.1781348744907\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.6104226281286\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:347.70335826944364\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:369.1406595221045\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:382.06398444736817\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.5358603337381\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.13742377742585\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.4695345385294\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.76817986564015\n",
            "##################################################\n",
            ">epoch=358, lrate=0.300, error=457.084\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.4744441162329698\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.357047562440002\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.661046152985826\n",
            "Iteration 150 | Accuracy: 75.07142857142857 | Loss:57.741958176733384\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.65989184295975\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.2708954243018\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.1916296219606\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.3344266753908\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.44990450540402\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:152.87376036076364\n",
            "Iteration 500 | Accuracy: 74.0 | Loss:173.79374164971335\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.84810814762182\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.36367932289224\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.46107079633882\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.9738720664334\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.88739925343458\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.1773409479099\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.12891264782513\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.68494446754767\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.02321774580525\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.44678933808194\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:347.53071486642574\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.95992489764126\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.9008886188204\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.36234170243955\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.97167324798585\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.29351960685165\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.5976144863306\n",
            "##################################################\n",
            ">epoch=359, lrate=0.300, error=456.921\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.460058738428564\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.335708985759332\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.61950606399748\n",
            "Iteration 150 | Accuracy: 75.35714285714286 | Loss:57.72144038731941\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.6189385448481\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.24255244964112\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.14642423486264\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.27718551879845\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.38726464247225\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:152.82102337909987\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:173.73655862723297\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:192.78381138388053\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.30153138446803\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.39402593950612\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.88401958117473\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.78188085385077\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:268.05499808956176\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.99485428150547\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.53958829702174\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.87230376242786\n",
            "Iteration 1000 | Accuracy: 74.5 | Loss:334.28646977933306\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:347.36274844853597\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.7836459297786\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.7423389369336\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.1970356458777\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.81432831934376\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:425.1267409291677\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.43712525089296\n",
            "##################################################\n",
            ">epoch=360, lrate=0.300, error=456.768\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4456726072979063\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.314961906110785\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.57282485589569\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.70383378031142\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.57919474285517\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.21789008544884\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.10842178278162\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.23264406718836\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.33743962403136\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.7810075866581\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.6908915535074\n",
            "Iteration 550 | Accuracy: 73.28571428571429 | Loss:192.72996236508158\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.24806339956635\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.3343371802177\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.80283343160926\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.68337682519046\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.9398994873911\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.8688316247292\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:302.4026517257086\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.72895823013664\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:334.133040123389\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.20288969791744\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.61541425894956\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.5919787655829\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.0426841669928\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.6680858605573\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:424.97163240386794\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.289317515339\n",
            "##################################################\n",
            ">epoch=361, lrate=0.300, error=456.628\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4311882122318658\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.294741098465934\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.52575629803777\n",
            "Iteration 150 | Accuracy: 75.71428571428571 | Loss:57.690516262523495\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.54365248423248\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.19918987732426\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.0784800844489\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.20035118017293\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.29978589097615\n",
            "Iteration 450 | Accuracy: 76.07142857142857 | Loss:152.75305713010198\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.65735300480947\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.68752590998935\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.20481367263164\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.28367760751394\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.73182587254985\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.5932860706457\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.8336067461456\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.7521241185337\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.27539473760777\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.59455723725506\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:333.9880792538197\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.05255299504444\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.4566908565324\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.4513049911025\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.9000591599088\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.5336130303654\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:424.82866981257723\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.15475558687933\n",
            "##################################################\n",
            ">epoch=362, lrate=0.300, error=456.502\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4166818351284403\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.275103084317436\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.47996703589778\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.68164822278879\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.51324219418102\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.1873027123015\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.05687585675336\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.17985499127894\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.27385789991214\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.73643813879082\n",
            "Iteration 500 | Accuracy: 74.14285714285714 | Loss:173.636272845345\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.65707694428409\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.17265328204846\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.24307712280242\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.67189576635377\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.51255243495126\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.73711472169833\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.6456317259124\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.15871338878856\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.4699243559267\n",
            "Iteration 1000 | Accuracy: 74.57142857142857 | Loss:333.8526323472914\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.912623563965\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.30841044780055\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.32127994926094\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.76959185637764\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.41122572422415\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:424.69802585618834\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.03367137937073\n",
            "##################################################\n",
            ">epoch=363, lrate=0.300, error=456.389\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.4023221576012086\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.256163636107143\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.436228328997885\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.67718531330514\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.48834483433178\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.18277721124879\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.04389202751634\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.1709403162983\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.25952884499594\n",
            "Iteration 450 | Accuracy: 76.07142857142857 | Loss:152.73063378389688\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.62815913404378\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.63924901430377\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.15253686817766\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.21365024555243\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.62410455794034\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.44236922439248\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.65161912392114\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.55066375051825\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:302.0539137626825\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.35604670094335\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.728002064804\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:346.78427080621196\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.1718032331466\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.2031496626611\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.65207023360665\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.3015889553749\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.58026475217537\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.9266792405119\n",
            "##################################################\n",
            ">epoch=364, lrate=0.300, error=456.291\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.3883345290834805\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.23803476515659\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.39505120738107\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.67703856513371\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.46917713452315\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.18608514193993\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.03988086133816\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.17359583238381\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.25691362727886\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:152.73530479155986\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.63376104251986\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.63477559521624\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.14575808477284\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.19684913829707\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.58997896260033\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.38447360525836\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.57884383105005\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.46938286813685\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.9631399070804\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.25435555033465\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.61613652337763\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.6693438103183\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.0487730416115\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.0988077590813\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.5489144050694\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.205978616929\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.47659771146374\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.83504194573794\n",
            "##################################################\n",
            ">epoch=365, lrate=0.300, error=456.207\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3749793790803206\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.220769803540282\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.35686273125566\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.68101744293901\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.4558527645311\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.19757642286031\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.04518396150331\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.18789760569452\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.26623814985254\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:152.75014385332832\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.65402409539433\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.6443929763209\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.15409003473744\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.19461805054533\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.57172838857807\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.34138927795848\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.5213069162981\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.4052666546912\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.8898150122879\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.16693957623255\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.5200280850101\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:346.5707866219358\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:367.9422937682542\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:381.01116383908743\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.4624827985174\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.12656930990755\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:424.38916817451076\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:440.7609624407395\n",
            "##################################################\n",
            ">epoch=366, lrate=0.300, error=456.142\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.362536803074353\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.204307447517646\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.32200275238528\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.68872666172003\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.4483492225839\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.21735712381532\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.06003721633101\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.21389232651397\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:132.28773080202748\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.77471073549447\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.69005282171366\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.66870979166632\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.17997450429777\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.20963208258706\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.5725709277228\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.31680685862645\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.4827234510862\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.363825845024\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.83933396824085\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.0968795347487\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.44444364962663\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.49344652821253\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8572169758623\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:380.94489966380723\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.39678551712706\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.06713785222786\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.32177056857984\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:440.70829899728665\n",
            "##################################################\n",
            ">epoch=367, lrate=0.300, error=456.097\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3513032650662304\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.188405340697415\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.29062969835591\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.69947016486283\n",
            "Iteration 200 | Accuracy: 74.64285714285714 | Loss:69.44646752630975\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.24515867086139\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.0845079084422\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.25151899767665\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.32157549182915\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.8082800951513\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.7431237324825\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.70809130773446\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.22682966961614\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.24575391261834\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.59731344181176\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.3162492190982\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:267.46870402525013\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.35382893306314\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.82025248188455\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:319.0488374883176\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.3974703494396\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.4459300171129\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8021915762449\n",
            "Iteration 1150 | Accuracy: 72.78571428571429 | Loss:380.9082971580896\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.3592992590936\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.0349073064645\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.2817664837033\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:440.6844384063154\n",
            "##################################################\n",
            ">epoch=368, lrate=0.300, error=456.080\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3416158292163907\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.172547625306553\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.2624927747991\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.71214201402841\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.44978898008362\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.28017603319343\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.11842717524965\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.30054855299493\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.36790888109826\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:152.84967761321394\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.81460828999326\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.76251037505543\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:209.2992070575931\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.30860968556988\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:241.65309295684364\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.3479066010475\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.48766367790586\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.3890693383907\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.84600944942696\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.0298244707285\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.39363332867595\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.44492787135613\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.79429583436087\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:380.9177255659063\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.36558338826137\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.0453617286452\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.28509952476907\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:440.7051892823299\n",
            "##################################################\n",
            ">epoch=369, lrate=0.300, error=456.106\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.333873357738701\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.15578634035672\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.23634094738285\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:57.72502988917308\n",
            "Iteration 200 | Accuracy: 74.28571428571429 | Loss:69.45756090805291\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.32075887857198\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.16114147179083\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.36044745820922\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.42674979487091\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:152.8970504161477\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:173.9047564689841\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.83077335207878\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.40074052429915\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.40447442543308\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:241.74850059422823\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.42170179751258\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.55007745054877\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.4886173293987\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.9352005212556\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.04867922828686\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.45792510222384\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.52429665336797\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.8695345976984\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.00788595224725\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.44999747543903\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.13378201622106\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.36803615650246\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:440.8066939715122\n",
            "##################################################\n",
            ">epoch=370, lrate=0.300, error=456.213\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3280239915176075\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.136321377513017\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.20875423576536\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.735455147676404\n",
            "Iteration 200 | Accuracy: 74.21428571428571 | Loss:69.46834716299902\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.36368419136137\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.21044263849424\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.42984999697791\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.49733509174655\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.94749174102145\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.0050642828887\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:192.90496226900592\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.52098438962946\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.52768459729967\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.88159573617867\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.53650952023224\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.6560937781613\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.6628679929427\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.0981486517451\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:319.10590704683926\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:333.6125000910662\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:346.7442568609185\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.10331419738117\n",
            "Iteration 1150 | Accuracy: 72.92857142857143 | Loss:381.2531301362928\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.6825739084766\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.37220545597535\n",
            "Iteration 1300 | Accuracy: 75.85714285714286 | Loss:424.6029282808631\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.06425845671833\n",
            "##################################################\n",
            ">epoch=371, lrate=0.300, error=456.480\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.320161804250112\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.109645752779738\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.17541159890511\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73892194564164\n",
            "Iteration 200 | Accuracy: 74.21428571428571 | Loss:69.47808991892673\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.3994763086844\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.255336163645\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.50064551131014\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.57087431770802\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:152.99277750319337\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.07095775882127\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.94497348046846\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.5982664431791\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.61766843316107\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.99640554826618\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.63385966106532\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.74941916196497\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.85103799436337\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:302.27594706940505\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.1548616599864\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.78138976489464\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0996286860441\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.5217621172711\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.68802612613894\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:401.0681826455567\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.7548698164824\n",
            "Iteration 1300 | Accuracy: 75.64285714285714 | Loss:424.98399662260545\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.47641162214336\n",
            "##################################################\n",
            ">epoch=372, lrate=0.300, error=456.912\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3078658181415463\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.071971166290297\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.137678333160665\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73329034547521\n",
            "Iteration 200 | Accuracy: 74.0 | Loss:69.4798001466419\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.40843983214161\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.26960911825437\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.54812172982692\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.6211577096543\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.01337432763202\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.03656093750337\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.8882852700364\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.55131093922162\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.57829359039926\n",
            "Iteration 700 | Accuracy: 74.71428571428571 | Loss:241.99213855386256\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.60680912346444\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.72384409552916\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.90449338485683\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.3232517349257\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.12093675476063\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.7865043437125\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:347.2422228203798\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.6541107184345\n",
            "Iteration 1150 | Accuracy: 72.85714285714285 | Loss:381.8206569419621\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.15468352852395\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.83723249093\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.06171556716686\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.59322721951816\n",
            "##################################################\n",
            ">epoch=373, lrate=0.300, error=457.038\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.3033583124585133\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.039011113914892\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.105348490165504\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.72834503486874\n",
            "Iteration 200 | Accuracy: 73.92857142857143 | Loss:69.49209713385768\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.44014907255371\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.3126325960079\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.62588823839297\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.7066224331027\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.04702567669545\n",
            "Iteration 500 | Accuracy: 74.07142857142858 | Loss:173.9517583148859\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:192.7875982126277\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.4365012959471\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.46126809576484\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:241.93003224112573\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.52029734106245\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.64352941389893\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:286.89302030743113\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.31209168399477\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.08678952964436\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.71280688118156\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:347.20381576454406\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.6096800932852\n",
            "Iteration 1150 | Accuracy: 73.0 | Loss:381.7877975027979\n",
            "Iteration 1200 | Accuracy: 73.5 | Loss:401.1133685741655\n",
            "Iteration 1250 | Accuracy: 73.92857142857143 | Loss:413.8141538151945\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.02410640259666\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.608965310701\n",
            "##################################################\n",
            ">epoch=374, lrate=0.300, error=457.047\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.3091457264373754\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.014508753029155\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.084911946823894\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.72363641665787\n",
            "Iteration 200 | Accuracy: 73.85714285714286 | Loss:69.52052997182588\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.50609026451065\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.40379501503348\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.75370874225028\n",
            "Iteration 400 | Accuracy: 75.57142857142857 | Loss:132.84857918405459\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:153.10757169484202\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.9320254827611\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:192.76862849380427\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.41894099006797\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.41711578348952\n",
            "Iteration 700 | Accuracy: 74.64285714285714 | Loss:241.96129446395085\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:255.5254698513043\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.6563344607963\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.948741196406\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:302.37982838972124\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.22160439482286\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.71223971143166\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.10438133860424\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.585104400069\n",
            "Iteration 1150 | Accuracy: 73.14285714285714 | Loss:381.81944774047\n",
            "Iteration 1200 | Accuracy: 73.42857142857143 | Loss:401.1825464236947\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.93260373531376\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.11818690408563\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.7655160007481\n",
            "##################################################\n",
            ">epoch=375, lrate=0.300, error=457.179\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.3328012803038407\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.0054780970098\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.07678582787834\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.73388799210075\n",
            "Iteration 200 | Accuracy: 73.57142857142858 | Loss:69.57876231887658\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:86.60940897592762\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.55029859322545\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.94195893336303\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.05896884723686\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:153.21552711804205\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.08623918368409\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.91793168077555\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.6436208230875\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.6184941535401\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:242.22772942881033\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:255.74358247591454\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.8858700064277\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.19365697543907\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:302.65642091671975\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.7225172478325\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.9285674741779\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0660234047123\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.4806499118932\n",
            "Iteration 1150 | Accuracy: 73.14285714285714 | Loss:381.73332636472105\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:401.1662278681622\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:413.9654710727719\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.11943138789115\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.8242899288359\n",
            "##################################################\n",
            ">epoch=376, lrate=0.300, error=457.206\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.365424436353983\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.012099307302996\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.08080903192943\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.75465215486249\n",
            "Iteration 200 | Accuracy: 73.21428571428571 | Loss:69.66707110345199\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:86.75675100531431\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.75771301522246\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:121.189356374016\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.34341650745083\n",
            "Iteration 450 | Accuracy: 75.21428571428571 | Loss:153.36327136367862\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.31084656891701\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.12229399740298\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.90906941528516\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.88350144468725\n",
            "Iteration 700 | Accuracy: 74.71428571428571 | Loss:242.52144146367206\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.96888836860862\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:268.1267796138477\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.4265578330751\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:302.9109927412464\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.1966446669937\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:334.2638786647981\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.38593543831\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:368.8166848363012\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.1160676688155\n",
            "Iteration 1200 | Accuracy: 73.35714285714286 | Loss:401.56251841303344\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.3872291783006\n",
            "Iteration 1300 | Accuracy: 75.78571428571429 | Loss:425.5104790331215\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:442.2728898431314\n",
            "##################################################\n",
            ">epoch=377, lrate=0.300, error=457.616\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.414993280026897\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.047177290677475\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.09191117450916\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.81083327155715\n",
            "Iteration 200 | Accuracy: 73.42857142857143 | Loss:69.73044127215553\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.78024032581472\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.81569631998133\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:121.28041569105508\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.45157469014663\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:153.39305636772403\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:174.35190535484452\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.12820046313345\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.9005836951714\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.8766231747436\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.5046644738905\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:255.88574290667347\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:268.05033262731007\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.34705195761734\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.8278772255761\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:320.18964366417845\n",
            "Iteration 1000 | Accuracy: 75.07142857142857 | Loss:334.2854202423123\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.40910434953895\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.849359868329\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.17528095431703\n",
            "Iteration 1200 | Accuracy: 73.28571428571429 | Loss:401.62252420656904\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.46414869754943\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.5621041881942\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.3807669483959\n",
            "##################################################\n",
            ">epoch=378, lrate=0.300, error=457.671\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.4749639942372343\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.12113175039645\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.12553154327287\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:57.89350394249022\n",
            "Iteration 200 | Accuracy: 73.85714285714286 | Loss:69.77356937322908\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.7112289212213\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.75144813310115\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.22560650670835\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.39532900034007\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.33940846627112\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:174.305684142179\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:193.0455914542097\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.79740624048742\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.77013588149305\n",
            "Iteration 700 | Accuracy: 74.85714285714286 | Loss:242.39137616548408\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.7205616366686\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.8901803391198\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:287.1886415331816\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.6591002704157\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:320.0509149311998\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:334.21332916725277\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.3424048014681\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:368.79457496479654\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1457557148618\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.5828766041181\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.43480615685576\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.5097545613291\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.38078027080604\n",
            "##################################################\n",
            ">epoch=379, lrate=0.300, error=457.613\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.5304181036106752\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.21910925351643\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.191023143093254\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:57.96995027159836\n",
            "Iteration 200 | Accuracy: 74.35714285714286 | Loss:69.78002554745412\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.52919655509596\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:103.55460468862977\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.00585336042764\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.17220017643103\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.19753293395755\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.17379499746406\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:192.88205451773518\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.6309283489089\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.58965975665484\n",
            "Iteration 700 | Accuracy: 74.78571428571429 | Loss:242.2156882510879\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.51022766232833\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.6885071606481\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.9891003286643\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.4480277091625\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.85219931516815\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:334.1124035941646\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.26607686094883\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.740845298434\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.129077034315\n",
            "Iteration 1200 | Accuracy: 73.57142857142858 | Loss:401.54141604791124\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.3975349091922\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.45403597599454\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.3656982194348\n",
            "##################################################\n",
            ">epoch=380, lrate=0.300, error=457.554\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.5684636907392209\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.310642396945198\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.27804946930367\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.03232007123628\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.77745961033547\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.28167002159482\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.30855021216645\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.7094952378442\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:132.86596722829427\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:153.05677363422637\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:174.00984881824758\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.69449196572833\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:209.44400598862697\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.3749800895222\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:242.0049821785313\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.28304344143126\n",
            "Iteration 800 | Accuracy: 75.85714285714286 | Loss:267.4707968087122\n",
            "Iteration 850 | Accuracy: 75.5 | Loss:286.7783141939088\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.2208158971839\n",
            "Iteration 950 | Accuracy: 75.57142857142857 | Loss:319.6250712486773\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.98307414051555\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:347.1795353810449\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.68685462482034\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1207106858251\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.4972618756791\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.34910471955345\n",
            "Iteration 1300 | Accuracy: 75.71428571428571 | Loss:425.39085707973044\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:442.33125273286134\n",
            "##################################################\n",
            ">epoch=381, lrate=0.300, error=457.487\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.5964022740123862\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.386366880281848\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.37380003408529\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.06615521642851\n",
            "Iteration 200 | Accuracy: 75.35714285714286 | Loss:69.78385343759379\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:86.08376916172756\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.13514674991309\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.4750184700707\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:132.60540230333402\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:152.97865494845001\n",
            "Iteration 500 | Accuracy: 74.21428571428571 | Loss:173.85008085951117\n",
            "Iteration 550 | Accuracy: 72.64285714285714 | Loss:192.50946436580327\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.18829198723256\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.09302832191037\n",
            "Iteration 700 | Accuracy: 74.92857142857143 | Loss:241.6860003193686\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:254.96777624018807\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.1462606980779\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:286.4798590452909\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.88636479073625\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:319.29421373752416\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.65983891285555\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.85060671898873\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:368.37546209742266\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.8423403695375\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:401.2071467368161\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:414.0457030055712\n",
            "Iteration 1300 | Accuracy: 75.57142857142857 | Loss:425.06130636718024\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:442.03076512143633\n",
            "##################################################\n",
            ">epoch=382, lrate=0.300, error=457.135\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.637530472621072\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.47567780350985\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.49338972412915\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:58.07272426672367\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.80879207513202\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.01551883482095\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.02084976084753\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:120.31553977559717\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.4384551655436\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:152.98577013572842\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:173.91475380936956\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:192.53961659414068\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:209.17087188930117\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.05648263952068\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.5500154104545\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:254.84669951693257\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:266.99252495985144\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.34624199273253\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.6913475317898\n",
            "Iteration 950 | Accuracy: 75.64285714285714 | Loss:319.0234385216441\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.31281448843396\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.4471726873265\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:367.97939269604814\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.473005259018\n",
            "Iteration 1200 | Accuracy: 73.71428571428571 | Loss:400.85451029283774\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.66399890908207\n",
            "Iteration 1300 | Accuracy: 75.5 | Loss:424.6292467341947\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.6313180469289\n",
            "##################################################\n",
            ">epoch=383, lrate=0.300, error=456.659\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.6876054243863232\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.591888391103236\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.64870825218957\n",
            "Iteration 150 | Accuracy: 75.71428571428571 | Loss:58.11574627582714\n",
            "Iteration 200 | Accuracy: 75.35714285714286 | Loss:69.90475968195133\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:86.1178920017642\n",
            "Iteration 300 | Accuracy: 76.28571428571429 | Loss:103.01765053021305\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:120.30101235123323\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:132.47800282634904\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:153.16931829686538\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.411334640138\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:193.06903016327473\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:209.67317533757657\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.42539991876365\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:241.81508265365974\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.12203084285136\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.2419017692148\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.5427470058749\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:301.8136907543495\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:318.96548770569063\n",
            "Iteration 1000 | Accuracy: 74.71428571428571 | Loss:333.2900118608758\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:346.43226110989525\n",
            "Iteration 1100 | Accuracy: 75.64285714285714 | Loss:367.9645522719196\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:381.52104983731715\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.90885083231586\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.66078915131817\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:424.5758335074469\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.5945469392489\n",
            "##################################################\n",
            ">epoch=384, lrate=0.300, error=456.559\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7166151348741643\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.68487615624825\n",
            "Iteration 100 | Accuracy: 76.21428571428571 | Loss:39.77158272612467\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:58.237428104090974\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:70.08595102326196\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.317176581493\n",
            "Iteration 300 | Accuracy: 76.64285714285714 | Loss:103.13264310717875\n",
            "Iteration 350 | Accuracy: 76.78571428571429 | Loss:120.45786651642872\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:132.69904132479687\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:153.51034197167724\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.64332340198763\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:193.30713204848092\n",
            "Iteration 600 | Accuracy: 75.14285714285714 | Loss:209.82068927540436\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.51418955870508\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:241.78127721207784\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:255.092402746672\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.18817901576904\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.32439345945284\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.5112440456784\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:318.4791274331613\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:332.92140018307265\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.1071774329197\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:367.6324107719011\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.29229881016323\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.694002075277\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.3663009843263\n",
            "Iteration 1300 | Accuracy: 75.28571428571429 | Loss:424.2319554835157\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.25709371847444\n",
            "##################################################\n",
            ">epoch=385, lrate=0.300, error=456.152\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7454478830474724\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.79646974219008\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.89931017899778\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:58.394465876283604\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:70.31639084455247\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.5720733341468\n",
            "Iteration 300 | Accuracy: 76.5 | Loss:103.28892400938878\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:120.77591274995766\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.1035904573632\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.03166848367243\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.79022753362528\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:193.43438200642828\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.01259793591348\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.69878642479304\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:241.96777355628842\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.27822931156214\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.37043210351203\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.4816836764936\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.62175547836245\n",
            "Iteration 950 | Accuracy: 75.42857142857143 | Loss:318.4860698635934\n",
            "Iteration 1000 | Accuracy: 74.78571428571429 | Loss:333.0130632010353\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.2466751478479\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.79300218653884\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.51953819368595\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:400.9469991588283\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.5834865982379\n",
            "Iteration 1300 | Accuracy: 75.35714285714286 | Loss:424.4149796968191\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.45143507292056\n",
            "##################################################\n",
            ">epoch=386, lrate=0.300, error=456.316\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.7568272634184474\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.846757647102983\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.95144386319332\n",
            "Iteration 150 | Accuracy: 75.21428571428571 | Loss:58.41820352119065\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:70.3685500721894\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.64676190931745\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.31471824857478\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:120.96333652200363\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.35175917013328\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.31480801309627\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.85676156837414\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:193.47758330387464\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.16433677004255\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:225.8830732377439\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.2176261181695\n",
            "Iteration 750 | Accuracy: 76.42857142857142 | Loss:255.51761206089196\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.62314289494856\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.8675218060255\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.9797844438267\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.74970324580124\n",
            "Iteration 1000 | Accuracy: 74.92857142857143 | Loss:333.34804221236425\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.6545247040697\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.2458122128856\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.00429692811457\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:401.44666205229174\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.08332839578185\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.8995709945167\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.95328361492716\n",
            "##################################################\n",
            ">epoch=387, lrate=0.300, error=456.815\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.758320675696666\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.851554340221167\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.95007028782442\n",
            "Iteration 150 | Accuracy: 75.28571428571429 | Loss:58.38585864373364\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:70.3213419622008\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.60838643443475\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.26878529488381\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.01222785870037\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.4359110782344\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.39868494684322\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:174.8808087495814\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.48919358013043\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:210.16371716656914\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.8375100865893\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.19458553067454\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.4971171200951\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.6035738610085\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.88032554657536\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.95994749256056\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.66103651844105\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.3222410880237\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:346.69260108698336\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.2893622543288\n",
            "Iteration 1150 | Accuracy: 73.21428571428571 | Loss:382.0824328301111\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.5237247075594\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.15323213397284\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.94934780584714\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.01772802080023\n",
            "##################################################\n",
            ">epoch=388, lrate=0.300, error=456.868\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.57142857142857 | Loss:1.762547104007464\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.8702779514685\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.96601801946799\n",
            "Iteration 150 | Accuracy: 75.35714285714286 | Loss:58.401477041570764\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:70.32464872722744\n",
            "Iteration 250 | Accuracy: 76.57142857142857 | Loss:86.6226770306933\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.26669180515732\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.14793332206906\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.61944455629043\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.58739767515334\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.9620001898001\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.54999244599713\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:210.21997585292345\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.86677530945101\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.2577357978031\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:255.56103667690962\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.67263555179636\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:286.9948816185174\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.04384551051027\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.68459472281705\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.40612041011974\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:346.8270560102989\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.3939612178199\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.18856764042835\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.62272376639265\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.2543042186983\n",
            "Iteration 1300 | Accuracy: 75.21428571428571 | Loss:425.0292102894522\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.11457213760514\n",
            "##################################################\n",
            ">epoch=389, lrate=0.300, error=456.950\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.7683863575067986\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.892065810014387\n",
            "Iteration 100 | Accuracy: 76.28571428571429 | Loss:39.98352964470457\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.408118488863344\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:70.31533868093871\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.62367632751324\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:103.25643553269282\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.271960781667\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.8070721124572\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.78579582105607\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.0699016022045\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:193.638469757699\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:210.28052004100647\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.88281305044038\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.30029274164914\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.60757845312145\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.72034349108077\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.0677077159286\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.0855354231021\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:318.677786705657\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.45208456993475\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:346.90146612173316\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.4107013561903\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.18857105579133\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.6132636964509\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.2413295727769\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.9960540434382\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:442.09781829937805\n",
            "##################################################\n",
            ">epoch=390, lrate=0.300, error=456.918\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7728614840124173\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.909529775259408\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.99582674272626\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:58.401965497499546\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.29650886570687\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.61553737974444\n",
            "Iteration 300 | Accuracy: 76.5 | Loss:103.23424041521979\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.39516304984151\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:133.99643239307818\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.9954462481241\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:175.1874554106429\n",
            "Iteration 550 | Accuracy: 73.28571428571429 | Loss:193.7359674458653\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:210.34494743090244\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.9060694926902\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.35002498334876\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.6619305721451\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.77461374377276\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.1402375565814\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.12895799089137\n",
            "Iteration 950 | Accuracy: 75.14285714285714 | Loss:318.6859736939877\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.5022502451741\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:346.96520479255844\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.4180250750959\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.17863794223825\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.5911649710391\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.2014533433478\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:424.94103560512735\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.0571538049706\n",
            "##################################################\n",
            ">epoch=391, lrate=0.300, error=456.866\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.7742474236024335\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.915018642905054\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.99452378455486\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:58.37987362624644\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.26547198629076\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.59385281682677\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.19654663432956\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.50511091375755\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.15344265101416\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:155.18177709346372\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.2984642242642\n",
            "Iteration 550 | Accuracy: 73.21428571428571 | Loss:193.82983284331186\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:210.39964657019542\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.92302096051327\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.3936676472575\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.71091883122338\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.82179676684257\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:287.19687060140734\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1592804471151\n",
            "Iteration 950 | Accuracy: 75.14285714285714 | Loss:318.69541606450827\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.5404565816997\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:347.0085169524004\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.42152425373075\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.1884659551606\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.58307323922634\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.1531387382939\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.883533348795\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:442.0096210048146\n",
            "##################################################\n",
            ">epoch=392, lrate=0.300, error=456.815\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.7719972679146125\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.907608908055117\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.9789300022787\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.34506062891499\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.22532966984723\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.56242503253624\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.14761283956574\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.59632348256315\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.2711610037427\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:155.3441581194458\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:175.39938489779317\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:193.9202206477693\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.44568053820976\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.9413961985189\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.4377378127001\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.76060202313772\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.8679805103984\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.2421527352371\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1823528419592\n",
            "Iteration 950 | Accuracy: 75.07142857142857 | Loss:318.7125225398059\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.5714041373748\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.0390202702629\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:368.42693736443846\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.231730392627\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.59967801389433\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.1061100366367\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:424.8348690195025\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.9644030956093\n",
            "##################################################\n",
            ">epoch=393, lrate=0.300, error=456.776\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.765076289066967\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.88622920021776\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.94826590563593\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.29570589136745\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.1723559954603\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:86.51798323883783\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:103.08528956262386\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:121.65058693752242\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:134.3612991353679\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:155.50243622683348\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.47902500183284\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:194.00178278854608\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.47294316206577\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.960999193358\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.473470459001\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.7984446176429\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.9030141026814\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.263260580672\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1878700341315\n",
            "Iteration 950 | Accuracy: 75.0 | Loss:318.733463743815\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:333.58709345288077\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:347.04582036410363\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.42427395764065\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.29994017464156\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.6318450390317\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.0562973927461\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:424.79769584949236\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.92135902565263\n",
            "##################################################\n",
            ">epoch=394, lrate=0.300, error=456.756\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7500019544628307\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.843314005840003\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.89615897601323\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.2283501181883\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.1019230177991\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.45461346094939\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.00548309026664\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.64377802710568\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:134.3881051449761\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:155.60545497105034\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.4952701266113\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:194.0403043332197\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.43612270260584\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.94595285887394\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.4492111534135\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.766463727826\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.8757411710399\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.20843531152866\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.1251787781009\n",
            "Iteration 950 | Accuracy: 75.0 | Loss:318.71661515568195\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.5425652067392\n",
            "Iteration 1050 | Accuracy: 74.5 | Loss:346.9740634368403\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:368.36834041189053\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.35311890327915\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:401.6261626876434\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.9506228278045\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:424.7366356457913\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.83792020538374\n",
            "##################################################\n",
            ">epoch=395, lrate=0.300, error=456.716\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.716604680921661\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.758333405489424\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.80562864771054\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.13885084671613\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:70.01182671600527\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.36620534619885\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.91184731128715\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.59056221867402\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.32830657624183\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:155.5916510666315\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.44886485352282\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:194.03278389073972\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.3453171183722\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.89372607041463\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.3544296724784\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.65545539042867\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.7751856730646\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:287.0530158139257\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.96555206278305\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.62582500596096\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.410790795544\n",
            "Iteration 1050 | Accuracy: 74.42857142857143 | Loss:346.79554520030007\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.2026468993791\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.2959643568873\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:401.54758061795746\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.78599097406396\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.6308989403945\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:441.71103711262265\n",
            "##################################################\n",
            ">epoch=396, lrate=0.300, error=456.623\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.6850417478028743\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.69685795690336\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.75223852981109\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.06564866506423\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.92987973385796\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:86.28945644315846\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:102.83261637160582\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:121.54482550207372\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.25792777362952\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:155.51105202524684\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.4455689310883\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:194.06231906714743\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.27026013630186\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.8394474714084\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.26349932565702\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.54831714733052\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.672889961678\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.867692151801\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:301.77503721753595\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.4952846598703\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.2505375744877\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.59500878974325\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:367.9795392493189\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.1440881708719\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.41734395508234\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.62133964607483\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:424.5349449563931\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.6021476726631\n",
            "##################################################\n",
            ">epoch=397, lrate=0.300, error=456.529\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.6684563493435194\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.66459624496214\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.72724887391053\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:58.003512663738924\n",
            "Iteration 200 | Accuracy: 74.85714285714286 | Loss:69.86500230011207\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.23045492397561\n",
            "Iteration 300 | Accuracy: 76.42857142857142 | Loss:102.74328570630954\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.50580259517076\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.2029264761009\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:155.416637725014\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:175.53962789476932\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:194.18772964350487\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.23209755752939\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.7968097550153\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.1971216416932\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:255.4690891909341\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.58527302021366\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.64571872922056\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.5492007112631\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.3187196460659\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:333.056880231438\n",
            "Iteration 1050 | Accuracy: 74.35714285714286 | Loss:346.3724125762879\n",
            "Iteration 1100 | Accuracy: 75.14285714285714 | Loss:367.7203207239366\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:381.94174074046396\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:401.1906936157478\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.37523756739745\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:424.324935081344\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:441.3827640498071\n",
            "##################################################\n",
            ">epoch=398, lrate=0.300, error=456.313\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.6582963240628898\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.653059662443745\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.716966629559934\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.93652842704121\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.79881423257716\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:86.16926616395101\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.62585396834928\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:121.44326375692762\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:134.13235517930548\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:155.30471217742377\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:175.64472729713125\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:194.3039480946159\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.38277799940505\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.92278206976866\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.33269073158655\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.55990831383946\n",
            "Iteration 800 | Accuracy: 76.21428571428571 | Loss:267.6862371618359\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:286.79100442338637\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.69862582856814\n",
            "Iteration 950 | Accuracy: 74.71428571428571 | Loss:318.517846940113\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.21883330771414\n",
            "Iteration 1050 | Accuracy: 74.28571428571429 | Loss:346.506886863436\n",
            "Iteration 1100 | Accuracy: 75.21428571428571 | Loss:367.8259582657237\n",
            "Iteration 1150 | Accuracy: 73.42857142857143 | Loss:382.0978857257657\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.29198947826256\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:413.4571568359148\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:424.4115459758575\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.4675094531218\n",
            "##################################################\n",
            ">epoch=399, lrate=0.300, error=456.403\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.653456500441866\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.649122251591574\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.71427713089186\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.89197781341966\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.73798202394454\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.10752551726627\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.52362621471893\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:121.35964205251712\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.0292468796595\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:155.1357394359555\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.59919396670762\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:194.23261062454682\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.58355438277596\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:226.06318430714987\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.5153289000359\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.6824622236922\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.8311642061361\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:287.05751193863654\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.9847113977314\n",
            "Iteration 950 | Accuracy: 74.64285714285714 | Loss:318.87754972803253\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.53660570467065\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.80341665902245\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.10765325157683\n",
            "Iteration 1150 | Accuracy: 73.35714285714286 | Loss:382.4148912119762\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.53909053112756\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:413.68889812767674\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.6205729777709\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.6809367242277\n",
            "##################################################\n",
            ">epoch=400, lrate=0.300, error=456.635\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.6418228390062812\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:16.624093831923318\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.69814984674302\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.8572501999713\n",
            "Iteration 200 | Accuracy: 74.92857142857143 | Loss:69.66860455401425\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:86.03273421028284\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.43661351727529\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.24749132783101\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.8694510079082\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.90910261585717\n",
            "Iteration 500 | Accuracy: 74.35714285714286 | Loss:175.3846508877759\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:193.9892170576881\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:210.51003659104933\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.93770823656627\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.40035305568244\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.5321320219063\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.68217412326277\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:286.9099488088829\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.8442589629908\n",
            "Iteration 950 | Accuracy: 74.57142857142857 | Loss:318.78612727287725\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.4344473344766\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.6918969015784\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:367.98786152179315\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.309681259638\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.39552513275174\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:413.54412855255316\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4596650270075\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:441.5227313958855\n",
            "##################################################\n",
            ">epoch=401, lrate=0.300, error=456.490\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.6329907150650222\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:16.607483625331405\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.68421119056739\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.82512097966748\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.61072274926651\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:85.96701881426986\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.35254539999036\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.16641434843022\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78059968015208\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.74430087970651\n",
            "Iteration 500 | Accuracy: 74.28571428571429 | Loss:175.1571865304533\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.72655673198443\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:210.60205833151565\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.97660467807245\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:242.42517726875383\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.53003473774217\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.67684461363405\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.88554523286575\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.82267616142445\n",
            "Iteration 950 | Accuracy: 74.78571428571429 | Loss:318.8110718863129\n",
            "Iteration 1000 | Accuracy: 74.85714285714286 | Loss:333.4544688011419\n",
            "Iteration 1050 | Accuracy: 73.92857142857143 | Loss:346.71107921366223\n",
            "Iteration 1100 | Accuracy: 75.28571428571429 | Loss:368.00746884396665\n",
            "Iteration 1150 | Accuracy: 73.28571428571429 | Loss:382.32863743280706\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.3502790088946\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.51920634351285\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4125814536815\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:441.48292635523154\n",
            "##################################################\n",
            ">epoch=402, lrate=0.300, error=456.451\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.636765137169399\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:16.615446479347657\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.68638504778429\n",
            "Iteration 150 | Accuracy: 75.5 | Loss:57.831182614298115\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.6051590126925\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:85.94431063548826\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.31853085652945\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.14161378563375\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.773173952209\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.66378268036846\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.99997253978472\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.56530825709567\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:210.71467941771752\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:226.1229999973393\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:242.53408250320305\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.62875362509843\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.7755329935599\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.9406866363211\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:301.8699201913605\n",
            "Iteration 950 | Accuracy: 74.85714285714286 | Loss:318.93124630077773\n",
            "Iteration 1000 | Accuracy: 75.0 | Loss:333.59811306807023\n",
            "Iteration 1050 | Accuracy: 74.07142857142858 | Loss:346.90811917548666\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.1748063910414\n",
            "Iteration 1150 | Accuracy: 73.5 | Loss:382.4862049166547\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.55276986879335\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.7369510081084\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:424.63604516243083\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:441.705177108904\n",
            "##################################################\n",
            ">epoch=403, lrate=0.300, error=456.658\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.0 | Loss:1.658154119187069\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.66681633954397\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.721642882339346\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.905080634887575\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.69353461148495\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:86.01230244860018\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:102.37605400603381\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.26888872827575\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.97631685591068\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.75562240699196\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.12696296273657\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.70395648382924\n",
            "Iteration 600 | Accuracy: 74.42857142857143 | Loss:211.23039673924313\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:226.7331812625382\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:243.1302943779124\n",
            "Iteration 750 | Accuracy: 75.85714285714286 | Loss:256.23145126086814\n",
            "Iteration 800 | Accuracy: 75.92857142857142 | Loss:268.4132730631461\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:287.58168953430334\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:302.51163196977035\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:319.6756074252894\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:334.4068627400394\n",
            "Iteration 1050 | Accuracy: 74.57142857142857 | Loss:347.87065633156834\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:368.99637927830366\n",
            "Iteration 1150 | Accuracy: 73.71428571428571 | Loss:383.13840858243486\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:402.3484846821768\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.5395997549359\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.45789295669624\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:442.53282633382173\n",
            "##################################################\n",
            ">epoch=404, lrate=0.300, error=457.477\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.661820610042898\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.683041489713386\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.69987956143714\n",
            "Iteration 150 | Accuracy: 75.42857142857143 | Loss:57.900085335364516\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.71079992538739\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.98910017526126\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.32367072372085\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:121.32173362954524\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.0818755816246\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.7638782039278\n",
            "Iteration 500 | Accuracy: 74.57142857142857 | Loss:175.23428002357798\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.81206827578555\n",
            "Iteration 600 | Accuracy: 73.71428571428571 | Loss:211.65347596899142\n",
            "Iteration 650 | Accuracy: 74.14285714285714 | Loss:227.2249796269661\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:243.6525798090798\n",
            "Iteration 750 | Accuracy: 75.78571428571429 | Loss:256.78109752104405\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:268.99744694680106\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:288.12647125197486\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:303.05637710667264\n",
            "Iteration 950 | Accuracy: 75.28571428571429 | Loss:320.2758290095933\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:335.02990053252375\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:348.5462665731299\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.5506505170376\n",
            "Iteration 1150 | Accuracy: 73.78571428571429 | Loss:383.5285180129198\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:402.63601495423455\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:414.8379556959809\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:425.7542837424652\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:442.8460407002963\n",
            "##################################################\n",
            ">epoch=405, lrate=0.300, error=457.795\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.662466368311813\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.706326987507016\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.68736311436325\n",
            "Iteration 150 | Accuracy: 75.57142857142857 | Loss:57.84500785151608\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.6415282395697\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.89773579194664\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.26588039796538\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:121.29099600667759\n",
            "Iteration 400 | Accuracy: 75.64285714285714 | Loss:134.08005535668286\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.70372708895366\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:175.15926414552854\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.73774727694163\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:211.61426784082664\n",
            "Iteration 650 | Accuracy: 74.0 | Loss:227.20955860202685\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:243.6204063745744\n",
            "Iteration 750 | Accuracy: 75.85714285714286 | Loss:256.78682311654154\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:268.9837907868682\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:288.07480800914504\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.99800188490474\n",
            "Iteration 950 | Accuracy: 75.5 | Loss:320.2413385443958\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:335.0021505843012\n",
            "Iteration 1050 | Accuracy: 74.64285714285714 | Loss:348.5026701683686\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:369.4947681044108\n",
            "Iteration 1150 | Accuracy: 73.64285714285714 | Loss:383.503928426151\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:402.4333638489895\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:414.65091537973547\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.522282228909\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:442.63215499713647\n",
            "##################################################\n",
            ">epoch=406, lrate=0.300, error=457.581\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.78571428571429 | Loss:1.6739491263820194\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:16.749526062312\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.696679032672364\n",
            "Iteration 150 | Accuracy: 75.64285714285714 | Loss:57.77029596915337\n",
            "Iteration 200 | Accuracy: 75.0 | Loss:69.52677594744738\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.77019123494782\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:102.23367566786264\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:121.18806338690737\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.99751169341582\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.62047936292933\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:175.02885303622426\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.57429073531972\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:211.3654304717858\n",
            "Iteration 650 | Accuracy: 73.71428571428571 | Loss:226.98148621509466\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:243.34012351868026\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:256.5478013134045\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:268.70872607049756\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:287.7990146939431\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.711706422262\n",
            "Iteration 950 | Accuracy: 75.71428571428571 | Loss:319.9939539608347\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:334.7790328338907\n",
            "Iteration 1050 | Accuracy: 74.71428571428571 | Loss:348.23801172047416\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:369.23069534477116\n",
            "Iteration 1150 | Accuracy: 73.71428571428571 | Loss:383.2816446110572\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.984012992102\n",
            "Iteration 1250 | Accuracy: 73.92857142857143 | Loss:414.2379420129567\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:425.0369482442616\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:442.17458212833435\n",
            "##################################################\n",
            ">epoch=407, lrate=0.300, error=457.100\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.64285714285714 | Loss:1.693266203422017\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.798184717423197\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.70545977197226\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.7283403599963\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.4481661624363\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.66354924996828\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.17775528996535\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:121.04487356297042\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.8722230170928\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.5198212818045\n",
            "Iteration 500 | Accuracy: 74.71428571428571 | Loss:174.85966545961486\n",
            "Iteration 550 | Accuracy: 71.71428571428572 | Loss:193.3460310718056\n",
            "Iteration 600 | Accuracy: 73.64285714285714 | Loss:210.97396427296366\n",
            "Iteration 650 | Accuracy: 74.0 | Loss:226.5704378608803\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.895846707521\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:256.13291769141574\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:268.2556885000849\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.32669584095134\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:302.2130522339073\n",
            "Iteration 950 | Accuracy: 75.85714285714286 | Loss:319.50283278074\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:334.3432141582936\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:347.7617070134087\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:368.7506464309514\n",
            "Iteration 1150 | Accuracy: 74.0 | Loss:382.80571226536296\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:401.44065809792113\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.7408960400091\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.52143592323665\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:441.68066841949803\n",
            "##################################################\n",
            ">epoch=408, lrate=0.300, error=456.569\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.71428571428571 | Loss:1.7079143563743862\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.8194538724376\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.68946647723191\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.73959533442145\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.45141017684662\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.63479597004151\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:102.13224442054579\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.99769062506306\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.85656963825272\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.50010816203724\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.8561413690425\n",
            "Iteration 550 | Accuracy: 71.64285714285714 | Loss:193.29240064956454\n",
            "Iteration 600 | Accuracy: 73.57142857142858 | Loss:210.8925419935677\n",
            "Iteration 650 | Accuracy: 74.07142857142858 | Loss:226.44601759993475\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:242.781947916048\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:256.03087153078604\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:268.14059651384866\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:287.15844919012926\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:302.0214187797233\n",
            "Iteration 950 | Accuracy: 75.92857142857142 | Loss:319.30155791473624\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:334.17274216382725\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:347.5568219243982\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.5691628044874\n",
            "Iteration 1150 | Accuracy: 74.14285714285714 | Loss:382.6816406130235\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:401.35761115161887\n",
            "Iteration 1250 | Accuracy: 74.0 | Loss:413.7096727280986\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:424.4823963904458\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:441.66222342851444\n",
            "##################################################\n",
            ">epoch=409, lrate=0.300, error=456.543\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7106679052039282\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.798361641573177\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.64176784295803\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.7167267380156\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.42504379608751\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.5893291834432\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.10137105411243\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.93302662724064\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.80121448707555\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.494923867529\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.89187989888038\n",
            "Iteration 550 | Accuracy: 71.85714285714285 | Loss:193.28356675611587\n",
            "Iteration 600 | Accuracy: 74.57142857142857 | Loss:210.47131639429315\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.93163310407186\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:242.33870838444105\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.5444451305559\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.6490440266383\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.60752077844063\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.45568819631154\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.7447093976819\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.6605708571599\n",
            "Iteration 1050 | Accuracy: 74.78571428571429 | Loss:347.03555558119257\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:368.04323285456366\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:382.1458368830069\n",
            "Iteration 1200 | Accuracy: 73.64285714285714 | Loss:400.8466255878596\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:413.1785626433336\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.95347247145094\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:441.13732477495194\n",
            "##################################################\n",
            ">epoch=410, lrate=0.300, error=456.026\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7075283198756246\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.79052795664938\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.62599555940436\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.700327039893644\n",
            "Iteration 200 | Accuracy: 75.07142857142857 | Loss:69.41035274870526\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.57814489805334\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.08494859413383\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.89277245011591\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7625346342959\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.4920708024834\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.93091620733648\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.33501975621505\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.07949719904727\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.51264930191053\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.90876662129764\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.0811602773342\n",
            "Iteration 800 | Accuracy: 76.0 | Loss:267.1753972978883\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.0767784522587\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:300.91988489669603\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.21357701440024\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.15528777517414\n",
            "Iteration 1050 | Accuracy: 74.85714285714286 | Loss:346.5250222642149\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.50492477374655\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:381.55259719987913\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:400.2547295526692\n",
            "Iteration 1250 | Accuracy: 74.07142857142858 | Loss:412.54694056338485\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.3321666445163\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.5138627990807\n",
            "##################################################\n",
            ">epoch=411, lrate=0.300, error=455.391\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7100814833964395\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.81427131129125\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.645865402701574\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.72456357035503\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43413735368166\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.60731496808091\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.08822578821088\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.90378517440638\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78052588242522\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4850065797437\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.90146196473643\n",
            "Iteration 550 | Accuracy: 71.85714285714285 | Loss:193.28740140084804\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.25371533900466\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:225.68459550696682\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.07240689478087\n",
            "Iteration 750 | Accuracy: 76.07142857142857 | Loss:255.2462171795952\n",
            "Iteration 800 | Accuracy: 76.07142857142857 | Loss:267.332496484054\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.2074611733216\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:301.0366076257464\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.3292274529512\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:333.2879356325161\n",
            "Iteration 1050 | Accuracy: 74.92857142857143 | Loss:346.647384476006\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.61136703687134\n",
            "Iteration 1150 | Accuracy: 74.28571428571429 | Loss:381.6644594985878\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:400.39158538075986\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:412.68441306633963\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.4746682544511\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6590203014051\n",
            "##################################################\n",
            ">epoch=412, lrate=0.300, error=455.532\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.85714285714286 | Loss:1.7120667913012302\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.82020721678926\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.63717997004581\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.724178051228826\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43642854533135\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.60729872866773\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.07194865363402\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.89211572347438\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78017647250198\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.47240519514563\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.87253411644755\n",
            "Iteration 550 | Accuracy: 71.92857142857143 | Loss:193.24540897139119\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:210.28428472216407\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.70517873753468\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.09460245405862\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:255.26645212818414\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.34575362612304\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:286.1917737282971\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.00847614194834\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.30283079247386\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.2806671407154\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.63158364883816\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.5799770037552\n",
            "Iteration 1150 | Accuracy: 74.21428571428571 | Loss:381.63747757917923\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3939214302913\n",
            "Iteration 1250 | Accuracy: 74.14285714285714 | Loss:412.69005163976675\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.485737401575\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6725411145242\n",
            "##################################################\n",
            ">epoch=413, lrate=0.300, error=455.540\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 75.92857142857142 | Loss:1.714624995826624\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.825843644646373\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.62681678391809\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.72287172918464\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.4393669512521\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.60466431629185\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.05332975504778\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.88059544762298\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78126773967148\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4558803328661\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.83401365948046\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.1906742208353\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:210.35337109806017\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.76579922098094\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.16033244959908\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.33519767421475\n",
            "Iteration 800 | Accuracy: 76.14285714285714 | Loss:267.4081104664349\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.2298966585882\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:301.0334507418441\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.3322143094013\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.32913564436564\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.6690496378868\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.606015144405\n",
            "Iteration 1150 | Accuracy: 74.28571428571429 | Loss:381.6787691337354\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.47237053190196\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.77933894925377\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.579443672293\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.7687489893336\n",
            "##################################################\n",
            ">epoch=414, lrate=0.300, error=455.632\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7172218588493307\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.828746137188418\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.61114685027753\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71654634323237\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43761550820959\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.59459957670394\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.03369525891291\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.86462508834259\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.77749398283152\n",
            "Iteration 450 | Accuracy: 75.92857142857142 | Loss:154.4411321640857\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.80456627844782\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.1464130696629\n",
            "Iteration 600 | Accuracy: 74.14285714285714 | Loss:210.3504362000566\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.7475512684018\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.14881139249215\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.3204566203882\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:267.38765356714816\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.18204291700215\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.97425243207954\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.2813660668704\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.29905352775785\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.628028781314\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.55601682275864\n",
            "Iteration 1150 | Accuracy: 74.42857142857143 | Loss:381.639948188221\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:400.4705851539887\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.78521972072616\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:423.58989093413015\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.78106279734277\n",
            "##################################################\n",
            ">epoch=415, lrate=0.300, error=455.638\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7199156772986997\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.833624543366316\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.59848598506751\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71237187436705\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43673493378574\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.58511455169395\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.01787011347533\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.8503454151921\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7737259293148\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.42858219242575\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.77988657783987\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.10704356009208\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.32677267615298\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:225.70571938264663\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.11404669590755\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.27939865606896\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:267.3412597535371\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.106219681808\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.88814525086775\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:318.20648014956805\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:333.2462094311374\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.5646414922878\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.4848268997222\n",
            "Iteration 1150 | Accuracy: 74.57142857142857 | Loss:381.5764746516278\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.44270305589873\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.7619227917393\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.571393199779\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.76386760174773\n",
            "##################################################\n",
            ">epoch=416, lrate=0.300, error=455.615\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.722653471360539\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.84074550047381\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58918749890751\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71119806766675\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.43738499334272\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.5772477793765\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.00593448256396\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.83798741455819\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.770835501204\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4193082839039\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.75813859248788\n",
            "Iteration 550 | Accuracy: 72.0 | Loss:193.0712777214932\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.28798025637656\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.64706556262846\n",
            "Iteration 700 | Accuracy: 75.0 | Loss:242.06229069266723\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.21896279356557\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.27553556005444\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:286.0083439272292\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:300.780894131265\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.1121378779132\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.1753842090691\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.4850254737279\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.3960105174239\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.4901770680624\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3890202554984\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.7095996273969\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:423.52456231771527\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.71770114953046\n",
            "##################################################\n",
            ">epoch=417, lrate=0.300, error=455.561\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.72548111226933\n",
            "Iteration 50 | Accuracy: 77.07142857142857 | Loss:16.850505118137093\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58347825917471\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.71404112396627\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.44102484790298\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.57230976762222\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.99729825214679\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.82835108840519\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.77072792988048\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.41320926857708\n",
            "Iteration 500 | Accuracy: 74.42857142857143 | Loss:174.73587806438053\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:193.03579055350804\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.2511404239119\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.59007053747536\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:242.01070331237625\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.15840293743855\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:267.2095490898947\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:285.9077660752871\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:300.6715603567493\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:318.01635431353435\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:333.10372025109535\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.40638969415784\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.3062305685011\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.39902166260117\n",
            "Iteration 1200 | Accuracy: 73.85714285714286 | Loss:400.3278739034736\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.64826419661415\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.46929519243025\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.6625641833569\n",
            "##################################################\n",
            ">epoch=418, lrate=0.300, error=455.497\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7284337149541673\n",
            "Iteration 50 | Accuracy: 77.0 | Loss:16.862436787850267\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.58029876482119\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.72045523996539\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.44755575102306\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56973191422672\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.99133115703033\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.82151001723699\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7739135305554\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.4106949201794\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.71428666486216\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:193.00156926583097\n",
            "Iteration 600 | Accuracy: 74.07142857142858 | Loss:210.2144611345316\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:225.53224845760693\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.95763663028706\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.09586124250922\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.1416269307064\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.8031445986486\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.5587986001318\n",
            "Iteration 950 | Accuracy: 76.0 | Loss:317.9174707765711\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:333.02892901133276\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.3263309256414\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:367.2137011191605\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.30253027232175\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.25943214806597\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.578929854004\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.4064895141142\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.5995306599806\n",
            "##################################################\n",
            ">epoch=419, lrate=0.300, error=455.423\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.731363562925913\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.875504584437863\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.578628782892245\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.728920372361856\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.45546099447557\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56797923335809\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.98690486772307\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.81612254604435\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.77912078761685\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.41147053994223\n",
            "Iteration 500 | Accuracy: 74.5 | Loss:174.69354824399628\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.9690082035064\n",
            "Iteration 600 | Accuracy: 74.14285714285714 | Loss:210.17070427535188\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:225.46574340324386\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.89589864293728\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:255.0234240643169\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:267.06385733558034\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.68595015632644\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:300.43423807113305\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:317.8070617653722\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.9425069915314\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:346.2365756152494\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:367.10998153193106\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:381.1923906726377\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.17534366694787\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.493256324641\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.32799958169477\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.520435761285\n",
            "##################################################\n",
            ">epoch=420, lrate=0.300, error=455.333\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7340949648961144\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.888951603279658\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.5780099295389\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.73834544839799\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.46355129994507\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56603134622787\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.98274117005562\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.8109431192986\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78533496621768\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.4147157866851\n",
            "Iteration 500 | Accuracy: 74.64285714285714 | Loss:174.67197386417106\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.93704776291455\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:210.11966158127842\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:225.3904484245535\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.82472116063323\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.94038134207142\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:266.9752392075879\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.554098773881\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:300.2959714674069\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.68321269710634\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.8423665132096\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.1349921700502\n",
            "Iteration 1100 | Accuracy: 75.42857142857143 | Loss:366.99264686865104\n",
            "Iteration 1150 | Accuracy: 74.64285714285714 | Loss:381.06636142985906\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:400.0731699074421\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.38894283404915\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.2316976500238\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.42305462954755\n",
            "##################################################\n",
            ">epoch=421, lrate=0.300, error=455.223\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7365105906116005\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.902221388091853\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.57818625739288\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.74820114658043\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.4711346321908\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56328237047228\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.97795561174202\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.80545599270602\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7921399543528\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.41972752240088\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.648746254242\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.90553127412028\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:210.06254958174372\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.30748154294784\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.74455131440564\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.8472505621524\n",
            "Iteration 800 | Accuracy: 76.5 | Loss:266.8759704189244\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.4068394329424\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:300.1434277490296\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.54548574939344\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:332.7278082129127\n",
            "Iteration 1050 | Accuracy: 75.0 | Loss:346.0204942757246\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.860841499218\n",
            "Iteration 1150 | Accuracy: 74.64285714285714 | Loss:380.92420214164804\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:399.9526645429766\n",
            "Iteration 1250 | Accuracy: 74.21428571428571 | Loss:412.2659389559546\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:423.11760698039575\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:440.3073743097611\n",
            "##################################################\n",
            ">epoch=422, lrate=0.300, error=455.095\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.738501416680483\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.91468641566326\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.57899925602211\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.75812406787425\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.47764527839858\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.5592743391222\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.9720299344505\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.79938860017255\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.7992071298918\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.42607722404298\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.62386694043138\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.87519152496182\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.99911003548806\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.2162264577256\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:241.65426139915243\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.74275609141165\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:266.76442624939284\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.24152178019943\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.97415797163455\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.3916145802019\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:332.59649554860675\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.8903273047085\n",
            "Iteration 1100 | Accuracy: 75.35714285714286 | Loss:366.71216680921606\n",
            "Iteration 1150 | Accuracy: 74.71428571428571 | Loss:380.76410363390033\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:399.8120060388054\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:412.1224535061976\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.984039781295\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:440.1716796485055\n",
            "##################################################\n",
            ">epoch=423, lrate=0.300, error=454.947\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7399637017128837\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.92583943211659\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.580573466631584\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.76811109366748\n",
            "Iteration 200 | Accuracy: 75.14285714285714 | Loss:69.48298607296678\n",
            "Iteration 250 | Accuracy: 77.28571428571429 | Loss:85.55406183374673\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.96477681369336\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.7927433200829\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.80651704546406\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.43351211064976\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.59753208138122\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.8472140170452\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.93018231862166\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:225.1171643960089\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.5534328738084\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.62639182840041\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:266.6396535643407\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:285.0561829956505\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.78641973212774\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:317.22002450988754\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:332.4468651628753\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.7425028211283\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:366.5449428124679\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:380.58490821128265\n",
            "Iteration 1200 | Accuracy: 73.92857142857143 | Loss:399.6499759265954\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:411.95723280116\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.8298668299282\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:440.01479135919\n",
            "##################################################\n",
            ">epoch=424, lrate=0.300, error=454.779\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.740826379879552\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.93546532367107\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.583349237601745\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.77868323217361\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.4877611624148\n",
            "Iteration 250 | Accuracy: 77.28571428571429 | Loss:85.54837087827646\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.95646303590947\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.78600050269362\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8145423497064\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.44187200451776\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.57058915338132\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.82363806381534\n",
            "Iteration 600 | Accuracy: 74.21428571428571 | Loss:209.8576620603792\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:225.0117550978394\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.44253160760775\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.49857564698286\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:266.50165323860256\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:284.8500784648831\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:299.5797046942662\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:317.0301628895098\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:332.2783135053784\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:345.57623682237863\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.35847057656395\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:380.38610860999836\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.46589091804105\n",
            "Iteration 1250 | Accuracy: 74.28571428571429 | Loss:411.7694598037857\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.6544734760449\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:439.8360302731601\n",
            "##################################################\n",
            ">epoch=425, lrate=0.300, error=454.591\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.741051110273862\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.943704348921475\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.58798800054719\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:57.79072098076268\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.49314906073649\n",
            "Iteration 250 | Accuracy: 77.35714285714286 | Loss:85.54343230551925\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.94765143929928\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.77986055524183\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.82401020516576\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.45082077107475\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.5444500440675\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.80734205020383\n",
            "Iteration 600 | Accuracy: 74.28571428571429 | Loss:209.78339992473244\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.90148561183076\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.32217537367856\n",
            "Iteration 750 | Accuracy: 75.92857142857142 | Loss:254.35995300478157\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:266.3507781784013\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:284.62278930548797\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:299.35390180304375\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:316.8212972534161\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:332.08985923402935\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:345.3909723467304\n",
            "Iteration 1100 | Accuracy: 75.5 | Loss:366.1516887965344\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:380.1659380760679\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.25743066785617\n",
            "Iteration 1250 | Accuracy: 74.35714285714286 | Loss:411.556476391558\n",
            "Iteration 1300 | Accuracy: 74.85714285714286 | Loss:422.45561251415484\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:439.6330458135815\n",
            "##################################################\n",
            ">epoch=426, lrate=0.300, error=454.381\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7406177785621177\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.951078473695468\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.595212643103174\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.80520615979194\n",
            "Iteration 200 | Accuracy: 75.21428571428571 | Loss:69.50065737859288\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54071434431154\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.93881009980429\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.77484302770006\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.8353123629999\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4587955555357\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.52048972992802\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.8015134484661\n",
            "Iteration 600 | Accuracy: 74.35714285714286 | Loss:209.70841612783238\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.7875405489802\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:241.19313131866787\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:254.21154176371567\n",
            "Iteration 800 | Accuracy: 76.28571428571429 | Loss:266.1879683606164\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:284.3742052127098\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:299.10936988018204\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:316.5921943016193\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:331.8795061363049\n",
            "Iteration 1050 | Accuracy: 75.07142857142857 | Loss:345.18602910051595\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.9226225683589\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:379.920234636965\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:399.0191487342617\n",
            "Iteration 1250 | Accuracy: 74.42857142857143 | Loss:411.3122016564531\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:422.22793331363147\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:439.4003399022002\n",
            "##################################################\n",
            ">epoch=427, lrate=0.300, error=454.145\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.73950310353199\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.95841409829476\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.60557298461984\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.82288312041358\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.5117425656321\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54154543615653\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.92991579675724\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.77082868470524\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.84724625047195\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.4611916742048\n",
            "Iteration 500 | Accuracy: 74.78571428571429 | Loss:174.49851718293013\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.80761622245518\n",
            "Iteration 600 | Accuracy: 74.5 | Loss:209.63064299404402\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:224.66918834081974\n",
            "Iteration 700 | Accuracy: 75.14285714285714 | Loss:241.05569528861872\n",
            "Iteration 750 | Accuracy: 75.92857142857142 | Loss:254.05403906325878\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:266.01419684756763\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:284.10460763646006\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.8470633537784\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:316.34109540593306\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.6438325668289\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:344.96033093746126\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.66842154988797\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:379.64199178204836\n",
            "Iteration 1200 | Accuracy: 73.78571428571429 | Loss:398.7416003192822\n",
            "Iteration 1250 | Accuracy: 74.5 | Loss:411.02614587479\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:421.9619884078095\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:439.128317254658\n",
            "##################################################\n",
            ">epoch=428, lrate=0.300, error=453.874\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7376744460177593\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.96656928781076\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.61917952363831\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.843913213519926\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.52726173296873\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.54661352984289\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.92026560438686\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.76666978993956\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.85484704761697\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.44815829724445\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:174.47265417705879\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.81886482569726\n",
            "Iteration 600 | Accuracy: 74.78571428571429 | Loss:209.54056628051964\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.53891778419455\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:240.9058044643624\n",
            "Iteration 750 | Accuracy: 75.78571428571429 | Loss:253.88307610212237\n",
            "Iteration 800 | Accuracy: 76.35714285714286 | Loss:265.8259110004553\n",
            "Iteration 850 | Accuracy: 76.14285714285714 | Loss:283.8139230272157\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.56739587099753\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:316.06562566028913\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.37764822246965\n",
            "Iteration 1050 | Accuracy: 75.14285714285714 | Loss:344.7113159473361\n",
            "Iteration 1100 | Accuracy: 75.57142857142857 | Loss:365.38622041102093\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:379.3233345921691\n",
            "Iteration 1200 | Accuracy: 74.0 | Loss:398.41367039780454\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:410.6858447591517\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:421.6459613186677\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:438.8051886200718\n",
            "##################################################\n",
            ">epoch=429, lrate=0.300, error=453.554\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7351920746665306\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.97581886581921\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.63558485125889\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.86799238646749\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.54687527583435\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.55536591020622\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:101.90944143272954\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.76092479358759\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.84888330603323\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.4053052377356\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.42772882112277\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.81111763560858\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.42358267588668\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:224.38133218898346\n",
            "Iteration 700 | Accuracy: 75.07142857142857 | Loss:240.73217980343605\n",
            "Iteration 750 | Accuracy: 76.0 | Loss:253.68625880997254\n",
            "Iteration 800 | Accuracy: 76.42857142857142 | Loss:265.61264489377214\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:283.5051377429661\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:298.27207774614567\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.76782689407514\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:331.0797593238945\n",
            "Iteration 1050 | Accuracy: 75.42857142857143 | Loss:344.4373254595321\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:365.07997550391104\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:378.9691160662485\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:398.0399904017731\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:410.29568565876417\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:421.28223498051443\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:438.4341042863216\n",
            "##################################################\n",
            ">epoch=430, lrate=0.300, error=453.188\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7324948855304352\n",
            "Iteration 50 | Accuracy: 76.92857142857143 | Loss:16.985465101578864\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.65388969738075\n",
            "Iteration 150 | Accuracy: 75.78571428571429 | Loss:57.89525296015186\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.5691545929701\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.56591380701825\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:101.90030615666855\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.75527526118535\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.8262449234442\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.32870669332274\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.35487735163375\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.7599572044935\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.2798693785166\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:224.19451433212714\n",
            "Iteration 700 | Accuracy: 75.21428571428571 | Loss:240.53513366853383\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:253.4651603807772\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:265.3794191174006\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:283.1986042889671\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.97764217281104\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.4694626097221\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:330.7715105556883\n",
            "Iteration 1050 | Accuracy: 75.5 | Loss:344.1529441835665\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:364.7741724610756\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:378.6169293250874\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:397.66517031362963\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.902999022923\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:420.91311719025873\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:438.05923281866137\n",
            "##################################################\n",
            ">epoch=431, lrate=0.300, error=452.817\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7302471923153546\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:16.994265878397307\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.672120704921795\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:57.92501858350008\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.59199950195465\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.57586149674597\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.89811775925372\n",
            "Iteration 350 | Accuracy: 76.0 | Loss:120.7548242358379\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.80247214117614\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.24467830699072\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.27763091895574\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.68668359790976\n",
            "Iteration 600 | Accuracy: 74.85714285714286 | Loss:209.12220993740064\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.99602535914562\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:240.3316418555592\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:253.2376236198551\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:265.14498859506193\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:282.90782033685286\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.6959869511396\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:315.1842766229322\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:330.47031136693937\n",
            "Iteration 1050 | Accuracy: 75.5 | Loss:343.8709609298238\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:364.48358353813376\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:378.29056543957404\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:397.3189698743181\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.53953507413826\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:420.568358298671\n",
            "Iteration 1350 | Accuracy: 77.07142857142857 | Loss:437.7118241351311\n",
            "##################################################\n",
            ">epoch=432, lrate=0.300, error=452.472\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7285753579629337\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:17.001817318142276\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.68861894723043\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.95476132241196\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.61342376446088\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.5840638275777\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.90385963420604\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.76032515761995\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.79081584333295\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.18167482230345\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.2197494212115\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.62667990194913\n",
            "Iteration 600 | Accuracy: 74.92857142857143 | Loss:208.9614406486671\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.802499416955\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:240.13540957670645\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:253.01609174785426\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:264.91915796974706\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:282.63294509083516\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.4281825215869\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:314.91087786070483\n",
            "Iteration 1000 | Accuracy: 76.14285714285714 | Loss:330.1785891107855\n",
            "Iteration 1050 | Accuracy: 75.57142857142857 | Loss:343.5966072409185\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:364.20880457282306\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.98726198793094\n",
            "Iteration 1200 | Accuracy: 74.07142857142858 | Loss:396.9987986173517\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:409.20249240720665\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:420.24678711441555\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:437.3902496798069\n",
            "##################################################\n",
            ">epoch=433, lrate=0.300, error=452.154\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7273330689928683\n",
            "Iteration 50 | Accuracy: 76.85714285714286 | Loss:17.009035753745533\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.70376334156251\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:57.98358046717614\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.633509435216\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.59143069138705\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.91523541749396\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.76899778536142\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.789549714103\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.14183601942307\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.17984419060622\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.58510721838945\n",
            "Iteration 600 | Accuracy: 75.07142857142857 | Loss:208.81234590635907\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.6292882689234\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:239.96003990040776\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:252.814990988508\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.71490630898495\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.3899344164631\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:297.1899336421045\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.6659655816455\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.9147094865657\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:343.35049736306263\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.9666784918599\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:377.7209133098051\n",
            "Iteration 1200 | Accuracy: 74.28571428571429 | Loss:396.71874829977907\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:408.9064877348478\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.96398950008137\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:437.10881410479635\n",
            "##################################################\n",
            ">epoch=434, lrate=0.300, error=451.874\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.726460578972619\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.015948115183466\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.717525426660345\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:58.01121000326874\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.65264678716252\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.59834136665361\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.92984631110085\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.77901121411483\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.79575407085764\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.11844598572105\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.15383719230252\n",
            "Iteration 550 | Accuracy: 72.07142857142857 | Loss:192.55882290743463\n",
            "Iteration 600 | Accuracy: 75.0 | Loss:208.6799477981297\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.4793365031139\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.80797068882922\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:252.63781080107213\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.5353799892894\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.18303158128435\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.98555694599975\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.45510106614773\n",
            "Iteration 1000 | Accuracy: 76.14285714285714 | Loss:329.684462198578\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:343.1394199905911\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.76236066588956\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.4952144834649\n",
            "Iteration 1200 | Accuracy: 74.28571428571429 | Loss:396.4825615355627\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:408.65549526615655\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.72461691770036\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:436.87150769216055\n",
            "##################################################\n",
            ">epoch=435, lrate=0.300, error=451.636\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7258783554608899\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.022332734060576\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.72992723770049\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.037186130635334\n",
            "Iteration 200 | Accuracy: 75.28571428571429 | Loss:69.670609406272\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.60451515576266\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.94620740854718\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.78906599447134\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8066705170682\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.10673042795028\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.13758322172328\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.54352608175654\n",
            "Iteration 600 | Accuracy: 75.21428571428571 | Loss:208.5676420009107\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.35401879344252\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.6800080915763\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.48626044615256\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.38202697252086\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:282.0115331940871\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:296.81468246393325\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.2790684228841\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.4890625739406\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.96431777232635\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.59595374990664\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.3097626154108\n",
            "Iteration 1200 | Accuracy: 74.35714285714286 | Loss:396.28966624115\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.4490648506875\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.528542336975\n",
            "Iteration 1350 | Accuracy: 77.21428571428571 | Loss:436.67787450930257\n",
            "##################################################\n",
            ">epoch=436, lrate=0.300, error=451.441\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.725495976082387\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.02800166181375\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74073600048872\n",
            "Iteration 150 | Accuracy: 75.92857142857142 | Loss:58.06087930446231\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.68695444911185\n",
            "Iteration 250 | Accuracy: 77.21428571428571 | Loss:85.60937189379531\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:101.96288759813527\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.79798488461626\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.8199364718207\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10272234864502\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.12749637499667\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.53529422184536\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.47425696666184\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.25068415261228\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.57339607618468\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.3578975679747\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:264.25219089580065\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.8697534294385\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:296.6720634836098\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.1329020285969\n",
            "Iteration 1000 | Accuracy: 76.21428571428571 | Loss:329.32397135261476\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.82008483042534\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.4616988089185\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:377.158385736961\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:396.13343983310153\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.28045600786095\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:419.3692269522798\n",
            "Iteration 1350 | Accuracy: 77.14285714285715 | Loss:436.52121603939116\n",
            "##################################################\n",
            ">epoch=437, lrate=0.300, error=451.282\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.725245752291163\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.03303317389379\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74974943627684\n",
            "Iteration 150 | Accuracy: 75.85714285714286 | Loss:58.081835911794705\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.7013475605118\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.61240340307725\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:101.97878703501925\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80480611515294\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.83332666541665\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10312810709624\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:174.12027173867324\n",
            "Iteration 550 | Accuracy: 72.14285714285714 | Loss:192.53049647560354\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.39722713729842\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.1658570610789\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.48483455790375\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.2494145141114\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:264.14242482059245\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.7518141513146\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.55216407598255\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:314.0109455143415\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:329.1838754732597\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.7007975433074\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.3529422604383\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:377.03408655973794\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:396.0064148546754\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:408.1420306864751\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.23910748700445\n",
            "Iteration 1350 | Accuracy: 77.14285714285715 | Loss:436.3938611016317\n",
            "##################################################\n",
            ">epoch=438, lrate=0.300, error=451.152\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.72509072124367\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.03756844831194\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.75669872529815\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.09974716622006\n",
            "Iteration 200 | Accuracy: 75.42857142857143 | Loss:69.7135378294424\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.61315120051857\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:101.9930868357824\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80887303174353\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.84515699077855\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10535311602004\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:174.11352553629683\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.5264359519684\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.3321496294253\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:223.09457931579374\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.4096771905551\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.1558962325651\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:264.0476868969714\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.6511646464652\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.44873488639655\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.9065634891628\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:329.0622449272972\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.5994353579446\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.262000615395\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.9289297828826\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:395.9002980626805\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:408.02530468196954\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.1297459515603\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.2873036489193\n",
            "##################################################\n",
            ">epoch=439, lrate=0.300, error=451.042\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7250126421759622\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.041785587328658\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76141404184362\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.11449476234787\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.72335380795606\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.61131742316704\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.00538475397117\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80991448983565\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.85432570480887\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.10771956036263\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.10578825656194\n",
            "Iteration 550 | Accuracy: 72.21428571428572 | Loss:192.52138581282398\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.2750023433873\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:223.03251285988966\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:239.34382694915\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:252.07293483564254\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.96343982205985\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.5624040568588\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:296.3566239024343\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.8142315552231\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.9535321141246\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.51006143656906\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:363.18238424239746\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.83633998486687\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:395.80827472928297\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.92331303711074\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:419.03421608049695\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.19456740868014\n",
            "##################################################\n",
            ">epoch=440, lrate=0.300, error=450.945\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7249998226367627\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.045833012570238\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.7638181403802\n",
            "Iteration 150 | Accuracy: 76.0 | Loss:58.12609214440372\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73064708498039\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.60672776079944\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.01551304828375\n",
            "Iteration 350 | Accuracy: 76.07142857142857 | Loss:120.80793382481531\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.8602389168256\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.10920585583324\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.09632938092554\n",
            "Iteration 550 | Accuracy: 72.28571428571429 | Loss:192.51439872125263\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.2220036336419\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.97571598033295\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:239.28347479978206\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:251.996412018743\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.88542063219484\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:281.4808300657901\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.27135998451246\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.72917145761704\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.85285054441334\n",
            "Iteration 1050 | Accuracy: 75.64285714285714 | Loss:342.4274765350535\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.1085133816025\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.7508068209553\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:395.7246618391182\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:407.83025312716427\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:418.9467748172373\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:436.1098724433069\n",
            "##################################################\n",
            ">epoch=441, lrate=0.300, error=450.857\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.725041009493403\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.049867715997525\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76399417843802\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.1346971781755\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73531698432267\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.59936623959305\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.02346719309493\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.8031265495044\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.86267482094394\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10926553917344\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.08488291505117\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.50504154579602\n",
            "Iteration 600 | Accuracy: 75.28571428571429 | Loss:208.17016327642062\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.92115293256103\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.2255791137914\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.92303925030762\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.8101964241822\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.40276113090994\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.1894709778523\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.64772284262887\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:328.7564189043575\n",
            "Iteration 1050 | Accuracy: 75.64285714285714 | Loss:342.3476283086354\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:363.03610172718874\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:376.66823761042474\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.64520331447795\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.74178027636333\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:418.8631535665369\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:436.02891859669626\n",
            "##################################################\n",
            ">epoch=442, lrate=0.300, error=450.772\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7251231532286573\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.05405234183872\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.76217040663417\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.14058260161189\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73732339749067\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.58934825234671\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.02929843129144\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.79578009938167\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.86167547078355\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.10761766814846\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.07144204572572\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.49318987282774\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.11711336516936\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.86649158880851\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.16768146185927\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.85018099969346\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.73500094431995\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.32528464371796\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:296.10823564677196\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.567083539096\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.6613243692\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.26735618902103\n",
            "Iteration 1100 | Accuracy: 75.71428571428571 | Loss:362.9618593746275\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.5856186936908\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.5667044640855\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.6546336379133\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.7801772630195\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.9485004377251\n",
            "##################################################\n",
            ">epoch=443, lrate=0.300, error=450.688\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7252317594075721\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.05855832921182\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.758715313941465\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.14412375042832\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73672757001471\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.57691780675738\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.03310353938059\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.78623780933735\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.85749195555215\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.10417500114744\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:174.056162000256\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.478940653306\n",
            "Iteration 600 | Accuracy: 75.35714285714286 | Loss:208.06120494623678\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.8101673921254\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:239.10798486617222\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.77594015418947\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.657833033525\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.2462889757955\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:296.02570824433866\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.4853120116287\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.5655420684962\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.18441580423104\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:362.8834686563346\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.50094797080374\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.48695842128285\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.56656131035817\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.69567836328554\n",
            "Iteration 1350 | Accuracy: 77.0 | Loss:435.86641840917207\n",
            "##################################################\n",
            ">epoch=444, lrate=0.300, error=450.602\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7253521772663754\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.063543923403046\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.75410605515534\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.145776139658686\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.73372489992877\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.56242852313743\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.0350440225195\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.77489466929899\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.85055685988655\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.0990231301448\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.039333373283\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.4625892409524\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:208.00149695190584\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.75134012653152\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:239.0453401231819\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.69913616246745\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.5774421815792\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:281.1644267552204\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.9406752217484\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:313.40124545392524\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.4678543594787\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.0974210269125\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:362.7994968378394\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:376.4130990874752\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.40462092232883\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.47619282447783\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.60836200325457\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.78134396499746\n",
            "##################################################\n",
            ">epoch=445, lrate=0.300, error=450.514\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7254716637202683\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.069131041639533\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74889232114871\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.14606217358013\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.72867344416478\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.54633027608328\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.03539804370892\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.76222320671351\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.84146957346388\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.09244903149255\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.02139146943318\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.44463914196757\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.93783433175906\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.6899443124086\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.97933326225717\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.6193799208391\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.4934058627189\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:281.0791663892939\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.85269808785574\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.314504216826\n",
            "Iteration 1000 | Accuracy: 76.07142857142857 | Loss:328.36785370875396\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:342.0058796734166\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.7094238319098\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:376.3217950760513\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.3192016607561\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.38302796488307\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.5177914213215\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.6928081352485\n",
            "##################################################\n",
            ">epoch=446, lrate=0.300, error=450.423\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7255816471840075\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.075383424927473\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.74364325778622\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.145553098918256\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.72209238462497\n",
            "Iteration 250 | Accuracy: 77.14285714285715 | Loss:85.529143122682\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.034589092931\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:120.74878347174833\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.83095500487497\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.0849499782332\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:174.0029000901936\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.42577734377767\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.87087819373048\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.62670087266483\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.910344649365\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.53711435377141\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.40616722522356\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.99080136707033\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.7621159390194\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.2254630160934\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.2659103755758\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.9101885359463\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.6136430453264\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:376.22755991138456\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.2310369844418\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.28740490152956\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.4243557278798\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.6011752576811\n",
            "##################################################\n",
            ">epoch=447, lrate=0.300, error=450.328\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7256796075822582\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.08229635545304\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.73888148203066\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.14483477867593\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.71461369136335\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.51140922344382\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.03315672075134\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.73518409475138\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.8197752043303\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.0771801738105\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.98447770942948\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.40678129801023\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.8020136461889\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.56301260008243\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.839492598283\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.45353648229772\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:263.316949977414\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.90033988840827\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.6699328965889\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.135121326688\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.1630385390241\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.8115064383771\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.51334016000374\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:376.1315691996352\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.1411613478913\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:407.19036560880727\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.3291352116467\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.5075153109223\n",
            "##################################################\n",
            ">epoch=448, lrate=0.300, error=450.233\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7257697683575068\n",
            "Iteration 50 | Accuracy: 76.78571428571429 | Loss:17.089800834092134\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.73501588310036\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.14444946749371\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.70688749790177\n",
            "Iteration 250 | Accuracy: 77.07142857142857 | Loss:85.49361936199885\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.0316664849505\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.7219947821072\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.80860805212305\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.06982634781255\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.96667890960788\n",
            "Iteration 550 | Accuracy: 72.42857142857143 | Loss:192.3883711283475\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.73306682546664\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.5006686110816\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.76837424948414\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.37031716264877\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.2274698157618\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.8092166562641\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.57753498517\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:313.0448200472838\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:328.0606068351389\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.7114432025498\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.410177463298\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:376.0353400962443\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:395.0510137405265\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:407.09335568439286\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.23359963046556\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:435.41330745711747\n",
            "##################################################\n",
            ">epoch=449, lrate=0.300, error=450.136\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.725862177016936\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.09778058513584\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.73229677443806\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.14482897378206\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.69947607811068\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.47613676017004\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03060983033987\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.70965973596971\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.79794821964688\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.0634670974724\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.9498927554512\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.37107717126747\n",
            "Iteration 600 | Accuracy: 75.42857142857143 | Loss:207.66591447449323\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.4414387020258\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.69867416884685\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:251.28919364953023\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.1395211998336\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.71891390522586\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:295.48632262174306\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:312.95588730020637\n",
            "Iteration 1000 | Accuracy: 76.0 | Loss:327.95997667338645\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.61165557688156\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.3058762986869\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.94034932166693\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.9620635628803\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.99784484002544\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.13922701740535\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.32006017522303\n",
            "##################################################\n",
            ">epoch=450, lrate=0.300, error=450.041\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7259705098835023\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.10609473235502\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.73081014425253\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.146248628327726\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.69278312984487\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.45915236521529\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03035419301895\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.69846562321385\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78807900656528\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.0584886797627\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.93431272851888\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.35518901818386\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:207.60216766313135\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.38674335343092\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.6318267097071\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.21162345374802\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:263.0546290788417\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.63066320149505\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:295.39742584439597\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:312.8693720529011\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:327.86222926244255\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:341.5135307546611\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:362.2018887379361\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.8477513701012\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.87552552669973\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.9050395751674\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:418.0472174304078\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.22902255799596\n",
            "##################################################\n",
            ">epoch=451, lrate=0.300, error=449.948\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7261095319910438\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.11459759481388\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.73050663681017\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.148820342202974\n",
            "Iteration 200 | Accuracy: 75.5 | Loss:69.68704021795897\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.44268819410323\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03115935545983\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.68857244640893\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7791137693336\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.05508345612503\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.9199774529775\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.3407903685649\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.54304898213263\n",
            "Iteration 650 | Accuracy: 74.21428571428571 | Loss:222.3375239098621\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.56886846055792\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.13863464681955\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.9738991634775\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.54533420498365\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.3116038836872\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.78595900365923\n",
            "Iteration 1000 | Accuracy: 75.92857142857142 | Loss:327.76807686985177\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.41806987271866\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:362.0992786782976\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.75829730873744\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.79226521717544\n",
            "Iteration 1250 | Accuracy: 75.07142857142857 | Loss:406.8157903954177\n",
            "Iteration 1300 | Accuracy: 75.07142857142857 | Loss:417.95840530283084\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.14109239364177\n",
            "##################################################\n",
            ">epoch=452, lrate=0.300, error=449.857\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.726293067605209\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.123150683820086\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.731245164349446\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.152518895427946\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.68233675115205\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.42663670836156\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.03322843358544\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.68007368586136\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.7710668245879\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.053298779713\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.9068390807352\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.3278313414796\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.48942996998457\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.29428365356\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.5104663570199\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.07085551726482\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.8980480724809\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.4634812276383\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.2292984911215\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.70603121227975\n",
            "Iteration 1000 | Accuracy: 75.85714285714286 | Loss:327.6779252479066\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.325941711207\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:361.9987811681494\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.6724152770972\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.7128604919925\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.73065762661906\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.87333299224747\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:435.0568854102702\n",
            "##################################################\n",
            ">epoch=453, lrate=0.300, error=449.770\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7265327762350848\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.131627458239734\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.73283363543944\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.15722380008647\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67866688610187\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.41081379174938\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.0367550181892\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.6730507955527\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.76391800143713\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.05309106290116\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.89482204078672\n",
            "Iteration 550 | Accuracy: 72.35714285714285 | Loss:192.31619200513225\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4419228992214\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.25719735723612\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.45702570567974\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:251.00862644462305\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.82751570614215\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.3854566070584\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.15075144780434\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.6297923828835\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.5919985930601\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.2376109707943\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.9009382129748\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.5903546862016\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.6377248978885\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.6500399446833\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.79238723142566\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.9768679940061\n",
            "##################################################\n",
            ">epoch=454, lrate=0.300, error=449.688\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7268375281323802\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.13991400120212\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.73506051482101\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.16276270579102\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67597491948537\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.39501038646945\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.04194815067328\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66760760439493\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.75765840112814\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.0543630270991\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.88386143355928\n",
            "Iteration 550 | Accuracy: 72.42857142857143 | Loss:192.30572156863175\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.40095718409336\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.22621938622356\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.4088032738166\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.95211914468948\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.7625844603119\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.31152355022834\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.0761205765297\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.5573849249912\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.5104624102429\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.1534684939249\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.80623404996544\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.5123237262302\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.5672256152731\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.57429640119335\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.7159276080137\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.9014824363023\n",
            "##################################################\n",
            ">epoch=455, lrate=0.300, error=449.610\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.727213032162887\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.14790804434584\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.737717391681386\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.16894851139073\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67419082003735\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.37903561567761\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.04903351023539\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66388393845828\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7523180764824\n",
            "Iteration 450 | Accuracy: 76.35714285714286 | Loss:154.05698376213456\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8739246731682\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.29625762140626\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:207.36682466711488\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.2011692012823\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.36599364020927\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.9014310920243\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.7034721232339\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.24193903009296\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:295.00556546180144\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.4889751595822\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.4335144154952\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:341.07392913332666\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.71519410844616\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.43858825652916\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.50176603020077\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.50383123542036\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.6443756513595\n",
            "Iteration 1350 | Accuracy: 76.92857142857143 | Loss:434.8312330839858\n",
            "##################################################\n",
            ">epoch=456, lrate=0.300, error=449.536\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7276615039712544\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.15551747207141\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.7406134215471\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.17560554070079\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67325231956369\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.36274651118045\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.05823553725331\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66205148723272\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.74797788152793\n",
            "Iteration 450 | Accuracy: 76.28571428571429 | Loss:154.06079838847512\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.86502058209658\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.2876334422744\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.33969899562632\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.1817931604668\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.32877854146085\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.8566433392621\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.65038600068283\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:280.1769974646405\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.93929360784824\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.42479575704897\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:327.3614316219854\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.99948387966464\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:361.6284339268039\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.3695191623091\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.44182161006773\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.43913032128245\n",
            "Iteration 1300 | Accuracy: 75.21428571428571 | Loss:417.5782531199084\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.7667217178091\n",
            "##################################################\n",
            ">epoch=457, lrate=0.300, error=449.469\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.728181357156321\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.16265910388826\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.74358211331568\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.182582474521695\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.67311257567455\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.34606071593565\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.06974792769282\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.66229626191856\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.74476718568252\n",
            "Iteration 450 | Accuracy: 76.21428571428571 | Loss:154.06563423826074\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.85719801421533\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.27967959146537\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.31963456804425\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.16780486273785\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.29733755542782\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.81783825969654\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:262.6035349735911\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:280.1170363224265\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.87756824311225\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.3651464317929\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.2945724637476\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.9307046582223\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.5466562833997\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:375.30558600967976\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.3879277049003\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.38074867078836\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.5181688444815\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.70863122549656\n",
            "##################################################\n",
            ">epoch=458, lrate=0.300, error=449.408\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.72876702885614\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.169258794562545\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.74648139571931\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.18975243301316\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.67373501133204\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.32895125637461\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.08370246551347\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.6647940749774\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74285016481403\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.0713089997475\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.85053564288512\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.27222368917108\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.30654741390353\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.15890560942142\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.27182411816904\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.78508006751488\n",
            "Iteration 800 | Accuracy: 76.57142857142857 | Loss:262.56310349356727\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.0624117964795\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:294.8206862200596\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.3103622361602\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.2333417253762\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.8682092511739\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.4706042110342\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.24730458996794\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.340626219692\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.3292564824785\n",
            "Iteration 1300 | Accuracy: 75.14285714285714 | Loss:417.4647617774056\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.65766509903864\n",
            "##################################################\n",
            ">epoch=459, lrate=0.300, error=449.355\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7294091013137254\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.175254060188312\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.74918887797067\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.19700319341275\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.67507938955326\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.31142621317295\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.10014784180608\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.66968731513002\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74240508590506\n",
            "Iteration 450 | Accuracy: 76.14285714285714 | Loss:154.07764404094843\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.8451251553258\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.26508949222537\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.30017981042113\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.15478490637537\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.2523151837025\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.7583662059857\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.5291975871316\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:280.01345625925927\n",
            "Iteration 900 | Accuracy: 76.14285714285714 | Loss:294.7689379849204\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.26076347419354\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.17813201917124\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.81259977351766\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.40098440402903\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:375.19515397026896\n",
            "Iteration 1200 | Accuracy: 74.78571428571429 | Loss:394.3003845833164\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.2851565489382\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.4186135633094\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.6144563087192\n",
            "##################################################\n",
            ">epoch=460, lrate=0.300, error=449.310\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7300948782121788\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.180600241021793\n",
            "Iteration 100 | Accuracy: 76.85714285714286 | Loss:39.75159496449359\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.2042223876639\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.67708485035966\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.29349966506463\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.11904926515774\n",
            "Iteration 350 | Accuracy: 76.21428571428571 | Loss:120.67707091751329\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.74360173622554\n",
            "Iteration 450 | Accuracy: 76.0 | Loss:154.08448356599754\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.84105043707538\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.25809350501484\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.3000545856003\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.1551010557939\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.23874709322067\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.73756264933303\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.50177818200564\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.9704302245793\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.7225621183329\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.21660250515225\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.12925833374527\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.7643911881486\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.33837989063403\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.1494842359712\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:394.2675053163799\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.2487896387852\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.3801480887362\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5794636010698\n",
            "##################################################\n",
            ">epoch=461, lrate=0.300, error=449.273\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7308095255597653\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.185280616204707\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.75359640781798\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.21128315639199\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.67965592012962\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.27516230141728\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.14031523235505\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.68699146734063\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.7465806182823\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.09171770485509\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.83836430518878\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.25103549476046\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.3054322744264\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.1594455494682\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.23085402816912\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.72234051320484\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.48060066379736\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.9334802479171\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.68170501976755\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:312.1780205564319\n",
            "Iteration 1000 | Accuracy: 75.78571428571429 | Loss:327.0869011983061\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.7239459154478\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.28317190168156\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.11043768458137\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2420470734066\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.22024733784104\n",
            "Iteration 1300 | Accuracy: 75.0 | Loss:417.3495385493147\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5528764207897\n",
            "##################################################\n",
            ">epoch=462, lrate=0.300, error=449.245\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.731537773186673\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.189319931498\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.755092055807204\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.218034972189294\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68265627840954\n",
            "Iteration 250 | Accuracy: 77.0 | Loss:85.25635970921252\n",
            "Iteration 300 | Accuracy: 76.07142857142857 | Loss:102.16385072046587\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.69945634260334\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.7514334168335\n",
            "Iteration 450 | Accuracy: 75.85714285714286 | Loss:154.09930475344854\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.8370611617276\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.24367870608566\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.31528884525054\n",
            "Iteration 650 | Accuracy: 74.28571428571429 | Loss:222.16730014064788\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.22812480068302\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.71213124999568\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.46517757065124\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.9026087128432\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.6463905566031\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.1450204793985\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:327.0510672408554\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.6914243744569\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.2354857119504\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.07790054983445\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.22377502620174\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1993108913013\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3266416541657\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.53454840367135\n",
            "##################################################\n",
            ">epoch=463, lrate=0.300, error=449.227\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.78571428571429 | Loss:1.7322659938822964\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.192799466520167\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75598145658531\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.22430216450386\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68591255204322\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.23698326315005\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.18962955878777\n",
            "Iteration 350 | Accuracy: 76.14285714285714 | Loss:120.71444193280121\n",
            "Iteration 400 | Accuracy: 76.28571428571429 | Loss:133.75817795431846\n",
            "Iteration 450 | Accuracy: 75.78571428571429 | Loss:154.10728411504545\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.83703806378819\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.23571457342499\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.32832727805743\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.1779975945422\n",
            "Iteration 700 | Accuracy: 75.28571428571429 | Loss:238.22978466615876\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.7061086701352\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.45477002860986\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.8776506181943\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.6164939703666\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:312.1174485145762\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:327.02156271590974\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.66674839683384\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.1951621332263\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.05148778131434\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2121469290801\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1854258679907\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3109697123922\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.52397000576906\n",
            "##################################################\n",
            ">epoch=464, lrate=0.300, error=449.216\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.7329843044052244\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.195870164626253\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75616572894267\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.22988886097287\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68922669907671\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.21687294658604\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.21777677051462\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.73188308225029\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:133.76671227586698\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.1157672122149\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.8380278983015\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.22670232531675\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.34301938012803\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.19069225067264\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.2347917249814\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.70318747939933\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.4483933996527\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.85823756277006\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.59170002968443\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0949615417351\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.99795810230324\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6495569978504\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.16173717256527\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.0305423264102\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2063213629341\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1777042975816\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.3016930159273\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.520272258373\n",
            "##################################################\n",
            ">epoch=465, lrate=0.300, error=449.213\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.71428571428571 | Loss:1.733688299458397\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.198759245318012\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.75554826996333\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.234583606304966\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.69239078715599\n",
            "Iteration 250 | Accuracy: 76.92857142857143 | Loss:85.19582423621935\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.24865482767635\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.75161911487793\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.77672020242787\n",
            "Iteration 450 | Accuracy: 75.71428571428571 | Loss:154.12488791048114\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.83947773627455\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.2159654522086\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.35764672200472\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.2043343192725\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.24181690659842\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.70200362270612\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.4447970664407\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.8437094447103\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.5714064433978\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0769362723837\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.97950076083856\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.63911231417075\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.13438888260765\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:375.01410513063496\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.20514701161534\n",
            "Iteration 1250 | Accuracy: 75.0 | Loss:406.1749171423031\n",
            "Iteration 1300 | Accuracy: 74.92857142857143 | Loss:417.297636260594\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.522225188387\n",
            "##################################################\n",
            ">epoch=466, lrate=0.300, error=449.217\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.64285714285714 | Loss:1.7343802038807092\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.201766295575208\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.75403016081123\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.23815071724004\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.69519258433847\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.1735839073346\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.28294820179902\n",
            "Iteration 350 | Accuracy: 75.85714285714286 | Loss:120.77326386273923\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78748518984455\n",
            "Iteration 450 | Accuracy: 75.64285714285714 | Loss:154.13468188425455\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:173.8403411456097\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.20242399362954\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.37028708085234\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.21763343312028\n",
            "Iteration 700 | Accuracy: 75.35714285714286 | Loss:238.24916121921186\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.70081978340957\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4423519138438\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.83290381247446\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.55450410165236\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0622483190983\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.9649040944704\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.63408277424026\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.1117811619727\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:375.00078119023686\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:394.2070531946687\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.17539609821307\n",
            "Iteration 1300 | Accuracy: 74.78571428571429 | Loss:417.29718883754515\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5281510219366\n",
            "##################################################\n",
            ">epoch=467, lrate=0.300, error=449.225\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7350693897399667\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.205245954068104\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.751491490745536\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.240289670138594\n",
            "Iteration 200 | Accuracy: 75.85714285714286 | Loss:69.69739404804801\n",
            "Iteration 250 | Accuracy: 76.85714285714286 | Loss:85.14981210602707\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:102.32171594522951\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.79597075995787\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.7975690716051\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.14483818131993\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.83878940193867\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.18437784326488\n",
            "Iteration 600 | Accuracy: 76.0 | Loss:207.37872006901432\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.22902609344547\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.2545768263875\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.6973033591063\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4387681013281\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.82371200229\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.53892672678256\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.0488138546271\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.95191264241527\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6320963331843\n",
            "Iteration 1100 | Accuracy: 76.28571428571429 | Loss:361.09170786190936\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:374.9883964637354\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.2097138806559\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1767041382343\n",
            "Iteration 1300 | Accuracy: 74.71428571428571 | Loss:417.2979853237262\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5356092216788\n",
            "##################################################\n",
            ">epoch=468, lrate=0.300, error=449.234\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7357716021096576\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.209566523299614\n",
            "Iteration 100 | Accuracy: 77.07142857142857 | Loss:39.747745841638775\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.24054106743174\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.69865733310155\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.12397992335897\n",
            "Iteration 300 | Accuracy: 75.92857142857142 | Loss:102.36628299345922\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.81814215402552\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.80441421243626\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.15423125083103\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.83203153546702\n",
            "Iteration 550 | Accuracy: 72.5 | Loss:192.15941280536848\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:207.38037024434504\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.23674893687075\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.255046005391\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.68821555457205\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4306338169076\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.812295499391\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.5208657531971\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:312.03280279299236\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.93658809005785\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.6289923071251\n",
            "Iteration 1100 | Accuracy: 76.28571428571429 | Loss:361.07047763582017\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9733673900246\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.2093523494611\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1749084635848\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:417.29616557317263\n",
            "Iteration 1350 | Accuracy: 76.85714285714286 | Loss:434.5406636806724\n",
            "##################################################\n",
            ">epoch=469, lrate=0.300, error=449.242\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7365034766230658\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.21498956103353\n",
            "Iteration 100 | Accuracy: 77.07142857142857 | Loss:39.742461732215325\n",
            "Iteration 150 | Accuracy: 76.57142857142857 | Loss:58.238144262517416\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.69840661348317\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.09519876406674\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.4175882541805\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.8374433132947\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.80439946069214\n",
            "Iteration 450 | Accuracy: 75.5 | Loss:154.16022684845063\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:173.81700137120538\n",
            "Iteration 550 | Accuracy: 72.71428571428571 | Loss:192.12501597336612\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.37271675076315\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.23913273483768\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.24684326906552\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.66943014737794\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.41318869721493\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.79225171229484\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.4939234185522\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:312.00784239630445\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.912748289682\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:340.6181728551556\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:361.0423602296437\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9500908010138\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.19993703856943\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.1636696242121\n",
            "Iteration 1300 | Accuracy: 74.64285714285714 | Loss:417.2853399439114\n",
            "Iteration 1350 | Accuracy: 76.78571428571429 | Loss:434.5368603911041\n",
            "##################################################\n",
            ">epoch=470, lrate=0.300, error=449.241\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.7372635959895337\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.221292472212866\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.73512306036116\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.23205754185876\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.69579902368353\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.06226264301148\n",
            "Iteration 300 | Accuracy: 75.5 | Loss:102.47435608382604\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.85207093568683\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.79502899514156\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.1587964932283\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:173.79350059019131\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.0811549563223\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.35540808039795\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.23541553689478\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.227361205279\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.63816642944136\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.38253635852914\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.75633609724997\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.4507823881574\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.96678604912046\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.8741919694572\n",
            "Iteration 1050 | Accuracy: 75.71428571428571 | Loss:340.5927042961346\n",
            "Iteration 1100 | Accuracy: 76.21428571428571 | Loss:361.0013258626248\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.9126606713888\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.17475309205906\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.13575960277836\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.2577616882633\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.5164332092048\n",
            "##################################################\n",
            ">epoch=471, lrate=0.300, error=449.222\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.57142857142857 | Loss:1.737996867856922\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.22698486753347\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.72535989888404\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.222005552211535\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.69063748997493\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:85.02504432898624\n",
            "Iteration 300 | Accuracy: 75.64285714285714 | Loss:102.53105383136884\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:120.86366551330818\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.78049875732808\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.14916855153334\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:173.76913942540756\n",
            "Iteration 550 | Accuracy: 72.57142857142857 | Loss:192.03487231342305\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.33587639378243\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.22944643514103\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.20169805430004\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.6003014945476\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3438330732523\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.70670611119766\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.39354733234774\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.911766317688\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.82448497727216\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5553704516749\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.9500435713128\n",
            "Iteration 1150 | Accuracy: 74.78571428571429 | Loss:374.8638686930588\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.13582527383744\n",
            "Iteration 1250 | Accuracy: 74.92857142857143 | Loss:406.09284108659773\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.21402548424766\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.4800366341103\n",
            "##################################################\n",
            ">epoch=472, lrate=0.300, error=449.185\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7386034710756213\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22960366644507\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.71387286878675\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.210674592406576\n",
            "Iteration 200 | Accuracy: 76.0 | Loss:69.68543579670053\n",
            "Iteration 250 | Accuracy: 76.78571428571429 | Loss:84.98702387495906\n",
            "Iteration 300 | Accuracy: 75.57142857142857 | Loss:102.58224762000805\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.87780760168138\n",
            "Iteration 400 | Accuracy: 76.07142857142857 | Loss:133.7723010422284\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.13967486477415\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.75607038860517\n",
            "Iteration 550 | Accuracy: 72.64285714285714 | Loss:191.99840197769817\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.32896026759832\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.23259145040504\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.18435988809986\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:250.57119246479243\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.3130833369264\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.66104974860764\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.3401847374339\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.8600320207293\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.7809693690626\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5236799207775\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.9051498202277\n",
            "Iteration 1150 | Accuracy: 74.85714285714286 | Loss:374.8200242057332\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0991656134235\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.0508551516017\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.1695421130635\n",
            "Iteration 1350 | Accuracy: 76.71428571428571 | Loss:434.4430597240451\n",
            "##################################################\n",
            ">epoch=473, lrate=0.300, error=449.145\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.5 | Loss:1.7390636931683434\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22916497359005\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.70218743396689\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.20148790200404\n",
            "Iteration 200 | Accuracy: 75.92857142857142 | Loss:69.68329117231538\n",
            "Iteration 250 | Accuracy: 76.71428571428571 | Loss:84.95180061660038\n",
            "Iteration 300 | Accuracy: 75.42857142857143 | Loss:102.6311228422499\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:120.89782009955819\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.77573332265234\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.137783717626\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.75780804068492\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:191.9762648248166\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.3379427286665\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:222.24947867958878\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.17950027047723\n",
            "Iteration 750 | Accuracy: 76.14285714285714 | Loss:250.55520848571211\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.29538117541165\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.6267289090111\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.29824340566677\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.81860846536256\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.75008495978443\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.5048382218005\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.87411224497373\n",
            "Iteration 1150 | Accuracy: 74.92857142857143 | Loss:374.7876819795761\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.07095485047523\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.0155917818677\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.1302074596414\n",
            "Iteration 1350 | Accuracy: 76.64285714285714 | Loss:434.4110901310685\n",
            "##################################################\n",
            ">epoch=474, lrate=0.300, error=449.108\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.739412822917803\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22748400111724\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.690630722791155\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.19419134604255\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68353360570252\n",
            "Iteration 250 | Accuracy: 76.64285714285714 | Loss:84.91821405461752\n",
            "Iteration 300 | Accuracy: 75.28571428571429 | Loss:102.67986013144966\n",
            "Iteration 350 | Accuracy: 75.78571428571429 | Loss:120.92312366792345\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.78908382301944\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.14278767717607\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.7708907312811\n",
            "Iteration 550 | Accuracy: 72.78571428571429 | Loss:191.9651362091594\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.35785138243017\n",
            "Iteration 650 | Accuracy: 74.78571428571429 | Loss:222.27641440975106\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.1831824484314\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.54883986471793\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.28755344372286\n",
            "Iteration 850 | Accuracy: 76.07142857142857 | Loss:279.6011312232985\n",
            "Iteration 900 | Accuracy: 75.92857142857142 | Loss:294.26523768203685\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.78514220682627\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.72908250587335\n",
            "Iteration 1050 | Accuracy: 75.78571428571429 | Loss:340.4964560961463\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.85537579714077\n",
            "Iteration 1150 | Accuracy: 75.0 | Loss:374.7649059905978\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0493741470872\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:405.98500813540943\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.0941913914694\n",
            "Iteration 1350 | Accuracy: 76.57142857142857 | Loss:434.38206978352383\n",
            "##################################################\n",
            ">epoch=475, lrate=0.300, error=449.073\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7396381905718052\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.22539079948636\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.67970705993471\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.18919051452842\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68621997851027\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.8860323830724\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.72919140022617\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:120.95274615879289\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.8107080809424\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.1538580947894\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.79275803732975\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:191.96263786360285\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.3842090485662\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.31005144831911\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.19221797890557\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.54965953840036\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.28718133016406\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.5812819750898\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.2383105874039\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.7571438392133\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.71523326929173\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.49575909470315\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.847003091506\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.74986665439707\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0332639356291\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.95800087539703\n",
            "Iteration 1300 | Accuracy: 74.57142857142857 | Loss:417.0606169224287\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.35498371571197\n",
            "##################################################\n",
            ">epoch=476, lrate=0.300, error=449.037\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.739717933190355\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.223180433147274\n",
            "Iteration 100 | Accuracy: 76.92857142857143 | Loss:39.669755989280894\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.186911353860914\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.6912917584378\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.85532386159473\n",
            "Iteration 300 | Accuracy: 75.28571428571429 | Loss:102.77733552641247\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:120.98566119606286\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.8396236111319\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.17046778788452\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8210670304029\n",
            "Iteration 550 | Accuracy: 73.07142857142857 | Loss:191.96668500124923\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.4134954272939\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.34798473459932\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.205152114308\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.5570153782738\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.2937755479872\n",
            "Iteration 850 | Accuracy: 76.0 | Loss:279.5673466803611\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.21792396066377\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.73562064198165\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.708758189952\n",
            "Iteration 1050 | Accuracy: 75.85714285714286 | Loss:340.5026847962034\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.84939086110023\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.7435750723684\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.0249272074019\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.9372476203779\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.0327212723921\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.33309373231435\n",
            "##################################################\n",
            ">epoch=477, lrate=0.300, error=449.006\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7396782309265317\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:17.22179935574941\n",
            "Iteration 100 | Accuracy: 77.0 | Loss:39.66118905218548\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.187303187494145\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.69819745763557\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.82568829864366\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.8237575364841\n",
            "Iteration 350 | Accuracy: 75.64285714285714 | Loss:121.0196947520559\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.87283184066112\n",
            "Iteration 450 | Accuracy: 75.42857142857143 | Loss:154.19012302209015\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.8530717021551\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.97425448165257\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4392700785803\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.3839855813235\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.21692633426932\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:250.56666969249008\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.302600852888\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.553076791409\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.1978825538542\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.71489419309916\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.7037651242656\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:340.5106338779205\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.85632065703913\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.74055402878724\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.02005500769775\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.91894271067054\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.0069409059266\n",
            "Iteration 1350 | Accuracy: 76.5 | Loss:434.31298921979374\n",
            "##################################################\n",
            ">epoch=478, lrate=0.300, error=448.976\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7395298590951505\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.221157195048182\n",
            "Iteration 100 | Accuracy: 76.78571428571429 | Loss:39.65351095705405\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.189706421866724\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.7054373776205\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.79622670844182\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.86147399164064\n",
            "Iteration 350 | Accuracy: 75.71428571428571 | Loss:121.0534734216196\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:133.91013578696231\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.21324532914034\n",
            "Iteration 500 | Accuracy: 75.35714285714286 | Loss:173.88324960287667\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.98085955765364\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.45970294864122\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.4179525716538\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.22935670462698\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.58036222855432\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3166893507673\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.54760045452525\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.1881670071756\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.7064635738409\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.70851498567765\n",
            "Iteration 1050 | Accuracy: 76.07142857142857 | Loss:340.5273273418039\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.87529492435885\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.7498123104104\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.0293424545049\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.9144987426622\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:416.99640236402524\n",
            "Iteration 1350 | Accuracy: 76.42857142857142 | Loss:434.3082234755898\n",
            "##################################################\n",
            ">epoch=479, lrate=0.300, error=448.964\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7394720759926234\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.2251456708484\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.64804744186901\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.19271910222114\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.71212627856515\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.76511621577522\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.90487179236047\n",
            "Iteration 350 | Accuracy: 75.92857142857142 | Loss:121.08509455125285\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.9459827497908\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.22755547917697\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.93389875130262\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.99813092630043\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4702276077975\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.43009789419648\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.2255611569068\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.58014740433245\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.31321058051674\n",
            "Iteration 850 | Accuracy: 75.92857142857142 | Loss:279.50711562899124\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:294.14223485341574\n",
            "Iteration 950 | Accuracy: 76.07142857142857 | Loss:311.65886068455336\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:326.6791095803085\n",
            "Iteration 1050 | Accuracy: 76.07142857142857 | Loss:340.50633669861855\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.86071983059276\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.7252726766649\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.00567341583826\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.876407539746\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:416.9491145111278\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.2677548047352\n",
            "##################################################\n",
            ">epoch=480, lrate=0.300, error=448.914\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7391567643920045\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.223061764544628\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.63768368258132\n",
            "Iteration 150 | Accuracy: 76.14285714285714 | Loss:58.1961150972653\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.71305025672848\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.73094638989822\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.88250236692059\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:121.11213912547967\n",
            "Iteration 400 | Accuracy: 75.92857142857142 | Loss:134.00179553179163\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:154.27478134437965\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.9194604438948\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.98179360169894\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.4812216405907\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:222.47923690298617\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.26001076650718\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.62247760651022\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.3669767574657\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.58687569107116\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.227532528282\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.76173139546245\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.76718872598997\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:340.60011500637125\n",
            "Iteration 1100 | Accuracy: 75.85714285714286 | Loss:360.96398162931325\n",
            "Iteration 1150 | Accuracy: 75.21428571428571 | Loss:374.8273645104057\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.1152958886562\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.97487435290043\n",
            "Iteration 1300 | Accuracy: 74.5 | Loss:417.05478970030833\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.38038882748674\n",
            "##################################################\n",
            ">epoch=481, lrate=0.300, error=449.037\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7403116091616444\n",
            "Iteration 50 | Accuracy: 76.64285714285714 | Loss:17.259164571129816\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.65617848228901\n",
            "Iteration 150 | Accuracy: 76.07142857142857 | Loss:58.20920181560139\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.73769066271453\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.70895626075198\n",
            "Iteration 300 | Accuracy: 75.64285714285714 | Loss:103.08308542862929\n",
            "Iteration 350 | Accuracy: 76.5 | Loss:121.30155452275432\n",
            "Iteration 400 | Accuracy: 76.21428571428571 | Loss:134.26627987743402\n",
            "Iteration 450 | Accuracy: 75.57142857142857 | Loss:154.4593987943609\n",
            "Iteration 500 | Accuracy: 75.64285714285714 | Loss:174.8490487624398\n",
            "Iteration 550 | Accuracy: 73.92857142857143 | Loss:193.07461474838314\n",
            "Iteration 600 | Accuracy: 76.42857142857142 | Loss:207.59853923782035\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:222.4703394917417\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.0275684296515\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.34208779545358\n",
            "Iteration 800 | Accuracy: 77.0 | Loss:261.8829459488726\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.9869659670695\n",
            "Iteration 900 | Accuracy: 76.07142857142857 | Loss:293.6692400972205\n",
            "Iteration 950 | Accuracy: 76.35714285714286 | Loss:311.0937918713401\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.27171500946207\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:339.9202320116711\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.4648475629232\n",
            "Iteration 1150 | Accuracy: 75.07142857142857 | Loss:374.38424829479385\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.64106990681273\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.45974484630653\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:416.4815835364534\n",
            "Iteration 1350 | Accuracy: 76.42857142857142 | Loss:433.77854012443726\n",
            "##################################################\n",
            ">epoch=482, lrate=0.300, error=448.307\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.730534466929628\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.073923150427373\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.64498458156139\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.28482420374998\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.66701262040544\n",
            "Iteration 250 | Accuracy: 76.5 | Loss:84.6673821319879\n",
            "Iteration 300 | Accuracy: 74.64285714285714 | Loss:101.33607693843148\n",
            "Iteration 350 | Accuracy: 75.57142857142857 | Loss:120.29365370401752\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.41321230600244\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.6727896737141\n",
            "Iteration 500 | Accuracy: 75.5 | Loss:173.44444596122995\n",
            "Iteration 550 | Accuracy: 72.92857142857143 | Loss:191.58738863703567\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:206.6722358268722\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.69741490115302\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.3454212225485\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:249.71286660850913\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.4067602646101\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.62601770607273\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:293.31719814320246\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.84137978176494\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:325.8338801861585\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:339.5740465770079\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:359.9403233171779\n",
            "Iteration 1150 | Accuracy: 75.14285714285714 | Loss:373.82898386845005\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.0869150291898\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:404.8874439982767\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:415.9530090683576\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.2739363788163\n",
            "##################################################\n",
            ">epoch=483, lrate=0.300, error=447.932\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.748807778218683\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.45480516362455\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.796176627537974\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.32891470677883\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.74200566488479\n",
            "Iteration 250 | Accuracy: 76.42857142857142 | Loss:84.72738193567078\n",
            "Iteration 300 | Accuracy: 74.85714285714286 | Loss:101.88019523312441\n",
            "Iteration 350 | Accuracy: 75.0 | Loss:120.73686531785698\n",
            "Iteration 400 | Accuracy: 76.5 | Loss:133.8543446011615\n",
            "Iteration 450 | Accuracy: 75.0 | Loss:153.90398522520678\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:173.98746190415125\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.8920340177319\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.10118175302338\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:221.98522031554378\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:237.85401363453917\n",
            "Iteration 750 | Accuracy: 76.35714285714286 | Loss:250.20222450359563\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.988245456542\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:279.42953692304366\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:294.130761229092\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.66826639971504\n",
            "Iteration 1000 | Accuracy: 75.71428571428571 | Loss:326.61012014338525\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:340.3920790211411\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:360.7784073948229\n",
            "Iteration 1150 | Accuracy: 75.35714285714286 | Loss:374.66608323102804\n",
            "Iteration 1200 | Accuracy: 74.64285714285714 | Loss:393.9394128210179\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.74235382715096\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.82774708128693\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:434.1787775560002\n",
            "##################################################\n",
            ">epoch=484, lrate=0.300, error=448.903\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.74754344604716\n",
            "Iteration 50 | Accuracy: 76.42857142857142 | Loss:17.46137402872083\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.91870990380931\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.5334806679516\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:70.03229264885783\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.93795743836311\n",
            "Iteration 300 | Accuracy: 75.42857142857143 | Loss:103.25577278715093\n",
            "Iteration 350 | Accuracy: 76.42857142857142 | Loss:121.48010037695991\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:134.31105034392056\n",
            "Iteration 450 | Accuracy: 74.92857142857143 | Loss:154.55691091826554\n",
            "Iteration 500 | Accuracy: 75.0 | Loss:174.30209360839115\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.2543708615067\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.60086427156742\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.4758474435213\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:238.3092273572393\n",
            "Iteration 750 | Accuracy: 76.28571428571429 | Loss:250.6674854685705\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.4175091782304\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:279.6145851961348\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:294.25812567137626\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.8386099530381\n",
            "Iteration 1000 | Accuracy: 75.57142857142857 | Loss:326.8264778720453\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:340.6644193144674\n",
            "Iteration 1100 | Accuracy: 75.78571428571429 | Loss:361.1288175999882\n",
            "Iteration 1150 | Accuracy: 75.5 | Loss:374.9742272596896\n",
            "Iteration 1200 | Accuracy: 74.57142857142857 | Loss:394.25285085407455\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:406.0534026954993\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.13074845138834\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.49540885701185\n",
            "##################################################\n",
            ">epoch=485, lrate=0.300, error=449.191\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7442299997795523\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.402477460430894\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.77475820554672\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.31626542268356\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.8004734633196\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.6669682993611\n",
            "Iteration 300 | Accuracy: 75.21428571428571 | Loss:102.71885583093633\n",
            "Iteration 350 | Accuracy: 75.14285714285714 | Loss:121.36039030264138\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.40155981878678\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:154.35595721633922\n",
            "Iteration 500 | Accuracy: 74.92857142857143 | Loss:174.43444046025928\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:192.27913966298604\n",
            "Iteration 600 | Accuracy: 75.5 | Loss:207.60069487641297\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.22162888922506\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.27562119404266\n",
            "Iteration 750 | Accuracy: 76.21428571428571 | Loss:250.64904825786618\n",
            "Iteration 800 | Accuracy: 76.64285714285714 | Loss:262.44334364727115\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:279.75666191109093\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:294.43320384918746\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.9823795883817\n",
            "Iteration 1000 | Accuracy: 75.64285714285714 | Loss:326.9145492889192\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:340.7159293549809\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:361.19568282421886\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:375.05498985108034\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:394.35269733800646\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.13663496148484\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:417.2194622483539\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:434.6158159100435\n",
            "##################################################\n",
            ">epoch=486, lrate=0.300, error=449.353\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.42857142857142 | Loss:1.7438110237472841\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.431066792405726\n",
            "Iteration 100 | Accuracy: 76.71428571428571 | Loss:39.87367705732485\n",
            "Iteration 150 | Accuracy: 76.21428571428571 | Loss:58.48633329286699\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.98866119997079\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.78106516268942\n",
            "Iteration 300 | Accuracy: 76.14285714285714 | Loss:103.29716830323568\n",
            "Iteration 350 | Accuracy: 76.92857142857143 | Loss:121.60686252028583\n",
            "Iteration 400 | Accuracy: 75.42857142857143 | Loss:134.37216567286953\n",
            "Iteration 450 | Accuracy: 74.35714285714286 | Loss:154.2934567618397\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.5719217767984\n",
            "Iteration 550 | Accuracy: 74.35714285714286 | Loss:192.42113937200975\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:207.45342935196135\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:222.1203608938283\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:238.05055717731128\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:250.45966025714444\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:262.17432195884936\n",
            "Iteration 850 | Accuracy: 75.78571428571429 | Loss:279.2570252437099\n",
            "Iteration 900 | Accuracy: 76.0 | Loss:293.8608207907498\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:311.3214629338071\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:326.39890864882375\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:340.2127103361495\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.7819077203876\n",
            "Iteration 1150 | Accuracy: 75.42857142857143 | Loss:374.57582796658625\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.88363986065923\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.6731849626364\n",
            "Iteration 1300 | Accuracy: 74.42857142857143 | Loss:416.7114025094275\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.1345827191351\n",
            "##################################################\n",
            ">epoch=487, lrate=0.300, error=448.785\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.35714285714286 | Loss:1.7383464837673748\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.268529274047406\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.587579082012766\n",
            "Iteration 150 | Accuracy: 76.64285714285714 | Loss:58.190633409316916\n",
            "Iteration 200 | Accuracy: 75.85714285714286 | Loss:69.57662205294979\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.38616085465738\n",
            "Iteration 300 | Accuracy: 74.85714285714286 | Loss:101.42578098445787\n",
            "Iteration 350 | Accuracy: 75.35714285714286 | Loss:120.07389427976909\n",
            "Iteration 400 | Accuracy: 76.14285714285714 | Loss:133.2612663557755\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:153.25271026346945\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.13488585169222\n",
            "Iteration 550 | Accuracy: 73.14285714285714 | Loss:191.07781539634726\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:206.48842710207745\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.5361890634098\n",
            "Iteration 700 | Accuracy: 75.5 | Loss:237.22620996685907\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.58801923672408\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.341218518208\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.5319865788366\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.19150094232384\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.76101744839366\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:325.72273039916263\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:339.54173726204147\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.0475615004376\n",
            "Iteration 1150 | Accuracy: 75.5 | Loss:373.87724168588113\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.1913854395558\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:404.9923277862228\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.06897787458564\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.48581728831493\n",
            "##################################################\n",
            ">epoch=488, lrate=0.300, error=448.197\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.746001316715153\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.434355364818078\n",
            "Iteration 100 | Accuracy: 76.64285714285714 | Loss:39.83133996147133\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.428449732940265\n",
            "Iteration 200 | Accuracy: 75.71428571428571 | Loss:69.91971133499469\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.70361763962283\n",
            "Iteration 300 | Accuracy: 75.35714285714286 | Loss:102.91485612617045\n",
            "Iteration 350 | Accuracy: 75.42857142857143 | Loss:121.41495020820045\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:134.47515390554827\n",
            "Iteration 450 | Accuracy: 74.64285714285714 | Loss:154.39744364644383\n",
            "Iteration 500 | Accuracy: 74.85714285714286 | Loss:174.31215694427632\n",
            "Iteration 550 | Accuracy: 73.42857142857143 | Loss:192.16129471145027\n",
            "Iteration 600 | Accuracy: 75.64285714285714 | Loss:207.521101460341\n",
            "Iteration 650 | Accuracy: 74.35714285714286 | Loss:222.24155475872698\n",
            "Iteration 700 | Accuracy: 75.42857142857143 | Loss:238.23858053567764\n",
            "Iteration 750 | Accuracy: 76.5 | Loss:250.62683965244483\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.42229743367255\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:279.64369224773964\n",
            "Iteration 900 | Accuracy: 75.85714285714286 | Loss:294.3056003447377\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.900302856645\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.823285330672\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:340.64023092264057\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.19290573205313\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:375.03293922474313\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.38203019472417\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.16641447980123\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.2538646944101\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.6997433541862\n",
            "##################################################\n",
            ">epoch=489, lrate=0.300, error=449.451\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.745001432022466\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.443529802856933\n",
            "Iteration 100 | Accuracy: 76.42857142857142 | Loss:39.89158109603906\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.49727298098512\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:70.00677577718213\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.74407096927047\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:103.15370596909294\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.44740733505573\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.2926612723455\n",
            "Iteration 450 | Accuracy: 74.78571428571429 | Loss:154.4545078940986\n",
            "Iteration 500 | Accuracy: 75.07142857142857 | Loss:174.09013517487364\n",
            "Iteration 550 | Accuracy: 73.78571428571429 | Loss:192.00050363790848\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:207.41517304019249\n",
            "Iteration 650 | Accuracy: 74.42857142857143 | Loss:222.31252662039557\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:238.1694423217171\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.56230967838442\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:262.3454241839714\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:279.4389866525946\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:294.0548493631666\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.6872727036838\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.6470843641092\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:340.50707067543186\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:361.09086899245796\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.9142074435313\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.29073741674125\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:406.09071238067105\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:417.1823849409479\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.6358060563811\n",
            "##################################################\n",
            ">epoch=490, lrate=0.300, error=449.366\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7437863021671076\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.39470616924946\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.76610592804974\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.30143841180427\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.8178394373367\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.53118850416011\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.91496677550184\n",
            "Iteration 350 | Accuracy: 76.57142857142857 | Loss:121.20961114175886\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:134.0945206710508\n",
            "Iteration 450 | Accuracy: 74.85714285714286 | Loss:154.20144763807716\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.80598450366477\n",
            "Iteration 550 | Accuracy: 73.71428571428571 | Loss:191.72921798775093\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:207.19896559286119\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:222.13213604812736\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.95638415701245\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:250.35415083015485\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:262.13959397735994\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:279.2042548434685\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.81786439684527\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.47358279675694\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:326.4172096527967\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:340.2630781772591\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.85385532435265\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.692035556964\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:394.0891504444156\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.89455065511527\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.9934480422561\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:434.45540627473764\n",
            "##################################################\n",
            ">epoch=491, lrate=0.300, error=449.187\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7447105875515843\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.391867413139067\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.76210922863524\n",
            "Iteration 150 | Accuracy: 76.28571428571429 | Loss:58.29419513250581\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.834682192703\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.51774986821687\n",
            "Iteration 300 | Accuracy: 76.57142857142857 | Loss:103.15521462363338\n",
            "Iteration 350 | Accuracy: 76.35714285714286 | Loss:121.46057850518932\n",
            "Iteration 400 | Accuracy: 74.85714285714286 | Loss:134.16725261317808\n",
            "Iteration 450 | Accuracy: 74.78571428571429 | Loss:153.85395014114064\n",
            "Iteration 500 | Accuracy: 75.14285714285714 | Loss:173.88882036461257\n",
            "Iteration 550 | Accuracy: 74.5 | Loss:191.69323651140584\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:206.82883047098042\n",
            "Iteration 650 | Accuracy: 74.5 | Loss:221.43979819547246\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.29279952070897\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.76805807577423\n",
            "Iteration 800 | Accuracy: 76.92857142857143 | Loss:261.4798436299979\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.5067973718144\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:293.07149989756164\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.5679900195079\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:325.69246948949217\n",
            "Iteration 1050 | Accuracy: 76.42857142857142 | Loss:339.5272846028676\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.15371798532516\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.9080296378945\n",
            "Iteration 1200 | Accuracy: 74.14285714285714 | Loss:393.33738671366973\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:405.2043396980068\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.23084503875305\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.7076628017146\n",
            "##################################################\n",
            ">epoch=492, lrate=0.300, error=448.327\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.28571428571429 | Loss:1.7303600608529042\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.11949659265292\n",
            "Iteration 100 | Accuracy: 76.57142857142857 | Loss:39.51297607858554\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.20925405780861\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.6432893946846\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.32870147030545\n",
            "Iteration 300 | Accuracy: 75.0 | Loss:101.40304762401831\n",
            "Iteration 350 | Accuracy: 75.28571428571429 | Loss:119.99202675772901\n",
            "Iteration 400 | Accuracy: 75.85714285714286 | Loss:133.22975284190161\n",
            "Iteration 450 | Accuracy: 74.71428571428571 | Loss:153.0939088152898\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:172.9317713337487\n",
            "Iteration 550 | Accuracy: 72.85714285714285 | Loss:190.85084609629783\n",
            "Iteration 600 | Accuracy: 75.71428571428571 | Loss:206.6996100562723\n",
            "Iteration 650 | Accuracy: 74.85714285714286 | Loss:221.7139509148843\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.38282550671806\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:249.85526380565958\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:261.64643914680624\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:278.681088702366\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.28820880428606\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:310.934901875396\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:325.9253331464844\n",
            "Iteration 1050 | Accuracy: 76.64285714285714 | Loss:339.7388833745412\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.2782043490689\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.0905323033818\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.4693079484765\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:405.2835293570097\n",
            "Iteration 1300 | Accuracy: 74.35714285714286 | Loss:416.3543027207895\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.82372451553783\n",
            "##################################################\n",
            ">epoch=493, lrate=0.300, error=448.517\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7512281368267126\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.45140025441434\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.75645818395222\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.24455301522509\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.75669425161209\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.43722167969057\n",
            "Iteration 300 | Accuracy: 75.85714285714286 | Loss:102.86263401400761\n",
            "Iteration 350 | Accuracy: 76.64285714285714 | Loss:121.1652135993296\n",
            "Iteration 400 | Accuracy: 75.71428571428571 | Loss:133.99999626394845\n",
            "Iteration 450 | Accuracy: 75.07142857142857 | Loss:154.11783648621008\n",
            "Iteration 500 | Accuracy: 75.21428571428571 | Loss:173.6922996714558\n",
            "Iteration 550 | Accuracy: 73.92857142857143 | Loss:191.60206374458468\n",
            "Iteration 600 | Accuracy: 75.57142857142857 | Loss:206.9620051929589\n",
            "Iteration 650 | Accuracy: 74.57142857142857 | Loss:221.9258574546992\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.7155231185836\n",
            "Iteration 750 | Accuracy: 76.78571428571429 | Loss:250.1294492208549\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.91097814755153\n",
            "Iteration 850 | Accuracy: 75.57142857142857 | Loss:278.90997263595216\n",
            "Iteration 900 | Accuracy: 75.78571428571429 | Loss:293.5096673152875\n",
            "Iteration 950 | Accuracy: 76.21428571428571 | Loss:311.2278265075366\n",
            "Iteration 1000 | Accuracy: 75.21428571428571 | Loss:326.1757002110357\n",
            "Iteration 1050 | Accuracy: 76.57142857142857 | Loss:339.9843362508403\n",
            "Iteration 1100 | Accuracy: 76.07142857142857 | Loss:360.5607612098717\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:374.3994101670483\n",
            "Iteration 1200 | Accuracy: 74.42857142857143 | Loss:393.8018115800919\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:405.61245919835574\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:416.7031249043519\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:434.1857230689733\n",
            "##################################################\n",
            ">epoch=494, lrate=0.300, error=448.894\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.07142857142857 | Loss:1.7510149431468907\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.43469933712102\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.763975079140245\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.27515734471674\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.810461057198\n",
            "Iteration 250 | Accuracy: 76.14285714285714 | Loss:84.45137308405431\n",
            "Iteration 300 | Accuracy: 76.21428571428571 | Loss:103.06834857387611\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:121.30165724210953\n",
            "Iteration 400 | Accuracy: 75.0 | Loss:133.96253232122197\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.8856734169864\n",
            "Iteration 500 | Accuracy: 75.42857142857143 | Loss:173.74680498343184\n",
            "Iteration 550 | Accuracy: 74.42857142857143 | Loss:191.6111790429854\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:206.67699380467033\n",
            "Iteration 650 | Accuracy: 74.64285714285714 | Loss:221.69311187869175\n",
            "Iteration 700 | Accuracy: 75.71428571428571 | Loss:237.37742482823242\n",
            "Iteration 750 | Accuracy: 76.57142857142857 | Loss:249.7565231406065\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.4291542626899\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.4016628735526\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:292.99056987520345\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:310.5620533192718\n",
            "Iteration 1000 | Accuracy: 75.14285714285714 | Loss:325.6331676529158\n",
            "Iteration 1050 | Accuracy: 76.35714285714286 | Loss:339.443029667666\n",
            "Iteration 1100 | Accuracy: 75.92857142857142 | Loss:360.04676613326416\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.80328175432146\n",
            "Iteration 1200 | Accuracy: 74.35714285714286 | Loss:393.2466061680071\n",
            "Iteration 1250 | Accuracy: 74.57142857142857 | Loss:405.0893772402236\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:416.1099109332951\n",
            "Iteration 1350 | Accuracy: 76.21428571428571 | Loss:433.593821119629\n",
            "##################################################\n",
            ">epoch=495, lrate=0.300, error=448.204\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7375477875314007\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.178362169843343\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.531126113485186\n",
            "Iteration 150 | Accuracy: 76.42857142857142 | Loss:58.23343249561609\n",
            "Iteration 200 | Accuracy: 75.78571428571429 | Loss:69.68386348665467\n",
            "Iteration 250 | Accuracy: 76.28571428571429 | Loss:84.30267781377775\n",
            "Iteration 300 | Accuracy: 75.07142857142857 | Loss:101.7397210440669\n",
            "Iteration 350 | Accuracy: 75.07142857142857 | Loss:120.40295040763111\n",
            "Iteration 400 | Accuracy: 76.0 | Loss:133.61804813446378\n",
            "Iteration 450 | Accuracy: 74.64285714285714 | Loss:153.33476793369675\n",
            "Iteration 500 | Accuracy: 75.28571428571429 | Loss:173.2606367111693\n",
            "Iteration 550 | Accuracy: 73.35714285714286 | Loss:191.09253849234824\n",
            "Iteration 600 | Accuracy: 75.78571428571429 | Loss:206.8226819706782\n",
            "Iteration 650 | Accuracy: 74.71428571428571 | Loss:221.92632686216214\n",
            "Iteration 700 | Accuracy: 75.57142857142857 | Loss:237.56710869084588\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.0200769925619\n",
            "Iteration 800 | Accuracy: 76.78571428571429 | Loss:261.8033257054427\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.82472136171106\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:293.44157301985985\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.11329683078185\n",
            "Iteration 1000 | Accuracy: 75.28571428571429 | Loss:326.0677506863867\n",
            "Iteration 1050 | Accuracy: 76.21428571428571 | Loss:339.83158094464255\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:360.3661245997768\n",
            "Iteration 1150 | Accuracy: 75.71428571428571 | Loss:374.21772545530234\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.62946211466\n",
            "Iteration 1250 | Accuracy: 74.78571428571429 | Loss:405.42447063448077\n",
            "Iteration 1300 | Accuracy: 74.21428571428571 | Loss:416.4863961100888\n",
            "Iteration 1350 | Accuracy: 76.14285714285714 | Loss:433.9844008451272\n",
            "##################################################\n",
            ">epoch=496, lrate=0.300, error=448.686\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.14285714285714 | Loss:1.7554149860576693\n",
            "Iteration 50 | Accuracy: 76.57142857142857 | Loss:17.457291226892973\n",
            "Iteration 100 | Accuracy: 76.35714285714286 | Loss:39.82973237560957\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.41522157948153\n",
            "Iteration 200 | Accuracy: 75.57142857142857 | Loss:69.95283466318557\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.55018580399535\n",
            "Iteration 300 | Accuracy: 76.0 | Loss:103.37547854959618\n",
            "Iteration 350 | Accuracy: 76.71428571428571 | Loss:120.67195153211455\n",
            "Iteration 400 | Accuracy: 75.21428571428571 | Loss:133.22550800871838\n",
            "Iteration 450 | Accuracy: 75.28571428571429 | Loss:153.61789427032684\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.2917436747498\n",
            "Iteration 550 | Accuracy: 73.5 | Loss:191.28239453317428\n",
            "Iteration 600 | Accuracy: 75.92857142857142 | Loss:206.41092412047993\n",
            "Iteration 650 | Accuracy: 75.0 | Loss:221.55652738838964\n",
            "Iteration 700 | Accuracy: 75.78571428571429 | Loss:237.19369304589515\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:249.66977449062233\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.3256809208545\n",
            "Iteration 850 | Accuracy: 75.71428571428571 | Loss:278.22161346240847\n",
            "Iteration 900 | Accuracy: 75.57142857142857 | Loss:292.8192559765531\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.4566284604338\n",
            "Iteration 1000 | Accuracy: 75.35714285714286 | Loss:325.52080424113177\n",
            "Iteration 1050 | Accuracy: 76.28571428571429 | Loss:339.28644543509535\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:359.86294639951285\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.668105797192\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:393.101916210665\n",
            "Iteration 1250 | Accuracy: 74.71428571428571 | Loss:404.93799823656667\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:415.93998310786105\n",
            "Iteration 1350 | Accuracy: 76.35714285714286 | Loss:433.4202353632953\n",
            "##################################################\n",
            ">epoch=497, lrate=0.300, error=448.013\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.7335545739270328\n",
            "Iteration 50 | Accuracy: 76.5 | Loss:17.132802384834285\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.55251983896989\n",
            "Iteration 150 | Accuracy: 76.35714285714286 | Loss:58.31549288366629\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.814866095038\n",
            "Iteration 250 | Accuracy: 76.21428571428571 | Loss:84.35167479737699\n",
            "Iteration 300 | Accuracy: 76.35714285714286 | Loss:102.93526386874738\n",
            "Iteration 350 | Accuracy: 76.78571428571429 | Loss:121.07789056149441\n",
            "Iteration 400 | Accuracy: 75.0 | Loss:133.75581654563567\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:154.05252493395804\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.69673462438044\n",
            "Iteration 550 | Accuracy: 74.28571428571429 | Loss:191.65162308261213\n",
            "Iteration 600 | Accuracy: 76.35714285714286 | Loss:206.5281217951835\n",
            "Iteration 650 | Accuracy: 75.42857142857143 | Loss:221.70932907748258\n",
            "Iteration 700 | Accuracy: 75.92857142857142 | Loss:237.2017069525275\n",
            "Iteration 750 | Accuracy: 76.71428571428571 | Loss:249.49413780885425\n",
            "Iteration 800 | Accuracy: 76.85714285714286 | Loss:261.1081949440538\n",
            "Iteration 850 | Accuracy: 75.64285714285714 | Loss:278.03548963198466\n",
            "Iteration 900 | Accuracy: 75.71428571428571 | Loss:292.6497130079347\n",
            "Iteration 950 | Accuracy: 76.28571428571429 | Loss:310.2491231009306\n",
            "Iteration 1000 | Accuracy: 75.42857142857143 | Loss:325.3421231919299\n",
            "Iteration 1050 | Accuracy: 76.5 | Loss:339.06541719206757\n",
            "Iteration 1100 | Accuracy: 76.0 | Loss:359.5926468239555\n",
            "Iteration 1150 | Accuracy: 75.57142857142857 | Loss:373.43069854156096\n",
            "Iteration 1200 | Accuracy: 74.5 | Loss:392.88977655906854\n",
            "Iteration 1250 | Accuracy: 74.64285714285714 | Loss:404.7326582233498\n",
            "Iteration 1300 | Accuracy: 74.28571428571429 | Loss:415.7264378980942\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.1769339425501\n",
            "##################################################\n",
            ">epoch=498, lrate=0.300, error=447.739\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 76.21428571428571 | Loss:1.7348390241026967\n",
            "Iteration 50 | Accuracy: 76.71428571428571 | Loss:17.10630752289006\n",
            "Iteration 100 | Accuracy: 76.5 | Loss:39.544148381467984\n",
            "Iteration 150 | Accuracy: 76.5 | Loss:58.31958819259994\n",
            "Iteration 200 | Accuracy: 75.64285714285714 | Loss:69.7932001148663\n",
            "Iteration 250 | Accuracy: 76.35714285714286 | Loss:84.32775296012662\n",
            "Iteration 300 | Accuracy: 75.78571428571429 | Loss:102.50395655361413\n",
            "Iteration 350 | Accuracy: 76.28571428571429 | Loss:120.9582082056121\n",
            "Iteration 400 | Accuracy: 75.78571428571429 | Loss:133.9446860601708\n",
            "Iteration 450 | Accuracy: 75.35714285714286 | Loss:153.98857484430386\n",
            "Iteration 500 | Accuracy: 75.57142857142857 | Loss:173.50084792684538\n",
            "Iteration 550 | Accuracy: 73.64285714285714 | Loss:191.55086895201828\n",
            "Iteration 600 | Accuracy: 75.85714285714286 | Loss:207.15456551807154\n",
            "Iteration 650 | Accuracy: 74.92857142857143 | Loss:222.22807342815972\n",
            "Iteration 700 | Accuracy: 75.64285714285714 | Loss:237.74010627642892\n",
            "Iteration 750 | Accuracy: 76.64285714285714 | Loss:250.16280551497826\n",
            "Iteration 800 | Accuracy: 76.71428571428571 | Loss:261.9053628132463\n",
            "Iteration 850 | Accuracy: 75.85714285714286 | Loss:278.79223683431434\n",
            "Iteration 900 | Accuracy: 75.64285714285714 | Loss:293.4110727207193\n",
            "Iteration 950 | Accuracy: 76.14285714285714 | Loss:311.12315960874577\n",
            "Iteration 1000 | Accuracy: 75.5 | Loss:326.09527273500373\n",
            "Iteration 1050 | Accuracy: 76.0 | Loss:339.72015804963985\n",
            "Iteration 1100 | Accuracy: 76.14285714285714 | Loss:360.16208050879226\n",
            "Iteration 1150 | Accuracy: 75.64285714285714 | Loss:374.1123346479926\n",
            "Iteration 1200 | Accuracy: 74.71428571428571 | Loss:393.50186686862156\n",
            "Iteration 1250 | Accuracy: 74.85714285714286 | Loss:405.27783140928466\n",
            "Iteration 1300 | Accuracy: 74.07142857142858 | Loss:416.33180996619643\n",
            "Iteration 1350 | Accuracy: 76.28571428571429 | Loss:433.81090470243805\n",
            "##################################################\n",
            ">epoch=499, lrate=0.300, error=448.484\n",
            "##################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYbNYaung4IZ",
        "outputId": "d2c2705e-3b51-4c52-ddcc-d2f303c8f3dd"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'weights': [-6.078553109080566, 2.4934096799347754, 3.807194287620623, 21.66199467578668, 10.274447808550104, -21.307413331874436, -9.819169129403278], 'output': 0.884998972585034, 'delta': -0.0007396889076164534}, {'weights': [11.84494427926206, 2.074320927486859, 10.8132249058571, -6.533845391731627, -11.36626787103271, 25.726275155280746, -4.896549214262629], 'output': 0.2324431563566603, 'delta': 8.714850982685043e-05}, {'weights': [5.7647528503597485, -1.9761247855597883, 2.992248822582852, -0.793268749399849, -17.30145182056697, 10.699120568278216, 5.329531382428484], 'output': 0.23757817116237495, 'delta': 0.00042476507324922723}, {'weights': [-5.17592206891633, 5.871406765819814, 1.2656194736807977, -0.756074289557698, 4.432380207396611, 8.217008565149914, -0.04327115598403503], 'output': 0.9999222156120263, 'delta': 5.654000482292983e-07}, {'weights': [3.2226109817393764, 3.1692610516011945, 10.873034558060404, -5.277485292209415, 14.559146012648618, -21.72514357475252, 3.8816150880809475], 'output': 0.057608343968132913, 'delta': 0.00046562952452166363}, {'weights': [4.005839011430371, 0.7862037422271424, 0.5745219135773116, -12.49693269651463, 0.20155861066996594, -1.5811998865500971, 5.165216133375101], 'output': 0.004665853226319138, 'delta': -1.9349403265001477e-05}, {'weights': [-7.373623945769268, 2.0172505127587845, -4.640483295603088, 0.04711001871112972, 3.869167693125737, 4.299280849513221, 1.2235882415097425], 'output': 0.9992973171461047, 'delta': 7.2035397465916285e-06}, {'weights': [-1.282506457856001, 0.8333917237466099, -2.641797607676581, -2.7426099168150984, 15.834409443914987, 15.574652278034305, -7.631182652884476], 'output': 0.9999833955159416, 'delta': -1.4253921030348073e-07}]\n",
            "[{'weights': [5.31700228014527, 9.848994333486337, -3.030533186965795, -4.153263987580531, 4.944809933724765, 3.3339907021242348, -4.432267365204261, 1.006617716520797, -3.1607580432427955], 'output': 0.015350943341831942, 'delta': 0.00010900031557390247}, {'weights': [7.855484141375599, 0.41922024935794255, -0.8444203929697766, -5.3138440334456485, -8.501190535219354, 3.0279599407001534, -8.988053833814194, 5.762716981979492, 6.446970407469958], 'output': 0.9864729703044965, 'delta': -0.001164479975373096}, {'weights': [6.644060896291788, -21.354450640768018, -2.0106450201997657, -6.417428207773722, 8.848670241329451, 0.4945065392252563, 2.2192113766486643, -12.019111414952295, 5.954786243783538], 'output': 9.025872575889129e-05, 'delta': 5.233448730047368e-06}, {'weights': [5.517619476170539, -5.325104750791348, -7.366003940206978, 6.1348480084394375, -5.167343915652828, 1.4323364363564652, 2.305075141400675, 9.401579917188323, -2.320375235438344], 'output': 0.9999999633985301, 'delta': -3.7791681481797674e-10}, {'weights': [-5.445937279451242, 16.288056991765547, 4.77460186745691, -7.644770243401249, -7.25957265312365, -0.41737243671773067, -9.707575283651309, 3.5900867335080493, -0.28126668043392367], 'output': 5.82702336961058e-07, 'delta': -1.4840695442111382e-08}, {'weights': [-0.4185906112050151, 4.978872967349762, -6.332900180317697, 2.2212975812537894, -14.602851918703477, -5.505044952939193, -0.9050153576958645, 10.559359614714987, -1.2808326076091476], 'output': 0.9998778895220348, 'delta': -2.1773612904978865e-06}, {'weights': [5.402816044427846, 0.1111464049593699, 7.2145195079032085, 6.719114507207456, -8.286411829596178, -4.350486465989169, 1.1195942894103217, -8.104588762690572, 0.1454478007290935], 'output': 0.9972727166365055, 'delta': 0.000234102104422174}, {'weights': [-14.721418046356078, 7.526788011288182, 6.039011325809572, -1.5114254463763008, -4.428394323605567, 5.728717448957034, -0.9907301088237551, 1.0535757467953515, -2.390468536763627], 'output': 9.091203603017798e-07, 'delta': 1.5602258605316758e-09}]\n",
            "[{'weights': [2.1353111176556108, -4.7444897061437095, 7.053163504928763, -7.652567111107018, -0.40125623704133057, -2.825331471490688, -11.404011872067981, -1.9795317785676816, -1.9968441474269985], 'output': 4.2181710112711644e-13, 'delta': -1.7792966680320894e-25}, {'weights': [-5.012880215733337, -2.21341984078837, 0.18856729293505425, -7.483140817616475, -3.9695619848326884, -3.2950282524332755, 5.856926946137229, -1.1116120224034158, 0.10757136061228052], 'output': 0.0008329878331523248, 'delta': -6.932907459697607e-07}, {'weights': [-5.50909583560708, 2.0390953605005584, -6.761735035931511, 2.4499442895155124, -4.255553432368887, 1.5528770590496541, 1.4038068606653975, -1.404715996280127, -3.526183042698855], 'output': 0.9781627811717243, 'delta': 0.0004664507398798201}, {'weights': [2.923634078647218, -1.1387788953303475, -1.9844362764690486, 4.060997735575597, -1.3109714215680959, -1.3281066364705163, 1.7010069397231218, -1.9024261992964981, -6.319851740054044], 'output': 0.04899953951480293, 'delta': -0.0022833091895064373}, {'weights': [1.666711260124929, -22.26255014698157, -5.599776861876085, 2.028023632047349, -8.055659750870165, -60.240902221458434, -9.002427396584025, 6.07757381782271, -2.7466449288033403], 'output': 1.267489242304844e-40, 'delta': -1.6065289793585074e-80}, {'weights': [0.8402060269686114, -1.1958437235027786, -3.5460127682011473, 7.698239563519808, 4.550296974247738, 3.251952171491927, -1.9463901998873718, 0.4375844352975591, -10.49700505694819], 'output': 0.06603153661052522, 'delta': -0.004072255509766978}, {'weights': [6.928410404465123, -12.598564891355151, -4.925996082654113, -23.125366015381037, 3.301990260446502, -17.454015306281384, -1.3346089326138693, 2.5242079107007136, -11.569704234184679], 'output': 2.6506867041080597e-29, 'delta': -7.026140003335248e-58}, {'weights': [-2.6699713690305487, -12.407153605036761, 6.950799811149303, 6.153175528507768, -3.568535315599872, -30.063971265159935, -4.163486897134035, -7.773105390289238, -6.061102041510371], 'output': 7.05853951166703e-21, 'delta': -4.982298003776465e-41}, {'weights': [-2.2569615778735583, 10.862798337786725, -4.788806839628161, -3.3134289945517845, 0.9027686997936187, 0.9447654907837316, -9.244556258413796, 0.021714127159222406, -1.315802469123125], 'output': 0.09885407630482668, 'delta': -0.008806113675360666}, {'weights': [0.7281632929645173, -6.662691753306422, -4.872996716431465, -1.6431399345702042, 3.513811344779828, 0.2978386951279658, -1.249226968408596, -1.4108904395863753, -2.807750810861706], 'output': 6.39022474811912e-06, 'delta': -4.0834711386823286e-11}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "1itOD1i9g4Ia",
        "outputId": "e364fe6a-fff1-47e5-d4d6-14903e3886d7"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h2-0.3.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h2-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD6CAYAAABXh3cLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAchElEQVR4nO3de3hc9X3n8fdXknWxbOtiy0K+G7AxEO6qgZLYxA6ESxLYlrIQto9L2Zi02YRCdoNpsilt+rRc8mxCn+5D6kITkxCwQ6BQsgSwCwkkYJABg/EFG/mObAnfr7I0+u4fc2xkaWSNpDlzdGY+r+fRM+f8zpmZr34afXT0Ozdzd0REJJ4Koi5ARET6TyEuIhJjCnERkRhTiIuIxJhCXEQkxhTiIiIxllaIm9ntZva+ma0ws8fMrNTMJpvZUjNbZ2YLzaw47GJFROR41ttx4mY2FngVOMPdD5nZIuD/AVcBT7r742b2I2C5uz94otcaNWqUT5o0KTOVi4jkiWXLln3s7jWplhWl+RpFQJmZtQFDgSZgFvDlYPkC4G7ghCE+adIkGhoa0nxLEREBMLONPS3rdTjF3bcC3wc2kQzvPcAyYLe7twerbQHGDrxUERHpi15D3MyqgGuAycAYoBy4It03MLO5ZtZgZg0tLS39LlRERLpLZ8fm54D17t7i7m3Ak8AlQKWZHR2OGQdsTfVkd5/v7vXuXl9Tk3JIR0RE+imdEN8EXGRmQ83MgNnASuAl4LpgnTnA0+GUKCIiPUlnTHwp8ATwFvBe8Jz5wJ3AHWa2DhgJPBxinSIikkJaR6e4+98Af9OluRGYnvGKREQkbTpjU0QkxhTiIhILh9sSvLr2Yx56pZFEh25mc1S6J/uISI46dCTBuub9jB5RwuadBxlbVUZdRVnKdVd+tJcjiQ6GlxZxSs0wDrcleGl1My37W/ni2WOoKi/m3S27ef79bbTsa+W1xh2MqxzKfdedzfjqod1e75nlH/Gz1zayqmkvZcWFNO9rTavmv//Vql7XGVZSxP7W9mPzJUUF/LeLJjK+qoyDbQncYV3zfkqKCigdUsgzyz+itS3BeROq+MyUUTz86nrqKss4/aTh/OGpo5hQPZSPdh9ibGUZ54yv5PXGHUyoHsqYyjK27DrISSNKKSos4OP9rZQUFTC8dEha38tA9XrafSbV19e7ztiUwWR/aztbdx2iqNAoLixIGTS5wN15Y/1OXli5nYdfXR91OXlnbGUZv5s3q9/PN7Nl7l6fapm2xPPMnoNtVAxNbiG0JzrYeeAI7R3OW5t2UT20mJVNe9m44yDjqspYs20frzfu4KxxFcyaNprxVUOpGV5Ch8PyLbupqyhlaeNOhpcW8cVzxvDmhp2sbNrLzv1HWNm0l/2t7WzccRBIfoiPOmPMCM6fUMXnz6xl/ccHWL5lD2ePreCMMSMoMMNxOhyKCoxEh+Mkp9s7nKICY/TwEpJHu8LBI+3sPtjG8s27WbZxF8NKi5h20gj2Hm7jw5b9/Mc7H9Hh8NlpNZQUFTKuqowNOw7ws9c3ZaQ/Rw0rpqSokM9Oq2H26bWcO66Sg20JDCgwI+HJmmuGlVBQYN2ef7gtweuNO3h5TQuXn1nL5FHluENhgdGW6GDH/iOMHFbMwSMJvvJIw7H+lHjZuvsQew61UVGW+a1zbYnngY/3t/LA4rX89PUeL78gIiFbfMdMTh09rF/P1ZZ4nnB3Dh5JsHT9Du779RpWb9sXdUkickw4G8wK8ZhrbU/w7PImnln+Eb/5QNemERms2hIK8ZzTtOcQdRVl7D54hJZ9rTy6dBOLGjZz9Vl1/GLZluPWrZ9YxbS64VwwsYp7n1vDtr2HI6paRPqjXSGeG9ydc//uRfYcautxna4BDtCwcRcNG3dlbIeciGRXW0dHKK+rEM+S9kQHD726nnueWx11KSISgbZ2hXhs7T3cxtl3vxB1GSISoaLC7oeYZoJOuw/Z4pXbFeAiwvkTqkJ5XW2JZ9D6jw/wyGsb+PHvNkRdiogMIndcNvXYCWqZphAfgFVNe2nYsJOP9hzmwZc/jLqcjBtTUcp19eN5fsU21mzXMeciPbnpwgk8unQTP71lOgt+v4HFq5r51hWn4Q63fHoypUMKQ3tvhXg/HGnv4P7nV/Ovr8TnGhTjqsq4cPJIvjJjMtNOGtGn595x2VTaEx0sXtXMwjc38XrjTg61JVKuO7ykiH2dLjo0EF88ZwzlxYWMGlbCBROrGFFWxNjKoXy8v5XW9g6GFBpbdx3izQ27cJyDrQmGlxbR3uEcbktOVw4tZubUGs4cMwIzY/fBI3zYsp+tuw9TNqSQ6vJiigqMU0cPo7wk+etwoLWddc372bTzIE+9vZWljTs4cCT5/Z43oZIZU2qYMbWGogKjuKiAU0cPY822fdQML2HbnsMk3OnocEqKCjmSSD6vuLCQ1vYEBQVGoRlHEh28t2UPm3cdpLHlAK837qA1xY4vM8jiSdUDtv4frzpui9PdefA3H3Lfr9cAMHNqTezPZ3h87kV8amwFb23cxR2LlvPC7TOoKBvCV2eewvjqoew51MbiVc188ewxWbkWj06774PfftDCjgOt3L5wedSl9OjWmSdz3vhKfrduB1Nqh3HdBeMYWqy/1fngg+37ePiV9by67mP++PyxXDpt9IDGYRs27KS1vYO2RAelQwq5cHL1sYC+84l3WdiwmSs/dRIvr2nhUFuCRbdezPTJ1b2+7qR5v+p3TVE5uaac+687hwsmhjOu3ZsTnXavEO9FR4dz93+8zyOvDc7rjsyYWsOR9gQTq8u554/PCm3cTSRT7n7mfX7y+w2hv8/U2mFUlhVz44XjueLMOl5a08yv3m2ied9hRg8v5aYLJ3DehCqGFBpFhcljPNoSHcdOyjGD4sKClBcuyzaFeJoOtyV4/v1t3Pb4O1GX0qvRw0v4z/95KcNKtJUt8bN550GeWLaFB5asTbl8ZHkxFWVDuOyMWm6+ZDJtiQ5eb9xBeUkRBQYnVZRRXlxIYYGx73A7b27YyfTJ1YypLGNE6RCKi3LrwDuFeA/aEh1s2XWIuopSXly5na8/9nbUJfXqzium8ReXnhJ1GSIZ9fgbm9hzqI1bZ+qzncqArmJoZqcBCzs1nQx8F3gkaJ8EbACud/ddAy02W15a3czNP3kz6jLSduuMk7nrqtOjLkMkFDdMnxB1CbHVa4i7+xrgXAAzKwS2Ak8B84Al7n6Pmc0L5u8MsdYBOdLeQVGB8Z2nV/DzpfG5/shts6fwjdlTKBwE43IiMvj0dUB1NvChu280s2uAS4P2BcDLDOIQn/qd56IuoVen1JTzX/9gPOUlRVx3wTgK7ZMdLiIiqfQ1xG8AHguma929KZjeBtRmrKoM257Fy7YWFRi3XzaVL0+fQFV5MQ+90pjypq51FaX80fljeXTpJuonVlE6pJDv/8k5oZ4UICK5J+0dm2ZWDHwEnOnu281st7tXdlq+y927HURpZnOBuQATJky4YOPG7B6qt3b7Pi77wW9Df5/l37382L0ru9q04yAz7n8JgK98ZjLX149nSu3w0GsSkdyQqduzXQm85e7bg/ntZlbn7k1mVgc0p3qSu88H5kPy6JQ+vN+AuXvoAf4Hk6r4xVf/8ITrTBg5lA33XB1qHSKSn/oy4HojnwylADwDzAmm5wBPZ6qoTAnrdkhH3XXltF4DXEQkTGltiZtZOXAZcGun5nuARWZ2C7ARuD7z5Q3M9H9YHNprv/Ht2YweXhra64uIpCOtEHf3A8DILm07SB6tMmjtPtjzLdD663fzZjG2sizjrysi0h86ZzsN35h1KjddNJGqocU5dzqviMSbQrwHi++YySk15bqglIgMagrxFHQkiYjERc6ODSQ6+n5kytTaYSz55swQqhERCUfObokvatjcp/V/878uZeLI8pCqEREJR86G+N5D6R+Zsvp7V+h0dxGJpZwdTkl3f+TiO2YowEUktnJ2SzwdJ7reiYhIHOTulji9b4orwEUk7nI3xE+Q4dMnV/PhP1yVvWJEREKSs8MpT761NWX7wrkXccHEKt0pR0RyQs6G+Mqmvd3a7r/ubC48eWSKtUVE4ilnh1NS+ZP68VGXICKSUXkV4iIiuSZvQvwbs6dEXYKISMblTYjXVegGDiKSe3IyxA+3JaIuQUQkK3IyxHceOBJ1CSIiWZGTIf6bD1q6tXm490wWEYlEToZ4Kh1KcRHJQWmFuJlVmtkTZrbazFaZ2cVmVm1mL5rZ2uCxKuxi05VqOEU7NkUkF6W7Jf4A8Gt3nwacA6wC5gFL3H0KsCSYHxTuf35Nt7bZp9dGUImISLh6DXEzqwBmAA8DuPsRd98NXAMsCFZbAFwbVpEiIpJaOlvik4EW4Mdm9raZPWRm5UCtuzcF62wDtKkrIpJl6YR4EXA+8KC7nwccoMvQibs7kHLPoZnNNbMGM2toael+1IiIiPRfOiG+Bdji7kuD+SdIhvp2M6sDCB6bUz3Z3ee7e72719fU1GSiZhERCfQa4u6+DdhsZqcFTbOBlcAzwJygbQ7wdCgViohIj9K9nvjXgUfNrBhoBG4m+QdgkZndAmwErg+nxL55Za2GbEQkf6QV4u7+DlCfYtHszJYzcD9fuqlb2/eu/VQElYiIhC/nzth8bsW2bm1/etHECCoREQlfzoW4iEg+UYiLiMSYQlxEJMYU4iIiMaYQFxGJsZwK8USHrhkuIvklp0L8Fw2boy5BRCSrcibE9xxqY96T70VdhohIVuVMiH/t0beiLkFEJOtyJsTXNu+LugQRkazLmRA3LOoSRESyLmdCXEQkH+VMiJs2xEUkD+VOiPfQ/vVZp2a1DhGRbMqZEO/Jp08dFXUJIiKhyZkQtx7GU84YMyLLlYiIZE/OhHhPhpcOiboEEZHQ5HyIi4jkMoW4iEiM5UyIpxoSv3XGydkvREQki9K6272ZbQD2AQmg3d3rzawaWAhMAjYA17v7rnDK7J+7rjo96hJERELVly3xz7r7ue5eH8zPA5a4+xRgSTAvIiJZNJDhlGuABcH0AuDagZcjIiJ9kW6IO/CCmS0zs7lBW627NwXT24DaVE80s7lm1mBmDS0tLQMsV0REOktrTBz4tLtvNbPRwItmtrrzQnd3M0t5bzR3nw/MB6ivrw/t/mlbdh0K66VFRAattLbE3X1r8NgMPAVMB7abWR1A8NgcVpG9aUt0dGv7zBSdbi8iua/XEDezcjMbfnQauBxYATwDzAlWmwM8HVaRvUl1g+S6itIIKhERya50hlNqgaeCa5MUAT9391+b2ZvAIjO7BdgIXB9emX1XWJAzh8CLiPSo1xB390bgnBTtO4DZYRSVCQW6vriI5IGc3Vz96sxToi5BRCR0ORvi46uHRl2CiEjocjbERUTygUJcRCTGciLEPbRTiEREBrecCHERkXyVEyHe1tH9jE0RkXyQEyH+2NJNUZcgIhKJnAjxA0cSUZcgIhKJnAhxEZF8lRshrsNTRCRP5UaIi4jkKYW4iEiM5USIazBFRPJVboS4UlxE8lROhPiC32+IugQRkUjkRIjva22PugQRkUjkRIiLiOQrhbiISIwpxEVEYiztEDezQjN728yeDeYnm9lSM1tnZgvNrDi8MkVEJJW+bInfBqzqNH8v8AN3PxXYBdySycJERKR3aYW4mY0DrgYeCuYNmAU8EayyALg2jAJFRKRn6W6J/xD4FnD07gsjgd3ufvTYvi3A2FRPNLO5ZtZgZg0tLS0DKlZERI7Xa4ib2ReAZndf1p83cPf57l7v7vU1NTX9eQkREelBURrrXAJ8ycyuAkqBEcADQKWZFQVb4+OAreGVKSIiqfS6Je7ud7n7OHefBNwA/Ke73wS8BFwXrDYHeDq0Kvto9PCSqEsQEcmKgRwnfidwh5mtIzlG/nBmShq4N779uahLEBHJinSGU45x95eBl4PpRmB65ksSEZF0xf6MzaY9h46bLy6M/bckIpK22CfevF++d9z8P/7RWRFVIiKSfbEP8e17Dx83XzqkMKJKRESyL/YhvnrbvqhLEBGJTOxDXEQknynERURiTCEuIhJjCnERkRjLuRA3i7oCEZHsybkQFxHJJwpxEZEYi3WI7zvc1q1Noykikk9iHeKrmrqf6DNymC5DKyL5I7Yh3p7o4Mv/+nq39umTqyOoRkQkGrEN8eZ9rbR3eNRliIhEKrYhLiIiCnERkViLbYjrpB4RkRiHuIiIxDjETUeEi4j0HuJmVmpmb5jZcjN738z+NmifbGZLzWydmS00s+LwyxURkc7S2RJvBWa5+znAucAVZnYRcC/wA3c/FdgF3BJemd2lGhOfMnpYNksQEYlcryHuSfuD2SHBlwOzgCeC9gXAtaFU2Acn15RHXYKISFalNSZuZoVm9g7QDLwIfAjsdvf2YJUtwNgenjvXzBrMrKGlpSUTNSdfN0VbgQ5ZEZE8k1aIu3vC3c8FxgHTgWnpvoG7z3f3enevr6mp6WeZ6fkfs04N9fVFRAabPh2d4u67gZeAi4FKMysKFo0Dtma4tj6bOFLDKSKSX9I5OqXGzCqD6TLgMmAVyTC/LlhtDvB0WEWmq8N1LRURyS9Fva9CHbDAzApJhv4id3/WzFYCj5vZ3wNvAw+HWGc3qeK6qEBj4iKSX3oNcXd/FzgvRXsjyfHxSMz/bWO3tqHF6fxNEhHJHbE9Y/OdzbujLkFEJHKxDXENnIiIxDjERUQkxiGu41BEROIc4jqcUEQkviEuIiIKcRGRWIttiGswRUQkziGuFBcRiW+Ii4iIQlxEJNZiG+IaTRERiXGIi4iIQlxEJNbiG+JdDk+pHVESUSEiItGJbYh3HRPXTZJFJB/FNsRFREQhLiISa7ENcZ2xKSIS4xBf17w/6hJERCLXa4ib2Xgze8nMVprZ+2Z2W9BebWYvmtna4LEq/HI/cagtcdz88FLdJFlE8k86W+LtwDfd/QzgIuBrZnYGMA9Y4u5TgCXBfOh2HjjCl/751W7tP7l5ejbeXkRkUOl189Xdm4CmYHqfma0CxgLXAJcGqy0AXgbuDKXKTs7/3osp28dUloX91iIig06fxsTNbBJwHrAUqA0CHmAbUNvDc+aaWYOZNbS0tAygVBER6SrtEDezYcAvgb9y972dl3nyhpcpjxdx9/nuXu/u9TU1NQMqVkREjpdWiJvZEJIB/qi7Pxk0bzezumB5HdAcTom9e/Cm86N6axGRSKVzdIoBDwOr3P3/dFr0DDAnmJ4DPJ358tJz5Vl1Ub21iEik0jku7xLgT4H3zOydoO2vgXuARWZ2C7ARuD6cEk/srLEVUbytiMigkM7RKa8CPV1danZmy+m7SaPKoy5BRCQysT1j8yhdu1BE8ln8Q1wpLiJ5LP4hHnUBIiIRin+Ia1NcRPJYDoR41BWIiEQn/iGuARURyWPxD3FluIjksfiHeNQFiIhEKP4hrhQXkTwW+xAvUIqLSB6LfYgrw0Ukn8U+xDUqLiL5LPYhri1xEclnsQrxzTsPdmsrUIiLSB6LVYi/t3VPtzad7CMi+SxWIZ7qSBQNp4hIPotViLfsb+3WpkMMRSSfxSrE//e/r4i6BBGRQSWde2xG7mevb+Sl1c0pl11+Zm2WqxERGTxiEeLfOcEW+Jl1ulGyiOSvXodTzOzfzKzZzFZ0aqs2sxfNbG3wWBVumScqMLJ3FhGJXDpj4j8BrujSNg9Y4u5TgCXBfCS0X1NE8lmvIe7uvwV2dmm+BlgQTC8Ars1wXSIikob+Hp1S6+5NwfQ2oMe9i2Y218wazKyhpaWln2/XM/eMv6SISGwM+BBDd3egxyh19/nuXu/u9TU1NQN9u24qyoZk/DVFROKivyG+3czqAILH1Mf/ZcgLt89I2b74jplhvq2IyKDX30MMnwHmAPcEj09nrKIUptYOZ8M9V4f5FiIisZTOIYaPAa8Bp5nZFjO7hWR4X2Zma4HPBfMiIpJlvW6Ju/uNPSyaneFaRESkj2J17RQRETmeQlxEJMYU4iIiMaYQFxGJMYW4iEiMKcRFRGLMPIsXHzGzFmBjP58+Cvg4g+WELU71qtbwxKneONUK8ap3oLVOdPeU1y3JaogPhJk1uHt91HWkK071qtbwxKneONUK8ao3zFo1nCIiEmMKcRGRGItTiM+PuoA+ilO9qjU8cao3TrVCvOoNrdbYjImLiEh3cdoSFxGRLmIR4mZ2hZmtMbN1ZhbJTZnNbLyZvWRmK83sfTO7LWivNrMXzWxt8FgVtJuZ/VNQ87tmdn6n15oTrL/WzOaEWHOhmb1tZs8G85PNbGlQ00IzKw7aS4L5dcHySZ1e466gfY2ZfT7EWivN7AkzW21mq8zs4sHat2Z2e/AZWGFmj5lZ6WDqWzP7NzNrNrMVndoy1pdmdoGZvRc855/M+n+78h5qvT/4HLxrZk+ZWWWnZSn7rKeM6Onnksl6Oy37ppm5mY0K5rPTt+4+qL+AQuBD4GSgGFgOnBFBHXXA+cH0cOAD4AzgPmBe0D4PuDeYvgp4DjDgImBp0F4NNAaPVcF0VUg13wH8HHg2mF8E3BBM/wj4i2D6L4EfBdM3AAuD6TOC/i4BJgc/h8KQal0A/PdguhioHIx9C4wF1gNlnfr0zwZT3wIzgPOBFZ3aMtaXwBvBuhY898oM13o5UBRM39up1pR9xgkyoqefSybrDdrHA8+TPA9mVDb7NuO/jJn+Ai4Gnu80fxdw1yCo62ngMmANUBe01QFrgul/AW7stP6aYPmNwL90aj9uvQzWNw5YAswCng0+FB93+uU41q/Bh+/iYLooWM+69nXn9TJcawXJYLQu7YOub0mG+ObgF7Ao6NvPD7a+BSZxfDBmpC+DZas7tR+3XiZq7bLsvwCPBtMp+4weMuJEn/lM1ws8AZwDbOCTEM9K38ZhOOXoL81RW4K2yAT/Ep8HLAVq3b0pWLQNqA2me6o7W9/PD4FvAR3B/Ehgt7u3p3jfYzUFy/cE62er1slAC/BjSw7/PGRm5QzCvnX3rcD3gU1AE8m+Wsbg7dujMtWXY4Ppru1h+XOSW6T0UlOq9hN95jPGzK4Btrr78i6LstK3cQjxQcXMhgG/BP7K3fd2XubJP5+RH+5jZl8Amt19WdS1pKmI5L+oD7r7ecABkv/yHzOI+rYKuIbkH54xQDlwRaRF9dFg6cvemNm3gXbg0ahr6YmZDQX+GvhuVDXEIcS3khxvOmpc0JZ1ZjaEZIA/6u5PBs3bzawuWF4HNAftPdWdje/nEuBLZrYBeJzkkMoDQKWZHb0lX+f3PVZTsLwC2JGlWiG5xbHF3ZcG80+QDPXB2LefA9a7e4u7twFPkuzvwdq3R2WqL7cG013bM8rM/gz4AnBT8EenP7XuoOefS6acQvIP+vLg920c8JaZndSPevvXt5kagwvri+RWWmPQUUd3WpwZQR0GPAL8sEv7/Ry/w+i+YPpqjt+p8UbQXk1y/Lcq+FoPVIdY96V8smPzFxy/k+cvg+mvcfzOt0XB9JkcvyOpkfB2bL4CnBZM3x3066DrW+BC4H1gaPD+C4CvD7a+pfuYeMb6ku47367KcK1XACuBmi7rpewzTpARPf1cMllvl2Ub+GRMPCt9G0pwZPqL5F7eD0jugf52RDV8muS/oO8C7wRfV5Ecd1sCrAUWd/phGPB/g5rfA+o7vdafA+uCr5tDrvtSPgnxk4MPybrgw10StJcG8+uC5Sd3ev63g+9hDQM4CiGNOs8FGoL+/ffgwz0o+xb4W2A1sAL4aRAqg6ZvgcdIjte3kfwv55ZM9iVQH3zvHwL/TJcd0hmodR3JMeOjv2c/6q3P6CEjevq5ZLLeLss38EmIZ6VvdcamiEiMxWFMXEREeqAQFxGJMYW4iEiMKcRFRGJMIS4iEmMKcRGRGFOIi4jEmEJcRCTG/j+FOYDc5XpMEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdlUlEQVR4nO3de5BcZ3nn8e+vL9NzkyzJGoQtCSSDQjAUBO/EmCUkgAmWHRaxFWDtZYMAZ1UJJjdgwcYV2A2hCgO1gCuswYDAzoIvGIhVxAGMzW1ZfBkDNpYvePAFSWtbg2+6zqW7n/2jX0mt8YxGmume7p7z+1R1zTnPeU+fp9/pefrMe06fo4jAzMyyIdfqBMzMbP646JuZZYiLvplZhrjom5lliIu+mVmGFFqdwJEsX7481qxZ0+o0zMw6ym233fbbiBiYallbF/01a9YwNDTU6jTMzDqKpIemW+bhHTOzDHHRNzPLkBmLvqTNknZKunNS/K8k3SNpq6SP1cUvkDQs6V5JZ9TF16fYsKTzG/syzMzsaBzNmP6XgX8CLj8QkPQqYAPw4ogYk/SMFD8ZOBt4AXAi8D1Jv5NW+wzwx8B24FZJWyLirka9EDMzm9mMRT8ifiRpzaTwXwIfjYix1GZnim8ArkzxByQNA6emZcMRcT+ApCtTWxd9M7N5NNsx/d8BXiHpZkk/lPT7Kb4S2FbXbnuKTRd/GkmbJA1JGhoZGZllemZmNpXZFv0CsAw4DfhvwNWS1IiEIuLSiBiMiMGBgSlPMzUzs1mabdHfDnwjam4BqsByYAewuq7dqhSbLt40O3eNcv1djzZzE2ZmHWe2Rf9fgFcBpAO1XcBvgS3A2ZJKktYC64BbgFuBdZLWSuqidrB3y1yTP5I3fe6n/NfLh6hWfb8AM7MDZjyQK+kK4JXAcknbgQ8Bm4HN6TTOcWBj1O7GslXS1dQO0JaB8yKikp7nXcB3gDywOSK2NuH1HPTQY/tS/s3ciplZZzmas3fOmWbRf5mm/UeAj0wRvw647piyMzOzhvI3cs3MMsRF38wsQ1z0zcwyxEXfzCxDXPTNzDLERd/MLENc9M3MMsRF38wsQ1z0zcwyxEXfzCxDXPTNzDLERd/MLENc9M3MMsRF38wsQ1z0zcwyxEXfzCxDZiz6kjZL2pnukjV52XskhaTlaV6SLpY0LOkOSafUtd0o6b702NjYl2FmZkfjaPb0vwysnxyUtBp4LfCbuvCZ1O6Luw7YBFyS2i6jdpvFlwKnAh+StHQuiZuZ2bGbsehHxI+Ax6dY9EngfUD9ncc3AJdHzU3AEkknAGcA10fE4xHxBHA9U3yQmJlZc81qTF/SBmBHRNw+adFKYFvd/PYUmy4+1XNvkjQkaWhkZGQ26ZmZ2TSOuehL6gU+AHyw8elARFwaEYMRMTgwMNCMTZiZZdZs9vSfA6wFbpf0ILAK+JmkZwI7gNV1bVel2HRxMzObR8dc9CPilxHxjIhYExFrqA3VnBIRjwBbgLems3hOA56KiIeB7wCvlbQ0HcB9bYqZmdk8OppTNq8Afgo8T9J2Seceofl1wP3AMPB54J0AEfE48GHg1vT4hxQzM7N5VJipQUScM8PyNXXTAZw3TbvNwOZjzM/MzBrI38g1M8sQF30zswxx0TczyxAXfTOzDHHRNzPLkAVf9CNmbmNmlhULvuibmdkhLvpmZhniom9mliEu+mZmGeKib2aWIS76ZmYZ4qJvZpYhLvpmZhniom9mliEzXk+/0530gesAeM5AH5ef+1JWLulpcUZmZq1zNHfO2ixpp6Q762Ifl3SPpDskfVPSkrplF0galnSvpDPq4utTbFjS+Y1/KUf265G9vPyjN7Lt8X3zvWkzs7ZxNMM7XwbWT4pdD7wwIl4E/Aq4AEDSycDZwAvSOv9LUl5SHvgMcCZwMnBOajvvvnrLb1qxWTOztjBj0Y+IHwGPT4p9NyLKafYmYFWa3gBcGRFjEfEAtXvlnpoewxFxf0SMA1emtvPukh/8uhWbNTNrC404kPsO4N/S9EpgW92y7Sk2XfxpJG2SNCRpaGRkpAHpmZnZAXMq+pIuBMrAVxqTDkTEpRExGBGDAwMDjXpaMzNjDmfvSHob8Drg9IiDV63fAayua7YqxThC3MzM5sms9vQlrQfeB7w+IupPh9kCnC2pJGktsA64BbgVWCdpraQuagd7t8wtdTMzO1Yz7ulLugJ4JbBc0nbgQ9TO1ikB10sCuCki/iIitkq6GriL2rDPeRFRSc/zLuA7QB7YHBFbm/B6jkpEkPI2M8uUGYt+RJwzRfiLR2j/EeAjU8SvA647puya5B//9W7+/nUtOWPUzKylMnkZhv9900OtTsHMrCUyWfQ9smNmWZXNoo+rvpllUzaLvmu+mWVUJov+eLna6hTMzFoik0W/XA0e2zPW6jTMzOZdJos+wKO7XPTNLHsyW/Q9rm9mWZTZon/WxT9udQpmZvMus0X/4CXizMwyJLNF38wsizJd9HfuGm11CmZm8yrTRf8T37231SmYmc2rTBd9X47BzLIm20XfNd/MMsZF38wsQ2Ys+pI2S9op6c662DJJ10u6L/1cmuKSdLGkYUl3SDqlbp2Nqf19kjY25+Ucmytu2dbqFMzM5tXR7Ol/GVg/KXY+cENErANuSPMAZ1K7L+46YBNwCdQ+JKjdZvGlwKnAhw58UJiZ2fyZsehHxI+AxyeFNwCXpenLgDfUxS+PmpuAJZJOAM4Aro+IxyPiCeB6nv5BYmZmTTbbMf0VEfFwmn4EWJGmVwL1YybbU2y6+NNI2iRpSNLQyMjILNMzM7OpzPlAbkQE0LCLGkTEpRExGBGDAwMDjXraaVWqvh6DmWXHbIv+o2nYhvRzZ4rvAFbXtVuVYtPFW+69X7u91SmYmc2b2Rb9LcCBM3A2AtfWxd+azuI5DXgqDQN9B3itpKXpAO5rU6zlvvnztvjsMTObF4WZGki6AnglsFzSdmpn4XwUuFrSucBDwJtT8+uAs4BhYB/wdoCIeFzSh4FbU7t/iIjJB4fNzKzJZiz6EXHONItOn6JtAOdN8zybgc3HlJ2ZmTVUpr+Re4CvtmlmWeGiD9z76O5Wp2BmNi9c9PHVNs0sO1z0gZxrvpllhIs+4B19M8sKF33gP3/+5lanYGY2L1z0zcwyxEXfzCxDXPTNzDLERd/MLENc9JNypdrqFMzMms5FP/nk937V6hTMzJrORT+5+2FfisHMFj4X/cTfzzKzLHDRTySXfTNb+Fz0E9d8M8uCORV9SX8naaukOyVdIalb0lpJN0salnSVpK7UtpTmh9PyNY14AY3imm9mWTDroi9pJfDXwGBEvBDIA2cDFwGfjIjnAk8A56ZVzgWeSPFPpnZt47t3PdrqFMzMmm6uwzsFoEdSAegFHgZeDVyTll8GvCFNb0jzpOWnywPpZmbzatZFPyJ2AJ8AfkOt2D8F3AY8GRHl1Gw7sDJNrwS2pXXLqf3xk59X0iZJQ5KGRkZGZpuemZlNYS7DO0up7b2vBU4E+oD1c00oIi6NiMGIGBwYGJjr05mZWZ25DO+8BnggIkYiYgL4BvByYEka7gFYBexI0zuA1QBp+XHAY3PYvpmZHaO5FP3fAKdJ6k1j86cDdwHfB96Y2mwErk3TW9I8afmNERFz2L6ZmR2juYzp30ztgOzPgF+m57oUeD/wbknD1Mbsv5hW+SJwfIq/Gzh/DnmbmdksFGZuMr2I+BDwoUnh+4FTp2g7CrxpLttrtvdfcwcXvfFFrU7DzKxp/I3cOlcNbWt1CmZmTeWib2aWIS76ZmYZ4qJvZpYhLvqT3D+yp9UpmJk1jYv+JL/c8VSrUzAzaxoXfTOzDHHRn+RLP3mw1SmYmTWNi/4kv9j2ZKtTMDNrGhd9M7MMcdGfwhW3/KbVKZiZNYWL/hSudNE3swXKRX8Kt2/3aZtmtjC56E+jUvWl/s1s4XHRn4bv2G5mC5GL/jSuuW17q1MwM2u4ORV9SUskXSPpHkl3S3qZpGWSrpd0X/q5NLWVpIslDUu6Q9IpjXkJzfG+r9/R6hTMzBpurnv6nwa+HRG/C7wYuJvabRBviIh1wA0cui3imcC69NgEXDLHbTfdWLnS6hTMzBpq1kVf0nHAH5LugRsR4xHxJLABuCw1uwx4Q5reAFweNTcBSySdMOvM58FVt/pOWma2sMxlT38tMAJ8SdLPJX1BUh+wIiIeTm0eAVak6ZVAfRXdnmJt64PXbm11CmZmDTWXol8ATgEuiYiXAHs5NJQDQEQEcEznPkraJGlI0tDIyMgc0muMf/7pg61OwcysYeZS9LcD2yPi5jR/DbUPgUcPDNuknzvT8h3A6rr1V6XYYSLi0ogYjIjBgYGBOaTXGH9/7VZue+iJVqdhZtYQsy76EfEIsE3S81LodOAuYAuwMcU2Atem6S3AW9NZPKcBT9UNA7W1P73k//L+a+5golJtdSpmZnNSmOP6fwV8RVIXcD/wdmofJFdLOhd4CHhzansdcBYwDOxLbTvGVUPbuGpoGxee9Xz+/BVrkfz1LTPrPKoNu7enwcHBGBoamtW6a87/1wZnc7jF3QU+92eDnHbSMn8AmFlbkXRbRAxOtWyue/qZtWu0zDmfv+ng/F+fvo7/9PurWbmkp4VZmZkdmYt+g1x8w31cfMN9B+f/4o+ew1te+ixWL+ttYVZmZodz0W+Sz/7w13z2h78GQIKPv/HFvP7FJ9JV8OWOzKx1XPTnQQS892u3896v3Q7AO16+lk1/eBLPPK67xZmZWda46LfA5p88wOafPADA6mU9vH/97/Ka56+gu5hvcWZmttC56LfYtsf3866v/vzg/EkDfZz7B2t53YtO5LieYgszM7OFyEW/zdw/spcLv3knF37zzoOx9S94Jme8cAWvet4zWNLb1cLszKzTueh3gG9vfYRvb33ksNhzn9HPn56yilesW87zT1hMPufvCpjZzFz0O9Twzj1c9O17uOjbh8cHn72Uf//c5Zy2dhkvWr2E/pJ/xWZ2iCvCAjP00BMMPfQEF0+xrJgXr1g3wEtWL2HtQB/PP2ExJx7XQ0+XDyCbZYWLfoZMVIIb79nJjffsnLFtTzHPc57Rx/NWLGZpb5GTBvo5cUk3y/tLrFjczdLeIoW8v3Ng1mlc9G1K+ycq3LljF3fu2DWn51mxuMTAohKFXI6VS3tY3F0gnxMnHNdDqZCjVMwz0N8FiL5SnsXdRXISPV15erryFHOiVMxTKuQo5nM+dmE2Ry761lSP7hrj0V1jAPxi25MtzubpetJ3I5b2FlncU6RSDZb3lygVa//FDPSXyEnk82J5XxflatDblWdxT5GJSrCoVKC7K09EsKi7QD6XQ8Ci7tqfVjGfozcNn3UVcpQKefI5UciLrnyOQk7kc/JF+2zeuOhbpu2fqNR+PlXh/z01CsB9O/e0MqWWWdJbZKJcpZDP0VPMM1ausLS3i0U9RYo5sXpZL8f1FOntyvPs43vpLuZZ1F3g+L4SxXyO/lKB7q4cxVyOQl7kJMbLVR7fN87esTJ7xyqMlSs8tmecagTL+rpY1F1kcU+BsYkqj+4aRap9IFarQV+pQDGfo1TIIUG1CrtHJ3jo8X1MVKo8d6Cf5YtKrFzSgwTlau2KwXnVPki78jly/s/waVz0zQyAJ/dNpKkKT+2vTT9xMFY7SWChWdRdYHl/Caj9V1csCCGW93cRQKmQ4/j+EuVKlb5Sgf5SgYlK0N9doJgT45UqfV0FKtVgrFKlryvPWLl2s6X+UoGxcpViXpQKOfZPVHjGom76SwXuengXS3u76C7meOC3e3nOQD85iVwOFpWKPLprlOWLSvze6iUNf80u+maWWbtHy+weLQPwwG/3tjibw/UU89z94fUNf16ffmFm1oYODD022pyLvqS8pJ9L+laaXyvpZknDkq5Kt1JEUinND6fla+a6bTMzOzaN2NP/G+DuuvmLgE9GxHOBJ4BzU/xc4IkU/2RqZ2Zm82hORV/SKuBPgC+keQGvBq5JTS4D3pCmN6R50vLT5fPUzMzm1Vz39D8FvA+opvnjgScjopzmtwMr0/RKYBtAWv5Uan8YSZskDUkaGhkZmWN6ZmZWb9ZFX9LrgJ0RcVsD8yEiLo2IwYgYHBgYaORTm5l1jGZ9xWAup2y+HHi9pLOAbmAx8GlgiaRC2ptfBexI7XcAq4HtkgrAccBjc9i+mdmC1axrW836WSPigohYFRFrgLOBGyPiLcD3gTemZhuBa9P0ljRPWn5jRMRst29mtpAVm7Sr34yPkvcD75Y0TG3M/osp/kXg+BR/N3B+E7YNgD9LzKzTNWtPvyHfyI2IHwA/SNP3A6dO0WYUeFMjtmdmttAV2214x8zMmqcr3znDOy3n0R0z63RtdyDXzMyap+A9/aPnHX0z63Rd3tM3M8sOH8g9Bj5l08w6XbPuB70gi76ZWadz0T8G3s83s07XrGvvLMiib2bW6Zp15fkFWfQ9pG9mnS7vom9mlh0e0z8G4VF9M+twORd9M7Ps8IHcY+AxfTPrdB7TNzPLEA/vmJllSNvt6UtaLen7ku6StFXS36T4MknXS7ov/Vya4pJ0saRhSXdIOqVRL8LMbKHJNWmXfC5PWwbeExEnA6cB50k6mdptEG+IiHXADRy6LeKZwLr02ARcModtm5ktaG335ayIeDgifpamdwN3AyuBDcBlqdllwBvS9Abg8qi5CVgi6YRZZ37E3JrxrGZm86fthnfqSVoDvAS4GVgREQ+nRY8AK9L0SmBb3WrbU2zyc22SNCRpaGRkpBHpmZl1nLb9cpakfuDrwN9GxK76ZVG7xvEx7XdHxKURMRgRgwMDA7PKyV/OMrNOl2vHPX1JRWoF/ysR8Y0UfvTAsE36uTPFdwCr61ZflWJmZjZJk+6hMqezdwR8Ebg7Iv5n3aItwMY0vRG4ti7+1nQWz2nAU3XDQA3lMX0z63TN2tMvzGHdlwN/BvxS0i9S7APAR4GrJZ0LPAS8OS27DjgLGAb2AW+fw7bNzBa0Zn05a9ZFPyL+DzBdVqdP0T6A82a7vWPhHX0z63RtffaOmZk1VtuevdOOfGN0M+t0TdrRX5hF38ys07XlKZvtyvv5ZtbpPLxjZpYh3tM/Bh7SN7NO13ZfzjIzs+bxKZtmZhnSdpdWbmse3jGzDucDuWZmGeKifwx8aWUzs6ktyKJvZtbpvKd/DHzKppl1Op+9Y2aWIc26tPKCLPre0TezTtekmr8wi76ZWadbMGP6ktZLulfSsKTzm7ENX1rZzDrdgvhylqQ88BngTOBk4BxJJ89nDmZmnWChHMg9FRiOiPsjYhy4EtjQ6I0UCx61MrPO1lfKN+V553Jj9NlYCWyrm98OvLS+gaRNwCaAZz3rWbPayOLuIje+54/Y+KVb2Pb4fnKCahrx6SnWOjIIjuspMlauUsiJnq48+8crdBfzdOVzjJWr9JcKBHFweqxcpVINFnUX2DtWJifRXcyzZ6xMqZAjnxN7x8r0lQpUqrX1+kp5xstVytWgv1Rgz1iZQi6tN1qmu5h/2nqj5QqL0vbK1aCvVNteISdKhRy7R8uUinly4mnbq+VZObi9vWNl8jnRU8yze6xMTzFPTlNvb3SiSiWC3q78wTxLhTy7RycoFfJIsG+8Ql+pQLlSZbRcob9UZGyiktYrsG+81i8H8uzpOpBnhUXdh7ZXv96BPAv5HF35HHtSnvmc2Dd++Otb1F1gbKJKNYLeun7pKhy+3t6xMv3dRSrVKqMTtX4ZnagQAb2lfFovd9h6ufT6+lOeYxNV+rsL7B+vUI26319eh+Wp1J8HXt+BPPdPVKhWa3+8e8YqFOvW6ysVELAnrVeu297oRAUBvV217RXztde3e7RMX1fh4O+hv1SgXK0e3N7oRJVIv4c9Y2W68jmKBbFntExvV+1Pfd94mf7uAhOVYGyi9lr3jad+6cqze7S2vUI+x679E/R05Ymovc96SwXGy1XGyhX6ump9X42gu1hbL58ThZzYPVamu5gjAvaPV+jpylOuBOVqsLin1keFnFjcU2T/eIXerjzFfI6947XXB7B3vJbz2EQl/R3VtieJvvT+LBXzdOXFnrHac9ReX+19Vq5UGa/Ufu/7J6oA9Bbz7B6rvZfzOaX+zBPUXt/i7iLjlSoTldr29o9XkGo1Y/doma7CoffngdpwYHvj5SoTldp7ZN94GSR6irlUG/K1fhk9fL3+UoGJytPX6y3mOWmgj//wohNnVf9mMt9Ff0YRcSlwKcDg4OCsB+dPGujnx+97dcPyMjNbCOZ7HGQHsLpuflWKmZnZPJjvon8rsE7SWkldwNnAlnnOwcwss+Z1eCciypLeBXwHyAObI2LrfOZgZpZl8z6mHxHXAdfN93bNzMzfyDUzyxQXfTOzDHHRNzPLEBd9M7MMUTtfnEzSCPDQHJ5iOfDbBqXTbJ2UK3RWvp2UK3RWvp2UK3RWvnPJ9dkRMTDVgrYu+nMlaSgiBludx9HopFyhs/LtpFyhs/LtpFyhs/JtVq4e3jEzyxAXfTOzDFnoRf/SVidwDDopV+isfDspV+isfDspV+isfJuS64Ie0zczs8Mt9D19MzOr46JvZpYhC7Loz8fN148ih9WSvi/pLklbJf1Nii+TdL2k+9LPpSkuSRennO+QdErdc21M7e+TtLHJeecl/VzSt9L8Wkk3p7yuSpfERlIpzQ+n5WvqnuOCFL9X0hlNynOJpGsk3SPpbkkva+e+lfR36X1wp6QrJHW3U99K2ixpp6Q762IN609J/07SL9M6F0uzvwHsNLl+PL0X7pD0TUlL6pZN2WfT1Ynpfi+NyrVu2XskhaTlaX5++jUiFtSD2iWbfw2cBHQBtwMntyCPE4BT0vQi4FfUbgb/MeD8FD8fuChNnwX8GyDgNODmFF8G3J9+Lk3TS5uY97uBrwLfSvNXA2en6c8Cf5mm3wl8Nk2fDVyVpk9OfV4C1qbfRb4JeV4G/Hma7gKWtGvfUrtN6ANAT12fvq2d+hb4Q+AU4M66WMP6E7gltVVa98wG5/paoJCmL6rLdco+4wh1YrrfS6NyTfHV1C4x/xCwfD77tSmFo5UP4GXAd+rmLwAuaIO8rgX+GLgXOCHFTgDuTdOfA86pa39vWn4O8Lm6+GHtGpzjKuAG4NXAt9Ib6bd1f0wH+za9YV+WpgupnSb3d327BuZ5HLUiqknxtuxbDt0belnqq28BZ7Rb3wJrOLyQNqQ/07J76uKHtWtErpOW/UfgK2l6yj5jmjpxpPd8I3MFrgFeDDzIoaI/L/26EId3prr5+soW5QJA+vf8JcDNwIqIeDgtegRYkaany3s+X8+ngPcB1TR/PPBkRJSn2PbBvNLyp1L7+ch3LTACfEm1oagvSOqjTfs2InYAnwB+AzxMra9uoz37tl6j+nNlmp4cb5Z3UNvrZYacpoof6T3fEJI2ADsi4vZJi+alXxdi0W8rkvqBrwN/GxG76pdF7eO5Lc6ZlfQ6YGdE3NbqXI5Cgdq/zJdExEuAvdSGHw5qs75dCmyg9mF1ItAHrG9pUseonfrzSCRdCJSBr7Q6l6lI6gU+AHywVTksxKLfNjdfl1SkVvC/EhHfSOFHJZ2Qlp8A7Ezx6fKer9fzcuD1kh4ErqQ2xPNpYImkA3dYq9/2wbzS8uOAx+Yp3+3A9oi4Oc1fQ+1DoF379jXAAxExEhETwDeo9Xc79m29RvXnjjQ9Od5Qkt4GvA54S/qQmk2ujzH976URnkPtw//29Le2CviZpGfOItfZ9WujxgPb5UFtL/D+1LEHDtC8oAV5CLgc+NSk+Mc5/ODYx9L0n3D4QZxbUnwZtfHrpenxALCsybm/kkMHcr/G4Qe13pmmz+Pwg41Xp+kXcPiBs/tpzoHcHwPPS9P/PfVrW/Yt8FJgK9CbcrgM+Kt261uePqbfsP7k6Qccz2pwruuBu4CBSe2m7DOOUCem+700KtdJyx7k0Jj+vPRr0wpHKx/UjoL/itrR+QtblMMfUPt3+A7gF+lxFrUxwxuA+4Dv1f3yBHwm5fxLYLDuud4BDKfH2+ch91dyqOiflN5Yw+mPoZTi3Wl+OC0/qW79C9PruJc5nKUxQ46/Bwyl/v2X9MfQtn0L/A/gHuBO4J9TEWqbvgWuoHa8YYLaf1LnNrI/gcH02n8N/BOTDsI3INdhauPeB/7WPjtTnzFNnZju99KoXCctf5BDRX9e+tWXYTAzy5CFOKZvZmbTcNE3M8sQF30zswxx0TczyxAXfTOzDHHRNzPLEBd9M7MM+f9s8fA0B61VWwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MCHfjRjOg4Ib",
        "outputId": "dd2d34c5-ffa1-4f9a-ff26-14177763bbd3"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h2-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dvRvULsIg4Ib",
        "outputId": "30c1d656-e2cc-4a08-c05a-f635a04ab2f7"
      },
      "source": [
        "# plt.plot(loss_score)\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h2-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPKwkYJYg4Ib",
        "outputId": "cd3e2fcb-6370-49a0-bac5-adf2aa565ed4"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 76.07142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpRok17ng4Ic",
        "outputId": "5509483d-2550-485e-e6a2-4e38f27c0485"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 73.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_xUurdQg4Ic"
      },
      "source": [
        "### lr=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXDY3sK9g4Id"
      },
      "source": [
        "net = initialize_network_double(6,8,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fn_8Om9xg4Id",
        "outputId": "0e7d2af6-1a87-42fe-9e92-761dc06377a5"
      },
      "source": [
        "train_network(net,train,0.1,500,10,accuracy_score,loss_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:8.645193140234495\n",
            "Iteration 50 | Accuracy: 10.142857142857142 | Loss:414.5060201608964\n",
            "Iteration 100 | Accuracy: 10.142857142857142 | Loss:667.9569578231936\n",
            "Iteration 150 | Accuracy: 10.142857142857142 | Loss:812.7396812835261\n",
            "Iteration 200 | Accuracy: 10.142857142857142 | Loss:925.193916639066\n",
            "Iteration 250 | Accuracy: 10.142857142857142 | Loss:1037.857784409908\n",
            "Iteration 300 | Accuracy: 10.142857142857142 | Loss:1128.4680876987711\n",
            "Iteration 350 | Accuracy: 10.142857142857142 | Loss:1177.7350006741965\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:1223.4707456878712\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:1268.566722520112\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:1313.8086177043042\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:1358.8864528733536\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:1404.1110931030432\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:1449.410367150181\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:1494.625610776241\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:1539.912664788666\n",
            "Iteration 800 | Accuracy: 10.071428571428571 | Loss:1585.1430375717096\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:1630.4755423111897\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:1675.5379355309344\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:1720.1931969334487\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:1765.5398376193534\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:1810.5620805296405\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:1855.7247476718007\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1901.0579054745222\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1946.2592949380326\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1991.3821450803773\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:2036.7324357262862\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:2081.6464630766145\n",
            "##################################################\n",
            ">epoch=0, lrate=0.100, error=2125.995\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882790855792202\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.086667347019414\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.21164377521549\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.69281031848845\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.70509574548532\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8793708386603\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9990044511737\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.16773451241903\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.524428612489\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.54692301464877\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.71778823123105\n",
            "Iteration 550 | Accuracy: 13.357142857142856 | Loss:497.7887538492335\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0539696809865\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3685450846967\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5627195430745\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.85261456271\n",
            "Iteration 800 | Accuracy: 19.142857142857142 | Loss:724.0825281147162\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.4164400136826\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4778031074795\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.1378556998311\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4820048710292\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.5055391128544\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6680599465957\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9999095058738\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.201120021986\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.3228057713095\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.671429526724\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5850142558088\n",
            "##################################################\n",
            ">epoch=1, lrate=0.100, error=1264.933\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882711292762078\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08606444923407\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.21039880474349\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.69047168057728\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.70158290983898\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8748758243745\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.99340607614\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1610486899136\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.51643851552814\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.53803446660686\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.7079595951847\n",
            "Iteration 550 | Accuracy: 12.285714285714286 | Loss:497.7783100642466\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0422736519669\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3555453010827\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5486574852149\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8376199626006\n",
            "Iteration 800 | Accuracy: 18.857142857142858 | Loss:724.0664285263999\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3995911850645\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4596434447129\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.1186379889867\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4617564028439\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.483552797106\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6452660444075\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9762174127557\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1766464051545\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.297363376218\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.6443511393725\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5574076497953\n",
            "##################################################\n",
            ">epoch=2, lrate=0.100, error=1264.904\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882623683921751\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08525227630182\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20886124861934\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68780709560897\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.69758016612488\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.86983077189277\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9871926491336\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1536804838331\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.50768588714254\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5283204732933\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.69724627986596\n",
            "Iteration 550 | Accuracy: 11.714285714285715 | Loss:497.7669425603501\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0295627321761\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3414427087199\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5334184300638\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8213906882257\n",
            "Iteration 800 | Accuracy: 18.642857142857142 | Loss:724.0490216391375\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3813800330287\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.440042123385\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0979139911175\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.439924413133\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4598690103664\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.6207193660266\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9507119749587\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1503016217064\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.269998532629\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.6152324981533\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.5277248165705\n",
            "##################################################\n",
            ">epoch=3, lrate=0.100, error=1264.873\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.888252571437705\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.084385142588566\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20721757841588\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68496353278468\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.69330706864505\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.86443583090826\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.98054627106325\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1458046163757\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4983348046103\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5179384578639\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.685797060453\n",
            "Iteration 550 | Accuracy: 11.214285714285714 | Loss:497.75479439065725\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.015972558172\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3263660591388\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.5171223539699\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.8040415379676\n",
            "Iteration 800 | Accuracy: 18.071428571428573 | Loss:724.0304144700357\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3619079216268\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.4190923890114\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0757702820855\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.4165879848864\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4345558315114\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5944826375807\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.9234490543827\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.1221355437283\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.2407545320818\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5841058477338\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4959944164111\n",
            "##################################################\n",
            ">epoch=4, lrate=0.100, error=1264.840\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882416681364984\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08345718164733\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20545632190282\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.68192186711627\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.68873540068267\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.85865494898442\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.97342263463634\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1373691607979\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4883241286163\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.5068195996823\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.67353610762876\n",
            "Iteration 550 | Accuracy: 10.857142857142858 | Loss:497.74178517056083\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:543.0014129832117\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.3102161697934\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4996616598858\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7854583711292\n",
            "Iteration 800 | Accuracy: 17.71428571428571 | Loss:724.0104848008859\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3410466423637\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3966571573883\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.0520625173712\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3915949627874\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.4074493784955\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5663862557809\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.8942516205057\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.091964665823\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.2094407365514\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5507689131819\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4620104844757\n",
            "##################################################\n",
            ">epoch=5, lrate=0.100, error=1264.804\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882295854790587\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08246203634134\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20356499643768\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6786614022505\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.68383483471393\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8524493862256\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9657742185862\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.1283184870017\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.47758847989417\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.49489011718333\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.6603820961851\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.7278287256189\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.985787367634\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2928869773893\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4809212177719\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7655191534188\n",
            "Iteration 800 | Accuracy: 17.357142857142858 | Loss:723.9891020774588\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.3186592782106\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3725902860638\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:859.026636976678\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.364783373769\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3783754922304\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5362500788148\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.862931628391\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.0595939890088\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.1758545200046\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.5150069622384\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.4255545393194\n",
            "##################################################\n",
            ">epoch=6, lrate=0.100, error=1264.766\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882162515073831\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08139288508632\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.20153013598866\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.67515994274856\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.67857310935247\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.84577795249217\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9575506074737\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.11859362407654\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4660587162425\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.4820717235062\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.64624869600004\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.7128336171018\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9689931787149\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2742662722748\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.460779156424\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7440948180572\n",
            "Iteration 800 | Accuracy: 17.142857142857142 | Loss:723.9661283708482\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2946012442047\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3467377516795\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9993318262915\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3359827930043\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3471512841477\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.5038850533906\n",
            "Iteration 1150 | Accuracy: 9.857142857142858 | Loss:1039.82929173764\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1085.0248187858708\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.139783072649\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.4765948253278\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.3863976884998\n",
            "##################################################\n",
            ">epoch=7, lrate=0.100, error=1264.725\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882016003097302\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.08024248692139\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.19933735785663\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.671393926661\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.67291630797186\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.83859739672351\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9486990096328\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.10813283785643\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.45366268066994\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.46828236915894\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.6310453796713\n",
            "Iteration 550 | Accuracy: 10.214285714285715 | Loss:497.6967040017268\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9509229728945\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2542368590329\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4391081267582\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.7210506264855\n",
            "Iteration 800 | Accuracy: 16.857142857142858 | Loss:723.9414198803407\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2687219102858\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.3189394499608\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9699790259117\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.3050164002261\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.3135874239034\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.4690956068156\n",
            "Iteration 1150 | Accuracy: 9.928571428571429 | Loss:1039.79312784435\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.987427208151\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.1010060704648\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.4352998543511\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.3443036902463\n",
            "##################################################\n",
            ">epoch=8, lrate=0.100, error=1264.681\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881855791429323\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.07900325563096\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1969714833694\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.66733863946922\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.6668292638495\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.83086297463748\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.93916499986113\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0968724454395\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.4403262445554\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.453437298902\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.61467857522933\n",
            "Iteration 550 | Accuracy: 10.142857142857142 | Loss:497.6793408516281\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.931465788984\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2326781640957\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.4157770626052\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6962480515647\n",
            "Iteration 800 | Accuracy: 16.642857142857142 | Loss:723.9148289974968\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2408668286528\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2890316288706\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9384068794585\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.2717037261714\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.2774911494485\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.4316827802461\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1039.7542324033336\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.94720371366\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.0592991813796\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.3908857838703\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.2990329249326\n",
            "##################################################\n",
            ">epoch=9, lrate=0.100, error=1264.634\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881681580746892\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.077667362682\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1944167132066\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.66296850225447\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.6602760720153\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.82252917458726\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.9288934591968\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0847478237564\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.42597459350407\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.43745037078094\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.5970531070308\n",
            "Iteration 550 | Accuracy: 10.214285714285715 | Loss:497.66064347035336\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.9105088810536\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.2094681969743\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.390653343385\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6695470760833\n",
            "Iteration 800 | Accuracy: 16.142857142857142 | Loss:723.886206809967\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.2108804391429\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2568498002537\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.9044430530911\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.2358639032047\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.238669774313\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3914478630053\n",
            "Iteration 1150 | Accuracy: 16.5 | Loss:1039.7123982910148\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.903933055287\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1130.0144381356126\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.34311719425\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.2503469564258\n",
            "##################################################\n",
            ">epoch=10, lrate=0.100, error=1264.583\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.88814934233999\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.07622686152091\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.19165684479282\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.65825740233123\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.65322064549196\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.81355052686763\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.91782961482517\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0716944879005\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.41053360367124\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.42023548076\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.5780737531921\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.6405111183339\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.887939581376\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1844856133439\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.363605091396\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6408086160392\n",
            "Iteration 800 | Accuracy: 15.571428571428573 | Loss:723.8554057236033\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1786089135549\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.2222317404518\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.8679176347481\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1973189705577\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.196934174353\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3481959833227\n",
            "Iteration 1150 | Accuracy: 19.642857142857142 | Loss:1039.6674226379612\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.857404241958\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.9662027410438\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.291763900872\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.198012976065\n",
            "##################################################\n",
            ">epoch=11, lrate=0.100, error=1264.529\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881291872009689\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.074673814599734\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18867549836234\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.65317899824333\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.64562719314696\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.8038823429841\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.90591998363334\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0576490010294\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.3939310165382\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.4017077896179\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.55764658677936\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.61884439063704\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8636468905946\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1576114108357\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.3345030992961\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.6098965265026\n",
            "Iteration 800 | Accuracy: 15.071428571428571 | Loss:723.8222816086758\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1439025092035\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1850198737228\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.8286654779861\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1558964336374\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.1521013524479\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.3017387134284\n",
            "Iteration 1150 | Accuracy: 19.428571428571427 | Loss:1039.619109639871\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.8074134462213\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.9143797725937\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.236604106474\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.1418069227097\n",
            "##################################################\n",
            ">epoch=12, lrate=0.100, error=1264.470\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881078144506404\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.073000389731824\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18545629030041\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.64770688521043\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.63746042320534\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.79348113444308\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8931129014676\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0425493425127\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.37609695460594\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.3817842738962\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.53567957609795\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.59554578828903\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8375221638323\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.1287295364807\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.3032216066362\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.5766783566315\n",
            "Iteration 800 | Accuracy: 14.714285714285714 | Loss:723.7866945627973\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.1066164676675\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1450619747444\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.78652670416\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.1114298865142\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.1039947613272\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.2518943166706\n",
            "Iteration 1150 | Accuracy: 19.28571428571429 | Loss:1039.5672709003827\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.753764361207\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.858763176878\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.1774246317777\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.0815135424034\n",
            "##################################################\n",
            ">epoch=13, lrate=0.100, error=1264.407\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880854288493136\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.071198876262024\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.18198286117092\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.64181446033965\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.62868520645574\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.78230436544874\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.879358202478\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.02633423577527\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.356963167801\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.3603829590489\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.51208174022054\n",
            "Iteration 550 | Accuracy: 10.285714285714285 | Loss:497.5705187388273\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.8094580507098\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0977254605266\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.2696368951268\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.5410237616289\n",
            "Iteration 800 | Accuracy: 14.428571428571429 | Loss:723.748507108853\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.0666092011613\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.1022088232785\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.7413439328293\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.0637561846677\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:949.0524407335876\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.1984839283884\n",
            "Iteration 1150 | Accuracy: 18.928571428571427 | Loss:1039.5117215032703\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.6962641409193\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.799149656351\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.1140161426372\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1220.016921256567\n",
            "##################################################\n",
            ">epoch=14, lrate=0.100, error=1264.340\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880623319080015\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06926155884955\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.17823864022228\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6354742952962\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.61926539433662\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.77030913666508\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.864605545033\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:317.0089408748509\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.33646032611557\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.33742010805634\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.48676006340634\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.5436642304696\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7793447430879\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0644816753812\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.2336225605212\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.502799369587\n",
            "Iteration 800 | Accuracy: 14.071428571428571 | Loss:723.7075785374425\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:769.0237363915699\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.056307344143\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.6929547264233\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:904.0127075657572\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.9972593049544\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.141321907895\n",
            "Iteration 1150 | Accuracy: 18.285714285714285 | Loss:1039.4522699541985\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.6347129980281\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.7353276452084\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1175.0461612515198\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.947809685923\n",
            "##################################################\n",
            ">epoch=15, lrate=0.100, error=1264.268\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880389298819751\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06718038428231\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.17420622108843\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.6286568290893\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.60916151425076\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.75744942406465\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.84880092038765\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.99030055273386\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.31451275667973\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.31280471392506\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.4596134554199\n",
            "Iteration 550 | Accuracy: 10.357142857142858 | Loss:497.51487432054637\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7470626924228\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:588.0288692267441\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1950404723847\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.4618590738743\n",
            "Iteration 800 | Accuracy: 13.714285714285715 | Loss:723.6637543033132\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.9778398391935\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:814.0071880321807\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.64117803796\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.9580974348695\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.9382481081814\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.0801990163427\n",
            "Iteration 1150 | Accuracy: 17.42857142857143 | Loss:1039.388700575103\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.568885991291\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.667058177924\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.9736139161885\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.8739282596387\n",
            "##################################################\n",
            ">epoch=16, lrate=0.100, error=1264.191\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880157330549876\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06494637133787\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1698662477997\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.62132825354115\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.59832718403786\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.7436716443566\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8318810721257\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9703319299336\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2910303178166\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.2864299380428\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.4305233673378\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.48402212663035\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.7124713515535\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.9907348497004\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1537269341053\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.4180292604163\n",
            "Iteration 800 | Accuracy: 13.0 | Loss:723.6168499798986\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.9287305318124\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.9546461846872\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.5857942245354\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.8996993461196\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.8751589434622\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:994.0148580450125\n",
            "Iteration 1150 | Accuracy: 16.142857142857142 | Loss:1039.3207479624361\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.4985065977073\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.5940472664424\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.8960697746866\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.7949656039843\n",
            "##################################################\n",
            ">epoch=17, lrate=0.100, error=1264.108\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879933447220564\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.06254874758185\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.16519577121021\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.61344758068907\n",
            "Iteration 200 | Accuracy: 10.5 | Loss:181.58670429460432\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.72890858361782\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.8137658919866\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9489320723661\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2658975877485\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.25816163038746\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.39934121394117\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.4509484825653\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.6753941446018\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.9498840209675\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.1094743589424\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.3710893309793\n",
            "Iteration 800 | Accuracy: 12.785714285714286 | Loss:723.5666302017738\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.8761663922303\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.8984175527464\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.5265193289126\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.8372199132037\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.8076679546701\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.9449628870387\n",
            "Iteration 1150 | Accuracy: 14.285714285714285 | Loss:1039.248064569818\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.423213161545\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.5159109596175\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.8131287353474\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.7105111280582\n",
            "##################################################\n",
            ">epoch=18, lrate=0.100, error=1264.020\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879724406724129\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05997384396729\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1601661227942\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.60496302872343\n",
            "Iteration 200 | Accuracy: 10.428571428571429 | Loss:181.57421725125286\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.7130720430614\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7943492557789\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9259658294302\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.23896109104464\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.22782463271756\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.36587337204895\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.4154460877627\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.6356005997053\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.906061043394\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.0620096613911\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.3207488099195\n",
            "Iteration 800 | Accuracy: 12.5 | Loss:723.5127840179605\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.8198262223291\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.83815015627\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.4629754930502\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.7702676057019\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.7353416464331\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.8700633819996\n",
            "Iteration 1150 | Accuracy: 11.928571428571429 | Loss:1039.1701838880574\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.3425207689552\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.4321357589163\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.7242527396093\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.6200118396769\n",
            "##################################################\n",
            ">epoch=19, lrate=0.100, error=1263.926\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879537428313322\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05720382300051\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.1547404374157\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5958079887242\n",
            "Iteration 200 | Accuracy: 11.5 | Loss:181.5607667469191\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.69604480556984\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7734890695722\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.9012544418144\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.2100156759316\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.1951879836054\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.3298649805868\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.37724244506114\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.592787107775\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.8589278285714\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:633.0109711761307\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.2666229534892\n",
            "Iteration 800 | Accuracy: 12.357142857142858 | Loss:723.4548987397882\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.7592820670693\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.7733747173676\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.394660064983\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.6983201252071\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.6576017060602\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.7895589913435\n",
            "Iteration 1150 | Accuracy: 10.642857142857142 | Loss:1039.0864824609214\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.2557818823525\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.3420378528099\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.6287224321911\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.5227282160458\n",
            "##################################################\n",
            ">epoch=20, lrate=0.100, error=1263.825\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879379930272028\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05421534057784\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.14887100394758\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5858968813512\n",
            "Iteration 200 | Accuracy: 14.642857142857144 | Loss:181.54622357178482\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.67767258639591\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7509973590707\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.87456429964607\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.17879118820304\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.1599502051818\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.2909838357689\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:497.33598293552393\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.5465578312594\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.808043051979\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.955885944423\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.2082087913373\n",
            "Iteration 800 | Accuracy: 12.285714285714286 | Loss:723.3924343494002\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.6939722037839\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.703476066734\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.320915805337\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.6206928979436\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.5736913225081\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.7026640537551\n",
            "Iteration 1150 | Accuracy: 10.214285714285715 | Loss:1038.996143641377\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.1621487179905\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.24472423338\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.5255960101458\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.4176924262688\n",
            "##################################################\n",
            ">epoch=21, lrate=0.100, error=1263.715\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879259336806078\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.05097823381085\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.14249660935194\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.57512115188587\n",
            "Iteration 200 | Accuracy: 19.071428571428573 | Loss:181.53042280789083\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.65775644918838\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.7266309930148\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.8455964607265\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.1449401990355\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.12172548189574\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.248805275369\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.29121494342945\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.4964067959925\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.7528427495557\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.8961485659053\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.144862839022\n",
            "Iteration 800 | Accuracy: 12.0 | Loss:723.3246997641285\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.623176141707\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.6276669119048\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.2409035525365\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.5365101270487\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.4826444132151\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.6083760257302\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.8981245678897\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1084.0605388736985\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.1390571984236\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.4136718249802\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.3036704242397\n",
            "##################################################\n",
            ">epoch=22, lrate=0.100, error=1263.596\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879183012705998\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.04745429089993\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.13553997312808\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.56334550547302\n",
            "Iteration 200 | Accuracy: 20.214285714285715 | Loss:181.51315846737685\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.63604580570905\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.70008316669526\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.8139769928795\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.10802687076364\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.0800308692631\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.20279822142214\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.24237317730626\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.4417013327403\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.692622422083\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.8310017345003\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:678.075780579173\n",
            "Iteration 800 | Accuracy: 11.785714285714285 | Loss:723.2508310087576\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.545991694729\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.5449638802922\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.1535771509359\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.4446782205762\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.3832573495907\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.5054462272508\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.791125849952\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.9496036568469\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1129.0236216000155\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.2914540140725\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.1791270646377\n",
            "##################################################\n",
            ">epoch=23, lrate=0.100, error=1263.467\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879158362429499\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.04359611320334\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.12790527894022\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.55040431795402\n",
            "Iteration 200 | Accuracy: 21.857142857142858 | Loss:181.49417832927992\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.61223172507155\n",
            "Iteration 300 | Accuracy: 10.5 | Loss:271.6709752760428\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.77924764664164\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.06751636393875\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:407.0342739709699\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.1523118018642\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.18876555145954\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.3816661519508\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.6265197228221\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.7595175040796\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.9999766849185\n",
            "Iteration 800 | Accuracy: 11.428571428571429 | Loss:723.1697701391579\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.4613129078275\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.454164363314\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:858.057659008714\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.3438599044192\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.2740611357018\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.3923509299042\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.6735616834615\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.8276967372815\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.8966923237306\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.1571184467123\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1219.0421913721964\n",
            "##################################################\n",
            ">epoch=24, lrate=0.100, error=1263.324\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879193105937121\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.03934604898134\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.11947574547142\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.5360980477873\n",
            "Iteration 200 | Accuracy: 23.857142857142858 | Loss:181.4731785381253\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.5859400177686\n",
            "Iteration 300 | Accuracy: 10.571428571428571 | Loss:271.63884848777496\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.74085601647215\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:362.0227637741784\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.9837400751433\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.0965615018865\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.1295585113219\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.3153667902271\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.5534962121292\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.6805776856554\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.9162642932232\n",
            "Iteration 800 | Accuracy: 11.214285714285714 | Loss:723.0802430559568\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.3678068738611\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.3538219216966\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.9516138742903\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.2324465102927\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.1532911434649\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.2672597566877\n",
            "Iteration 1150 | Accuracy: 10.071428571428571 | Loss:1038.5435272116094\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.6928398157374\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.7561985490943\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1174.0084753001165\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.8906181323878\n",
            "##################################################\n",
            ">epoch=25, lrate=0.100, error=1263.166\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879295725933084\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.03463518162451\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.11011117574274\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.52018946970412\n",
            "Iteration 200 | Accuracy: 24.357142857142858 | Loss:181.4497975168663\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.5567235239745\n",
            "Iteration 300 | Accuracy: 12.642857142857142 | Loss:271.6031542694664\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.6981443224978\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.97300157517276\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.92757769023723\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:452.03461376010233\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:497.0637606593597\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.241691135136\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.4723166475841\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.5928517589065\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.8232316265625\n",
            "Iteration 800 | Accuracy: 11.071428571428571 | Loss:722.9807343492248\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.2638874887616\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.242218074443\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.8336185020013\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:903.1085260095095\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:948.0188516407854\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:993.1279985033183\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1038.3987601035772\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.5426821562146\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.5996815447693\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.8429248243353\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.7217422492906\n",
            "##################################################\n",
            ">epoch=26, lrate=0.100, error=1262.990\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8879476073953018\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.02938239579552\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.09964549240587\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.50239964676874\n",
            "Iteration 200 | Accuracy: 25.357142857142854 | Loss:181.4236089001921\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.52405320943006\n",
            "Iteration 300 | Accuracy: 18.285714285714285 | Loss:271.5632433630943\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.6503361943944\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.917324878421\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.864781711751\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.9653682556413\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.9902038852072\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.1593281284255\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.3815247261397\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.4947711643457\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.7192147724826\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.8694578685222\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.1476847945663\n",
            "Iteration 900 | Accuracy: 9.857142857142858 | Loss:813.1173289774778\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.7015255891322\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.9698451049732\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.8682731787856\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.9720043336663\n",
            "Iteration 1150 | Accuracy: 10.142857142857142 | Loss:1038.236594212423\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.3744517383998\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.424243716144\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.6574039007708\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.5324233969723\n",
            "##################################################\n",
            ">epoch=27, lrate=0.100, error=1262.793\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.88797461243983\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.02349360423235\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.08788437566298\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.4824036848596\n",
            "Iteration 200 | Accuracy: 26.071428571428573 | Loss:181.3941134045137\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.48730792577\n",
            "Iteration 300 | Accuracy: 20.214285714285715 | Loss:271.51835300514676\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.5965211553544\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.85467424978526\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.79417381183185\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.8875375212852\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.9075215882874\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:542.0667431946731\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.2794146887986\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.3844993715203\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.6022659731801\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.7443222861399\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:768.0170091892313\n",
            "Iteration 900 | Accuracy: 9.928571428571429 | Loss:812.976786172922\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.5528210400315\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.8137644001096\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.6986616601044\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.7962720457874\n",
            "Iteration 1150 | Accuracy: 11.071428571428571 | Loss:1038.0539039479638\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1083.1848965651452\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.2264874107047\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.4483218444527\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.3189793378135\n",
            "##################################################\n",
            ">epoch=28, lrate=0.100, error=1262.570\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880120872087763\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.016861245849206\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.07460318295183\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.45982631667383\n",
            "Iteration 200 | Accuracy: 26.857142857142858 | Loss:181.3607296038585\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.44576276042872\n",
            "Iteration 300 | Accuracy: 20.07142857142857 | Loss:271.46759229169623\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.5356364857805\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.7838158696996\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.71437954511504\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.79962336195473\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.8141233556366\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.9621497227506\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.1639979535402\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.2598968292314\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.4701164315345\n",
            "Iteration 800 | Accuracy: 11.0 | Loss:722.6028905280089\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.8693093932534\n",
            "Iteration 900 | Accuracy: 10.714285714285714 | Loss:812.8178301140815\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.3845730494887\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.6372050765133\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.5066372302113\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.5972893403925\n",
            "Iteration 1150 | Accuracy: 19.5 | Loss:1037.8470371790697\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.9702137716233\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1128.002440964161\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1173.2114828085926\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1218.0771051079641\n",
            "##################################################\n",
            ">epoch=29, lrate=0.100, error=1262.318\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8880619378208519\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.009364063312994\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.05954516610792\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.43423695859508\n",
            "Iteration 200 | Accuracy: 26.857142857142858 | Loss:181.32278310132722\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.39857531612319\n",
            "Iteration 300 | Accuracy: 19.642857142857142 | Loss:271.4099248881639\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.4664451063122\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.70331767220216\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.6238002026519\n",
            "Iteration 500 | Accuracy: 10.428571428571429 | Loss:451.69988783357\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.7081635308173\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.8434738216397\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:587.0329616422546\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:632.1184773473038\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.3201298722591\n",
            "Iteration 800 | Accuracy: 10.928571428571429 | Loss:722.4423289478766\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.701619913151\n",
            "Iteration 900 | Accuracy: 17.285714285714285 | Loss:812.637251666775\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:857.1933677341344\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.4365815666331\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.2882567948693\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.3709544543052\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.6117296614539\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.725959125207\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1127.7474639946195\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.9419863206886\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.801769198881\n",
            "##################################################\n",
            ">epoch=30, lrate=0.100, error=1262.031\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8881265987012659\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:46.00086677433745\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.04241930780991\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.405142635378\n",
            "Iteration 200 | Accuracy: 26.42857142857143 | Loss:181.27949198416303\n",
            "Iteration 250 | Accuracy: 10.5 | Loss:226.34476727853914\n",
            "Iteration 300 | Accuracy: 19.28571428571429 | Loss:271.3441458846884\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.38750500153014\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.61151649590914\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.5205732606296\n",
            "Iteration 500 | Accuracy: 10.5 | Loss:451.58631172698574\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.58749588458915\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.7083037781148\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.8836095692072\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.9573455084973\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:677.1492356724898\n",
            "Iteration 800 | Accuracy: 10.857142857142858 | Loss:722.2593341396804\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.5104852981597\n",
            "Iteration 900 | Accuracy: 19.5 | Loss:812.4313075591822\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.9752162778746\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:902.2077044512076\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:947.0389027931993\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:992.1124578714705\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.3429817679535\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.446916723508\n",
            "Iteration 1250 | Accuracy: 9.5 | Loss:1127.4561103119674\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.6340829958297\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.4870628776255\n",
            "##################################################\n",
            ">epoch=31, lrate=0.100, error=1261.703\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8882091778816338\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.99121837727369\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.02289549069305\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.37197458357022\n",
            "Iteration 200 | Accuracy: 25.5 | Loss:181.22994302296217\n",
            "Iteration 250 | Accuracy: 13.357142857142856 | Loss:226.28319434840702\n",
            "Iteration 300 | Accuracy: 18.571428571428573 | Loss:271.2688443883287\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.2971192840956\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.5064637875146\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.40250685004855\n",
            "Iteration 500 | Accuracy: 10.5 | Loss:451.4565239859546\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.44959641619334\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.5538042521699\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.7127638884664\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.7730911263561\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.9538159841916\n",
            "Iteration 800 | Accuracy: 10.785714285714286 | Loss:722.0500098813916\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.2918321491319\n",
            "Iteration 900 | Accuracy: 19.428571428571427 | Loss:812.1955781019495\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.7254000279906\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.9456183115019\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.7530996861071\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:991.8160878341932\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1037.0348553404071\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1082.12688469155\n",
            "Iteration 1250 | Accuracy: 11.5 | Loss:1127.1219014636984\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1172.2809356309583\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1217.1259511130122\n",
            "##################################################\n",
            ">epoch=32, lrate=0.100, error=1261.327\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8883136424136178\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.98024641983574\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:91.00059199232778\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.33406028764637\n",
            "Iteration 200 | Accuracy: 24.21428571428571 | Loss:181.17304749867978\n",
            "Iteration 250 | Accuracy: 19.857142857142858 | Loss:226.21249056175884\n",
            "Iteration 300 | Accuracy: 18.285714285714285 | Loss:271.1823348305532\n",
            "Iteration 350 | Accuracy: 10.428571428571429 | Loss:316.1932457656757\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.3858254672193\n",
            "Iteration 450 | Accuracy: 10.428571428571429 | Loss:406.26696053878254\n",
            "Iteration 500 | Accuracy: 10.785714285714286 | Loss:451.30767093004084\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.2914209426339\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.3765578756991\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.5165866792606\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.5615961247398\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.729499557639\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.8096435435593\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:767.0407352650278\n",
            "Iteration 900 | Accuracy: 19.0 | Loss:811.9247092491721\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.4381925687724\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.644310356724\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.4241882294965\n",
            "Iteration 1100 | Accuracy: 10.071428571428571 | Loss:991.4748867915392\n",
            "Iteration 1150 | Accuracy: 19.92857142857143 | Loss:1036.6801146443556\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1081.7582972491984\n",
            "Iteration 1250 | Accuracy: 14.142857142857142 | Loss:1126.7369269958192\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1171.874196875289\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1216.7098334630828\n",
            "##################################################\n",
            ">epoch=33, lrate=0.100, error=1260.893\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8884450788943591\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.96774296620639\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.9750469833428\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.29056806661026\n",
            "Iteration 200 | Accuracy: 23.42857142857143 | Loss:181.10745875760918\n",
            "Iteration 250 | Accuracy: 20.357142857142858 | Loss:226.13096425960828\n",
            "Iteration 300 | Accuracy: 18.0 | Loss:271.0825292071656\n",
            "Iteration 350 | Accuracy: 10.857142857142858 | Loss:316.07333254196\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.2466973368768\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:406.11062926875684\n",
            "Iteration 500 | Accuracy: 11.0 | Loss:451.13617754331744\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:496.10914686341084\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:541.1722770683745\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.2902588736233\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.3176855972716\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.4707903133612\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.5323050313159\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.7509965165389\n",
            "Iteration 900 | Accuracy: 19.142857142857142 | Loss:811.6119517940161\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:856.1063673106389\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:901.2961933280021\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:946.0437522788969\n",
            "Iteration 1100 | Accuracy: 10.357142857142858 | Loss:991.0800490929724\n",
            "Iteration 1150 | Accuracy: 19.857142857142858 | Loss:1036.2695974376147\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1081.331563571011\n",
            "Iteration 1250 | Accuracy: 14.714285714285714 | Loss:1126.291146618026\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1171.4032716140844\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1216.227779071028\n",
            "##################################################\n",
            ">epoch=34, lrate=0.100, error=1260.391\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8886100912103123\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.95343711752795\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.94566332840365\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.24040819231456\n",
            "Iteration 200 | Accuracy: 22.357142857142858 | Loss:181.0314281079527\n",
            "Iteration 250 | Accuracy: 19.857142857142858 | Loss:226.036415474793\n",
            "Iteration 300 | Accuracy: 17.642857142857142 | Loss:270.9667131388754\n",
            "Iteration 350 | Accuracy: 13.214285714285715 | Loss:315.934035740466\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:361.08528602179683\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:405.9291748572402\n",
            "Iteration 500 | Accuracy: 11.5 | Loss:450.93734056732535\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.8977357167697\n",
            "Iteration 600 | Accuracy: 9.714285714285714 | Loss:540.9353135369844\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:586.0274362981615\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:631.0345361547091\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:676.1704393389208\n",
            "Iteration 800 | Accuracy: 10.714285714285714 | Loss:721.2101705506229\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.4144332443185\n",
            "Iteration 900 | Accuracy: 21.642857142857146 | Loss:811.2483879875904\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:855.7203754466285\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:900.8912406598591\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:945.6006641749303\n",
            "Iteration 1100 | Accuracy: 12.785714285714286 | Loss:990.6199196849531\n",
            "Iteration 1150 | Accuracy: 19.857142857142858 | Loss:1035.7911709430946\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1080.8339704369985\n",
            "Iteration 1250 | Accuracy: 16.142857142857142 | Loss:1125.7712362648838\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1170.8540971951975\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1215.6652637706213\n",
            "##################################################\n",
            ">epoch=35, lrate=0.100, error=1259.805\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8888174291770741\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.93694954236246\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.91161601418938\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.1820742340813\n",
            "Iteration 200 | Accuracy: 21.857142857142858 | Loss:180.94257318657048\n",
            "Iteration 250 | Accuracy: 19.357142857142858 | Loss:225.92584030426872\n",
            "Iteration 300 | Accuracy: 17.357142857142858 | Loss:270.83118316360475\n",
            "Iteration 350 | Accuracy: 14.571428571428571 | Loss:315.7707692884232\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.896399631912\n",
            "Iteration 450 | Accuracy: 10.5 | Loss:405.71664220305536\n",
            "Iteration 500 | Accuracy: 11.714285714285715 | Loss:450.7046868046323\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.6502464993407\n",
            "Iteration 600 | Accuracy: 10.071428571428571 | Loss:540.6578838825327\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:585.7193907403642\n",
            "Iteration 700 | Accuracy: 10.428571428571429 | Loss:630.7027424445738\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:675.818455962882\n",
            "Iteration 800 | Accuracy: 10.642857142857142 | Loss:720.832458856875\n",
            "Iteration 850 | Accuracy: 10.0 | Loss:766.019757909723\n",
            "Iteration 900 | Accuracy: 21.21428571428571 | Loss:810.8217202220959\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:855.2670615230869\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:900.4156321339759\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:945.079590855571\n",
            "Iteration 1100 | Accuracy: 17.785714285714285 | Loss:990.0784267379992\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1035.2280999141346\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1080.2479649684203\n",
            "Iteration 1250 | Accuracy: 16.92857142857143 | Loss:1125.1587897644022\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1170.2072421031585\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1215.002202758922\n",
            "##################################################\n",
            ">epoch=36, lrate=0.100, error=1259.114\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8890789771323999\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.91772558362033\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.871712384296\n",
            "Iteration 150 | Accuracy: 9.714285714285714 | Loss:136.1134073679147\n",
            "Iteration 200 | Accuracy: 21.642857142857146 | Loss:180.83752885089805\n",
            "Iteration 250 | Accuracy: 18.5 | Loss:225.79498116284108\n",
            "Iteration 300 | Accuracy: 16.714285714285715 | Loss:270.6706940005059\n",
            "Iteration 350 | Accuracy: 15.5 | Loss:315.5770247014844\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.6726810629583\n",
            "Iteration 450 | Accuracy: 10.642857142857142 | Loss:405.4645820292593\n",
            "Iteration 500 | Accuracy: 12.071428571428571 | Loss:450.4290144474388\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.35681188782155\n",
            "Iteration 600 | Accuracy: 11.714285714285715 | Loss:540.3289077466608\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:585.3537167147689\n",
            "Iteration 700 | Accuracy: 10.714285714285714 | Loss:630.3089133927401\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:675.4006214488498\n",
            "Iteration 800 | Accuracy: 10.428571428571429 | Loss:720.3838314785186\n",
            "Iteration 850 | Accuracy: 10.142857142857142 | Loss:765.5508928857172\n",
            "Iteration 900 | Accuracy: 20.214285714285715 | Loss:810.3144550823164\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:854.7277373562242\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:899.8497171559775\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:944.4587428957511\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:989.432714951086\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1034.5565845753545\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1079.5485576535993\n",
            "Iteration 1250 | Accuracy: 17.92857142857143 | Loss:1124.4276088819886\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1169.4350386365777\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1214.2099817544356\n",
            "##################################################\n",
            ">epoch=37, lrate=0.100, error=1258.290\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8894112914477537\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.89494136089685\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.82419012197455\n",
            "Iteration 150 | Accuracy: 9.928571428571429 | Loss:136.0312538707002\n",
            "Iteration 200 | Accuracy: 21.21428571428571 | Loss:180.71143017974336\n",
            "Iteration 250 | Accuracy: 18.071428571428573 | Loss:225.63765392971743\n",
            "Iteration 300 | Accuracy: 15.785714285714286 | Loss:270.47762982895415\n",
            "Iteration 350 | Accuracy: 15.714285714285714 | Loss:315.3433536367159\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.40346804470386\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:405.16074271609824\n",
            "Iteration 500 | Accuracy: 12.5 | Loss:450.09697022322325\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:495.00311724314537\n",
            "Iteration 600 | Accuracy: 13.285714285714286 | Loss:539.9322712984803\n",
            "Iteration 650 | Accuracy: 10.428571428571429 | Loss:584.9123887458213\n",
            "Iteration 700 | Accuracy: 20.214285714285715 | Loss:629.8335651006464\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:674.8962559528497\n",
            "Iteration 800 | Accuracy: 10.357142857142858 | Loss:719.8419844708479\n",
            "Iteration 850 | Accuracy: 15.785714285714286 | Loss:764.984433402962\n",
            "Iteration 900 | Accuracy: 19.57142857142857 | Loss:809.7011736646992\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:854.0752798845957\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:899.164935759303\n",
            "Iteration 1050 | Accuracy: 10.071428571428571 | Loss:943.7064605538801\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:988.6495441010567\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1033.7420144239497\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1078.6993583807985\n",
            "Iteration 1250 | Accuracy: 17.71428571428571 | Loss:1123.5395761331217\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1168.4972104508745\n",
            "Iteration 1350 | Accuracy: 10.142857142857142 | Loss:1213.2469213987567\n",
            "##################################################\n",
            ">epoch=38, lrate=0.100, error=1257.287\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.889838020066996\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.86736667142233\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.76641606197556\n",
            "Iteration 150 | Accuracy: 16.142857142857142 | Loss:135.93094655783682\n",
            "Iteration 200 | Accuracy: 20.92857142857143 | Loss:180.55711788360813\n",
            "Iteration 250 | Accuracy: 17.71428571428571 | Loss:225.4447046500777\n",
            "Iteration 300 | Accuracy: 15.142857142857144 | Loss:270.2407170909071\n",
            "Iteration 350 | Accuracy: 16.428571428571427 | Loss:315.0557850412139\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:360.0730300928384\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:404.7870373133156\n",
            "Iteration 500 | Accuracy: 12.5 | Loss:449.68884307977896\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:494.56803410108864\n",
            "Iteration 600 | Accuracy: 14.357142857142858 | Loss:539.4441126551246\n",
            "Iteration 650 | Accuracy: 11.214285714285714 | Loss:584.3687102281403\n",
            "Iteration 700 | Accuracy: 20.285714285714285 | Loss:629.2478120168353\n",
            "Iteration 750 | Accuracy: 9.5 | Loss:674.2747049769064\n",
            "Iteration 800 | Accuracy: 10.285714285714285 | Loss:719.1738497322522\n",
            "Iteration 850 | Accuracy: 29.57142857142857 | Loss:764.2856445925494\n",
            "Iteration 900 | Accuracy: 19.28571428571429 | Loss:808.9442262973841\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:853.2695380963983\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:898.3189293115211\n",
            "Iteration 1050 | Accuracy: 10.357142857142858 | Loss:942.7757769402132\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:987.6795331103334\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1032.7329781767621\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1077.6462183873973\n",
            "Iteration 1250 | Accuracy: 17.642857142857142 | Loss:1122.4380417417203\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1167.3338564026208\n",
            "Iteration 1350 | Accuracy: 10.214285714285715 | Loss:1212.0509811395755\n",
            "##################################################\n",
            ">epoch=39, lrate=0.100, error=1256.042\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 10.142857142857142 | Loss:0.8903938847427512\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.83314433306157\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.69439852302258\n",
            "Iteration 150 | Accuracy: 17.57142857142857 | Loss:135.80545589490262\n",
            "Iteration 200 | Accuracy: 20.785714285714285 | Loss:180.3638284578966\n",
            "Iteration 250 | Accuracy: 17.285714285714285 | Loss:225.2022787683169\n",
            "Iteration 300 | Accuracy: 14.428571428571429 | Loss:269.9428873221189\n",
            "Iteration 350 | Accuracy: 17.357142857142858 | Loss:314.69319164162624\n",
            "Iteration 400 | Accuracy: 9.642857142857144 | Loss:359.6576474345143\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:404.3161614116813\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:449.1748939920013\n",
            "Iteration 550 | Accuracy: 10.428571428571429 | Loss:494.01966641258144\n",
            "Iteration 600 | Accuracy: 15.571428571428573 | Loss:538.8282706767156\n",
            "Iteration 650 | Accuracy: 18.071428571428573 | Loss:583.682180398425\n",
            "Iteration 700 | Accuracy: 20.357142857142858 | Loss:628.5078002269147\n",
            "Iteration 750 | Accuracy: 10.0 | Loss:673.4894132307178\n",
            "Iteration 800 | Accuracy: 10.214285714285715 | Loss:718.3291726459244\n",
            "Iteration 850 | Accuracy: 29.142857142857142 | Loss:763.4016909654707\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:807.9864516591595\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:852.2495363655299\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:897.2472142929668\n",
            "Iteration 1050 | Accuracy: 16.57142857142857 | Loss:941.5951443682254\n",
            "Iteration 1100 | Accuracy: 19.92857142857143 | Loss:986.4473106284263\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1031.4510065837806\n",
            "Iteration 1200 | Accuracy: 10.142857142857142 | Loss:1076.3063151199444\n",
            "Iteration 1250 | Accuracy: 16.92857142857143 | Loss:1121.036477531667\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1165.8533965122203\n",
            "Iteration 1350 | Accuracy: 14.428571428571429 | Loss:1210.5271907561348\n",
            "##################################################\n",
            ">epoch=40, lrate=0.100, error=1254.455\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 12.928571428571429 | Loss:0.8911317236536767\n",
            "Iteration 50 | Accuracy: 10.5 | Loss:45.789398314850644\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.60192396000897\n",
            "Iteration 150 | Accuracy: 18.0 | Loss:135.64388573301954\n",
            "Iteration 200 | Accuracy: 20.642857142857142 | Loss:180.11486991881603\n",
            "Iteration 250 | Accuracy: 16.28571428571429 | Loss:224.88873584576282\n",
            "Iteration 300 | Accuracy: 14.142857142857142 | Loss:269.55746629208784\n",
            "Iteration 350 | Accuracy: 27.642857142857142 | Loss:314.22259180689923\n",
            "Iteration 400 | Accuracy: 9.785714285714285 | Loss:359.1204124876047\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:403.70555752377487\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:448.50880055258267\n",
            "Iteration 550 | Accuracy: 10.5 | Loss:493.3082573729185\n",
            "Iteration 600 | Accuracy: 16.5 | Loss:538.0280914193017\n",
            "Iteration 650 | Accuracy: 20.285714285714285 | Loss:582.78922677712\n",
            "Iteration 700 | Accuracy: 20.285714285714285 | Loss:627.544660168903\n",
            "Iteration 750 | Accuracy: 18.428571428571427 | Loss:672.4671957043857\n",
            "Iteration 800 | Accuracy: 10.214285714285715 | Loss:717.2288577259011\n",
            "Iteration 850 | Accuracy: 28.285714285714285 | Loss:762.2493459157592\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:806.7379631104088\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:850.9192644467755\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:895.8479563295241\n",
            "Iteration 1050 | Accuracy: 19.92857142857143 | Loss:940.051464962072\n",
            "Iteration 1100 | Accuracy: 19.857142857142858 | Loss:984.8334398476517\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1029.771732052392\n",
            "Iteration 1200 | Accuracy: 10.285714285714285 | Loss:1074.5480630950092\n",
            "Iteration 1250 | Accuracy: 16.642857142857142 | Loss:1119.1976111226563\n",
            "Iteration 1300 | Accuracy: 10.071428571428571 | Loss:1163.9103725864227\n",
            "Iteration 1350 | Accuracy: 19.92857142857143 | Loss:1208.5244387360267\n",
            "##################################################\n",
            ">epoch=41, lrate=0.100, error=1252.370\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 15.571428571428573 | Loss:0.8921361196648566\n",
            "Iteration 50 | Accuracy: 10.571428571428571 | Loss:45.73148121494074\n",
            "Iteration 100 | Accuracy: 10.5 | Loss:90.47890543855567\n",
            "Iteration 150 | Accuracy: 18.285714285714285 | Loss:135.42861139368057\n",
            "Iteration 200 | Accuracy: 20.642857142857142 | Loss:179.7831999540552\n",
            "Iteration 250 | Accuracy: 15.5 | Loss:224.46875834323643\n",
            "Iteration 300 | Accuracy: 14.000000000000002 | Loss:269.0408949814919\n",
            "Iteration 350 | Accuracy: 28.357142857142858 | Loss:313.5901889699657\n",
            "Iteration 400 | Accuracy: 11.5 | Loss:358.40132275905484\n",
            "Iteration 450 | Accuracy: 10.785714285714286 | Loss:402.88589017638935\n",
            "Iteration 500 | Accuracy: 12.571428571428573 | Loss:447.6151242300056\n",
            "Iteration 550 | Accuracy: 10.714285714285714 | Loss:492.352564560394\n",
            "Iteration 600 | Accuracy: 17.57142857142857 | Loss:536.9506187597011\n",
            "Iteration 650 | Accuracy: 20.357142857142858 | Loss:581.5852641717042\n",
            "Iteration 700 | Accuracy: 20.214285714285715 | Loss:626.2450749305917\n",
            "Iteration 750 | Accuracy: 26.21428571428571 | Loss:671.0874023355653\n",
            "Iteration 800 | Accuracy: 12.071428571428571 | Loss:715.7422747508498\n",
            "Iteration 850 | Accuracy: 26.285714285714285 | Loss:760.6910558729405\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:805.0504130501868\n",
            "Iteration 950 | Accuracy: 10.071428571428571 | Loss:849.1198460457615\n",
            "Iteration 1000 | Accuracy: 10.071428571428571 | Loss:893.9520354897908\n",
            "Iteration 1050 | Accuracy: 19.92857142857143 | Loss:937.9567207694374\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:982.6387746143004\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1027.4876847046387\n",
            "Iteration 1200 | Accuracy: 12.071428571428571 | Loss:1072.151384938392\n",
            "Iteration 1250 | Accuracy: 16.428571428571427 | Loss:1116.6922044597154\n",
            "Iteration 1300 | Accuracy: 10.142857142857142 | Loss:1161.2615113220943\n",
            "Iteration 1350 | Accuracy: 19.78571428571429 | Loss:1205.7893842776084\n",
            "##################################################\n",
            ">epoch=42, lrate=0.100, error=1249.521\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 26.71428571428571 | Loss:0.8935526881406133\n",
            "Iteration 50 | Accuracy: 13.857142857142858 | Loss:45.65141795229294\n",
            "Iteration 100 | Accuracy: 10.571428571428571 | Loss:90.30797386282298\n",
            "Iteration 150 | Accuracy: 18.5 | Loss:135.12941784966034\n",
            "Iteration 200 | Accuracy: 21.142857142857142 | Loss:179.32236220580646\n",
            "Iteration 250 | Accuracy: 15.071428571428571 | Loss:223.88124974627846\n",
            "Iteration 300 | Accuracy: 14.071428571428571 | Loss:268.31776742488864\n",
            "Iteration 350 | Accuracy: 28.57142857142857 | Loss:312.7030197198196\n",
            "Iteration 400 | Accuracy: 13.5 | Loss:357.39695405726\n",
            "Iteration 450 | Accuracy: 10.857142857142858 | Loss:401.7373697988739\n",
            "Iteration 500 | Accuracy: 12.714285714285714 | Loss:446.3635181087403\n",
            "Iteration 550 | Accuracy: 10.857142857142858 | Loss:491.0116621954389\n",
            "Iteration 600 | Accuracy: 18.5 | Loss:535.433692300224\n",
            "Iteration 650 | Accuracy: 20.357142857142858 | Loss:579.8871983420094\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:624.4107440156873\n",
            "Iteration 750 | Accuracy: 29.142857142857142 | Loss:669.138197037121\n",
            "Iteration 800 | Accuracy: 17.142857142857142 | Loss:713.6394708948453\n",
            "Iteration 850 | Accuracy: 24.785714285714285 | Loss:758.484549956561\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:802.6627396756371\n",
            "Iteration 950 | Accuracy: 10.214285714285715 | Loss:846.5704039341645\n",
            "Iteration 1000 | Accuracy: 11.285714285714285 | Loss:891.2591678145152\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:934.9767743774652\n",
            "Iteration 1100 | Accuracy: 19.78571428571429 | Loss:979.5082159180051\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1024.2285326290971\n",
            "Iteration 1200 | Accuracy: 14.499999999999998 | Loss:1068.7225044005088\n",
            "Iteration 1250 | Accuracy: 16.357142857142858 | Loss:1113.1107375974434\n",
            "Iteration 1300 | Accuracy: 13.285714285714286 | Loss:1157.4713571800125\n",
            "Iteration 1350 | Accuracy: 27.285714285714285 | Loss:1201.8670782769047\n",
            "##################################################\n",
            ">epoch=43, lrate=0.100, error=1245.434\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 29.714285714285715 | Loss:0.8956588207056959\n",
            "Iteration 50 | Accuracy: 15.642857142857142 | Loss:45.53439898488019\n",
            "Iteration 100 | Accuracy: 13.857142857142858 | Loss:90.05681473761898\n",
            "Iteration 150 | Accuracy: 18.642857142857142 | Loss:134.6904416589316\n",
            "Iteration 200 | Accuracy: 21.571428571428573 | Loss:178.64625988950758\n",
            "Iteration 250 | Accuracy: 15.071428571428571 | Loss:223.01236798389883\n",
            "Iteration 300 | Accuracy: 14.499999999999998 | Loss:267.24746185143545\n",
            "Iteration 350 | Accuracy: 28.714285714285715 | Loss:311.3883196828172\n",
            "Iteration 400 | Accuracy: 15.285714285714286 | Loss:355.9151406887098\n",
            "Iteration 450 | Accuracy: 15.5 | Loss:400.036979266181\n",
            "Iteration 500 | Accuracy: 17.285714285714285 | Loss:444.51106724886216\n",
            "Iteration 550 | Accuracy: 14.428571428571429 | Loss:489.0214534488608\n",
            "Iteration 600 | Accuracy: 18.285714285714285 | Loss:533.1714476163693\n",
            "Iteration 650 | Accuracy: 30.07142857142857 | Loss:577.3480974471657\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:621.6664494748933\n",
            "Iteration 750 | Accuracy: 31.071428571428573 | Loss:666.2165343913633\n",
            "Iteration 800 | Accuracy: 25.71428571428571 | Loss:710.4813439970695\n",
            "Iteration 850 | Accuracy: 23.214285714285715 | Loss:755.1671509213801\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:799.0761021603053\n",
            "Iteration 950 | Accuracy: 12.928571428571429 | Loss:842.7302192411678\n",
            "Iteration 1000 | Accuracy: 14.214285714285715 | Loss:887.1883392549724\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:930.4648944643495\n",
            "Iteration 1100 | Accuracy: 28.92857142857143 | Loss:974.7522040447541\n",
            "Iteration 1150 | Accuracy: 19.78571428571429 | Loss:1019.2736842418183\n",
            "Iteration 1200 | Accuracy: 16.428571428571427 | Loss:1063.4942404159656\n",
            "Iteration 1250 | Accuracy: 16.357142857142858 | Loss:1107.6565629805577\n",
            "Iteration 1300 | Accuracy: 18.642857142857142 | Loss:1151.6905971863105\n",
            "Iteration 1350 | Accuracy: 23.42857142857143 | Loss:1195.8663678249059\n",
            "##################################################\n",
            ">epoch=44, lrate=0.100, error=1239.175\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 35.5 | Loss:0.8990546210254405\n",
            "Iteration 50 | Accuracy: 26.785714285714285 | Loss:45.35010667109499\n",
            "Iteration 100 | Accuracy: 16.642857142857142 | Loss:89.65936753092629\n",
            "Iteration 150 | Accuracy: 29.07142857142857 | Loss:133.99858128607136\n",
            "Iteration 200 | Accuracy: 19.57142857142857 | Loss:177.58014999810692\n",
            "Iteration 250 | Accuracy: 16.071428571428573 | Loss:221.6308254974743\n",
            "Iteration 300 | Accuracy: 16.071428571428573 | Loss:265.54404932855357\n",
            "Iteration 350 | Accuracy: 28.714285714285715 | Loss:309.2975117457845\n",
            "Iteration 400 | Accuracy: 17.42857142857143 | Loss:353.5659761294791\n",
            "Iteration 450 | Accuracy: 26.21428571428571 | Loss:397.33204394286264\n",
            "Iteration 500 | Accuracy: 17.42857142857143 | Loss:441.5634601409667\n",
            "Iteration 550 | Accuracy: 16.642857142857142 | Loss:485.84038934796257\n",
            "Iteration 600 | Accuracy: 28.214285714285715 | Loss:529.5328424524181\n",
            "Iteration 650 | Accuracy: 30.0 | Loss:573.2483103385201\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:617.2365173979804\n",
            "Iteration 750 | Accuracy: 30.357142857142854 | Loss:661.4816639814384\n",
            "Iteration 800 | Accuracy: 27.57142857142857 | Loss:705.3474469347082\n",
            "Iteration 850 | Accuracy: 30.571428571428573 | Loss:749.7698690026089\n",
            "Iteration 900 | Accuracy: 19.357142857142858 | Loss:793.2421061674509\n",
            "Iteration 950 | Accuracy: 14.714285714285714 | Loss:836.4497702715557\n",
            "Iteration 1000 | Accuracy: 17.285714285714285 | Loss:880.4978033225659\n",
            "Iteration 1050 | Accuracy: 19.78571428571429 | Loss:923.0412989297097\n",
            "Iteration 1100 | Accuracy: 30.0 | Loss:966.8969469538908\n",
            "Iteration 1150 | Accuracy: 21.142857142857142 | Loss:1011.0777970359163\n",
            "Iteration 1200 | Accuracy: 18.857142857142858 | Loss:1054.8253229113363\n",
            "Iteration 1250 | Accuracy: 26.64285714285714 | Loss:1098.627560414546\n",
            "Iteration 1300 | Accuracy: 22.142857142857142 | Loss:1142.0992002377548\n",
            "Iteration 1350 | Accuracy: 33.57142857142857 | Loss:1185.8673430988827\n",
            "##################################################\n",
            ">epoch=45, lrate=0.100, error=1228.728\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 31.71428571428571 | Loss:0.9051944486791735\n",
            "Iteration 50 | Accuracy: 37.857142857142854 | Loss:45.029970781172345\n",
            "Iteration 100 | Accuracy: 28.642857142857142 | Loss:88.96787398288546\n",
            "Iteration 150 | Accuracy: 31.071428571428573 | Loss:132.80547467213177\n",
            "Iteration 200 | Accuracy: 19.78571428571429 | Loss:175.73998136325724\n",
            "Iteration 250 | Accuracy: 22.285714285714285 | Loss:219.2334990436181\n",
            "Iteration 300 | Accuracy: 22.642857142857142 | Loss:262.5857321060745\n",
            "Iteration 350 | Accuracy: 28.57142857142857 | Loss:305.6869201290392\n",
            "Iteration 400 | Accuracy: 24.428571428571427 | Loss:349.5013644350522\n",
            "Iteration 450 | Accuracy: 27.21428571428571 | Loss:392.64165430992557\n",
            "Iteration 500 | Accuracy: 18.571428571428573 | Loss:436.44403503182394\n",
            "Iteration 550 | Accuracy: 38.357142857142854 | Loss:480.2769975904801\n",
            "Iteration 600 | Accuracy: 29.85714285714286 | Loss:523.128921153612\n",
            "Iteration 650 | Accuracy: 30.0 | Loss:565.9959124586576\n",
            "Iteration 700 | Accuracy: 20.142857142857142 | Loss:609.4184891533012\n",
            "Iteration 750 | Accuracy: 30.857142857142854 | Loss:653.0606754166082\n",
            "Iteration 800 | Accuracy: 36.714285714285715 | Loss:696.175380856973\n",
            "Iteration 850 | Accuracy: 29.85714285714286 | Loss:740.1286590816613\n",
            "Iteration 900 | Accuracy: 27.785714285714285 | Loss:782.7998306702564\n",
            "Iteration 950 | Accuracy: 15.285714285714286 | Loss:825.1001876966764\n",
            "Iteration 1000 | Accuracy: 26.142857142857146 | Loss:868.3375166871006\n",
            "Iteration 1050 | Accuracy: 29.85714285714286 | Loss:909.5663525537918\n",
            "Iteration 1100 | Accuracy: 30.07142857142857 | Loss:952.6000923671025\n",
            "Iteration 1150 | Accuracy: 30.0 | Loss:996.1212497642646\n",
            "Iteration 1200 | Accuracy: 19.857142857142858 | Loss:1039.022336283751\n",
            "Iteration 1250 | Accuracy: 27.0 | Loss:1082.1986407441468\n",
            "Iteration 1300 | Accuracy: 32.57142857142858 | Loss:1124.5995003194012\n",
            "Iteration 1350 | Accuracy: 38.857142857142854 | Loss:1167.5270924465258\n",
            "##################################################\n",
            ">epoch=46, lrate=0.100, error=1209.521\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.357142857142854 | Loss:0.9173910630814293\n",
            "Iteration 50 | Accuracy: 41.57142857142857 | Loss:44.41383318247879\n",
            "Iteration 100 | Accuracy: 38.857142857142854 | Loss:87.65065469347559\n",
            "Iteration 150 | Accuracy: 37.714285714285715 | Loss:130.57685390535107\n",
            "Iteration 200 | Accuracy: 24.857142857142858 | Loss:172.30537499699358\n",
            "Iteration 250 | Accuracy: 24.5 | Loss:214.78538673568536\n",
            "Iteration 300 | Accuracy: 25.785714285714285 | Loss:257.0994076934556\n",
            "Iteration 350 | Accuracy: 29.142857142857142 | Loss:299.102774476857\n",
            "Iteration 400 | Accuracy: 38.92857142857143 | Loss:341.9777661449157\n",
            "Iteration 450 | Accuracy: 38.142857142857146 | Loss:383.96684985316426\n",
            "Iteration 500 | Accuracy: 38.642857142857146 | Loss:426.9353954829593\n",
            "Iteration 550 | Accuracy: 38.57142857142858 | Loss:469.84908708802936\n",
            "Iteration 600 | Accuracy: 34.07142857142857 | Loss:511.12168699377776\n",
            "Iteration 650 | Accuracy: 30.142857142857142 | Loss:552.3361184112817\n",
            "Iteration 700 | Accuracy: 22.071428571428573 | Loss:594.7811285001682\n",
            "Iteration 750 | Accuracy: 35.785714285714285 | Loss:637.0900394796103\n",
            "Iteration 800 | Accuracy: 38.142857142857146 | Loss:678.6999990162241\n",
            "Iteration 850 | Accuracy: 34.0 | Loss:721.7937974294397\n",
            "Iteration 900 | Accuracy: 39.285714285714285 | Loss:762.8468537077932\n",
            "Iteration 950 | Accuracy: 17.214285714285715 | Loss:803.1940765632119\n",
            "Iteration 1000 | Accuracy: 39.85714285714286 | Loss:844.7906001788185\n",
            "Iteration 1050 | Accuracy: 30.142857142857142 | Loss:883.6909902961517\n",
            "Iteration 1100 | Accuracy: 30.28571428571429 | Loss:925.2007149890619\n",
            "Iteration 1150 | Accuracy: 36.5 | Loss:967.3879485219369\n",
            "Iteration 1200 | Accuracy: 26.71428571428571 | Loss:1008.9221875232191\n",
            "Iteration 1250 | Accuracy: 36.5 | Loss:1050.9764281917317\n",
            "Iteration 1300 | Accuracy: 38.642857142857146 | Loss:1091.303914981897\n",
            "Iteration 1350 | Accuracy: 39.42857142857143 | Loss:1132.542862158415\n",
            "##################################################\n",
            ">epoch=47, lrate=0.100, error=1172.838\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.57142857142858 | Loss:0.9389687634945457\n",
            "Iteration 50 | Accuracy: 42.785714285714285 | Loss:43.215211656587044\n",
            "Iteration 100 | Accuracy: 41.57142857142857 | Loss:85.17043534428643\n",
            "Iteration 150 | Accuracy: 39.285714285714285 | Loss:126.52150998013089\n",
            "Iteration 200 | Accuracy: 40.14285714285714 | Loss:166.11085188190197\n",
            "Iteration 250 | Accuracy: 35.57142857142857 | Loss:206.9432827350961\n",
            "Iteration 300 | Accuracy: 39.714285714285715 | Loss:247.46552248579042\n",
            "Iteration 350 | Accuracy: 38.714285714285715 | Loss:287.84678827379753\n",
            "Iteration 400 | Accuracy: 39.214285714285715 | Loss:328.77157184180385\n",
            "Iteration 450 | Accuracy: 38.714285714285715 | Loss:368.81711275917496\n",
            "Iteration 500 | Accuracy: 39.214285714285715 | Loss:410.24706435989697\n",
            "Iteration 550 | Accuracy: 39.214285714285715 | Loss:451.4584755543082\n",
            "Iteration 600 | Accuracy: 36.92857142857143 | Loss:490.20516763118195\n",
            "Iteration 650 | Accuracy: 34.5 | Loss:528.673561952748\n",
            "Iteration 700 | Accuracy: 34.92857142857143 | Loss:569.5869088838685\n",
            "Iteration 750 | Accuracy: 39.85714285714286 | Loss:609.4009921330387\n",
            "Iteration 800 | Accuracy: 39.42857142857143 | Loss:648.5397303579215\n",
            "Iteration 850 | Accuracy: 40.07142857142857 | Loss:690.2031663691654\n",
            "Iteration 900 | Accuracy: 39.357142857142854 | Loss:728.5308153833446\n",
            "Iteration 950 | Accuracy: 29.78571428571429 | Loss:765.8941412354573\n",
            "Iteration 1000 | Accuracy: 42.07142857142857 | Loss:805.0355719640381\n",
            "Iteration 1050 | Accuracy: 37.214285714285715 | Loss:840.7642814877051\n",
            "Iteration 1100 | Accuracy: 38.07142857142857 | Loss:880.1307459580198\n",
            "Iteration 1150 | Accuracy: 39.357142857142854 | Loss:920.2243055531089\n",
            "Iteration 1200 | Accuracy: 33.92857142857143 | Loss:960.0861083689518\n",
            "Iteration 1250 | Accuracy: 37.57142857142857 | Loss:1000.4499900148329\n",
            "Iteration 1300 | Accuracy: 39.214285714285715 | Loss:1037.7718521405875\n",
            "Iteration 1350 | Accuracy: 39.85714285714286 | Loss:1076.6650932141522\n",
            "##################################################\n",
            ">epoch=48, lrate=0.100, error=1114.617\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.85714285714286 | Loss:0.9663622827764417\n",
            "Iteration 50 | Accuracy: 42.714285714285715 | Loss:41.511897149055955\n",
            "Iteration 100 | Accuracy: 42.642857142857146 | Loss:81.72043320004724\n",
            "Iteration 150 | Accuracy: 39.357142857142854 | Loss:121.04372529438734\n",
            "Iteration 200 | Accuracy: 42.07142857142857 | Loss:157.93472008387158\n",
            "Iteration 250 | Accuracy: 40.42857142857143 | Loss:196.7605542044664\n",
            "Iteration 300 | Accuracy: 43.214285714285715 | Loss:235.0415406794008\n",
            "Iteration 350 | Accuracy: 39.14285714285714 | Loss:273.54873917540556\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:311.90761056421644\n",
            "Iteration 450 | Accuracy: 39.214285714285715 | Loss:349.81994364372156\n",
            "Iteration 500 | Accuracy: 39.357142857142854 | Loss:389.4192001968162\n",
            "Iteration 550 | Accuracy: 39.57142857142858 | Loss:428.68084719398144\n",
            "Iteration 600 | Accuracy: 40.285714285714285 | Loss:464.7263953681459\n",
            "Iteration 650 | Accuracy: 39.07142857142858 | Loss:500.3903409675333\n",
            "Iteration 700 | Accuracy: 39.214285714285715 | Loss:539.5017081499601\n",
            "Iteration 750 | Accuracy: 40.14285714285714 | Loss:576.7397270454983\n",
            "Iteration 800 | Accuracy: 40.0 | Loss:613.4153435189427\n",
            "Iteration 850 | Accuracy: 41.214285714285715 | Loss:653.3958992725791\n",
            "Iteration 900 | Accuracy: 38.92857142857143 | Loss:688.9150970737526\n",
            "Iteration 950 | Accuracy: 40.5 | Loss:723.8582465169744\n",
            "Iteration 1000 | Accuracy: 42.57142857142857 | Loss:760.829179359178\n",
            "Iteration 1050 | Accuracy: 39.285714285714285 | Loss:793.6225463444213\n",
            "Iteration 1100 | Accuracy: 39.92857142857143 | Loss:830.9883565245423\n",
            "Iteration 1150 | Accuracy: 39.57142857142858 | Loss:868.959004961999\n",
            "Iteration 1200 | Accuracy: 39.785714285714285 | Loss:907.2763567527287\n",
            "Iteration 1250 | Accuracy: 37.5 | Loss:945.8022142812245\n",
            "Iteration 1300 | Accuracy: 39.357142857142854 | Loss:980.3395152172234\n",
            "Iteration 1350 | Accuracy: 39.57142857142858 | Loss:1017.0993237548574\n",
            "##################################################\n",
            ">epoch=49, lrate=0.100, error=1052.996\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.64285714285714 | Loss:0.9915280983127853\n",
            "Iteration 50 | Accuracy: 42.92857142857143 | Loss:39.95746574027437\n",
            "Iteration 100 | Accuracy: 43.142857142857146 | Loss:78.50294444273563\n",
            "Iteration 150 | Accuracy: 40.285714285714285 | Loss:115.97560644740693\n",
            "Iteration 200 | Accuracy: 42.142857142857146 | Loss:150.51027597036446\n",
            "Iteration 250 | Accuracy: 43.42857142857143 | Loss:187.50782012779183\n",
            "Iteration 300 | Accuracy: 43.142857142857146 | Loss:223.77971171386034\n",
            "Iteration 350 | Accuracy: 39.285714285714285 | Loss:260.5539608966089\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:296.750119092378\n",
            "Iteration 450 | Accuracy: 40.14285714285714 | Loss:333.0432470604687\n",
            "Iteration 500 | Accuracy: 40.14285714285714 | Loss:371.14801616265873\n",
            "Iteration 550 | Accuracy: 40.57142857142857 | Loss:408.8881370701077\n",
            "Iteration 600 | Accuracy: 44.07142857142857 | Loss:442.7214932025026\n",
            "Iteration 650 | Accuracy: 40.0 | Loss:476.20993450036224\n",
            "Iteration 700 | Accuracy: 39.92857142857143 | Loss:513.6878591926185\n",
            "Iteration 750 | Accuracy: 39.57142857142858 | Loss:549.0358673715576\n",
            "Iteration 800 | Accuracy: 40.0 | Loss:583.8182773229978\n",
            "Iteration 850 | Accuracy: 41.214285714285715 | Loss:622.2983792913286\n",
            "Iteration 900 | Accuracy: 38.857142857142854 | Loss:655.5880879011764\n",
            "Iteration 950 | Accuracy: 41.14285714285714 | Loss:688.9462257138949\n",
            "Iteration 1000 | Accuracy: 42.642857142857146 | Loss:724.3117180655352\n",
            "Iteration 1050 | Accuracy: 39.214285714285715 | Loss:754.7905484874447\n",
            "Iteration 1100 | Accuracy: 40.92857142857143 | Loss:790.6348685920404\n",
            "Iteration 1150 | Accuracy: 39.42857142857143 | Loss:826.8947069105722\n",
            "Iteration 1200 | Accuracy: 40.714285714285715 | Loss:863.9642153060308\n",
            "Iteration 1250 | Accuracy: 39.07142857142858 | Loss:900.836681413144\n",
            "Iteration 1300 | Accuracy: 39.57142857142858 | Loss:933.2518717766247\n",
            "Iteration 1350 | Accuracy: 39.85714285714286 | Loss:968.3894209954652\n",
            "##################################################\n",
            ">epoch=50, lrate=0.100, error=1002.699\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 39.92857142857143 | Loss:1.0103402138091797\n",
            "Iteration 50 | Accuracy: 43.42857142857143 | Loss:38.749624197452235\n",
            "Iteration 100 | Accuracy: 43.714285714285715 | Loss:75.93961411362295\n",
            "Iteration 150 | Accuracy: 41.714285714285715 | Loss:111.9365515541249\n",
            "Iteration 200 | Accuracy: 41.85714285714286 | Loss:144.65003885549456\n",
            "Iteration 250 | Accuracy: 43.57142857142857 | Loss:180.20822549800323\n",
            "Iteration 300 | Accuracy: 43.214285714285715 | Loss:214.91742050575985\n",
            "Iteration 350 | Accuracy: 39.42857142857143 | Loss:250.25247573706568\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:284.8630131549927\n",
            "Iteration 450 | Accuracy: 41.35714285714286 | Loss:319.9843764058668\n",
            "Iteration 500 | Accuracy: 41.5 | Loss:356.9524932501777\n",
            "Iteration 550 | Accuracy: 41.785714285714285 | Loss:393.62855196302104\n",
            "Iteration 600 | Accuracy: 44.07142857142857 | Loss:425.77869546204477\n",
            "Iteration 650 | Accuracy: 41.14285714285714 | Loss:457.6930447394858\n",
            "Iteration 700 | Accuracy: 41.214285714285715 | Loss:493.8510774359571\n",
            "Iteration 750 | Accuracy: 40.64285714285714 | Loss:527.8849585752747\n",
            "Iteration 800 | Accuracy: 40.14285714285714 | Loss:561.3083271604155\n",
            "Iteration 850 | Accuracy: 42.57142857142857 | Loss:598.5939513518756\n",
            "Iteration 900 | Accuracy: 38.857142857142854 | Loss:630.2446337567004\n",
            "Iteration 950 | Accuracy: 41.85714285714286 | Loss:662.5525259063771\n",
            "Iteration 1000 | Accuracy: 42.785714285714285 | Loss:696.7711266044863\n",
            "Iteration 1050 | Accuracy: 39.214285714285715 | Loss:725.5482994770792\n",
            "Iteration 1100 | Accuracy: 41.642857142857146 | Loss:760.3304159481247\n",
            "Iteration 1150 | Accuracy: 40.214285714285715 | Loss:795.311605494827\n",
            "Iteration 1200 | Accuracy: 40.92857142857143 | Loss:831.4428798517636\n",
            "Iteration 1250 | Accuracy: 40.785714285714285 | Loss:866.9574217444823\n",
            "Iteration 1300 | Accuracy: 39.785714285714285 | Loss:897.8611955632639\n",
            "Iteration 1350 | Accuracy: 40.714285714285715 | Loss:931.8285252898373\n",
            "##################################################\n",
            ">epoch=51, lrate=0.100, error=964.956\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 42.42857142857142 | Loss:1.0234374952315328\n",
            "Iteration 50 | Accuracy: 45.92857142857143 | Loss:37.84730836939063\n",
            "Iteration 100 | Accuracy: 47.42857142857143 | Loss:73.99968809425918\n",
            "Iteration 150 | Accuracy: 42.0 | Loss:108.88989590454479\n",
            "Iteration 200 | Accuracy: 41.714285714285715 | Loss:140.25586174419178\n",
            "Iteration 250 | Accuracy: 43.714285714285715 | Loss:174.74062049255514\n",
            "Iteration 300 | Accuracy: 46.285714285714285 | Loss:208.30569568239707\n",
            "Iteration 350 | Accuracy: 40.07142857142857 | Loss:242.53761139980966\n",
            "Iteration 400 | Accuracy: 39.14285714285714 | Loss:276.03632183931734\n",
            "Iteration 450 | Accuracy: 42.0 | Loss:310.31535248762486\n",
            "Iteration 500 | Accuracy: 41.92857142857142 | Loss:346.4225339054717\n",
            "Iteration 550 | Accuracy: 47.214285714285715 | Loss:382.36806155000403\n",
            "Iteration 600 | Accuracy: 44.21428571428571 | Loss:413.2794943739554\n",
            "Iteration 650 | Accuracy: 41.785714285714285 | Loss:444.09989575192475\n",
            "Iteration 700 | Accuracy: 41.785714285714285 | Loss:479.25070024817495\n",
            "Iteration 750 | Accuracy: 41.714285714285715 | Loss:512.3721462169113\n",
            "Iteration 800 | Accuracy: 40.85714285714286 | Loss:544.8359486525297\n",
            "Iteration 850 | Accuracy: 44.21428571428571 | Loss:581.2115006917667\n",
            "Iteration 900 | Accuracy: 42.214285714285715 | Loss:611.688644298916\n",
            "Iteration 950 | Accuracy: 42.285714285714285 | Loss:643.2726401633136\n",
            "Iteration 1000 | Accuracy: 43.0 | Loss:676.6768348760436\n",
            "Iteration 1050 | Accuracy: 39.85714285714286 | Loss:704.234623852125\n",
            "Iteration 1100 | Accuracy: 42.642857142857146 | Loss:738.286826976301\n",
            "Iteration 1150 | Accuracy: 39.285714285714285 | Loss:772.3300379728827\n",
            "Iteration 1200 | Accuracy: 43.0 | Loss:807.7787466295048\n",
            "Iteration 1250 | Accuracy: 42.42857142857142 | Loss:842.2431923986271\n",
            "Iteration 1300 | Accuracy: 40.214285714285715 | Loss:872.0802213518301\n",
            "Iteration 1350 | Accuracy: 46.14285714285714 | Loss:905.1991775054755\n",
            "##################################################\n",
            ">epoch=52, lrate=0.100, error=937.462\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 46.785714285714285 | Loss:1.0322032462064035\n",
            "Iteration 50 | Accuracy: 49.714285714285715 | Loss:37.17929355605468\n",
            "Iteration 100 | Accuracy: 49.785714285714285 | Loss:72.5564643945795\n",
            "Iteration 150 | Accuracy: 42.642857142857146 | Loss:106.63428268163095\n",
            "Iteration 200 | Accuracy: 42.42857142857142 | Loss:137.01408774469766\n",
            "Iteration 250 | Accuracy: 43.857142857142854 | Loss:170.69533701883836\n",
            "Iteration 300 | Accuracy: 48.714285714285715 | Loss:203.4342222360119\n",
            "Iteration 350 | Accuracy: 43.28571428571429 | Loss:236.8578854292899\n",
            "Iteration 400 | Accuracy: 40.64285714285714 | Loss:269.5848214508732\n",
            "Iteration 450 | Accuracy: 42.142857142857146 | Loss:303.2554021880896\n",
            "Iteration 500 | Accuracy: 42.642857142857146 | Loss:338.7042210379701\n",
            "Iteration 550 | Accuracy: 50.28571428571429 | Loss:374.1382909975226\n",
            "Iteration 600 | Accuracy: 44.642857142857146 | Loss:404.13882782551025\n",
            "Iteration 650 | Accuracy: 42.07142857142857 | Loss:434.20307367577465\n",
            "Iteration 700 | Accuracy: 42.285714285714285 | Loss:468.60582071257267\n",
            "Iteration 750 | Accuracy: 41.642857142857146 | Loss:501.0814763888517\n",
            "Iteration 800 | Accuracy: 41.85714285714286 | Loss:532.8604412432941\n",
            "Iteration 850 | Accuracy: 44.92857142857143 | Loss:568.5513528411199\n",
            "Iteration 900 | Accuracy: 44.5 | Loss:598.189454886437\n",
            "Iteration 950 | Accuracy: 42.714285714285715 | Loss:629.2518823637848\n",
            "Iteration 1000 | Accuracy: 43.57142857142857 | Loss:662.0620204212403\n",
            "Iteration 1050 | Accuracy: 40.85714285714286 | Loss:688.741510657458\n",
            "Iteration 1100 | Accuracy: 43.214285714285715 | Loss:722.2803326686089\n",
            "Iteration 1150 | Accuracy: 40.14285714285714 | Loss:755.6319006720291\n",
            "Iteration 1200 | Accuracy: 46.5 | Loss:790.5838131155667\n",
            "Iteration 1250 | Accuracy: 43.857142857142854 | Loss:824.2584174273258\n",
            "Iteration 1300 | Accuracy: 41.642857142857146 | Loss:853.3306222638915\n",
            "Iteration 1350 | Accuracy: 48.642857142857146 | Loss:885.8177292315615\n",
            "##################################################\n",
            ">epoch=53, lrate=0.100, error=917.449\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 48.214285714285715 | Loss:1.0384137905373958\n",
            "Iteration 50 | Accuracy: 51.57142857142857 | Loss:36.67840411282978\n",
            "Iteration 100 | Accuracy: 50.78571428571429 | Loss:71.47563096322288\n",
            "Iteration 150 | Accuracy: 45.5 | Loss:104.95266372282647\n",
            "Iteration 200 | Accuracy: 45.357142857142854 | Loss:134.60202164973768\n",
            "Iteration 250 | Accuracy: 44.785714285714285 | Loss:167.66361048079236\n",
            "Iteration 300 | Accuracy: 50.21428571428571 | Loss:199.7956555645743\n",
            "Iteration 350 | Accuracy: 45.92857142857143 | Loss:232.63103281305666\n",
            "Iteration 400 | Accuracy: 43.785714285714285 | Loss:264.8142569081928\n",
            "Iteration 450 | Accuracy: 44.857142857142854 | Loss:298.0363332616307\n",
            "Iteration 500 | Accuracy: 45.64285714285714 | Loss:332.973621031452\n",
            "Iteration 550 | Accuracy: 51.857142857142854 | Loss:368.033918929481\n",
            "Iteration 600 | Accuracy: 45.07142857142858 | Loss:397.3542736597991\n",
            "Iteration 650 | Accuracy: 42.92857142857143 | Loss:426.88515661981796\n",
            "Iteration 700 | Accuracy: 44.642857142857146 | Loss:460.73359381212975\n",
            "Iteration 750 | Accuracy: 41.714285714285715 | Loss:492.73790016662787\n",
            "Iteration 800 | Accuracy: 42.714285714285715 | Loss:524.0149378276352\n",
            "Iteration 850 | Accuracy: 47.35714285714286 | Loss:559.1864265695901\n",
            "Iteration 900 | Accuracy: 46.42857142857143 | Loss:588.2113861960491\n",
            "Iteration 950 | Accuracy: 43.142857142857146 | Loss:618.881495762857\n",
            "Iteration 1000 | Accuracy: 43.857142857142854 | Loss:651.239912745161\n",
            "Iteration 1050 | Accuracy: 41.85714285714286 | Loss:677.2737256746442\n",
            "Iteration 1100 | Accuracy: 43.42857142857143 | Loss:710.4358674618034\n",
            "Iteration 1150 | Accuracy: 42.714285714285715 | Loss:743.2666129303185\n",
            "Iteration 1200 | Accuracy: 47.85714285714286 | Loss:777.8480945891757\n",
            "Iteration 1250 | Accuracy: 44.42857142857143 | Loss:810.9261479339453\n",
            "Iteration 1300 | Accuracy: 43.92857142857143 | Loss:839.4353070885938\n",
            "Iteration 1350 | Accuracy: 50.21428571428571 | Loss:871.4331526974645\n",
            "##################################################\n",
            ">epoch=54, lrate=0.100, error=902.594\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 49.214285714285715 | Loss:1.0433755379491427\n",
            "Iteration 50 | Accuracy: 53.214285714285715 | Loss:36.290339037369975\n",
            "Iteration 100 | Accuracy: 51.714285714285715 | Loss:70.64396596433627\n",
            "Iteration 150 | Accuracy: 47.14285714285714 | Loss:103.66535185191567\n",
            "Iteration 200 | Accuracy: 47.14285714285714 | Loss:132.7578492208629\n",
            "Iteration 250 | Accuracy: 46.64285714285714 | Loss:165.32348049157383\n",
            "Iteration 300 | Accuracy: 50.92857142857142 | Loss:196.99225463795352\n",
            "Iteration 350 | Accuracy: 47.42857142857143 | Loss:229.38796807544466\n",
            "Iteration 400 | Accuracy: 45.357142857142854 | Loss:261.1743511324345\n",
            "Iteration 450 | Accuracy: 47.0 | Loss:294.05387543238317\n",
            "Iteration 500 | Accuracy: 47.214285714285715 | Loss:328.5851025543832\n",
            "Iteration 550 | Accuracy: 53.0 | Loss:363.3563881070406\n",
            "Iteration 600 | Accuracy: 45.857142857142854 | Loss:392.15716050984076\n",
            "Iteration 650 | Accuracy: 44.285714285714285 | Loss:421.2975384419265\n",
            "Iteration 700 | Accuracy: 45.92857142857143 | Loss:454.72748256462506\n",
            "Iteration 750 | Accuracy: 42.07142857142857 | Loss:486.37468515939923\n",
            "Iteration 800 | Accuracy: 44.21428571428571 | Loss:517.2703480942256\n",
            "Iteration 850 | Accuracy: 49.642857142857146 | Loss:552.0372833117622\n",
            "Iteration 900 | Accuracy: 47.85714285714286 | Loss:580.5949553425171\n",
            "Iteration 950 | Accuracy: 43.57142857142857 | Loss:610.9567548082289\n",
            "Iteration 1000 | Accuracy: 44.285714285714285 | Loss:642.9561598793676\n",
            "Iteration 1050 | Accuracy: 42.35714285714286 | Loss:668.5009685054674\n",
            "Iteration 1100 | Accuracy: 43.57142857142857 | Loss:701.3722652541359\n",
            "Iteration 1150 | Accuracy: 43.714285714285715 | Loss:733.7982884818108\n",
            "Iteration 1200 | Accuracy: 49.785714285714285 | Loss:768.0921526339399\n",
            "Iteration 1250 | Accuracy: 44.785714285714285 | Loss:800.707638552943\n",
            "Iteration 1300 | Accuracy: 45.57142857142858 | Loss:828.7883976127886\n",
            "Iteration 1350 | Accuracy: 51.5 | Loss:860.3898105817535\n",
            "##################################################\n",
            ">epoch=55, lrate=0.100, error=891.188\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 49.642857142857146 | Loss:1.0477682694753463\n",
            "Iteration 50 | Accuracy: 54.214285714285715 | Loss:35.97552543097599\n",
            "Iteration 100 | Accuracy: 52.28571428571429 | Loss:69.97720926818532\n",
            "Iteration 150 | Accuracy: 48.214285714285715 | Loss:102.64056968002294\n",
            "Iteration 200 | Accuracy: 49.28571428571429 | Loss:131.29173720065063\n",
            "Iteration 250 | Accuracy: 48.07142857142857 | Loss:163.44549856605434\n",
            "Iteration 300 | Accuracy: 51.42857142857142 | Loss:194.74219790266866\n",
            "Iteration 350 | Accuracy: 48.0 | Loss:226.79284636288045\n",
            "Iteration 400 | Accuracy: 47.07142857142857 | Loss:258.27505919931036\n",
            "Iteration 450 | Accuracy: 48.35714285714286 | Loss:290.88017095623104\n",
            "Iteration 500 | Accuracy: 48.285714285714285 | Loss:325.0800950068373\n",
            "Iteration 550 | Accuracy: 54.0 | Loss:359.61395990374774\n",
            "Iteration 600 | Accuracy: 46.714285714285715 | Loss:388.00704586999194\n",
            "Iteration 650 | Accuracy: 46.07142857142857 | Loss:416.84758742453704\n",
            "Iteration 700 | Accuracy: 48.214285714285715 | Loss:449.95069351572846\n",
            "Iteration 750 | Accuracy: 44.285714285714285 | Loss:481.31614585727414\n",
            "Iteration 800 | Accuracy: 45.92857142857143 | Loss:511.9100642691658\n",
            "Iteration 850 | Accuracy: 50.28571428571429 | Loss:546.3497772481488\n",
            "Iteration 900 | Accuracy: 48.57142857142857 | Loss:574.531773273971\n",
            "Iteration 950 | Accuracy: 44.42857142857143 | Loss:604.640109387086\n",
            "Iteration 1000 | Accuracy: 44.357142857142854 | Loss:636.3417618414142\n",
            "Iteration 1050 | Accuracy: 42.785714285714285 | Loss:661.5029692123072\n",
            "Iteration 1100 | Accuracy: 43.92857142857143 | Loss:694.1376003471581\n",
            "Iteration 1150 | Accuracy: 45.42857142857143 | Loss:726.2373340204045\n",
            "Iteration 1200 | Accuracy: 51.07142857142857 | Loss:760.2967690430961\n",
            "Iteration 1250 | Accuracy: 44.92857142857143 | Loss:792.5400785380378\n",
            "Iteration 1300 | Accuracy: 46.785714285714285 | Loss:820.2829205320028\n",
            "Iteration 1350 | Accuracy: 52.642857142857146 | Loss:851.5479097170663\n",
            "##################################################\n",
            ">epoch=56, lrate=0.100, error=882.057\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 50.42857142857143 | Loss:1.051906878564522\n",
            "Iteration 50 | Accuracy: 55.42857142857143 | Loss:35.70711585792435\n",
            "Iteration 100 | Accuracy: 53.0 | Loss:69.41726672808862\n",
            "Iteration 150 | Accuracy: 49.214285714285715 | Loss:101.78815483315434\n",
            "Iteration 200 | Accuracy: 50.0 | Loss:130.07448317861892\n",
            "Iteration 250 | Accuracy: 48.92857142857142 | Loss:161.87452360037602\n",
            "Iteration 300 | Accuracy: 52.0 | Loss:192.8561148666238\n",
            "Iteration 350 | Accuracy: 48.857142857142854 | Loss:224.62010838804093\n",
            "Iteration 400 | Accuracy: 47.57142857142857 | Loss:255.8559064576742\n",
            "Iteration 450 | Accuracy: 49.57142857142857 | Loss:288.2295264461452\n",
            "Iteration 500 | Accuracy: 49.5 | Loss:322.15037821967877\n",
            "Iteration 550 | Accuracy: 54.42857142857142 | Loss:356.47786497268504\n",
            "Iteration 600 | Accuracy: 48.07142857142857 | Loss:384.54204040228075\n",
            "Iteration 650 | Accuracy: 47.42857142857143 | Loss:413.1403108406574\n",
            "Iteration 700 | Accuracy: 48.785714285714285 | Loss:445.97709190711225\n",
            "Iteration 750 | Accuracy: 45.857142857142854 | Loss:477.1108543014862\n",
            "Iteration 800 | Accuracy: 47.5 | Loss:507.45603562046944\n",
            "Iteration 850 | Accuracy: 51.28571428571429 | Loss:541.6195963287325\n",
            "Iteration 900 | Accuracy: 49.42857142857143 | Loss:569.4824090100989\n",
            "Iteration 950 | Accuracy: 46.0 | Loss:599.3730084145845\n",
            "Iteration 1000 | Accuracy: 44.714285714285715 | Loss:630.8178773760806\n",
            "Iteration 1050 | Accuracy: 43.142857142857146 | Loss:655.6668601469643\n",
            "Iteration 1100 | Accuracy: 44.285714285714285 | Loss:688.0993384944525\n",
            "Iteration 1150 | Accuracy: 47.07142857142857 | Loss:719.9258233328557\n",
            "Iteration 1200 | Accuracy: 53.0 | Loss:753.7846639080772\n",
            "Iteration 1250 | Accuracy: 45.285714285714285 | Loss:785.7165831666169\n",
            "Iteration 1300 | Accuracy: 48.142857142857146 | Loss:813.1831871411467\n",
            "Iteration 1350 | Accuracy: 52.78571428571428 | Loss:844.1502643626231\n",
            "##################################################\n",
            ">epoch=57, lrate=0.100, error=874.420\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 50.78571428571429 | Loss:1.055961271987922\n",
            "Iteration 50 | Accuracy: 55.85714285714286 | Loss:35.46763335238392\n",
            "Iteration 100 | Accuracy: 53.42857142857142 | Loss:68.92562588890972\n",
            "Iteration 150 | Accuracy: 49.92857142857143 | Loss:101.04855234335479\n",
            "Iteration 200 | Accuracy: 50.71428571428571 | Loss:129.02074958461827\n",
            "Iteration 250 | Accuracy: 50.0 | Loss:160.50808266006445\n",
            "Iteration 300 | Accuracy: 52.92857142857142 | Loss:191.20968017006797\n",
            "Iteration 350 | Accuracy: 49.0 | Loss:222.72275986690903\n",
            "Iteration 400 | Accuracy: 48.35714285714286 | Loss:253.7474237947977\n",
            "Iteration 450 | Accuracy: 50.21428571428571 | Loss:285.91636597147857\n",
            "Iteration 500 | Accuracy: 50.42857142857143 | Loss:319.5940868613223\n",
            "Iteration 550 | Accuracy: 54.785714285714285 | Loss:353.73355434317915\n",
            "Iteration 600 | Accuracy: 49.42857142857143 | Loss:381.5253196043795\n",
            "Iteration 650 | Accuracy: 48.5 | Loss:409.91807924223167\n",
            "Iteration 700 | Accuracy: 49.57142857142857 | Loss:442.52782938931153\n",
            "Iteration 750 | Accuracy: 47.07142857142857 | Loss:473.4633173142399\n",
            "Iteration 800 | Accuracy: 48.57142857142857 | Loss:503.59531125098016\n",
            "Iteration 850 | Accuracy: 52.142857142857146 | Loss:537.515800631182\n",
            "Iteration 900 | Accuracy: 50.21428571428571 | Loss:565.0935371050612\n",
            "Iteration 950 | Accuracy: 47.14285714285714 | Loss:594.7895309472176\n",
            "Iteration 1000 | Accuracy: 45.64285714285714 | Loss:626.0052596353514\n",
            "Iteration 1050 | Accuracy: 43.714285714285715 | Loss:650.5908564775643\n",
            "Iteration 1100 | Accuracy: 44.57142857142857 | Loss:682.8433461725135\n",
            "Iteration 1150 | Accuracy: 47.5 | Loss:714.4324992557715\n",
            "Iteration 1200 | Accuracy: 54.142857142857146 | Loss:748.1120867642401\n",
            "Iteration 1250 | Accuracy: 46.07142857142857 | Loss:779.7738070313935\n",
            "Iteration 1300 | Accuracy: 49.0 | Loss:807.0069987402081\n",
            "Iteration 1350 | Accuracy: 53.642857142857146 | Loss:837.7004687221988\n",
            "##################################################\n",
            ">epoch=58, lrate=0.100, error=867.763\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 51.42857142857142 | Loss:1.0600557541175535\n",
            "Iteration 50 | Accuracy: 55.85714285714286 | Loss:35.24577499598658\n",
            "Iteration 100 | Accuracy: 53.92857142857142 | Loss:68.4769379991772\n",
            "Iteration 150 | Accuracy: 50.642857142857146 | Loss:100.3826460077288\n",
            "Iteration 200 | Accuracy: 51.714285714285715 | Loss:128.07436991877847\n",
            "Iteration 250 | Accuracy: 50.78571428571429 | Loss:159.27839657581063\n",
            "Iteration 300 | Accuracy: 53.07142857142857 | Loss:189.72117099172678\n",
            "Iteration 350 | Accuracy: 49.5 | Loss:221.00520926371735\n",
            "Iteration 400 | Accuracy: 49.07142857142857 | Loss:251.83937759989058\n",
            "Iteration 450 | Accuracy: 51.42857142857142 | Loss:283.8203511171355\n",
            "Iteration 500 | Accuracy: 51.214285714285715 | Loss:317.2790319816175\n",
            "Iteration 550 | Accuracy: 55.214285714285715 | Loss:351.2409346630525\n",
            "Iteration 600 | Accuracy: 49.57142857142857 | Loss:378.8016469922232\n",
            "Iteration 650 | Accuracy: 49.214285714285715 | Loss:407.01246342153075\n",
            "Iteration 700 | Accuracy: 50.5 | Loss:439.4201357667693\n",
            "Iteration 750 | Accuracy: 48.214285714285715 | Loss:470.1796596311337\n",
            "Iteration 800 | Accuracy: 49.28571428571429 | Loss:500.12232337932784\n",
            "Iteration 850 | Accuracy: 53.07142857142857 | Loss:533.820419323799\n",
            "Iteration 900 | Accuracy: 50.71428571428571 | Loss:561.1328234863932\n",
            "Iteration 950 | Accuracy: 48.285714285714285 | Loss:590.6490055010029\n",
            "Iteration 1000 | Accuracy: 46.785714285714285 | Loss:621.6542888322366\n",
            "Iteration 1050 | Accuracy: 44.857142857142854 | Loss:646.0103053002018\n",
            "Iteration 1100 | Accuracy: 45.57142857142858 | Loss:678.0970244198201\n",
            "Iteration 1150 | Accuracy: 48.35714285714286 | Loss:709.4729790478464\n",
            "Iteration 1200 | Accuracy: 54.714285714285715 | Loss:742.9864689180727\n",
            "Iteration 1250 | Accuracy: 46.57142857142857 | Loss:774.406237467131\n",
            "Iteration 1300 | Accuracy: 50.357142857142854 | Loss:801.4362997672258\n",
            "Iteration 1350 | Accuracy: 53.92857142857142 | Loss:831.8707054822855\n",
            "##################################################\n",
            ">epoch=59, lrate=0.100, error=861.749\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 51.92857142857142 | Loss:1.0642923367851354\n",
            "Iteration 50 | Accuracy: 56.14285714285714 | Loss:35.033972306186755\n",
            "Iteration 100 | Accuracy: 54.214285714285715 | Loss:68.05415074122392\n",
            "Iteration 150 | Accuracy: 51.214285714285715 | Loss:99.76420186114503\n",
            "Iteration 200 | Accuracy: 52.35714285714286 | Loss:127.19769146046197\n",
            "Iteration 250 | Accuracy: 51.78571428571429 | Loss:158.13952042844983\n",
            "Iteration 300 | Accuracy: 53.35714285714286 | Loss:188.33557955433704\n",
            "Iteration 350 | Accuracy: 50.142857142857146 | Loss:219.40379685874214\n",
            "Iteration 400 | Accuracy: 49.857142857142854 | Loss:250.05845540227804\n",
            "Iteration 450 | Accuracy: 52.0 | Loss:281.86168942776595\n",
            "Iteration 500 | Accuracy: 51.642857142857146 | Loss:315.11652875543115\n",
            "Iteration 550 | Accuracy: 55.42857142857143 | Loss:348.9061364015379\n",
            "Iteration 600 | Accuracy: 50.642857142857146 | Loss:376.2664640631022\n",
            "Iteration 650 | Accuracy: 50.21428571428571 | Loss:404.3102781734059\n",
            "Iteration 700 | Accuracy: 51.5 | Loss:436.53106038029256\n",
            "Iteration 750 | Accuracy: 49.357142857142854 | Loss:467.12934687670304\n",
            "Iteration 800 | Accuracy: 49.714285714285715 | Loss:496.89839818557726\n",
            "Iteration 850 | Accuracy: 53.714285714285715 | Loss:530.3860463506606\n",
            "Iteration 900 | Accuracy: 51.0 | Loss:557.4433424115031\n",
            "Iteration 950 | Accuracy: 49.142857142857146 | Loss:586.7888903139246\n",
            "Iteration 1000 | Accuracy: 48.07142857142857 | Loss:617.5962022666617\n",
            "Iteration 1050 | Accuracy: 46.14285714285714 | Loss:641.7463222457673\n",
            "Iteration 1100 | Accuracy: 46.35714285714286 | Loss:673.6761288960939\n",
            "Iteration 1150 | Accuracy: 50.142857142857146 | Loss:704.8545233814071\n",
            "Iteration 1200 | Accuracy: 54.85714285714286 | Loss:738.2094933865696\n",
            "Iteration 1250 | Accuracy: 47.214285714285715 | Loss:769.4068880276618\n",
            "Iteration 1300 | Accuracy: 51.0 | Loss:796.2554981521554\n",
            "Iteration 1350 | Accuracy: 54.285714285714285 | Loss:826.4381000124436\n",
            "##################################################\n",
            ">epoch=60, lrate=0.100, error=856.147\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 52.714285714285715 | Loss:1.0687461977907464\n",
            "Iteration 50 | Accuracy: 56.49999999999999 | Loss:34.82678954369093\n",
            "Iteration 100 | Accuracy: 54.57142857142857 | Loss:67.6452562116683\n",
            "Iteration 150 | Accuracy: 51.92857142857142 | Loss:99.17487714019863\n",
            "Iteration 200 | Accuracy: 52.42857142857142 | Loss:126.36453991488452\n",
            "Iteration 250 | Accuracy: 52.5 | Loss:157.05891032859503\n",
            "Iteration 300 | Accuracy: 53.57142857142857 | Loss:187.01422506001083\n",
            "Iteration 350 | Accuracy: 51.0 | Loss:217.87413291259924\n",
            "Iteration 400 | Accuracy: 50.357142857142854 | Loss:248.35374607971568\n",
            "Iteration 450 | Accuracy: 52.28571428571429 | Loss:279.9850680699982\n",
            "Iteration 500 | Accuracy: 52.42857142857142 | Loss:313.04427593301716\n",
            "Iteration 550 | Accuracy: 55.92857142857143 | Loss:346.6630266478211\n",
            "Iteration 600 | Accuracy: 51.0 | Loss:373.84569589411024\n",
            "Iteration 650 | Accuracy: 50.642857142857146 | Loss:401.7314765065041\n",
            "Iteration 700 | Accuracy: 52.0 | Loss:433.7737509468207\n",
            "Iteration 750 | Accuracy: 50.142857142857146 | Loss:464.22009885130507\n",
            "Iteration 800 | Accuracy: 50.357142857142854 | Loss:493.8251999354607\n",
            "Iteration 850 | Accuracy: 53.78571428571428 | Loss:527.1079638535163\n",
            "Iteration 900 | Accuracy: 51.28571428571429 | Loss:553.9135905764343\n",
            "Iteration 950 | Accuracy: 49.857142857142854 | Loss:583.0937218517732\n",
            "Iteration 1000 | Accuracy: 48.857142857142854 | Loss:613.7109997226404\n",
            "Iteration 1050 | Accuracy: 47.14285714285714 | Loss:637.6720189883421\n",
            "Iteration 1100 | Accuracy: 47.214285714285715 | Loss:669.449868333793\n",
            "Iteration 1150 | Accuracy: 51.28571428571429 | Loss:700.4396762294579\n",
            "Iteration 1200 | Accuracy: 55.14285714285714 | Loss:733.6396621904721\n",
            "Iteration 1250 | Accuracy: 48.35714285714286 | Loss:764.6281642038423\n",
            "Iteration 1300 | Accuracy: 51.28571428571429 | Loss:791.3107842951059\n",
            "Iteration 1350 | Accuracy: 54.714285714285715 | Loss:821.2427049210336\n",
            "##################################################\n",
            ">epoch=61, lrate=0.100, error=850.791\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.214285714285715 | Loss:1.0734635067580571\n",
            "Iteration 50 | Accuracy: 56.57142857142857 | Loss:34.619957491544525\n",
            "Iteration 100 | Accuracy: 55.14285714285714 | Loss:67.24121050135213\n",
            "Iteration 150 | Accuracy: 52.35714285714286 | Loss:98.60106052371495\n",
            "Iteration 200 | Accuracy: 52.5 | Loss:125.55572267097888\n",
            "Iteration 250 | Accuracy: 53.142857142857146 | Loss:156.01207554798503\n",
            "Iteration 300 | Accuracy: 53.78571428571428 | Loss:185.72812317994007\n",
            "Iteration 350 | Accuracy: 51.5 | Loss:216.38316524788817\n",
            "Iteration 400 | Accuracy: 50.92857142857142 | Loss:246.68746870750732\n",
            "Iteration 450 | Accuracy: 52.85714285714286 | Loss:278.1494905232647\n",
            "Iteration 500 | Accuracy: 52.78571428571428 | Loss:311.0154578542129\n",
            "Iteration 550 | Accuracy: 56.07142857142857 | Loss:344.4613924594303\n",
            "Iteration 600 | Accuracy: 51.714285714285715 | Loss:371.4829900004405\n",
            "Iteration 650 | Accuracy: 51.0 | Loss:399.2151970287808\n",
            "Iteration 700 | Accuracy: 52.57142857142857 | Loss:431.0823348887576\n",
            "Iteration 750 | Accuracy: 51.714285714285715 | Loss:461.3818161263631\n",
            "Iteration 800 | Accuracy: 51.714285714285715 | Loss:490.82761565718124\n",
            "Iteration 850 | Accuracy: 54.285714285714285 | Loss:523.9060187586246\n",
            "Iteration 900 | Accuracy: 52.0 | Loss:550.4579396725884\n",
            "Iteration 950 | Accuracy: 50.71428571428571 | Loss:579.4748163422962\n",
            "Iteration 1000 | Accuracy: 49.5 | Loss:609.9064806848685\n",
            "Iteration 1050 | Accuracy: 48.0 | Loss:633.690388541868\n",
            "Iteration 1100 | Accuracy: 48.0 | Loss:665.3180851235155\n",
            "Iteration 1150 | Accuracy: 52.28571428571429 | Loss:696.1223460880772\n",
            "Iteration 1200 | Accuracy: 55.85714285714286 | Loss:729.1676735789191\n",
            "Iteration 1250 | Accuracy: 48.642857142857146 | Loss:759.9559156728101\n",
            "Iteration 1300 | Accuracy: 51.5 | Loss:786.4831413606474\n",
            "Iteration 1350 | Accuracy: 55.00000000000001 | Loss:816.1595727001499\n",
            "##################################################\n",
            ">epoch=62, lrate=0.100, error=845.551\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.57142857142857 | Loss:1.0784736851343195\n",
            "Iteration 50 | Accuracy: 56.714285714285715 | Loss:34.40974859697765\n",
            "Iteration 100 | Accuracy: 55.214285714285715 | Loss:66.83450248484948\n",
            "Iteration 150 | Accuracy: 53.214285714285715 | Loss:98.03172402630608\n",
            "Iteration 200 | Accuracy: 52.714285714285715 | Loss:124.75601336239619\n",
            "Iteration 250 | Accuracy: 53.85714285714286 | Loss:154.97897632748118\n",
            "Iteration 300 | Accuracy: 54.214285714285715 | Loss:184.45345858169986\n",
            "Iteration 350 | Accuracy: 51.92857142857142 | Loss:214.90388482057438\n",
            "Iteration 400 | Accuracy: 51.5 | Loss:245.02867914101316\n",
            "Iteration 450 | Accuracy: 53.214285714285715 | Loss:276.3214456150049\n",
            "Iteration 500 | Accuracy: 53.35714285714286 | Loss:308.9913345955265\n",
            "Iteration 550 | Accuracy: 55.92857142857143 | Loss:342.258831316505\n",
            "Iteration 600 | Accuracy: 52.214285714285715 | Loss:369.1311551666685\n",
            "Iteration 650 | Accuracy: 51.714285714285715 | Loss:396.7104249369051\n",
            "Iteration 700 | Accuracy: 52.85714285714286 | Loss:428.4016530904523\n",
            "Iteration 750 | Accuracy: 52.28571428571429 | Loss:458.555618002373\n",
            "Iteration 800 | Accuracy: 52.714285714285715 | Loss:487.84197113071633\n",
            "Iteration 850 | Accuracy: 55.14285714285714 | Loss:520.7119662990651\n",
            "Iteration 900 | Accuracy: 52.5 | Loss:547.0029997973367\n",
            "Iteration 950 | Accuracy: 51.42857142857142 | Loss:575.8560995338817\n",
            "Iteration 1000 | Accuracy: 50.71428571428571 | Loss:606.1035918242077\n",
            "Iteration 1050 | Accuracy: 48.42857142857142 | Loss:629.7187332786059\n",
            "Iteration 1100 | Accuracy: 48.5 | Loss:661.1952377896494\n",
            "Iteration 1150 | Accuracy: 52.85714285714286 | Loss:691.8109464078066\n",
            "Iteration 1200 | Accuracy: 56.785714285714285 | Loss:724.6990359187515\n",
            "Iteration 1250 | Accuracy: 49.42857142857143 | Loss:755.2909449293252\n",
            "Iteration 1300 | Accuracy: 51.642857142857146 | Loss:781.6691200370564\n",
            "Iteration 1350 | Accuracy: 55.35714285714286 | Loss:811.078871720289\n",
            "##################################################\n",
            ">epoch=63, lrate=0.100, error=840.314\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 53.92857142857142 | Loss:1.0838161017978123\n",
            "Iteration 50 | Accuracy: 57.07142857142857 | Loss:34.19250070514256\n",
            "Iteration 100 | Accuracy: 55.42857142857143 | Loss:66.41805474596718\n",
            "Iteration 150 | Accuracy: 53.5 | Loss:97.45675318384541\n",
            "Iteration 200 | Accuracy: 53.642857142857146 | Loss:123.95192132175552\n",
            "Iteration 250 | Accuracy: 54.50000000000001 | Loss:153.9412837399523\n",
            "Iteration 300 | Accuracy: 54.64285714285714 | Loss:183.16810420918378\n",
            "Iteration 350 | Accuracy: 52.214285714285715 | Loss:213.41130237308525\n",
            "Iteration 400 | Accuracy: 52.142857142857146 | Loss:243.3485659617821\n",
            "Iteration 450 | Accuracy: 53.5 | Loss:274.4697550140776\n",
            "Iteration 500 | Accuracy: 53.78571428571428 | Loss:306.93562998880094\n",
            "Iteration 550 | Accuracy: 56.35714285714286 | Loss:340.0145850630281\n",
            "Iteration 600 | Accuracy: 52.85714285714286 | Loss:366.7457746332957\n",
            "Iteration 650 | Accuracy: 52.642857142857146 | Loss:394.16906681621583\n",
            "Iteration 700 | Accuracy: 53.142857142857146 | Loss:425.67955744443964\n",
            "Iteration 750 | Accuracy: 53.57142857142857 | Loss:455.6856413198381\n",
            "Iteration 800 | Accuracy: 53.78571428571428 | Loss:484.8071752391379\n",
            "Iteration 850 | Accuracy: 55.714285714285715 | Loss:517.4599208691808\n",
            "Iteration 900 | Accuracy: 52.85714285714286 | Loss:543.4774983487113\n",
            "Iteration 950 | Accuracy: 52.78571428571428 | Loss:572.1636193922399\n",
            "Iteration 1000 | Accuracy: 51.28571428571429 | Loss:602.225497962285\n",
            "Iteration 1050 | Accuracy: 49.57142857142857 | Loss:625.6768237865716\n",
            "Iteration 1100 | Accuracy: 49.57142857142857 | Loss:656.9983166891739\n",
            "Iteration 1150 | Accuracy: 53.35714285714286 | Loss:687.4158493714576\n",
            "Iteration 1200 | Accuracy: 57.285714285714285 | Loss:720.1411276950587\n",
            "Iteration 1250 | Accuracy: 49.857142857142854 | Loss:750.5352658267502\n",
            "Iteration 1300 | Accuracy: 52.0 | Loss:776.7665738891945\n",
            "Iteration 1350 | Accuracy: 55.64285714285714 | Loss:805.8914213209528\n",
            "##################################################\n",
            ">epoch=64, lrate=0.100, error=834.965\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 54.35714285714286 | Loss:1.0895710944135348\n",
            "Iteration 50 | Accuracy: 57.49999999999999 | Loss:33.96434461445791\n",
            "Iteration 100 | Accuracy: 55.785714285714285 | Loss:65.98455092005867\n",
            "Iteration 150 | Accuracy: 53.714285714285715 | Loss:96.86575696858499\n",
            "Iteration 200 | Accuracy: 53.92857142857142 | Loss:123.130119928318\n",
            "Iteration 250 | Accuracy: 54.64285714285714 | Loss:152.88042376904374\n",
            "Iteration 300 | Accuracy: 54.85714285714286 | Loss:181.84917045250307\n",
            "Iteration 350 | Accuracy: 53.0 | Loss:211.87961170879848\n",
            "Iteration 400 | Accuracy: 52.5 | Loss:241.61734733702656\n",
            "Iteration 450 | Accuracy: 53.57142857142857 | Loss:272.56200086966516\n",
            "Iteration 500 | Accuracy: 54.285714285714285 | Loss:304.8108130418399\n",
            "Iteration 550 | Accuracy: 56.64285714285714 | Loss:337.6856942291387\n",
            "Iteration 600 | Accuracy: 53.35714285714286 | Loss:364.28105970268\n",
            "Iteration 650 | Accuracy: 53.0 | Loss:391.5414529173614\n",
            "Iteration 700 | Accuracy: 53.214285714285715 | Loss:422.86192234991955\n",
            "Iteration 750 | Accuracy: 54.142857142857146 | Loss:452.71380072735053\n",
            "Iteration 800 | Accuracy: 54.85714285714286 | Loss:481.6591572403979\n",
            "Iteration 850 | Accuracy: 56.285714285714285 | Loss:514.0806402378638\n",
            "Iteration 900 | Accuracy: 53.142857142857146 | Loss:539.806533036197\n",
            "Iteration 950 | Accuracy: 53.714285714285715 | Loss:568.3195116165185\n",
            "Iteration 1000 | Accuracy: 52.35714285714286 | Loss:598.1911087521479\n",
            "Iteration 1050 | Accuracy: 50.142857142857146 | Loss:621.4794229946008\n",
            "Iteration 1100 | Accuracy: 50.28571428571429 | Loss:652.6393219139546\n",
            "Iteration 1150 | Accuracy: 53.642857142857146 | Loss:682.8420259492201\n",
            "Iteration 1200 | Accuracy: 57.785714285714285 | Loss:715.3957035871734\n",
            "Iteration 1250 | Accuracy: 49.92857142857143 | Loss:745.5845262375658\n",
            "Iteration 1300 | Accuracy: 52.142857142857146 | Loss:771.666640685039\n",
            "Iteration 1350 | Accuracy: 56.00000000000001 | Loss:800.481256204731\n",
            "##################################################\n",
            ">epoch=65, lrate=0.100, error=829.383\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 54.92857142857142 | Loss:1.0958662386701779\n",
            "Iteration 50 | Accuracy: 57.64285714285714 | Loss:33.72136619998432\n",
            "Iteration 100 | Accuracy: 56.00000000000001 | Loss:65.52654329890787\n",
            "Iteration 150 | Accuracy: 54.285714285714285 | Loss:96.24776900202194\n",
            "Iteration 200 | Accuracy: 54.57142857142857 | Loss:122.27674010822035\n",
            "Iteration 250 | Accuracy: 55.214285714285715 | Loss:151.77685139697468\n",
            "Iteration 300 | Accuracy: 55.285714285714285 | Loss:180.4722418358194\n",
            "Iteration 350 | Accuracy: 53.35714285714286 | Loss:210.28132317368681\n",
            "Iteration 400 | Accuracy: 53.28571428571428 | Loss:239.80353207004234\n",
            "Iteration 450 | Accuracy: 54.0 | Loss:270.5634236401191\n",
            "Iteration 500 | Accuracy: 54.214285714285715 | Loss:302.57735137644886\n",
            "Iteration 550 | Accuracy: 57.49999999999999 | Loss:335.22692638912224\n",
            "Iteration 600 | Accuracy: 53.714285714285715 | Loss:361.6890170704528\n",
            "Iteration 650 | Accuracy: 53.42857142857142 | Loss:388.7752321529268\n",
            "Iteration 700 | Accuracy: 53.78571428571428 | Loss:419.8915669713499\n",
            "Iteration 750 | Accuracy: 55.50000000000001 | Loss:449.57870485163124\n",
            "Iteration 800 | Accuracy: 56.49999999999999 | Loss:478.32990174383826\n",
            "Iteration 850 | Accuracy: 56.714285714285715 | Loss:510.50119170328617\n",
            "Iteration 900 | Accuracy: 53.714285714285715 | Loss:535.9114658658684\n",
            "Iteration 950 | Accuracy: 54.64285714285714 | Loss:564.2413858834277\n",
            "Iteration 1000 | Accuracy: 53.714285714285715 | Loss:593.9140837097087\n",
            "Iteration 1050 | Accuracy: 50.857142857142854 | Loss:617.034404541999\n",
            "Iteration 1100 | Accuracy: 51.142857142857146 | Loss:648.0233104361943\n",
            "Iteration 1150 | Accuracy: 54.35714285714286 | Loss:677.9874896224776\n",
            "Iteration 1200 | Accuracy: 58.214285714285715 | Loss:710.3574405045555\n",
            "Iteration 1250 | Accuracy: 50.357142857142854 | Loss:740.3273807090027\n",
            "Iteration 1300 | Accuracy: 53.642857142857146 | Loss:766.2524084312869\n",
            "Iteration 1350 | Accuracy: 56.714285714285715 | Loss:794.7250684237542\n",
            "##################################################\n",
            ">epoch=66, lrate=0.100, error=823.439\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 55.214285714285715 | Loss:1.1028229029353889\n",
            "Iteration 50 | Accuracy: 57.785714285714285 | Loss:33.45996022269725\n",
            "Iteration 100 | Accuracy: 56.14285714285714 | Loss:65.03684484577566\n",
            "Iteration 150 | Accuracy: 54.57142857142857 | Loss:95.59146080013826\n",
            "Iteration 200 | Accuracy: 54.64285714285714 | Loss:121.37681057815057\n",
            "Iteration 250 | Accuracy: 55.285714285714285 | Loss:150.609672029552\n",
            "Iteration 300 | Accuracy: 55.64285714285714 | Loss:179.0111336183459\n",
            "Iteration 350 | Accuracy: 54.142857142857146 | Loss:208.58708762929717\n",
            "Iteration 400 | Accuracy: 54.07142857142857 | Loss:237.87361832830638\n",
            "Iteration 450 | Accuracy: 54.50000000000001 | Loss:268.4365264349684\n",
            "Iteration 500 | Accuracy: 54.85714285714286 | Loss:300.19357112067223\n",
            "Iteration 550 | Accuracy: 57.92857142857143 | Loss:332.5913851846809\n",
            "Iteration 600 | Accuracy: 53.85714285714286 | Loss:358.91887312243995\n",
            "Iteration 650 | Accuracy: 53.92857142857142 | Loss:385.8142651901405\n",
            "Iteration 700 | Accuracy: 54.214285714285715 | Loss:416.70731028329095\n",
            "Iteration 750 | Accuracy: 56.285714285714285 | Loss:446.2145856844512\n",
            "Iteration 800 | Accuracy: 57.35714285714286 | Loss:474.74633367063143\n",
            "Iteration 850 | Accuracy: 56.85714285714286 | Loss:506.64421184560064\n",
            "Iteration 900 | Accuracy: 54.142857142857146 | Loss:531.7085250379519\n",
            "Iteration 950 | Accuracy: 54.785714285714285 | Loss:559.8400165854559\n",
            "Iteration 1000 | Accuracy: 54.42857142857142 | Loss:589.300191286771\n",
            "Iteration 1050 | Accuracy: 51.92857142857142 | Loss:612.23979651376\n",
            "Iteration 1100 | Accuracy: 52.07142857142857 | Loss:643.0448896162142\n",
            "Iteration 1150 | Accuracy: 54.85714285714286 | Loss:672.7390569144954\n",
            "Iteration 1200 | Accuracy: 58.14285714285714 | Loss:704.9093596133785\n",
            "Iteration 1250 | Accuracy: 50.92857142857142 | Loss:734.6415369723263\n",
            "Iteration 1300 | Accuracy: 54.35714285714286 | Loss:760.3938594741558\n",
            "Iteration 1350 | Accuracy: 57.57142857142858 | Loss:788.4863685045182\n",
            "##################################################\n",
            ">epoch=67, lrate=0.100, error=816.990\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 55.42857142857143 | Loss:1.1104852732681576\n",
            "Iteration 50 | Accuracy: 57.99999999999999 | Loss:33.17633818957266\n",
            "Iteration 100 | Accuracy: 56.14285714285714 | Loss:64.50746141683364\n",
            "Iteration 150 | Accuracy: 55.00000000000001 | Loss:94.88400681726417\n",
            "Iteration 200 | Accuracy: 54.785714285714285 | Loss:120.41210317667952\n",
            "Iteration 250 | Accuracy: 55.714285714285715 | Loss:149.35397207406808\n",
            "Iteration 300 | Accuracy: 55.57142857142857 | Loss:177.43458397931838\n",
            "Iteration 350 | Accuracy: 55.07142857142857 | Loss:206.76204895334638\n",
            "Iteration 400 | Accuracy: 54.714285714285715 | Loss:235.78745337565732\n",
            "Iteration 450 | Accuracy: 55.00000000000001 | Loss:266.1363330219206\n",
            "Iteration 500 | Accuracy: 55.07142857142857 | Loss:297.6100089038756\n",
            "Iteration 550 | Accuracy: 58.5 | Loss:329.7240812124801\n",
            "Iteration 600 | Accuracy: 54.0 | Loss:355.9099090880165\n",
            "Iteration 650 | Accuracy: 54.785714285714285 | Loss:382.5906876082074\n",
            "Iteration 700 | Accuracy: 55.07142857142857 | Loss:413.23538170267267\n",
            "Iteration 750 | Accuracy: 56.42857142857143 | Loss:442.54213925248797\n",
            "Iteration 800 | Accuracy: 57.714285714285715 | Loss:470.82029437016047\n",
            "Iteration 850 | Accuracy: 57.42857142857143 | Loss:502.4166387271545\n",
            "Iteration 900 | Accuracy: 54.714285714285715 | Loss:527.0960721880822\n",
            "Iteration 950 | Accuracy: 54.92857142857142 | Loss:555.0060346388381\n",
            "Iteration 1000 | Accuracy: 55.00000000000001 | Loss:584.2335682808831\n",
            "Iteration 1050 | Accuracy: 53.85714285714286 | Loss:606.9702660530972\n",
            "Iteration 1100 | Accuracy: 53.57142857142857 | Loss:637.5738827145107\n",
            "Iteration 1150 | Accuracy: 55.35714285714286 | Loss:666.9563663015251\n",
            "Iteration 1200 | Accuracy: 58.785714285714285 | Loss:698.9055600563497\n",
            "Iteration 1250 | Accuracy: 52.0 | Loss:728.3758259071096\n",
            "Iteration 1300 | Accuracy: 56.285714285714285 | Loss:753.9292188800031\n",
            "Iteration 1350 | Accuracy: 57.92857142857143 | Loss:781.5949873251768\n",
            "##################################################\n",
            ">epoch=68, lrate=0.100, error=809.859\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 56.14285714285714 | Loss:1.118838245443174\n",
            "Iteration 50 | Accuracy: 58.07142857142858 | Loss:32.86522294544965\n",
            "Iteration 100 | Accuracy: 56.35714285714286 | Loss:63.927332392135405\n",
            "Iteration 150 | Accuracy: 55.42857142857143 | Loss:94.10855074784985\n",
            "Iteration 200 | Accuracy: 55.57142857142857 | Loss:119.35826297251353\n",
            "Iteration 250 | Accuracy: 56.07142857142857 | Loss:147.97671797421884\n",
            "Iteration 300 | Accuracy: 55.92857142857143 | Loss:175.70100905175659\n",
            "Iteration 350 | Accuracy: 55.714285714285715 | Loss:204.75994332627147\n",
            "Iteration 400 | Accuracy: 55.285714285714285 | Loss:233.49164232686408\n",
            "Iteration 450 | Accuracy: 55.285714285714285 | Loss:263.6032994801315\n",
            "Iteration 500 | Accuracy: 55.57142857142857 | Loss:294.7611766194097\n",
            "Iteration 550 | Accuracy: 58.785714285714285 | Loss:326.5523026358165\n",
            "Iteration 600 | Accuracy: 54.0 | Loss:352.58179767835077\n",
            "Iteration 650 | Accuracy: 55.57142857142857 | Loss:379.01508608123\n",
            "Iteration 700 | Accuracy: 55.35714285714286 | Loss:409.3786402132309\n",
            "Iteration 750 | Accuracy: 56.57142857142857 | Loss:438.45724732367773\n",
            "Iteration 800 | Accuracy: 58.785714285714285 | Loss:466.4367282745511\n",
            "Iteration 850 | Accuracy: 57.49999999999999 | Loss:497.69669920042224\n",
            "Iteration 900 | Accuracy: 54.85714285714286 | Loss:521.9419033445345\n",
            "Iteration 950 | Accuracy: 55.35714285714286 | Loss:549.5977261588962\n",
            "Iteration 1000 | Accuracy: 55.35714285714286 | Loss:578.5640202698223\n",
            "Iteration 1050 | Accuracy: 54.785714285714285 | Loss:601.0644403633119\n",
            "Iteration 1100 | Accuracy: 54.785714285714285 | Loss:631.4425076782298\n",
            "Iteration 1150 | Accuracy: 55.714285714285715 | Loss:660.4595278161324\n",
            "Iteration 1200 | Accuracy: 59.0 | Loss:692.1577113359536\n",
            "Iteration 1250 | Accuracy: 52.642857142857146 | Loss:721.3364152490999\n",
            "Iteration 1300 | Accuracy: 56.214285714285715 | Loss:746.6513845120178\n",
            "Iteration 1350 | Accuracy: 58.14285714285714 | Loss:773.8342230166518\n",
            "##################################################\n",
            ">epoch=69, lrate=0.100, error=801.823\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 56.714285714285715 | Loss:1.1278626636065945\n",
            "Iteration 50 | Accuracy: 58.285714285714285 | Loss:32.51967848098914\n",
            "Iteration 100 | Accuracy: 56.49999999999999 | Loss:63.28229969381463\n",
            "Iteration 150 | Accuracy: 56.14285714285714 | Loss:93.24396572274397\n",
            "Iteration 200 | Accuracy: 56.00000000000001 | Loss:118.18531194263488\n",
            "Iteration 250 | Accuracy: 56.35714285714286 | Loss:146.4370888822282\n",
            "Iteration 300 | Accuracy: 56.35714285714286 | Loss:173.75921824442295\n",
            "Iteration 350 | Accuracy: 56.285714285714285 | Loss:202.524086384593\n",
            "Iteration 400 | Accuracy: 55.85714285714286 | Loss:230.9218942904688\n",
            "Iteration 450 | Accuracy: 55.85714285714286 | Loss:260.76536813743917\n",
            "Iteration 500 | Accuracy: 56.64285714285714 | Loss:291.56875822196815\n",
            "Iteration 550 | Accuracy: 58.64285714285714 | Loss:322.9900221192042\n",
            "Iteration 600 | Accuracy: 54.785714285714285 | Loss:348.8387929872194\n",
            "Iteration 650 | Accuracy: 56.00000000000001 | Loss:374.981955991011\n",
            "Iteration 700 | Accuracy: 56.00000000000001 | Loss:405.0228549819649\n",
            "Iteration 750 | Accuracy: 56.99999999999999 | Loss:433.8378168521279\n",
            "Iteration 800 | Accuracy: 59.14285714285714 | Loss:461.46244353251325\n",
            "Iteration 850 | Accuracy: 57.85714285714286 | Loss:492.34451142661015\n",
            "Iteration 900 | Accuracy: 55.285714285714285 | Loss:516.0974721178458\n",
            "Iteration 950 | Accuracy: 55.714285714285715 | Loss:543.4568980709965\n",
            "Iteration 1000 | Accuracy: 56.00000000000001 | Loss:572.1232755736237\n",
            "Iteration 1050 | Accuracy: 55.85714285714286 | Loss:594.341346791012\n",
            "Iteration 1100 | Accuracy: 55.714285714285715 | Loss:624.4630379431642\n",
            "Iteration 1150 | Accuracy: 57.07142857142857 | Loss:653.0515574179459\n",
            "Iteration 1200 | Accuracy: 59.285714285714285 | Loss:684.4582280417359\n",
            "Iteration 1250 | Accuracy: 53.642857142857146 | Loss:713.3124521139807\n",
            "Iteration 1300 | Accuracy: 56.785714285714285 | Loss:738.3351714479683\n",
            "Iteration 1350 | Accuracy: 58.357142857142854 | Loss:764.9733672415674\n",
            "##################################################\n",
            ">epoch=70, lrate=0.100, error=792.643\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.42857142857143 | Loss:1.1374794774696435\n",
            "Iteration 50 | Accuracy: 58.357142857142854 | Loss:32.13360257246522\n",
            "Iteration 100 | Accuracy: 56.49999999999999 | Loss:62.55995831090837\n",
            "Iteration 150 | Accuracy: 56.64285714285714 | Loss:92.27084179108397\n",
            "Iteration 200 | Accuracy: 56.57142857142857 | Loss:116.86560890187883\n",
            "Iteration 250 | Accuracy: 56.49999999999999 | Loss:144.69737513692408\n",
            "Iteration 300 | Accuracy: 56.49999999999999 | Loss:171.5630494818215\n",
            "Iteration 350 | Accuracy: 56.785714285714285 | Loss:200.0040303342858\n",
            "Iteration 400 | Accuracy: 56.49999999999999 | Loss:228.0235561072838\n",
            "Iteration 450 | Accuracy: 56.64285714285714 | Loss:257.5601461712143\n",
            "Iteration 500 | Accuracy: 57.214285714285715 | Loss:287.96830554567316\n",
            "Iteration 550 | Accuracy: 58.785714285714285 | Loss:318.9699406120175\n",
            "Iteration 600 | Accuracy: 55.42857142857143 | Loss:344.60235101544555\n",
            "Iteration 650 | Accuracy: 56.285714285714285 | Loss:370.40589991905966\n",
            "Iteration 700 | Accuracy: 56.14285714285714 | Loss:400.07693410462275\n",
            "Iteration 750 | Accuracy: 57.214285714285715 | Loss:428.58683199694326\n",
            "Iteration 800 | Accuracy: 59.92857142857143 | Loss:455.79511994082816\n",
            "Iteration 850 | Accuracy: 58.14285714285714 | Loss:486.25638027528976\n",
            "Iteration 900 | Accuracy: 55.50000000000001 | Loss:509.458852773537\n",
            "Iteration 950 | Accuracy: 55.714285714285715 | Loss:536.473948036255\n",
            "Iteration 1000 | Accuracy: 56.214285714285715 | Loss:564.7934694143983\n",
            "Iteration 1050 | Accuracy: 56.214285714285715 | Loss:586.6719938828944\n",
            "Iteration 1100 | Accuracy: 56.35714285714286 | Loss:616.5028233643983\n",
            "Iteration 1150 | Accuracy: 57.714285714285715 | Loss:644.6023149271177\n",
            "Iteration 1200 | Accuracy: 59.71428571428572 | Loss:675.6683160622898\n",
            "Iteration 1250 | Accuracy: 54.57142857142857 | Loss:704.1689579867981\n",
            "Iteration 1300 | Accuracy: 57.49999999999999 | Loss:728.835720935064\n",
            "Iteration 1350 | Accuracy: 58.71428571428572 | Loss:754.8748753698086\n",
            "##################################################\n",
            ">epoch=71, lrate=0.100, error=782.184\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.57142857142858 | Loss:1.1474128863973785\n",
            "Iteration 50 | Accuracy: 58.71428571428572 | Loss:31.70712680235618\n",
            "Iteration 100 | Accuracy: 56.57142857142857 | Loss:61.760011997065135\n",
            "Iteration 150 | Accuracy: 56.85714285714286 | Loss:91.18549756767327\n",
            "Iteration 200 | Accuracy: 56.92857142857143 | Loss:115.39227069375093\n",
            "Iteration 250 | Accuracy: 56.64285714285714 | Loss:142.74861255417787\n",
            "Iteration 300 | Accuracy: 56.92857142857143 | Loss:169.1046207403419\n",
            "Iteration 350 | Accuracy: 56.99999999999999 | Loss:197.19227971087534\n",
            "Iteration 400 | Accuracy: 56.99999999999999 | Loss:224.79421782570944\n",
            "Iteration 450 | Accuracy: 56.785714285714285 | Loss:253.9825468183468\n",
            "Iteration 500 | Accuracy: 57.714285714285715 | Loss:283.9633309230012\n",
            "Iteration 550 | Accuracy: 59.07142857142858 | Loss:314.50544250657595\n",
            "Iteration 600 | Accuracy: 55.92857142857143 | Loss:339.87750187581287\n",
            "Iteration 650 | Accuracy: 57.49999999999999 | Loss:365.29425471424844\n",
            "Iteration 700 | Accuracy: 56.92857142857143 | Loss:394.55234761961253\n",
            "Iteration 750 | Accuracy: 57.714285714285715 | Loss:422.71743957979345\n",
            "Iteration 800 | Accuracy: 60.42857142857143 | Loss:449.4576192335143\n",
            "Iteration 850 | Accuracy: 58.42857142857143 | Loss:479.46536840697064\n",
            "Iteration 900 | Accuracy: 56.49999999999999 | Loss:502.07499149361956\n",
            "Iteration 950 | Accuracy: 56.00000000000001 | Loss:528.7031314346103\n",
            "Iteration 1000 | Accuracy: 56.42857142857143 | Loss:556.6298582494593\n",
            "Iteration 1050 | Accuracy: 56.35714285714286 | Loss:578.1104443308079\n",
            "Iteration 1100 | Accuracy: 56.85714285714286 | Loss:607.6208517559934\n",
            "Iteration 1150 | Accuracy: 58.07142857142858 | Loss:635.1936198562165\n",
            "Iteration 1200 | Accuracy: 59.857142857142854 | Loss:665.8707731437397\n",
            "Iteration 1250 | Accuracy: 55.07142857142857 | Loss:694.0031130703925\n",
            "Iteration 1300 | Accuracy: 57.785714285714285 | Loss:718.2551140179419\n",
            "Iteration 1350 | Accuracy: 58.71428571428572 | Loss:743.6679339235965\n",
            "##################################################\n",
            ">epoch=72, lrate=0.100, error=770.588\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 57.92857142857143 | Loss:1.1571293345995008\n",
            "Iteration 50 | Accuracy: 58.857142857142854 | Loss:31.252628457474998\n",
            "Iteration 100 | Accuracy: 56.92857142857143 | Loss:60.9059496505929\n",
            "Iteration 150 | Accuracy: 56.99999999999999 | Loss:90.01669595007152\n",
            "Iteration 200 | Accuracy: 57.285714285714285 | Loss:113.80194338765544\n",
            "Iteration 250 | Accuracy: 57.214285714285715 | Loss:140.64208917784686\n",
            "Iteration 300 | Accuracy: 57.07142857142857 | Loss:166.4536226518273\n",
            "Iteration 350 | Accuracy: 57.49999999999999 | Loss:194.16690780872747\n",
            "Iteration 400 | Accuracy: 57.214285714285715 | Loss:221.33073861414354\n",
            "Iteration 450 | Accuracy: 57.285714285714285 | Loss:250.1382547970567\n",
            "Iteration 500 | Accuracy: 58.357142857142854 | Loss:279.68189062779635\n",
            "Iteration 550 | Accuracy: 59.285714285714285 | Loss:309.7512052280615\n",
            "Iteration 600 | Accuracy: 56.714285714285715 | Loss:334.82153629420867\n",
            "Iteration 650 | Accuracy: 57.64285714285714 | Loss:359.8210556600079\n",
            "Iteration 700 | Accuracy: 57.285714285714285 | Loss:388.6422015073197\n",
            "Iteration 750 | Accuracy: 57.714285714285715 | Loss:416.4371298089592\n",
            "Iteration 800 | Accuracy: 60.92857142857143 | Loss:442.68723175691605\n",
            "Iteration 850 | Accuracy: 58.42857142857143 | Loss:472.2322771450733\n",
            "Iteration 900 | Accuracy: 56.785714285714285 | Loss:494.240205501262\n",
            "Iteration 950 | Accuracy: 56.214285714285715 | Loss:520.4594577299614\n",
            "Iteration 1000 | Accuracy: 56.49999999999999 | Loss:547.96432333377\n",
            "Iteration 1050 | Accuracy: 56.714285714285715 | Loss:569.0066316308765\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:598.1835220586738\n",
            "Iteration 1150 | Accuracy: 58.14285714285714 | Loss:625.2327823837253\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:655.4898327417752\n",
            "Iteration 1250 | Accuracy: 56.07142857142857 | Loss:683.2612527890325\n",
            "Iteration 1300 | Accuracy: 58.07142857142858 | Loss:707.0660526218164\n",
            "Iteration 1350 | Accuracy: 58.857142857142854 | Loss:731.8679121901407\n",
            "##################################################\n",
            ">epoch=73, lrate=0.100, error=758.398\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.42857142857143 | Loss:1.1659533288160733\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:30.794873254569882\n",
            "Iteration 100 | Accuracy: 57.14285714285714 | Loss:60.0456187226934\n",
            "Iteration 150 | Accuracy: 57.49999999999999 | Loss:88.82805714686728\n",
            "Iteration 200 | Accuracy: 57.785714285714285 | Loss:112.17900190477836\n",
            "Iteration 250 | Accuracy: 57.49999999999999 | Loss:138.49454745135696\n",
            "Iteration 300 | Accuracy: 57.14285714285714 | Loss:163.76131602805015\n",
            "Iteration 350 | Accuracy: 57.92857142857143 | Loss:191.09565469167737\n",
            "Iteration 400 | Accuracy: 57.57142857142858 | Loss:217.8297352628996\n",
            "Iteration 450 | Accuracy: 57.85714285714286 | Loss:246.2451946789412\n",
            "Iteration 500 | Accuracy: 58.42857142857143 | Loss:275.37152668384414\n",
            "Iteration 550 | Accuracy: 59.42857142857143 | Loss:304.99075307719244\n",
            "Iteration 600 | Accuracy: 56.92857142857143 | Loss:329.73568359362383\n",
            "Iteration 650 | Accuracy: 57.57142857142858 | Loss:354.3159612728997\n",
            "Iteration 700 | Accuracy: 57.64285714285714 | Loss:382.7062689608902\n",
            "Iteration 750 | Accuracy: 57.99999999999999 | Loss:410.1302754914914\n",
            "Iteration 800 | Accuracy: 61.07142857142858 | Loss:435.90938684737654\n",
            "Iteration 850 | Accuracy: 58.71428571428572 | Loss:465.0120157215407\n",
            "Iteration 900 | Accuracy: 56.85714285714286 | Loss:486.44926872801346\n",
            "Iteration 950 | Accuracy: 56.285714285714285 | Loss:512.267856435977\n",
            "Iteration 1000 | Accuracy: 56.57142857142857 | Loss:539.3510625638559\n",
            "Iteration 1050 | Accuracy: 56.49999999999999 | Loss:559.9503147403317\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:588.8031633325028\n",
            "Iteration 1150 | Accuracy: 58.857142857142854 | Loss:615.3742362245298\n",
            "Iteration 1200 | Accuracy: 60.21428571428571 | Loss:645.2089586315344\n",
            "Iteration 1250 | Accuracy: 56.285714285714285 | Loss:672.6477821342231\n",
            "Iteration 1300 | Accuracy: 58.5 | Loss:696.0120447020321\n",
            "Iteration 1350 | Accuracy: 59.14285714285714 | Loss:720.2594708842283\n",
            "##################################################\n",
            ">epoch=74, lrate=0.100, error=746.429\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.71428571428572 | Loss:1.173300826011294\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:30.361517919818635\n",
            "Iteration 100 | Accuracy: 57.14285714285714 | Loss:59.232941221162164\n",
            "Iteration 150 | Accuracy: 57.85714285714286 | Loss:87.69464908847397\n",
            "Iteration 200 | Accuracy: 58.42857142857143 | Loss:110.6246358747803\n",
            "Iteration 250 | Accuracy: 57.92857142857143 | Loss:136.44454803359764\n",
            "Iteration 300 | Accuracy: 57.35714285714286 | Loss:161.2030941502378\n",
            "Iteration 350 | Accuracy: 58.14285714285714 | Loss:188.17344636700693\n",
            "Iteration 400 | Accuracy: 58.14285714285714 | Loss:214.5129260123499\n",
            "Iteration 450 | Accuracy: 58.285714285714285 | Loss:242.5505117950299\n",
            "Iteration 500 | Accuracy: 59.07142857142858 | Loss:271.3030498404105\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:300.52472670500015\n",
            "Iteration 600 | Accuracy: 57.14285714285714 | Loss:324.9465570073864\n",
            "Iteration 650 | Accuracy: 57.785714285714285 | Loss:349.134086660892\n",
            "Iteration 700 | Accuracy: 57.99999999999999 | Loss:377.1279823605907\n",
            "Iteration 750 | Accuracy: 58.57142857142858 | Loss:404.20429202591316\n",
            "Iteration 800 | Accuracy: 61.5 | Loss:429.5652957989723\n",
            "Iteration 850 | Accuracy: 58.785714285714285 | Loss:458.2691552231866\n",
            "Iteration 900 | Accuracy: 57.214285714285715 | Loss:479.1959068954311\n",
            "Iteration 950 | Accuracy: 56.14285714285714 | Loss:504.6480007573925\n",
            "Iteration 1000 | Accuracy: 56.64285714285714 | Loss:531.337851235795\n",
            "Iteration 1050 | Accuracy: 56.57142857142857 | Loss:551.526030612083\n",
            "Iteration 1100 | Accuracy: 57.214285714285715 | Loss:580.0823116930809\n",
            "Iteration 1150 | Accuracy: 59.285714285714285 | Loss:606.2459079018583\n",
            "Iteration 1200 | Accuracy: 60.21428571428571 | Loss:635.6838784582982\n",
            "Iteration 1250 | Accuracy: 56.57142857142857 | Loss:662.8303257696073\n",
            "Iteration 1300 | Accuracy: 59.0 | Loss:685.7936710087836\n",
            "Iteration 1350 | Accuracy: 59.21428571428572 | Loss:709.5667152888044\n",
            "##################################################\n",
            ">epoch=75, lrate=0.100, error=735.422\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 58.785714285714285 | Loss:1.1788586004279564\n",
            "Iteration 50 | Accuracy: 59.21428571428572 | Loss:29.971524183603005\n",
            "Iteration 100 | Accuracy: 56.99999999999999 | Loss:58.50487309390355\n",
            "Iteration 150 | Accuracy: 58.07142857142858 | Loss:86.67122769289878\n",
            "Iteration 200 | Accuracy: 58.5 | Loss:109.2136526924919\n",
            "Iteration 250 | Accuracy: 57.92857142857143 | Loss:134.59283167773597\n",
            "Iteration 300 | Accuracy: 57.714285714285715 | Loss:158.9036948174213\n",
            "Iteration 350 | Accuracy: 58.42857142857143 | Loss:185.5404923082666\n",
            "Iteration 400 | Accuracy: 58.5 | Loss:211.53464157481213\n",
            "Iteration 450 | Accuracy: 58.857142857142854 | Loss:239.22744950703455\n",
            "Iteration 500 | Accuracy: 59.14285714285714 | Loss:267.65929918291295\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:296.5495950196137\n",
            "Iteration 600 | Accuracy: 57.49999999999999 | Loss:320.6727085543315\n",
            "Iteration 650 | Accuracy: 58.07142857142858 | Loss:344.5116281210979\n",
            "Iteration 700 | Accuracy: 58.357142857142854 | Loss:372.15930224525084\n",
            "Iteration 750 | Accuracy: 58.785714285714285 | Loss:398.92509205222683\n",
            "Iteration 800 | Accuracy: 61.357142857142854 | Loss:423.93590541553596\n",
            "Iteration 850 | Accuracy: 58.92857142857143 | Loss:452.29501348991124\n",
            "Iteration 900 | Accuracy: 57.14285714285714 | Loss:472.7818366512408\n",
            "Iteration 950 | Accuracy: 56.35714285714286 | Loss:497.91398223782835\n",
            "Iteration 1000 | Accuracy: 56.714285714285715 | Loss:524.2546471018113\n",
            "Iteration 1050 | Accuracy: 56.92857142857143 | Loss:544.0859604279997\n",
            "Iteration 1100 | Accuracy: 57.285714285714285 | Loss:572.3806900519307\n",
            "Iteration 1150 | Accuracy: 59.71428571428572 | Loss:598.2117972151514\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:627.2947882025617\n",
            "Iteration 1250 | Accuracy: 56.85714285714286 | Loss:654.1905031604223\n",
            "Iteration 1300 | Accuracy: 59.357142857142854 | Loss:676.8081978156811\n",
            "Iteration 1350 | Accuracy: 59.285714285714285 | Loss:700.1901847357422\n",
            "##################################################\n",
            ">epoch=76, lrate=0.100, error=725.784\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.0 | Loss:1.1826121042186484\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:29.63137309562996\n",
            "Iteration 100 | Accuracy: 57.07142857142857 | Loss:57.87343227528526\n",
            "Iteration 150 | Accuracy: 58.07142857142858 | Loss:85.77903095006812\n",
            "Iteration 200 | Accuracy: 58.64285714285714 | Loss:107.97587808537415\n",
            "Iteration 250 | Accuracy: 58.214285714285715 | Loss:132.97776496640995\n",
            "Iteration 300 | Accuracy: 57.85714285714286 | Loss:156.90834609839334\n",
            "Iteration 350 | Accuracy: 58.42857142857143 | Loss:183.24963105983312\n",
            "Iteration 400 | Accuracy: 58.71428571428572 | Loss:208.94827270576906\n",
            "Iteration 450 | Accuracy: 59.21428571428572 | Loss:236.33770264639534\n",
            "Iteration 500 | Accuracy: 59.21428571428572 | Loss:264.4993761513083\n",
            "Iteration 550 | Accuracy: 59.64285714285714 | Loss:293.1233737809973\n",
            "Iteration 600 | Accuracy: 57.785714285714285 | Loss:316.9836323721279\n",
            "Iteration 650 | Accuracy: 58.285714285714285 | Loss:340.5225902051293\n",
            "Iteration 700 | Accuracy: 58.14285714285714 | Loss:367.8765212435516\n",
            "Iteration 750 | Accuracy: 59.14285714285714 | Loss:394.3719229484416\n",
            "Iteration 800 | Accuracy: 61.357142857142854 | Loss:419.09887001584053\n",
            "Iteration 850 | Accuracy: 59.42857142857143 | Loss:447.1663131155384\n",
            "Iteration 900 | Accuracy: 57.35714285714286 | Loss:467.27954911724726\n",
            "Iteration 950 | Accuracy: 56.714285714285715 | Loss:492.13773856094514\n",
            "Iteration 1000 | Accuracy: 56.85714285714286 | Loss:518.1762289195076\n",
            "Iteration 1050 | Accuracy: 57.285714285714285 | Loss:537.709984906122\n",
            "Iteration 1100 | Accuracy: 57.49999999999999 | Loss:565.7771605895836\n",
            "Iteration 1150 | Accuracy: 59.785714285714285 | Loss:591.3412836350075\n",
            "Iteration 1200 | Accuracy: 60.07142857142858 | Loss:620.1151143099747\n",
            "Iteration 1250 | Accuracy: 57.714285714285715 | Loss:646.7964423658628\n",
            "Iteration 1300 | Accuracy: 59.64285714285714 | Loss:669.1241095082697\n",
            "Iteration 1350 | Accuracy: 59.357142857142854 | Loss:692.1890666442449\n",
            "##################################################\n",
            ">epoch=77, lrate=0.100, error=717.568\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.285714285714285 | Loss:1.1847640873935905\n",
            "Iteration 50 | Accuracy: 59.285714285714285 | Loss:29.338751825330863\n",
            "Iteration 100 | Accuracy: 57.07142857142857 | Loss:57.332961103639\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:85.01350227783587\n",
            "Iteration 200 | Accuracy: 59.0 | Loss:106.90616497471275\n",
            "Iteration 250 | Accuracy: 58.357142857142854 | Loss:131.59012845983617\n",
            "Iteration 300 | Accuracy: 57.92857142857143 | Loss:155.20284888435634\n",
            "Iteration 350 | Accuracy: 58.64285714285714 | Loss:181.28727162246832\n",
            "Iteration 400 | Accuracy: 58.57142857142858 | Loss:206.7329628868486\n",
            "Iteration 450 | Accuracy: 59.42857142857143 | Loss:233.86046796102877\n",
            "Iteration 500 | Accuracy: 59.92857142857143 | Loss:261.79404942419916\n",
            "Iteration 550 | Accuracy: 59.64285714285714 | Loss:290.2080544765454\n",
            "Iteration 600 | Accuracy: 58.285714285714285 | Loss:313.84314045495483\n",
            "Iteration 650 | Accuracy: 58.57142857142858 | Loss:337.1265634386249\n",
            "Iteration 700 | Accuracy: 58.5 | Loss:364.23345451892214\n",
            "Iteration 750 | Accuracy: 59.357142857142854 | Loss:390.4949847216301\n",
            "Iteration 800 | Accuracy: 61.42857142857143 | Loss:414.99439846300015\n",
            "Iteration 850 | Accuracy: 59.64285714285714 | Loss:442.81651577607425\n",
            "Iteration 900 | Accuracy: 57.785714285714285 | Loss:462.6118412406578\n",
            "Iteration 950 | Accuracy: 56.785714285714285 | Loss:487.234460473361\n",
            "Iteration 1000 | Accuracy: 56.99999999999999 | Loss:513.0129355556162\n",
            "Iteration 1050 | Accuracy: 57.285714285714285 | Loss:532.3028715049237\n",
            "Iteration 1100 | Accuracy: 57.57142857142858 | Loss:560.1716361023925\n",
            "Iteration 1150 | Accuracy: 59.857142857142854 | Loss:585.5201639741637\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:614.0274429755606\n",
            "Iteration 1250 | Accuracy: 57.714285714285715 | Loss:640.5232591453049\n",
            "Iteration 1300 | Accuracy: 59.857142857142854 | Loss:662.608959173879\n",
            "Iteration 1350 | Accuracy: 59.42857142857143 | Loss:685.417566164\n",
            "##################################################\n",
            ">epoch=78, lrate=0.100, error=710.619\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.5 | Loss:1.1856288707246416\n",
            "Iteration 50 | Accuracy: 59.357142857142854 | Loss:29.08767596666912\n",
            "Iteration 100 | Accuracy: 57.42857142857143 | Loss:56.8706102167316\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:84.35804225293323\n",
            "Iteration 200 | Accuracy: 58.92857142857143 | Loss:105.98291899757801\n",
            "Iteration 250 | Accuracy: 58.42857142857143 | Loss:130.3988969218619\n",
            "Iteration 300 | Accuracy: 57.99999999999999 | Loss:153.74640104345028\n",
            "Iteration 350 | Accuracy: 59.07142857142858 | Loss:179.60913869269552\n",
            "Iteration 400 | Accuracy: 59.285714285714285 | Loss:204.83515515359358\n",
            "Iteration 450 | Accuracy: 59.92857142857143 | Loss:231.73804319405744\n",
            "Iteration 500 | Accuracy: 61.0 | Loss:259.4763542504491\n",
            "Iteration 550 | Accuracy: 59.42857142857143 | Loss:287.7260353216468\n",
            "Iteration 600 | Accuracy: 58.64285714285714 | Loss:311.16989004816554\n",
            "Iteration 650 | Accuracy: 58.64285714285714 | Loss:334.23457059586974\n",
            "Iteration 700 | Accuracy: 58.785714285714285 | Loss:361.1327343426046\n",
            "Iteration 750 | Accuracy: 59.357142857142854 | Loss:387.1911292671521\n",
            "Iteration 800 | Accuracy: 61.57142857142858 | Loss:411.5075777694103\n",
            "Iteration 850 | Accuracy: 59.92857142857143 | Loss:439.1226060544861\n",
            "Iteration 900 | Accuracy: 58.07142857142858 | Loss:458.6444172330019\n",
            "Iteration 950 | Accuracy: 56.92857142857143 | Loss:483.0604218079418\n",
            "Iteration 1000 | Accuracy: 57.14285714285714 | Loss:508.6136907400457\n",
            "Iteration 1050 | Accuracy: 57.42857142857143 | Loss:527.704158468441\n",
            "Iteration 1100 | Accuracy: 57.785714285714285 | Loss:555.3983306192108\n",
            "Iteration 1150 | Accuracy: 59.92857142857143 | Loss:580.5693600547376\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:608.8468342649411\n",
            "Iteration 1250 | Accuracy: 57.99999999999999 | Loss:635.1791632254339\n",
            "Iteration 1300 | Accuracy: 59.92857142857143 | Loss:657.0613554088524\n",
            "Iteration 1350 | Accuracy: 59.64285714285714 | Loss:679.6617682693808\n",
            "##################################################\n",
            ">epoch=79, lrate=0.100, error=704.715\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.71428571428572 | Loss:1.1855502224822305\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.87169149204512\n",
            "Iteration 100 | Accuracy: 57.64285714285714 | Loss:56.472949004718025\n",
            "Iteration 150 | Accuracy: 58.214285714285715 | Loss:83.79367962380225\n",
            "Iteration 200 | Accuracy: 59.14285714285714 | Loss:105.18122728644788\n",
            "Iteration 250 | Accuracy: 58.42857142857143 | Loss:129.36915718297172\n",
            "Iteration 300 | Accuracy: 57.99999999999999 | Loss:152.49399646743507\n",
            "Iteration 350 | Accuracy: 59.07142857142858 | Loss:178.1652310194137\n",
            "Iteration 400 | Accuracy: 59.71428571428572 | Loss:203.1966507786846\n",
            "Iteration 450 | Accuracy: 60.07142857142858 | Loss:229.90680128720987\n",
            "Iteration 500 | Accuracy: 61.07142857142858 | Loss:257.4748378314655\n",
            "Iteration 550 | Accuracy: 59.14285714285714 | Loss:285.59621600927784\n",
            "Iteration 600 | Accuracy: 58.785714285714285 | Loss:308.877005415036\n",
            "Iteration 650 | Accuracy: 58.857142857142854 | Loss:331.75202567887476\n",
            "Iteration 700 | Accuracy: 59.0 | Loss:358.47180225014415\n",
            "Iteration 750 | Accuracy: 59.64285714285714 | Loss:384.35223832291985\n",
            "Iteration 800 | Accuracy: 61.92857142857143 | Loss:408.5199118188261\n",
            "Iteration 850 | Accuracy: 59.857142857142854 | Loss:435.9588149932243\n",
            "Iteration 900 | Accuracy: 58.42857142857143 | Loss:455.24207288325044\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:479.4719147418865\n",
            "Iteration 1000 | Accuracy: 57.214285714285715 | Loss:504.8277998770217\n",
            "Iteration 1050 | Accuracy: 57.64285714285714 | Loss:523.7538594018127\n",
            "Iteration 1100 | Accuracy: 57.85714285714286 | Loss:551.2928371348172\n",
            "Iteration 1150 | Accuracy: 59.785714285714285 | Loss:576.3139097988723\n",
            "Iteration 1200 | Accuracy: 60.285714285714285 | Loss:604.3923279078747\n",
            "Iteration 1250 | Accuracy: 58.42857142857143 | Loss:630.5779523505315\n",
            "Iteration 1300 | Accuracy: 59.92857142857143 | Loss:652.2863660964582\n",
            "Iteration 1350 | Accuracy: 59.57142857142858 | Loss:674.7166787571098\n",
            "##################################################\n",
            ">epoch=80, lrate=0.100, error=699.643\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 59.92857142857143 | Loss:1.1848507169988405\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.68512658673095\n",
            "Iteration 100 | Accuracy: 57.714285714285715 | Loss:56.12849974548719\n",
            "Iteration 150 | Accuracy: 58.5 | Loss:83.30342409101725\n",
            "Iteration 200 | Accuracy: 59.14285714285714 | Loss:104.47879987146133\n",
            "Iteration 250 | Accuracy: 58.57142857142858 | Loss:128.47007207363677\n",
            "Iteration 300 | Accuracy: 58.14285714285714 | Loss:151.40620257014712\n",
            "Iteration 350 | Accuracy: 59.285714285714285 | Loss:176.91107396805631\n",
            "Iteration 400 | Accuracy: 59.92857142857143 | Loss:201.76676245676978\n",
            "Iteration 450 | Accuracy: 60.07142857142858 | Loss:228.31079705929986\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:255.72765879365247\n",
            "Iteration 550 | Accuracy: 59.357142857142854 | Loss:283.74890745109997\n",
            "Iteration 600 | Accuracy: 58.785714285714285 | Loss:306.88898076518376\n",
            "Iteration 650 | Accuracy: 59.285714285714285 | Loss:329.59699943540465\n",
            "Iteration 700 | Accuracy: 59.14285714285714 | Loss:356.16223169190556\n",
            "Iteration 750 | Accuracy: 59.857142857142854 | Loss:381.88534492047563\n",
            "Iteration 800 | Accuracy: 62.142857142857146 | Loss:405.9302826126628\n",
            "Iteration 850 | Accuracy: 60.0 | Loss:433.21819978119385\n",
            "Iteration 900 | Accuracy: 58.57142857142858 | Loss:452.2907149419106\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:476.34820270516207\n",
            "Iteration 1000 | Accuracy: 57.214285714285715 | Loss:501.52891954821416\n",
            "Iteration 1050 | Accuracy: 57.85714285714286 | Loss:520.3178810439957\n",
            "Iteration 1100 | Accuracy: 57.92857142857143 | Loss:547.7177613566645\n",
            "Iteration 1150 | Accuracy: 60.07142857142858 | Loss:572.6086862049742\n",
            "Iteration 1200 | Accuracy: 60.14285714285714 | Loss:600.5135909695742\n",
            "Iteration 1250 | Accuracy: 58.285714285714285 | Loss:626.5656674664914\n",
            "Iteration 1300 | Accuracy: 60.0 | Loss:648.1230809655008\n",
            "Iteration 1350 | Accuracy: 59.5 | Loss:670.4137925507624\n",
            "##################################################\n",
            ">epoch=81, lrate=0.100, error=695.230\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.14285714285714 | Loss:1.1838046042807107\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.52330908428921\n",
            "Iteration 100 | Accuracy: 57.85714285714286 | Loss:55.82809413010223\n",
            "Iteration 150 | Accuracy: 58.42857142857143 | Loss:82.87339837750723\n",
            "Iteration 200 | Accuracy: 59.21428571428572 | Loss:103.85753802735805\n",
            "Iteration 250 | Accuracy: 58.64285714285714 | Loss:127.67688477558356\n",
            "Iteration 300 | Accuracy: 58.357142857142854 | Loss:150.45149057078768\n",
            "Iteration 350 | Accuracy: 59.5 | Loss:175.81066953447672\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:200.50512367435462\n",
            "Iteration 450 | Accuracy: 60.14285714285714 | Loss:226.90510296438222\n",
            "Iteration 500 | Accuracy: 61.357142857142854 | Loss:254.185682604724\n",
            "Iteration 550 | Accuracy: 59.5 | Loss:282.12884392555105\n",
            "Iteration 600 | Accuracy: 59.07142857142858 | Loss:305.1455239039332\n",
            "Iteration 650 | Accuracy: 59.357142857142854 | Loss:327.704307231465\n",
            "Iteration 700 | Accuracy: 59.57142857142858 | Loss:354.1338852980674\n",
            "Iteration 750 | Accuracy: 59.92857142857143 | Loss:379.71683103584274\n",
            "Iteration 800 | Accuracy: 62.0 | Loss:403.65897817605014\n",
            "Iteration 850 | Accuracy: 60.07142857142858 | Loss:430.8165829462969\n",
            "Iteration 900 | Accuracy: 58.57142857142858 | Loss:449.70094981196576\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:473.5952006847477\n",
            "Iteration 1000 | Accuracy: 57.35714285714286 | Loss:498.6188309955503\n",
            "Iteration 1050 | Accuracy: 57.92857142857143 | Loss:517.2919916624546\n",
            "Iteration 1100 | Accuracy: 58.14285714285714 | Loss:544.5664855199038\n",
            "Iteration 1150 | Accuracy: 60.14285714285714 | Loss:569.3416355263987\n",
            "Iteration 1200 | Accuracy: 60.42857142857143 | Loss:597.0943094376061\n",
            "Iteration 1250 | Accuracy: 58.42857142857143 | Loss:623.0236511395192\n",
            "Iteration 1300 | Accuracy: 60.0 | Loss:644.4476531443598\n",
            "Iteration 1350 | Accuracy: 59.57142857142858 | Loss:666.6236130427233\n",
            "##################################################\n",
            ">epoch=82, lrate=0.100, error=691.343\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.357142857142854 | Loss:1.1826258745866114\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.382418618852597\n",
            "Iteration 100 | Accuracy: 57.92857142857143 | Loss:55.56447370547478\n",
            "Iteration 150 | Accuracy: 58.42857142857143 | Loss:82.49262756459008\n",
            "Iteration 200 | Accuracy: 59.357142857142854 | Loss:103.303264276609\n",
            "Iteration 250 | Accuracy: 58.92857142857143 | Loss:126.97044443034022\n",
            "Iteration 300 | Accuracy: 58.57142857142858 | Loss:149.60551520041574\n",
            "Iteration 350 | Accuracy: 59.71428571428572 | Loss:174.83592718096327\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:199.38067909850304\n",
            "Iteration 450 | Accuracy: 60.21428571428571 | Loss:225.6548867702356\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:252.81114767964823\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:280.69351267698255\n",
            "Iteration 600 | Accuracy: 59.07142857142858 | Loss:303.6000934005576\n",
            "Iteration 650 | Accuracy: 59.357142857142854 | Loss:326.02384023939607\n",
            "Iteration 700 | Accuracy: 59.64285714285714 | Loss:352.33297293447674\n",
            "Iteration 750 | Accuracy: 59.57142857142858 | Loss:377.79028065450893\n",
            "Iteration 800 | Accuracy: 62.28571428571429 | Loss:401.64509845976886\n",
            "Iteration 850 | Accuracy: 60.07142857142858 | Loss:428.68965402804207\n",
            "Iteration 900 | Accuracy: 58.64285714285714 | Loss:447.404675387519\n",
            "Iteration 950 | Accuracy: 57.14285714285714 | Loss:471.14189160584095\n",
            "Iteration 1000 | Accuracy: 57.42857142857143 | Loss:496.02360858448634\n",
            "Iteration 1050 | Accuracy: 58.07142857142858 | Loss:514.5977234464415\n",
            "Iteration 1100 | Accuracy: 58.357142857142854 | Loss:541.7587980681616\n",
            "Iteration 1150 | Accuracy: 60.42857142857143 | Loss:566.4288106886812\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:594.047097749594\n",
            "Iteration 1250 | Accuracy: 58.785714285714285 | Loss:619.863084496233\n",
            "Iteration 1300 | Accuracy: 60.285714285714285 | Loss:641.1675122893465\n",
            "Iteration 1350 | Accuracy: 59.785714285714285 | Loss:663.2493082452953\n",
            "##################################################\n",
            ">epoch=83, lrate=0.100, error=687.882\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.285714285714285 | Loss:1.1814663729420578\n",
            "Iteration 50 | Accuracy: 59.42857142857143 | Loss:28.259281462709243\n",
            "Iteration 100 | Accuracy: 57.99999999999999 | Loss:55.331789250747214\n",
            "Iteration 150 | Accuracy: 58.92857142857143 | Loss:82.15247128090975\n",
            "Iteration 200 | Accuracy: 59.42857142857143 | Loss:102.80494498137102\n",
            "Iteration 250 | Accuracy: 58.92857142857143 | Loss:126.33605874665334\n",
            "Iteration 300 | Accuracy: 58.5 | Loss:148.8495985701681\n",
            "Iteration 350 | Accuracy: 59.857142857142854 | Loss:173.96509828001226\n",
            "Iteration 400 | Accuracy: 60.285714285714285 | Loss:198.36969043466578\n",
            "Iteration 450 | Accuracy: 59.92857142857143 | Loss:224.53333928622888\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:251.57522024297722\n",
            "Iteration 550 | Accuracy: 59.71428571428572 | Loss:279.41037161386504\n",
            "Iteration 600 | Accuracy: 59.14285714285714 | Loss:302.2170526034896\n",
            "Iteration 650 | Accuracy: 59.64285714285714 | Loss:324.5174050194233\n",
            "Iteration 700 | Accuracy: 59.57142857142858 | Loss:350.718567184772\n",
            "Iteration 750 | Accuracy: 59.71428571428572 | Loss:376.06276383323785\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:399.8424083355313\n",
            "Iteration 850 | Accuracy: 60.21428571428571 | Loss:426.78850802622804\n",
            "Iteration 900 | Accuracy: 58.71428571428572 | Loss:445.35018073211285\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:468.93519989917843\n",
            "Iteration 1000 | Accuracy: 57.49999999999999 | Loss:493.688167400239\n",
            "Iteration 1050 | Accuracy: 58.285714285714285 | Loss:512.1765615015206\n",
            "Iteration 1100 | Accuracy: 58.357142857142854 | Loss:539.2348572668651\n",
            "Iteration 1150 | Accuracy: 60.357142857142854 | Loss:563.8078366794094\n",
            "Iteration 1200 | Accuracy: 60.357142857142854 | Loss:591.3067855477434\n",
            "Iteration 1250 | Accuracy: 58.92857142857143 | Loss:617.0179601915866\n",
            "Iteration 1300 | Accuracy: 60.42857142857143 | Loss:638.2139746708938\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:660.2188829436212\n",
            "##################################################\n",
            ">epoch=84, lrate=0.100, error=684.773\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.357142857142854 | Loss:1.1804208092310937\n",
            "Iteration 50 | Accuracy: 59.5 | Loss:28.151208641938712\n",
            "Iteration 100 | Accuracy: 58.07142857142858 | Loss:55.125209085263684\n",
            "Iteration 150 | Accuracy: 59.21428571428572 | Loss:81.8460817229333\n",
            "Iteration 200 | Accuracy: 59.64285714285714 | Loss:102.35392762677014\n",
            "Iteration 250 | Accuracy: 58.857142857142854 | Loss:125.762378002045\n",
            "Iteration 300 | Accuracy: 58.71428571428572 | Loss:148.1692861831395\n",
            "Iteration 350 | Accuracy: 59.785714285714285 | Loss:173.1812231099879\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:197.45385321459747\n",
            "Iteration 450 | Accuracy: 60.0 | Loss:223.51967025089922\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:250.45570328067188\n",
            "Iteration 550 | Accuracy: 59.857142857142854 | Loss:278.254289535002\n",
            "Iteration 600 | Accuracy: 59.14285714285714 | Loss:300.9689530772783\n",
            "Iteration 650 | Accuracy: 59.57142857142858 | Loss:323.15571887392434\n",
            "Iteration 700 | Accuracy: 59.92857142857143 | Loss:349.25932337322155\n",
            "Iteration 750 | Accuracy: 59.71428571428572 | Loss:374.50136598949285\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:398.2155330883608\n",
            "Iteration 850 | Accuracy: 60.42857142857143 | Loss:425.0755829076635\n",
            "Iteration 900 | Accuracy: 59.14285714285714 | Loss:443.4977649478782\n",
            "Iteration 950 | Accuracy: 57.214285714285715 | Loss:466.93535845513213\n",
            "Iteration 1000 | Accuracy: 57.785714285714285 | Loss:491.57132754549303\n",
            "Iteration 1050 | Accuracy: 58.214285714285715 | Loss:509.9846943240728\n",
            "Iteration 1100 | Accuracy: 58.5 | Loss:536.9497823006415\n",
            "Iteration 1150 | Accuracy: 60.57142857142858 | Loss:561.4321251172277\n",
            "Iteration 1200 | Accuracy: 60.785714285714285 | Loss:588.8244779451167\n",
            "Iteration 1250 | Accuracy: 59.0 | Loss:614.4389013676517\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:635.5357525523724\n",
            "Iteration 1350 | Accuracy: 60.07142857142858 | Loss:657.4783846920465\n",
            "##################################################\n",
            ">epoch=85, lrate=0.100, error=681.962\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.5 | Loss:1.1795362199707478\n",
            "Iteration 50 | Accuracy: 59.57142857142858 | Loss:28.055891149899633\n",
            "Iteration 100 | Accuracy: 58.14285714285714 | Loss:54.94066164869113\n",
            "Iteration 150 | Accuracy: 59.14285714285714 | Loss:81.56798593742457\n",
            "Iteration 200 | Accuracy: 59.92857142857143 | Loss:101.94333549857289\n",
            "Iteration 250 | Accuracy: 59.07142857142858 | Loss:125.24050352086411\n",
            "Iteration 300 | Accuracy: 58.857142857142854 | Loss:147.55320626278424\n",
            "Iteration 350 | Accuracy: 60.0 | Loss:172.47088447503904\n",
            "Iteration 400 | Accuracy: 60.42857142857143 | Loss:196.6188190000583\n",
            "Iteration 450 | Accuracy: 60.14285714285714 | Loss:222.5975126059007\n",
            "Iteration 500 | Accuracy: 61.42857142857143 | Loss:249.43523038523426\n",
            "Iteration 550 | Accuracy: 59.785714285714285 | Loss:277.2055435699271\n",
            "Iteration 600 | Accuracy: 59.285714285714285 | Loss:299.8343598082103\n",
            "Iteration 650 | Accuracy: 59.57142857142858 | Loss:321.9160103913961\n",
            "Iteration 700 | Accuracy: 60.14285714285714 | Loss:347.93087334334894\n",
            "Iteration 750 | Accuracy: 59.785714285714285 | Loss:373.08043883642335\n",
            "Iteration 800 | Accuracy: 62.5 | Loss:396.73697280462096\n",
            "Iteration 850 | Accuracy: 60.71428571428571 | Loss:423.52148727172204\n",
            "Iteration 900 | Accuracy: 59.285714285714285 | Loss:441.81635118764234\n",
            "Iteration 950 | Accuracy: 57.35714285714286 | Loss:465.1122016198119\n",
            "Iteration 1000 | Accuracy: 57.92857142857143 | Loss:489.64186795701806\n",
            "Iteration 1050 | Accuracy: 58.14285714285714 | Loss:507.9888357832779\n",
            "Iteration 1100 | Accuracy: 58.5 | Loss:534.8693720611585\n",
            "Iteration 1150 | Accuracy: 60.785714285714285 | Loss:559.2663199425\n",
            "Iteration 1200 | Accuracy: 60.92857142857143 | Loss:586.5628898442167\n",
            "Iteration 1250 | Accuracy: 59.14285714285714 | Loss:612.0883154646722\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:633.0938707851581\n",
            "Iteration 1350 | Accuracy: 60.14285714285714 | Loss:654.9866249125228\n",
            "##################################################\n",
            ">epoch=86, lrate=0.100, error=679.407\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.71428571428571 | Loss:1.1788237206239118\n",
            "Iteration 50 | Accuracy: 59.857142857142854 | Loss:27.97133862025076\n",
            "Iteration 100 | Accuracy: 58.14285714285714 | Loss:54.77468054902796\n",
            "Iteration 150 | Accuracy: 59.357142857142854 | Loss:81.31378415321369\n",
            "Iteration 200 | Accuracy: 60.42857142857143 | Loss:101.5676204523774\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:124.76332374177271\n",
            "Iteration 300 | Accuracy: 59.07142857142858 | Loss:146.99223036263126\n",
            "Iteration 350 | Accuracy: 60.14285714285714 | Loss:171.8232878319075\n",
            "Iteration 400 | Accuracy: 60.57142857142858 | Loss:195.85312002579596\n",
            "Iteration 450 | Accuracy: 60.285714285714285 | Loss:221.75374550220937\n",
            "Iteration 500 | Accuracy: 61.357142857142854 | Loss:248.49993401041314\n",
            "Iteration 550 | Accuracy: 59.857142857142854 | Loss:276.2483510903521\n",
            "Iteration 600 | Accuracy: 59.357142857142854 | Loss:298.7962259779384\n",
            "Iteration 650 | Accuracy: 59.64285714285714 | Loss:320.7802314612808\n",
            "Iteration 700 | Accuracy: 60.0 | Loss:346.71389197205616\n",
            "Iteration 750 | Accuracy: 59.857142857142854 | Loss:371.7795623877308\n",
            "Iteration 800 | Accuracy: 62.28571428571429 | Loss:395.3849012524969\n",
            "Iteration 850 | Accuracy: 60.642857142857146 | Loss:422.1026820955752\n",
            "Iteration 900 | Accuracy: 59.42857142857143 | Loss:440.2810292415866\n",
            "Iteration 950 | Accuracy: 57.49999999999999 | Loss:463.44228952712484\n",
            "Iteration 1000 | Accuracy: 58.07142857142858 | Loss:487.8754890110901\n",
            "Iteration 1050 | Accuracy: 58.5 | Loss:506.16303527297583\n",
            "Iteration 1100 | Accuracy: 58.785714285714285 | Loss:532.9668544203466\n",
            "Iteration 1150 | Accuracy: 60.857142857142854 | Loss:557.2828532000935\n",
            "Iteration 1200 | Accuracy: 61.142857142857146 | Loss:584.4928287918447\n",
            "Iteration 1250 | Accuracy: 59.42857142857143 | Loss:609.9367449427457\n",
            "Iteration 1300 | Accuracy: 60.785714285714285 | Loss:630.8578447489632\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:652.71123713311\n",
            "##################################################\n",
            ">epoch=87, lrate=0.100, error=677.073\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 61.0 | Loss:1.1782706748965908\n",
            "Iteration 50 | Accuracy: 59.785714285714285 | Loss:27.895843616778116\n",
            "Iteration 100 | Accuracy: 58.285714285714285 | Loss:54.62431251650644\n",
            "Iteration 150 | Accuracy: 59.5 | Loss:81.07992814681451\n",
            "Iteration 200 | Accuracy: 60.357142857142854 | Loss:101.22223627938479\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:124.32503024986707\n",
            "Iteration 300 | Accuracy: 59.14285714285714 | Loss:146.47887186767576\n",
            "Iteration 350 | Accuracy: 60.285714285714285 | Loss:171.22960462595458\n",
            "Iteration 400 | Accuracy: 60.14285714285714 | Loss:195.14740977933076\n",
            "Iteration 450 | Accuracy: 60.357142857142854 | Loss:220.9776519029289\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:247.63848845026112\n",
            "Iteration 550 | Accuracy: 59.92857142857143 | Loss:275.3698224724745\n",
            "Iteration 600 | Accuracy: 59.357142857142854 | Loss:297.8407149015878\n",
            "Iteration 650 | Accuracy: 59.785714285714285 | Loss:319.7337649577789\n",
            "Iteration 700 | Accuracy: 60.07142857142858 | Loss:345.59270701459684\n",
            "Iteration 750 | Accuracy: 60.14285714285714 | Loss:370.5820800039319\n",
            "Iteration 800 | Accuracy: 62.42857142857143 | Loss:394.14158573577265\n",
            "Iteration 850 | Accuracy: 60.71428571428571 | Loss:420.79984537936303\n",
            "Iteration 900 | Accuracy: 59.57142857142858 | Loss:438.8713278340475\n",
            "Iteration 950 | Accuracy: 57.92857142857143 | Loss:461.9067032704521\n",
            "Iteration 1000 | Accuracy: 58.214285714285715 | Loss:486.2525144247897\n",
            "Iteration 1050 | Accuracy: 58.64285714285714 | Loss:504.48628728374814\n",
            "Iteration 1100 | Accuracy: 58.857142857142854 | Loss:531.2204649331566\n",
            "Iteration 1150 | Accuracy: 60.71428571428571 | Loss:555.4593900881547\n",
            "Iteration 1200 | Accuracy: 61.57142857142858 | Loss:582.5905928576043\n",
            "Iteration 1250 | Accuracy: 59.64285714285714 | Loss:607.9601763273657\n",
            "Iteration 1300 | Accuracy: 60.642857142857146 | Loss:628.8028659958375\n",
            "Iteration 1350 | Accuracy: 59.92857142857143 | Loss:650.6257920047863\n",
            "##################################################\n",
            ">epoch=88, lrate=0.100, error=674.933\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 61.0 | Loss:1.177851742144664\n",
            "Iteration 50 | Accuracy: 59.92857142857143 | Loss:27.82795658661447\n",
            "Iteration 100 | Accuracy: 58.42857142857143 | Loss:54.487056167906985\n",
            "Iteration 150 | Accuracy: 59.857142857142854 | Loss:80.86354635347459\n",
            "Iteration 200 | Accuracy: 60.57142857142858 | Loss:100.9033957959345\n",
            "Iteration 250 | Accuracy: 59.357142857142854 | Loss:123.920766446746\n",
            "Iteration 300 | Accuracy: 59.285714285714285 | Loss:146.00685858347035\n",
            "Iteration 350 | Accuracy: 60.357142857142854 | Loss:170.6825038093048\n",
            "Iteration 400 | Accuracy: 60.14285714285714 | Loss:194.49392752655382\n",
            "Iteration 450 | Accuracy: 60.357142857142854 | Loss:220.2603185081537\n",
            "Iteration 500 | Accuracy: 61.285714285714285 | Loss:246.8414287006591\n",
            "Iteration 550 | Accuracy: 60.285714285714285 | Loss:274.55922175121157\n",
            "Iteration 600 | Accuracy: 59.42857142857143 | Loss:296.95635982267754\n",
            "Iteration 650 | Accuracy: 59.857142857142854 | Loss:318.76450491323885\n",
            "Iteration 700 | Accuracy: 60.0 | Loss:344.5543161955366\n",
            "Iteration 750 | Accuracy: 60.21428571428571 | Loss:369.4740673531608\n",
            "Iteration 800 | Accuracy: 62.857142857142854 | Loss:392.99226981280646\n",
            "Iteration 850 | Accuracy: 61.0 | Loss:419.596748190856\n",
            "Iteration 900 | Accuracy: 59.785714285714285 | Loss:437.5700262511859\n",
            "Iteration 950 | Accuracy: 57.99999999999999 | Loss:460.4894267892836\n",
            "Iteration 1000 | Accuracy: 58.285714285714285 | Loss:484.7562221744558\n",
            "Iteration 1050 | Accuracy: 58.92857142857143 | Loss:502.9408052015385\n",
            "Iteration 1100 | Accuracy: 58.857142857142854 | Loss:529.6117088713188\n",
            "Iteration 1150 | Accuracy: 60.785714285714285 | Loss:553.7770020614445\n",
            "Iteration 1200 | Accuracy: 61.642857142857146 | Loss:580.8361087485956\n",
            "Iteration 1250 | Accuracy: 59.92857142857143 | Loss:606.1381328619592\n",
            "Iteration 1300 | Accuracy: 60.71428571428571 | Loss:626.9078077680076\n",
            "Iteration 1350 | Accuracy: 60.0 | Loss:648.7077612833455\n",
            "##################################################\n",
            ">epoch=89, lrate=0.100, error=672.965\n",
            "##################################################\n",
            "Iteration 0 | Accuracy: 60.92857142857143 | Loss:1.1775376589735598\n",
            "Iteration 50 | Accuracy: 60.07142857142858 | Loss:27.76646117027676\n",
            "Iteration 100 | Accuracy: 58.5 | Loss:54.36081031048093\n",
            "Iteration 150 | Accuracy: 59.92857142857143 | Loss:80.66229543075214\n",
            "Iteration 200 | Accuracy: 60.857142857142854 | Loss:100.60788656758885\n",
            "Iteration 250 | Accuracy: 59.5 | Loss:123.54637496513439\n",
            "Iteration 300 | Accuracy: 59.357142857142854 | Loss:145.57083069470818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e00e2c4d0cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-7b03cfe96db7>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, train, lr, n_epochs, n_outputs, accuracy_score, loss_score)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# store accuracy and loss every 50 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0maccuracy_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mloss_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-84545ac55474>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(network, data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-3d8116f75108>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(network, row)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1cf82b1a902f>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0me_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0me_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqVN8NTyg4Ie"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjtmm_kWg4Ie"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h2-0.1-68810.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h2-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU98J4C3g4Ie"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h2-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xph2aMH-g4Ie"
      },
      "source": [
        "# plt.plot(loss_score)\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h2-0.1-68810.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBd4Qporg4If"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McIGkexjg4If"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG1eDuARg4If"
      },
      "source": [
        "### lr=0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5K-17NAg4If"
      },
      "source": [
        "net = initialize_network_double(6,8,8,10)\n",
        "accuracy_score = []\n",
        "loss_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhyExAjGg4Ig"
      },
      "source": [
        "train_network(net,train,lr = 0.05,n_epochs=500,n_outputs=10,accuracy_score,loss_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahlks3itg4Ig"
      },
      "source": [
        "for layer in net:\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjhJO_hPg4Ig"
      },
      "source": [
        "dir = '/content/drive/MyDrive/##### ONLINE Classes SEM 3-2/Machine Learning/MLAssignment2/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy_score)\n",
        "plt.savefig(pathdir+'acc-iter-h2-0.05.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score)\n",
        "plt.savefig(pathdir+'loss-iter-h2-0.05.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlBWHK8Ag4Ig"
      },
      "source": [
        "# plt.plot(accuracy_score)\n",
        "plt.plot(accuracy_score[::28])\n",
        "plt.savefig(pathdir+'acc-epoch-h2-0.05.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_score[::28])\n",
        "plt.savefig(pathdir+'loss-epoch-h2-0.3.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Brj6mu3g4Ig"
      },
      "source": [
        "train_acc = calculate_accuracy(net,train)\n",
        "print(f'Training Accuracy: {train_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSe6yjDRg4Ih"
      },
      "source": [
        "test_acc = calculate_accuracy(net,test)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}