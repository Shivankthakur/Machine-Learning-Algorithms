# -*- coding: utf-8 -*-
"""LinearPerceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gMGv7XhS6R6XpikuGg3lW1IQQZ4pmXQI
"""

# Commented out IPython magic to ensure Python compatibility.
import sklearn.datasets
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

#reading the dataset

df1 = np.genfromtxt('dataset_LP_1.txt',delimiter=',')
df1[df1==0] = -1
df2 = np.genfromtxt('dataset_LP_2.csv',delimiter=',')
df2[df2==0] = -1

def train_test_split(dataset, frac):
  np.random.shuffle(dataset)
  indices = np.random.permutation(dataset.shape[0])
  training_idx, test_idx = indices[:int(frac*dataset.shape[0])], indices[int(frac*dataset.shape[0]):]

  X_train, y_train, X_test, y_test = dataset[training_idx,:-1], dataset[training_idx, -1:], dataset[test_idx,:-1], dataset[test_idx, -1:]
  X_train = X_train.T
  X_test = X_test.T
  return X_train, y_train, X_test, y_test

X_train1, y_train1, X_test1, y_test1 = train_test_split(df1, 0.7)
X_train2, y_train2, X_test2, y_test2 = train_test_split(df2, 0.7)
print(X_train1.shape)
print(y_train1.shape)
print(X_test1.shape)
print(y_test1.shape)

def loss_function(X,y,w):
  if (np.dot(w.T, X))*y < 0:
    return 1
  else:
    return 0

def train_perceptron(X,y,w,n = 1000000,lr = 1):
  size = X.shape[1]
  count=0
  epochs=int(n/size)
  for epoch in range(epochs):
    if(epoch>0):
      if count==0:
        print(f"No Misclassified samples at this point, Iteration: {it}")
        break
      else:
        print(f"After {epoch} epochs, number of Misclassified samples are: {count}")
        count=0
    for it in range(size):
      cur_X = np.reshape(X[:,it],newshape=(X.shape[0],1))
      cur_Y = y[it]

      temp = np.dot(w.T, cur_X)
      if temp>=0:
        temp = 1.0
      else:
        temp = -1.0

      if temp!=cur_Y:
        w = np.add(w,lr*cur_Y*cur_X)
        count = count+1
    if count==0:
      break
  return w

def predict(dataset):
  misclass_count1 = 0
  misclass_count2 = 0

  if(dataset==1):
    for i in range(X_test1.shape[1]):
      X_testing = X_test1[:,i].T
      y_testing = y_test1[i]
      count = loss_function(X_testing,y_testing,w1)
      misclass_count1 += count
    print("Miscalculations in Test1 data : ",misclass_count1)
    acc1 = 100*(1 - (misclass_count1/X_test1.shape[1]))
    print("Accuracy of Test 1 model: ", acc1, "%")
  elif(dataset==2):
    for i in range(X_test2.shape[1]):
      X_testing = X_test2[:,i].T
      y_testing = y_test2[i]
      count = loss_function(X_testing,y_testing,w2)
      misclass_count2 = misclass_count2 + count
    print("Misclassifications in Test2 data : ",misclass_count2)
    acc2 = 100*(1 - (misclass_count2/X_test2.shape[1]))
    print("Accuracy of Test 2 model: ", acc2, "%")

w1 = np.random.rand(X_train1.shape[0],1)
w1 = train_perceptron(X_train1,y_train1,w1,10000000,0.1)

print(f"Final w is: {w1}")

predict(dataset=1)

w2 = np.random.rand(X_train2.shape[0],1)
w2 = train_perceptron(X_train2,y_train2,w2,10000000,0.1)

print(f"Final w is: {w2}")

predict(dataset=2)







